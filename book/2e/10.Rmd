---
suppress-bibliography: true
---

```{r console_start, include=FALSE}
console_start()
```

```{console setup_history, include=FALSE}
 export CHAPTER="10"
 export HISTFILE=/history/history_${CHAPTER}
 rm -f $HISTFILE
```


# 다국어 데이터 과학 {#chapter-10-polyglot-data-science}


다국어 사용자(polyglot)란 여러 언어를 말하는 사람을 뜻합니다.
제가 생각하는 다국어 데이터 과학자는 데이터를 수집, 정제, 탐색, 모델링하기 위해 여러 프로그래밍 언어, 도구 및 기술을 사용하는 사람입니다.

커맨드 라인은 이러한 다국어 접근 방식을 장려합니다.
커맨드 라인은 도구가 유닉스 철학을 따르기만 한다면 해당 도구가 어떤 프로그래밍 언어로 작성되었는지 상관하지 않습니다.
우리는 [4장](#chapter-4-creating-command-line-tools)에서 Bash, Python, R로 커맨드 라인 도구를 만들며 이를 명확히 확인했습니다.
게다가 우리는 CSV 파일에서 직접 SQL 쿼리를 실행했고 커맨드 라인에서 R 표현식을 실행하기도 했습니다.
요약하자면, 우리는 이미 충분히 인식하지 못한 채로 다국어 데이터 과학을 수행해 온 것입니다!

이 장에서는 이를 뒤집어서 한 걸음 더 나아가 보겠습니다.
다양한 프로그래밍 언어와 환경에서 커맨드 라인을 활용하는 방법을 보여드리겠습니다.
솔직히 말해서, 우리는 데이터 과학 커리어 전체를 커맨드 라인에서만 보내지는 않을 것이기 때문입니다.
저의 경우, 데이터를 분석할 때는 종종 RStudio IDE를 사용하고 무언가를 구현할 때는 파이썬을 자주 사용합니다.
저는 작업을 완수하는 데 도움이 되는 것이라면 무엇이든 사용합니다.

다른 애플리케이션으로 전환하지 않고도 커맨드 라인을 항상 손이 닿는 곳에 둘 수 있다는 사실은 큰 위안이 됩니다.
별도의 애플리케이션으로 옮겨가서 워크플로우를 끊지 않고도 빠르게 명령어를 실행할 수 있게 해줍니다.
`curl`로 파일을 다운로드하거나, `head`로 데이터를 검사하거나, `git`으로 백업을 만들거나, `make`로 웹사이트를 컴파일하는 등의 작업을 예로 들 수 있습니다.
일반적으로 평소라면 많은 코드가 필요하거나 커맨드 라 없이는 아예 불가능한 작업들입니다.


## 개요

이 장에서 여러분은 다음 방법을 배우게 됩니다.

* JupyterLab 및 RStudio IDE 내에서 터미널 실행하기
* Python 및 R에서 임의의 커맨드 라인 도구와 상호작용하기
* Apache Spark에서 쉘 명령어를 사용하여 데이터 변환하기

이 장은 다음 파일들로 시작합니다.

```{console}
cd /data/ch10
l
```

이 파일들을 가져오는 방법은 [2장](#chapter-2-getting-started)에 설명되어 있습니다.
그 외의 파일들은 커맨드 라인 도구를 사용하여 다운로드하거나 생성한 것들입니다.

## Jupyter

프로젝트 Jupyter는 2014년 IPython 프로젝트에서 탄생한 오픈소스 프로젝트로, 모든 프로그래밍 언어에 걸쳐 대화형 데이터 과학 및 과학적 컴퓨팅을 지원하도록 발전해 왔습니다.
Jupyter는 Python, R, Julia, Scala를 포함하여 40개 이상의 프로그래밍 언어를 지원합니다.
이 섹션에서는 파이썬에 집중하겠습니다.

이 프로젝트에는 JupyterLab, Jupyter Notebook, Jupyter Console이 포함됩니다.
파이썬을 대화형으로 다루는 가장 기본적인 방식인 Jupyter Console부터 시작하겠습니다.
다음은 커맨드 라인을 활용하는 몇 가지 방법을 보여주는 Jupyter Console 세션입니다.

```{console remove=list(1, "1R"), callouts=c("date", "open", "int", "import", "curl", "rm -v", "upper")}
cat /data/.cache/jupyter-console#!expect_prompt=FALSE
C-C#!literal=FALSE
```
<1> `date`나 파이썬 패키지 설치를 위한 `pip`와 같은 임의의 쉘 명령어 및 파이프라인을 실행할 수 있습니다.
<2> *alice.txt*의 줄 수를 세기 위한 이 파이썬 코드 줄과 그 아래의 `wc` 호출을 비교해 보십시오.
<3> 표준 출력은 문자열 리스트로 반환되므로, *total_lines* 값을 사용하려면 첫 번째 항목을 가져와서 정수형으로 캐스팅해야 합니다.
<4> 파일을 다운로드하기 위한 이 셀과 다음 셀을 그 아래의 `curl` 호출과 비교해 보십시오.
<5> 중괄호를 사용하여 파이썬 변수를 쉘 명령어의 일부로 사용할 수 있습니다.
<6> 중괄호 문자를 그대로 사용하고 싶다면 두 번 입력하십시오.
<7> 파이썬 변수를 표준 입력으로 사용하는 것도 가능하지만, 보시다시피 상당히 까다롭습니다.

Jupyter Notebook은 본질적으로 Jupyter Console의 브라우저 기반 버전입니다.
느낌표(`!`)와 bash 매직(magic)을 포함하여 커맨드 라인을 활용하는 동일한 방식들을 지원합니다.
가장 큰 차이점은 노트북에 코드뿐만 아니라 마크업 텍스트, 수식, 데이터 시각화도 포함할 수 있다는 것입니다.
이러한 이유로 데이터 과학자들 사이에서 매우 인기가 있습니다.
Jupyter Notebook은 별도의 프로젝트이자 환경이지만, 저는 더 완벽한 IDE 기능을 제공하는 JupyterLab을 사용하여 노트북을 작업하는 것을 선호합니다.

그림 \@ref(fig:jupyterlab)은 JupyterLab의 스크린샷으로, 파일 탐색기(왼쪽), 코드 에디터(가운데), 노트북(오른쪽), 그리고 터미널(아래)을 보여줍니다. 뒤의 세 가지는 모두 커맨드 라인을 활용하는 방법을 보여줍니다.
코드는 다음 섹션에서 다시 다루겠습니다.
이 특정 노트북은 방금 논의한 콘솔 세션과 매우 유사합니다.
터미널은 여러분이 커맨드 라인 도구를 실행할 수 있는 완전한 쉘을 제공합니다.
이 터미널과 코드, 노트북 사이에는 상호작용이 불가능하다는 점에 유의하십시오.
따라서 이 터미널은 별도의 터미널 애플리케이션을 열어두는 것과 크게 다르지 않지만, Docker 컨테이너 내부나 원격 서버에서 작업할 때는 여전히 유용합니다.

```{r jupyterlab, echo=FALSE, fig.cap="파일 탐색기, 코드 에디터, 노트북, 터미널이 포함된 JupyterLab", fig.align="center"}
knitr::include_graphics("images/screenshot_jupyterlab.png")
```


```{block2, type="rmdcaution"}
스크린샷의 이 노트북에는 이른바 `%%bash` 매직을 사용하는 셀도 포함되어 있는데, 이를 통해 여러 줄의 Bash 스크립트를 작성할 수 있습니다.
이 방식은 파이썬 변수를 사용하기가 훨씬 더 어렵기 때문에 권장하지 않습니다.
차라리 별도의 파일에 Bash 스크립트를 만들고 느낌표(`!`)를 사용하여 실행하는 것이 낫습니다.
```


## Python

`subprocess` 모듈을 사용하면 파이썬에서 커맨드 라인 도구를 실행하고 그들의 표준 입력 및 출력에 연결할 수 있습니다.
이 모듈은 오래된 `os.system()` 함수보다 권장되는 방식입니다.
기본적으로 쉘에서 실행되지는 않지만, `run()` 함수의 `shell` 인자를 통해 이를 변경할 수 있습니다.

```{console, callouts=c("run", "open", "split", "grep", "stdout")}
bat count.py
```
<1> 커맨드 라인을 활용하는 권장되는 방법은 `subprocess` 모듈의 `run()` 함수를 사용하는 것입니다.
<2> *filename* 파일을 엽니다.
<3> 전체 텍스트를 단어별로 나눕니다.
<4> `grep` 커맨드 라인 도구를 실행하며, 이때 *words*가 표준 입력으로 전달됩니다.
<5> 표준 출력은 하나의 긴 문자열로 제공됩니다. 여기서는 *pattern*의 발생 횟수를 세기 위해 각 줄바꿈 문자를 기준으로 문자열을 나눕니다.

이 커맨드 라인 도구는 다음과 같이 사용됩니다.

```{console}
./count.py alice.txt alice
```

15행의 `run` 호출의 첫 번째 인자가 문자열 리스트라는 점에 주목하십시오. 첫 번째 항목은 커맨드 라인 도구의 이름이고, 나머지 항목들은 인자들입니다.
이는 단일 문자열을 전달하는 것과는 다릅니다.
또한 이는 리다이렉션이나 파이핑과 같은 기능을 가능하게 하는 다른 쉘 구문을 사용할 수 없음을 의미합니다.


## R

R에는 커맨드 라인을 활용하는 여러 가지 방법이 있습니다.

아래 예제에서는 R 세션을 시작하고 `system2()` 함수를 사용하여 *이상한 나라의 앨리스(Alice’s Adventures in Wonderland)*라는 책에서 *alice*라는 문자열이 몇 번 나타나는지 세어보겠습니다.

```{r, include=FALSE}
# set_prompt(engine$session, prompts$R)
```

```{console, callouts=c("readLines", "strsplit", "system2", "length")}
R --quiet
lines <- readLines("alice.txt")
head(lines)
words <- unlist(strsplit(lines, " "))
head(words)
alice <- system2("grep", c("-i", "alice"), input = words, stdout = TRUE)
head(alice)
length(alice)
```
<1> *alice.txt* 파일을 읽어옵니다.
<2> 텍스트를 단어별로 나눕니다.
<3> `grep` 커맨드 라인 도구를 호출하여 문자열 *alice*와 일치하는 줄만 남깁니다. 문자 벡터 *words*가 표준 입력으로 전달됩니다.
<4> 문자 벡터 *alice*의 요소 수를 셉니다.

`system2()`의 단점은 문자 벡터를 커맨드 라인 도구의 표준 입력으로 전달하기 전에 먼저 파일에 기록한다는 점입니다.
이는 대량의 데이터와 잦은 호출을 처리할 때 문제가 될 수 있습니다.

데이터를 디스크에 쓰지 않고 직접 전달하는 명명된 파이프(named pipe)를 사용하는 것이 훨씬 더 효율적입니다.
이는 `pipe()`와 `fifo()` 함수를 통해 가능합니다.
이 방법을 제안해 준 Jim Hester에게 감사를 표합니다.
아래 코드는 이를 보여줍니다.

```{console callouts=c("fifo", "grep", "writeLines", "readLines", "close")}
out_con <- fifo("out", "w+")
in_con <- pipe("grep b > out")
writeLines(c("foo", "bar"), in_con)
readLines(out_con)
close(out_con); close(in_con); unlink("out")
```
<1> `fifo()` 함수는 *out*이라는 특별한 선입선출(FIFO) 파일을 생성합니다. 이는 (stdin이나 stdout처럼) 파이프 연결에 대한 참조일 뿐이며, 실제로 디스크에 데이터가 기록되지는 않습니다.
<2> `grep` 도구는 *b*를 포함하는 줄만 남기고 이를 명명된 파이프 *out*에 씁니다.
<3> 두 개의 값을 쉘 명령어의 표준 입력으로 씁니다.
<4> `grep`에 의해 생성된 표준 출력을 문자 벡터로 읽어옵니다.
<5> 연결을 관리하고 특별 파일을 삭제합니다.


<!-- check out the processx package https://processx.r-lib.org/. experimental at the time of writing. but seems very promising to working with connections in a more robust manner. -->


<!-- # all four options are executed in a shell.  -->
<!-- # no stdin and no stdout: system -->
<!-- # stdin but no stdout: writeLines(pipe) -->
<!-- # stdout but no stdin: readLines(pipe) -->
<!-- readLines(pipe("")) -->
<!-- # both stdin and stdout: fifo, readLines, writeLines -->
<!-- first-in first-out special file, named pipe -->
<!-- When processes are -->
<!-- exchanging data via the FIFO, the kernel passes all data -->
<!-- internally without writing it to the filesystem. -->


<!-- ## Leveraging the Command Line Elsewhere -->

<!-- ### Clipboard -->

<!-- yank -->
<!-- pbcopy pbpaste -->

<!-- when formatting emailadresses -->


이 방식은 꽤 많은 상용구 코드(연결 생성, 쓰기, 읽기, 정리 등)를 필요로 하므로, 저는 이를 돕기 위한 함수 `sh()`를 작성했습니다.
`magrittr` 패키지의 파이프 연산자(`%>%`)를 사용하여 여러 쉘 명령어를 사슬처럼 연결할 수 있습니다.


```{console}
library(magrittr)

sh <- function(.data, command) {#! expect_prompt=FALSE
  temp_file <- tempfile()#! expect_prompt=FALSE
  out_con <- fifo(temp_file, "w+")#! expect_prompt=FALSE
  in_con <- pipe(paste0(command, " > ", temp_file))#! expect_prompt=FALSE
  writeLines(as.character(.data), in_con)#! expect_prompt=FALSE
  result <- readLines(out_con)#! expect_prompt=FALSE
  close(out_con)#! expect_prompt=FALSE
  close(in_con)#! expect_prompt=FALSE
  unlink(temp_file)#! expect_prompt=FALSE
  result#! expect_prompt=FALSE
}

lines <- readLines("alice.txt")
words <- unlist(strsplit(lines, " "))

sh(words, "grep -i alice") %>%#! expect_prompt=FALSE
  sh("wc -l") %>%#! expect_prompt=FALSE
  sh("cowsay") %>%#! expect_prompt=FALSE
  cli::cat_boxx()

q("no")#! expect_prompt=FALSE
```

```{r, include=FALSE}
# set_prompt(engine$session, prompts$bash)
```


## RStudio

RStudio IDE는 아마도 R을 사용하는 가장 인기 있는 환경일 것입니다.
RStudio를 열면 가장 먼저 콘솔 탭이 보입니다.

```{r rstudio-console, echo=FALSE, fig.cap="콘솔 탭이 열려 있는 RStudio IDE", fig.align="center"}
knitr::include_graphics("images/screenshot_rstudio_console.png")
```

터미널 탭은 콘솔 탭 바로 옆에 있습니다.
터미널 탭은 완전한 쉘을 제공합니다.

```{r rstudio-terminal, echo=FALSE, fig.cap="터미널 탭이 열려 있는 RStudio IDE", fig.align="center"}
knitr::include_graphics("images/screenshot_rstudio_terminal.png")
```

JupyterLab과 마찬가지로, 이 터미널은 콘솔이나 R 스크립트와 직접 연결되어 있지 않다는 점에 유의하십시오.


## Apache Spark

Apache Spark는 클러스터 컴퓨팅 프레임워크입니다.
데이터를 메모리에 다 올리는 것이 불가능할 때 찾게 되는 강력한 도구입니다.
Spark 자체는 Scala로 작성되었지만, [PySpark](https://spark.apache.org/docs/latest/api/python/index.html)를 사용하는 Python이나 [SparkR](https://spark.apache.org/docs/latest/sparkr.html) 또는 [sparklyr](https://spark.rstudio.com/)을 사용하는 R을 통해서도 상호작용할 수 있습니다.

데이터 처리 및 머신러닝 파이프라인은 일련의 변환(transformations)과 하나의 최종 작업(action)을 통해 정의됩니다.
이러한 변환 중 하나가 `pipe()` 변환으로, 이를 통해 전체 데이터셋을 Bash나 Perl 스크립트와 같은 쉘 명령어로 실행할 수 있습니다.
데이터셋의 항목들이 표준 입력으로 기록되고, 표준 출력은 문자열 RDD로 반환됩니다.

아래 세션에서 Spark 쉘을 시작하고 다시 한번 *이상한 나라의 앨리스*에서 *alice*의 발생 횟수를 세어보겠습니다.

```{console, remove=list("alias", 2, 4, "cache"), callouts=c("textFile", "flatMap", "grep", "wc", "res3", "toInt", "res5")}
alias spark-shell=echo
spark-shell --master local[6]#!enter=FALSE
C-C#!literal=FALSE
cat /data/.cache/spark
```
<1> 각 줄이 하나의 요소가 되도록 *alice.txt*를 읽어옵니다.
<2> 각 요소를 공백을 기준으로 나눕니다. 즉, 각 줄이 단어들로 나누어집니다.
<3> 각 파티션을 `grep`으로 파이핑하여 문자열 *alice*와 일치하는 요소만 남깁니다.
<4> 각 파티션을 `wc`로 파이핑하여 요소의 수를 셉니다.
<5> 각 파티션에 대해 하나의 카운트 값이 생성됩니다.
<6> 모든 카운트를 합산하여 최종 카운트를 구합니다. 요소들을 문자열에서 정수형으로 먼저 변환해야 함에 유의하십시오.
<7> 위의 단계들을 하나의 명령어로 결합한 것입니다.

```{block2, type="rmdtip"}
`pipe()` 변환은 PySpark, SparkR, sparklyr에서도 사용할 수 있습니다.
```

<!-- https://stackoverflow.com/questions/54239583/question-about-rdd-pipe-operator-on-apache-spark -->

If you want to use a custom command-line tool in your pipeline, then you need to make sure that it's present on all nodes in the cluster (known as the executors).
One way to do this is to specify the filename(s) with the `--files` option when you're submitting Spark applications using `spark-submit`.

Matei Zaharia와 Bill Chambers(Apache Spark의 원저자)는 그들의 저서 *Spark: The Definitive Guide*에서 "`pipe` 메소드는 아마도 Spark의 가장 흥미로운 메소드 중 하나일 것"이라고 언급했습니다.
정말 대단한 찬사입니다!
Apache Spark의 개발자들이 50년 된 기술을 활용할 수 있는 기능을 추가했다는 것은 정말 멋진 일이라고 생각합니다.


<!-- ### Notable mentions -->

<!-- - Julia: Blog post with an introduction: https://blog.leahhanson.us/post/julia/julia-commands.html -->
<!-- - Visual Studio Code https://code.visualstudio.com/docs/editor/integrated-terminal -->
<!-- - Emacs -->
<!-- - VIM (using ! command) -->
<!-- - OS: Guake, -->
<!-- - OS: iTerm2:    https://www.sharmaprakash.com.np/guake-like-dropdown-terminal-in-mac/ -->
<!-- https://github.com/shelljs/shelljs -->
<!-- https://amoffat.github.io/sh/ -->
<!-- https://plumbum.readthedocs.io/en/latest/ -->
<!-- <\!-- ## Other Combinations -\-> -->

<!-- - reticulate -->
<!-- - Rpy2 -->
<!-- - sparkr -->
<!-- - sparklyr -->


<!-- TODO: MUST: Write Summary or Conclusion -->
<!-- # Summary -->
<!-- TODO: MUST: Talk about other combinations between languages. This is already possible with this approah, but there are tighter integrations. -->

## 요약

이 장에서 여러분은 프로그래밍 언어와 다른 환경을 포함하여 다양한 상황에서 커맨드 라인을 활용하는 몇 가지 방법을 배웠습니다.
커맨드 라인이 진공 상태에서 존재하는 것이 아니라는 점을 깨닫는 것이 중요합니다.
가장 중요한 것은 작업을 안정적으로 완수할 수 있는 도구들을 사용하는 것이며, 때로는 이들을 조합해서 사용하는 것입니다.

이제 네 개의 OSEMN 장과 네 개의 중간 막(intermezzo) 장을 모두 마쳤으니, 이제 마지막 장에서 전체 내용을 마무리하고 결론을 맺을 시간입니다.


## 더 읽어보기

- 커맨드 라인을 사용하지 않고 두 프로그래밍 언어를 직접 통합하는 방법도 있습니다. 예를 들어, R의 [`reticulate` 패키지](https://rstudio.github.io/reticulate/)를 사용하면 파이썬과 직접 인터페이스할 수 있습니다.
