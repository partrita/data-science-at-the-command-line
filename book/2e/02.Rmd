---
suppress-bibliography: true
---

```{r console_start, include=FALSE}
console_start()
```

```{console setup_history, include=FALSE}
 export CHAPTER="02"
 export HISTFILE=/history/history_${CHAPTER}
 rm -f $HISTFILE
```


# 시작하기 {#chapter-2-getting-started}

이 장에서는 커맨드 라인에서 데이터 과학을 수행하기 위한 모든 전제 조건이 갖춰졌는지 확인할 것입니다.
전제 조건은 세 부분으로 나뉩니다. (1) 이 책에서 사용하는 것과 동일한 데이터셋 확보, (2) 이 책 전체에서 사용하는 모든 커맨드 라인 도구가 포함된 적절한 환경 구축, (3) 커맨드 라인을 사용할 때 작용하는 필수적인 개념들에 대한 이해입니다.

먼저 데이터셋을 다운로드하는 방법을 설명합니다.
둘째로, 필요한 모든 커맨드 라인 도구를 포함하고 있는 우분투 리눅스 기반 가상 환경인 Docker 이미지를 설치하는 방법을 설명합니다.
그다음에는 예제를 통해 필수적인 유닉스 개념들을 살펴볼 것입니다.

이 장을 마칠 때쯤이면 여러분은 데이터 과학의 첫 번째 단계인 데이터 획득을 계속하는 데 필요한 모든 것을 갖추게 될 것입니다.


## 데이터 확보하기

이 책에서 사용하는 데이터셋은 다음과 같이 다운로드할 수 있습니다.

1. https://www.datascienceatthecommandline.com/2e/data.zip 에서 ZIP 파일을 다운로드합니다.
2. 새 디렉터리를 만듭니다. 이름은 원하는 대로 지어도 되지만, 커맨드 라인에서 작업하기 편하도록 소문자, 숫자, 하이픈(-) 또는 언더스코어(_)만 사용하는 것을 권장합니다. 예를 들어 *dsatcl2e-data*와 같이 지을 수 있습니다. 이 디렉터리의 위치를 기억해 두세요.
3. ZIP 파일을 해당 디렉터리로 옮기고 압축을 풉니다.
4. 이제 이 디렉터리에는 각 장별로 하나의 하위 디렉터리가 들어 있게 됩니다.

다음 절에서는 이 데이터를 다루기 위한 모든 커맨드 라인 도구가 포함된 환경을 설치하는 방법을 설명합니다.


## Docker 이미지 설치하기 {#docker-image}

이 책에서는 매우 다양한 커맨드 라인 도구를 사용합니다.
유닉스에는 이미 많은 도구가 기본으로 설치되어 있고, 관련 도구들을 포함하는 많은 패키지들도 제공됩니다.
이러한 패키지들을 직접 설치하는 것이 그리 어렵지는 않습니다.
하지만 패키지로 제공되지 않아 수동으로 복잡하게 설치해야 하는 도구들도 사용하게 될 것입니다.
일일이 설치 과정을 거치지 않고 필요한 도구들을 한꺼번에 갖추기 위해, 여러분이 윈도우, macOS, 리눅스 중 어떤 운영체제를 사용하든 이 책을 위해 특별히 제작된 Docker 이미지를 설치하시길 강력히 권장합니다.

Docker 이미지는 하나 이상의 애플리케이션과 그에 필요한 모든 의존성을 하나로 묶은 것입니다.
Docker 컨테이너는 이미지를 실행하는 격리된 환경입니다.
이후에 수행할 것처럼 `docker` 커맨드 라인 도구를 사용하거나 Docker GUI를 통해 이미지와 컨테이너를 관리할 수 있습니다.
어떤 면에서 Docker 컨테이너는 가상 머신과 비슷하지만, 자원을 훨씬 적게 사용합니다.
이 장의 끝에서 Docker에 대해 더 배울 수 있는 자료들을 제안하겠습니다.

```{block2, type="rmdtip"}
Docker 컨테이너 내부가 아닌 로컬 환경에서 직접 커맨드 라인 도구들을 실행하고 싶다면, 물론 도구들을 개별적으로 직접 설치하셔도 됩니다.
다만 이 과정은 매우 많은 시간이 소요된다는 점을 유의해 주세요.
부록에 이 책에서 사용된 모든 커맨드 라인 도구의 목록이 있습니다.
설치 안내는 우분투 기준으로만 되어 있습니다.
책에서 사용된 스크립트와 데이터셋은 이 책의 [GitHub 저장소](https://github.com/datasciencetoolbox/datasciencetoolbox)를 클론하여 얻을 수 있습니다.
```

Docker 이미지를 설치하려면 먼저 [Docker 웹사이트](https://www.docker.com/products/docker)에서 Docker를 다운로드하여 설치해야 합니다.
Docker가 설치되면 터미널(또는 명령 프롬프트)에서 다음 명령어를 입력하여 Docker 이미지를 다운로드합니다(달러 표시는 입력하지 마세요).

```{console docker_pull}
docker pull datasciencetoolbox/dsatcl2e#! enter=FALSE
```

```{console docker_pull_cancel, include=FALSE}
C-C #! literal=FALSE
```

Docker 이미지는 다음과 같이 실행할 수 있습니다.

```{console, docker_run}
docker run --rm -it datasciencetoolbox/dsatcl2e#! enter=FALSE
```

```{console, docker_run_cancel, include=FALSE}
C-C #! literal=FALSE
```

이제 필요한 모든 커맨드 라인 도구가 설치된 격리된 환경(*Docker 컨테이너*라고 불립니다) 내부에 들어와 있습니다.
다음 명령어를 입력했을 때 열정적인 소 한 마리가 나타난다면 모든 것이 제대로 작동하는 것입니다.

```{console cowsay_lets_moove}
cowsay "Let's moove\!"
```

컨테이너 안팎으로 데이터를 주고받으려면 볼륨(volume)을 추가하여 로컬 디렉터리를 컨테이너 내부의 디렉터리에 매핑할 수 있습니다.
먼저 새로운 디렉터리를 만들고 해당 디렉터리로 이동한 뒤, macOS나 리눅스라면 다음 명령어를 실행하는 것을 추천합니다.

```{console docker_run_v}
docker run --rm -it -v "$(pwd)":/data datasciencetoolbox/dsatcl2e#! enter=FALSE
```

```{console, docker_run_v_cancel, include=FALSE}
C-C #! literal=FALSE
```

윈도우에서 명령 프롬프트(`cmd`)를 사용 중이라면 다음과 같이 입력합니다.

```{console eval=FALSE}
C:\> docker run --rm -it -v "%cd%":/data datasciencetoolbox/dsatcl2e
```

윈도우 PowerShell을 사용 중이라면 다음과 같이 입력합니다.

```{console eval=FALSE}
PS C:\> docker run --rm -it -v ${PWD}:/data datasciencetoolbox/dsatcl2e
```

위의 명령어에서 `-v` 옵션은 `docker`에게 현재 디렉터리를 컨테이너 내부의 */data* 디렉터리로 매핑하도록 지시합니다. 따라서 이곳이 Docker 컨테이너 안팎으로 데이터를 주고받는 통로가 됩니다.


```{block2, type="rmdnote"}
Docker 이미지에 대해 더 자세히 알고 싶다면 [Docker Hub 페이지](https://hub.docker.com/r/datasciencetoolbox/dsatcl2e)를 방문해 보세요.
```

작업을 마쳤다면 `exit`를 입력하여 Docker 컨테이너를 종료할 수 있습니다.


## 필수 유닉스 개념 {#essential-concepts}

[1장](#chapter-1-introduction)에서 커맨드 라인이 무엇인지 잠시 보여드렸습니다.
이제 여러분은 Docker 이미지를 실행하고 있으니, 본격적으로 시작할 수 있습니다.
이 절에서는 커맨드 라인에서 데이터 과학을 편안하게 수행하기 위해 꼭 알아야 할 몇 가지 개념과 도구들을 다룹니다.
지금까지 주로 그래픽 사용자 인터페이스(GUI)로 작업해 오셨다면 상당한 변화로 느껴질 수 있습니다.
하지만 걱정하지 마세요. 기초부터 시작해서 점진적으로 더 고급 주제로 나아갈 것입니다.

```{block2, type="rmdnote"}
이 절은 유닉스에 대한 완전한 교육 과정이 아닙니다.
데이터 과학을 수행하는 데 꼭 필요한 개념과 도구들만 설명하겠습니다.
Docker 이미지의 장점 중 하나는 이미 많은 것들이 설정되어 있다는 점입니다.
더 자세히 알고 싶다면 이 장의 끝에 있는 '더 읽을거리' 절을 참고해 주세요.
```


### 환경 (The Environment)

여러분은 이제 막 새로운 환경에 로그인했습니다.
무언가를 시작하기 전에, 이 환경에 대해 전반적으로 이해하는 것이 좋습니다.
환경은 대략 네 개의 계층으로 정의되며, 위에서 아래 방향으로 간단히 살펴보겠습니다.

커맨드 라인 도구 (Command-line tools)

:   가장 먼저 여러분이 직접 다루게 될 커맨드 라인 도구들이 있습니다.
이 도구들은 해당 명령어를 입력하여 사용합니다.
커맨드 라인 도구에는 여러 유형이 있으며, 이에 대해서는 다음 절에서 자세히 다루겠습니다.
도구의 예로는 `ls` [@ls], `cat` [@cat], `jq` [@jq] 등이 있습니다.

터미널 (Terminal)

:   두 번째 계층인 터미널은 명령어를 입력하는 애플리케이션입니다. 책에서 다음과 같은 텍스트를 보게 된다면:

    ```{console}
    seq 3
    ```

    터미널에 `seq 3`이라고 입력하고 **`Enter`**를 누르면 됩니다.
(커맨드 라인 도구 `seq` [@seq]는 보시다시피 일련의 숫자들을 생성합니다.) 달러 표시는 입력하지 않습니다.
그것은 단지 터미널에 입력할 수 있는 명령어임을 알려주는 표시일 뿐입니다.
이 달러 표시를 프롬프트(prompt)라고 부릅니다.
`seq 3` 아래에 있는 텍스트는 해당 명령어의 출력 결과입니다.

쉘 (Shell)

:   세 번째 계층은 쉘입니다. 명령어를 입력하고 **`Enter`**를 누르면 터미널은 그 명령어를 쉘로 보냅니다. *쉘*은 명령어를 해석하는 프로그램입니다. 저는 Z 쉘(Zsh)을 사용하지만, Bash나 Fish와 같은 다른 쉘들도 많이 있습니다.

운영체제 (Operating system)

:   네 번째 계층은 운영체제이며, 우리의 경우에는 GNU/리눅스입니다. 리눅스는 커널(kernel)의 이름으로, 운영체제의 심장과 같습니다. 커널은 CPU, 디스크 등 하드웨어와 직접 소통합니다. 또한 커널은 우리의 커맨드 라인 도구들을 실행합니다. GNU(GNU’s not UNIX의 약자)는 기본적인 도구들의 모음을 의미합니다. 우리가 사용하는 Docker 이미지는 우분투라는 특정 GNU/리눅스 배포판을 기반으로 합니다.


### 커맨드 라인 도구 실행하기

이제 환경에 대한 기본적인 이해가 생겼으니, 직접 명령어를 실행해 볼 차례입니다.
터미널에 다음을 입력하고(달러 표시 제외) **`Enter`**를 누르세요.

```{console}
pwd
```

여러분은 방금 하나의 커맨드 라인 도구를 포함하는 명령어를 실행했습니다.
`pwd` [@pwd] 도구는 현재 여러분이 위치한 디렉터리의 이름을 출력합니다.
로그인했을 때의 기본 위치는 홈 디렉터리입니다.

Z 쉘 내장 명령어인 `cd` 도구를 사용하면 다른 디렉터리로 이동할 수 있습니다.

```{console, callouts=c(1, 3, 6, 8, 11)}
cd /data/ch02
pwd
cd ..
pwd
cd ch02
```
<1> */data/ch02* 디렉터리로 이동합니다.
<2> 현재 디렉터리를 출력합니다.
<3> 상위 디렉터리로 이동합니다.
<4> 다시 현재 디렉터리를 출력합니다.
<5> 하위 디렉터리 *ch02*로 이동합니다.

`cd` 뒤에 오는 부분은 이동하고자 하는 디렉터리를 지정합니다.
명령어 뒤에 오는 값들을 *커맨드 라인 인자(arguments)* 또는 *옵션(options)*이라고 부릅니다.
마침표 두 개(`..`)는 상위 디렉터리를 의미합니다.
참고로 마침표 하나(`.`)는 현재 디렉터리를 의미합니다.
`cd .`은 아무런 효과가 없겠지만, 마침표 하나가 다른 곳에서 쓰이는 것을 보게 될 것입니다.
다른 명령어를 시도해 봅시다.

```{console}
head -n 3 movies.txt
```

여기서는 `head` [@head]에 세 개의 커맨드 라인 인자를 전달했습니다.
첫 번째는 옵션입니다. 여기서는 짧은 옵션인 `-n`을 사용했습니다.
가끔 짧은 옵션은 긴 형태의 변형을 가지기도 하는데, 이 경우 `--lines`가 됩니다.
두 번째는 해당 옵션에 속하는 값입니다.
세 번째는 파일 이름입니다.
이 명령어는 */data/ch02/movies.txt* 파일의 처음 세 줄을 출력합니다.


### 다섯 가지 유형의 커맨드 라인 도구

```{console, include=FALSE}
 alias bat='bat --tabs 8 --paging never --terminal-width 70'
```

저는 '커맨드 라인 도구'라는 용어를 많이 사용하지만, 지금까지 실제로 그것이 무엇을 의미하는지는 설명하지 않았습니다.
저는 이 용어를 커맨드 라인에서 실행할 수 있는 *모든 것*을 가리키는 포괄적인 용어로 사용합니다(\@ref(fig:umbrella) 참고).
내부적으로 각 커맨드 라인 도구는 다음 다섯 가지 유형 중 하나에 속합니다.

- 바이너리 실행 파일 (Binary executable)
- 쉘 내장 명령어 (Shell builtin)
- 해석되는 스크립트 (Interpreted script)
- 쉘 함수 (Shell function)
- 별칭 (Alias)

```{r umbrella, echo=FALSE, fig.cap="저는 '커맨드 라인 도구'를 포괄적인 용어로 사용합니다", fig.align="center"}
knitr::include_graphics("images/dscl_0201.png")
```

각 유형 간의 차이를 아는 것이 좋습니다.
Docker 이미지에 미리 설치된 커맨드 라인 도구들은 대부분 처음 두 가지 유형(바이너리 실행 파일과 쉘 내장 명령어)으로 구성됩니다.
나머지 세 유형(해석되는 스크립트, 쉘 함수, 별칭)은 우리의 데이터 과학 도구 상자를 더욱 확장하고, 우리가 더 효율적이고 생산적인 데이터 과학자가 될 수 있게 해줍니다.

바이너리 실행 파일 (Binary Executable)

:   바이너리 실행 파일은 고전적인 의미의 프로그램입니다. 바이너리 실행 파일은 소스 코드를 기계어로 컴파일하여 만들어집니다. 즉, 텍스트 에디터로 파일을 열어도 내용을 읽을 수 없습니다.

쉘 내장 명령어 (Shell Builtin)

:   쉘 내장 명령어는 쉘(우리 환경에서는 Z 쉘 또는 `zsh`)이 제공하는 커맨드 라인 도구입니다. `cd`와 `pwd`가 그 예입니다. 내장 명령어는 쉘마다 다를 수 있습니다. 바이너리 실행 파일과 마찬가지로 내용을 쉽게 검사하거나 변경할 수 없습니다.

해석되는 스크립트 (Interpreted Script)

:   해석되는 스크립트는 바이너리 실행 파일에 의해 실행되는 텍스트 파일입니다. 파이썬, R, Bash 스크립트 등이 예입니다. 해석되는 스크립트의 큰 장점은 직접 읽고 수정할 수 있다는 것입니다. 아래의 스크립트가 파이썬에 의해 해석되는 이유는 확장자가 *.py*이기 때문이 아니라, 스크립트의 첫 번째 줄이 이를 실행해야 할 바이너리를 정의하고 있기 때문입니다.

    ```{console bat_fac}
    bat fac.py
    ```

    이 스크립트는 매개변수로 전달한 정수의 팩토리얼을 계산합니다. 커맨드 라인에서 다음과 같이 호출할 수 있습니다.

    ```{console run_fac}
    ./fac.py 5
    ```

    [4장](#chapter-4-creating-command-line-tools)에서는 해석되는 스크립트를 사용하여 재사용 가능한 커맨드 라인 도구를 만드는 방법을 아주 자세히 다룰 것입니다.

쉘 함수 (Shell Function)

:   쉘 함수는 우리 환경의 경우 `zsh`에 의해 실행되는 함수입니다. 스크립트와 유사한 기능을 제공하지만, 대개 스크립트보다는 크기가 작습니다(꼭 그래야 하는 것은 아니지만요). 또한 더 개인적인 용도로 쓰이는 경향이 있습니다. 다음 명령어는 `fac`이라는 함수를 정의하는데, 앞서 본 파이썬 스크립트와 마찬가지로 전달된 정수의 팩토리얼을 계산합니다. 이 함수는 `seq`로 숫자 목록을 생성하고, `paste` [@paste]를 사용해 숫자들 사이에 `*`를 넣어 한 줄로 만든 뒤, 이를 계산하여 결과를 출력하는 `bc` [@bc]로 전달함으로써 작동합니다.

    ```{console fac_zsh}
    fac() { (echo 1; seq $1) | paste -s -d\* - | bc; }
    fac 5
    ```

    Z 쉘의 설정 파일인 *~/.zshrc*는 쉘 함수를 정의하기에 좋은 곳입니다. 그렇게 하면 함수를 항상 사용할 수 있습니다.

별칭 (Alias)

:   별칭은 매크로와 같습니다. 어떤 명령어를 항상 같은 매개변수와 함께(혹은 명령어의 일부를) 실행하게 된다면, 시간을 아끼기 위해 별칭을 정의할 수 있습니다. 별칭은 특정 명령어를 계속 오타 낼 때도 매우 유용합니다(Chris Wiggins가 관리하는 [유용한 별칭 목록](https://github.com/chrishwiggins/mise/blob/master/sh/aliases-public.sh)을 참고하세요). 다음 명령어는 그러한 별칭을 정의합니다.

    ```{console define_alias}
    alias l='ls --color -lhF --group-directories-first'
    alias les=less
    ```

    이제 커맨드 라인에 다음과 같이 입력하면, 쉘은 발견한 각 별칭을 해당 값으로 대체합니다.

    ```{console run_alias}
    cd /data
    l
    cd ch02
    ```

    별칭은 매개변수를 허용하지 않으므로 쉘 함수보다 단순합니다. 앞서 정의한 `fac` 함수는 매개변수 때문에 별칭으로 정의할 수 없었습니다. 그럼에도 별칭은 수많은 키 입력을 줄여줍니다. 쉘 함수와 마찬가지로 별칭도 대개 홈 디렉터리에 있는 *.zshrc* 파일에 정의합니다. 현재 정의된 모든 별칭을 보려면 인자 없이 `alias`를 실행해 보세요. 무엇이 보이나요?

이 책에서는 마지막 세 가지 유형인 해석되는 스크립트, 쉘 함수, 별칭에 주로 집중할 것입니다.
이들은 쉽게 변경할 수 있기 때문입니다.
커맨드 라인 도구의 목적은 여러분의 삶을 편하게 만들고, 여러분을 더 생산적이고 효율적인 데이터 과학자로 만드는 것입니다.
명령어 `type`(그 자체로 쉘 내장 명령어입니다)을 사용하여 커맨드 라인 도구의 유형을 확인할 수 있습니다.

```{console type}
type -a pwd
type -a cd
type -a fac
type -a l
```

```{console, include=FALSE}
 alias bat='bat --tabs 8 --paging never --terminal-width 80'
```

`type`은 `pwd`에 대해 세 개의 커맨드 라인 도구를 반환합니다.
이 경우, 여러분이 `pwd`를 입력하면 목록에서 가장 먼저 보고된 도구가 사용됩니다.
다음 절에서는 커맨드 라인 도구들을 조합하는 방법을 살펴보겠습니다.


### 커맨드 라인 도구 조합하기 {#combining-command-line-tools}

대부분의 커맨드 라인 도구는 유닉스 철학[@raymond2003art]을 따르기 때문에, 한 가지 작업만 아주 잘하도록 설계되어 있습니다.
예를 들어, `grep` [@grep] 도구는 행을 필터링할 수 있고, `wc` [@wc]는 행의 개수를 셀 수 있으며, `sort` [@sort]는 행을 정렬할 수 있습니다.
커맨드 라인의 진정한 힘은 작지만 강력한 이러한 도구들을 조합하는 능력에서 나옵니다.

이러한 힘은 도구들 사이의 통신 스트림(communication streams)을 관리함으로써 가능해집니다.
각 도구는 세 가지 표준 통신 스트림을 가집니다: 표준 입력(standard input), 표준 출력(standard output), 표준 오류(standard error).
이들은 종종 *`stdin`*, *`stdout`*, *`stderr`*로 줄여서 부릅니다.

표준 출력과 표준 오류는 모두 기본적으로 터미널로 연결되어 있어, 일반적인 결과와 오류 메시지가 모두 화면에 출력됩니다.
\@ref(fig:diagram-essential-streams)는 `pwd`와 `rev`[@rev]를 예로 들어 이를 설명합니다.
`rev`를 실행하면 아무 일도 일어나지 않는 것을 볼 수 있습니다.
그 이유는 `rev`가 입력을 기다리고 있기 때문이며, 기본적으로는 키보드로 입력하는 값들이 입력값이 됩니다.
문장을 하나 입력하고 **`Enter`**를 눌러 보세요.
`rev`는 즉시 여러분의 입력을 거꾸로 뒤집어 응답할 것입니다.
입력 전송을 중단하려면 **`Ctrl-D`**를 누르면 되며, 그러면 `rev`가 멈춥니다.

```{r diagram-essential-streams, echo=FALSE, fig.cap="모든 도구는 표준 입력(*`stdin`*), 표준 출력(*`stdout`*), 표준 오류(*`stderr`*)라는 세 가지 표준 스트림을 가집니다", fig.align="center"}
knitr::include_graphics("images/dscl_0202.png")
```

실제로 여러분은 키보드를 입력 소스로 쓰기보다는, 다른 도구가 생성한 출력물이나 파일의 내용을 입력으로 사용하게 될 것입니다.
예를 들어 `curl`을 사용하여 루이스 캐럴의 *이상한 나라의 앨리스*를 다운로드하고, 그 결과를 다음 도구로 *파이프(pipe)*할 수 있습니다.
(`curl`에 대해서는 [3장](#chapter-3-obtaining-data)에서 더 자세히 다룰 것입니다.)
도구 연결은 파이프 연산자(`|`)를 사용하여 수행합니다.

```{r diagram-essential-pipe, echo=FALSE, fig.cap="한 도구의 출력을 다른 도구로 파이프할 수 있습니다", fig.align="center"}
knitr::include_graphics("images/dscl_0203.png")
```

우리는 `curl`의 출력을 `grep`으로 *파이프*하여 특정 패턴으로 행을 필터링할 수 있습니다.
목차에 나열된 장(chapter) 목록을 보고 싶다고 가정해 봅시다.
다음과 같이 `curl`과 `grep`을 조합할 수 있습니다.

```{console}
curl -s "https://www.gutenberg.org/files/11/11-0.txt" | grep " CHAPTER"
```

그리고 이 책에 *몇 개의* 장이 있는지 알고 싶다면, 개수를 세는 데 탁월한 `wc`를 사용할 수 있습니다.

```{console seq_grep_wc, callouts="wc"}
curl -s "https://www.gutenberg.org/files/11/11-0.txt" |
grep " CHAPTER" |
wc -l
```
<1> `-l` 옵션은 `wc`가 입력받은 행의 수만 출력하도록 지정합니다. 기본적으로는 글자 수와 단어 수도 함께 반환합니다.

파이프 연결은 자동화된 복사 및 붙여넣기라고 생각해도 좋습니다.
파이프 연산자를 사용해 도구들을 조합하는 요령을 터득하고 나면, 그 활용 가능성이 무궁무진하다는 것을 깨닫게 될 것입니다.


### 입력과 출력 리다이렉션 (Redirecting Input and Output)

한 도구의 출력을 다른 도구로 파이프하는 것 외에도, 파일로 저장할 수 있습니다.
전체 경로를 지정하지 않으면 파일은 현재 디렉터리에 저장됩니다.
이것을 *출력 리다이렉션(output redirection)*이라고 하며, 다음과 같이 작동합니다.

```{console seq_redirect}
curl "https://www.gutenberg.org/files/11/11-0.txt" | grep " CHAPTER" > chapters.txt
cat chapters.txt
```

여기서는 `grep`의 출력을 */data/ch02* 디렉터리에 *chapters.txt*라는 이름의 파일로 저장합니다.
파일이 아직 없으면 새로 생성됩니다. 이미 파일이 존재한다면 그 내용은 덮어쓰여집니다.
\@ref(fig:diagram-essential-redirect-stdout)는 출력 리다이렉션의 개념을 보여줍니다.
표준 오류는 여전히 터미널로 연결되어 있음에 유의하세요.

```{r diagram-essential-redirect-stdout, echo=FALSE, fig.cap="도구의 출력을 파일로 리다이렉션할 수 있습니다", fig.align="center"}
knitr::include_graphics("images/dscl_0204.png")
```

출력을 기존 파일 내용 뒤에 덧붙이려면 `>>`를 사용합니다.

```{console echo_append}
echo -n "Hello" > greeting.txt
echo " World" >> greeting.txt
```

`echo` 도구는 지정한 값을 출력합니다.
`-n` 옵션은 출력 끝에 줄바꿈 문자를 붙이지 않도록 지정합니다.

출력을 파일에 저장하는 것은 중간 분석 결과를 보관했다가 나중에 분석을 이어가고자 할 때 유용합니다.
*greeting.txt* 파일의 내용을 다시 사용하려면, 파일을 읽어서 출력하는 `cat`을 사용하면 됩니다.

```{console, callouts="wc"}
cat greeting.txt
cat greeting.txt | wc -w
```
<1> `-w` 옵션은 `wc`가 단어 수만 세도록 합니다.

같은 결과를 작다 기호(`<`)를 사용해서도 얻을 수 있습니다.

```{console}
< greeting.txt wc -w
```

이 방식은 별도의 프로세스를 실행하지 않고 파일을 `wc`의 표준 입력으로 직접 전달합니다 [^cat].
\@ref(fig:diagram-essential-stdin-cat)는 이 두 가지 방식의 차이를 보여줍니다.
최종 결과는 동일합니다.

```{r diagram-essential-stdin-cat, echo=FALSE, fig.cap="파일의 내용을 입력으로 사용하는 두 가지 방법", fig.align="center"}
knitr::include_graphics("images/dscl_0205.png")
```

많은 커맨드 라인 도구들과 마찬가지로, `wc`는 하나 이상의 파일 이름을 인자로 받을 수 있습니다.
예를 들어 다음과 같습니다.

```{console}
wc -w greeting.txt movies.txt
```

이 경우 `wc`는 각 파일의 이름도 함께 출력합니다.


어떤 도구의 출력이든 */dev/null*이라는 특수 파일로 리다이렉션하여 출력을 억제할 수 있습니다.
저는 주로 오류 메시지를 보지 않기 위해 이 방법을 사용합니다(\@ref(fig:diagram-essential-redirect-devnull) 참고).
다음 명령어는 `cat`이 *404.txt* 파일을 찾을 수 없어 오류 메시지를 생성하게 합니다.

```{console}
cat movies.txt 404.txt
```

다음과 같이 표준 오류를 */dev/null*로 리다이렉션할 수 있습니다.

```{console callouts=1}
cat movies.txt 404.txt 2> /dev/null
```
<1> *`2`*는 표준 오류를 의미합니다.

```{r diagram-essential-redirect-devnull, echo=FALSE, fig.cap="*`stderr`*를 */dev/null*로 리다이렉션하기", fig.align="center", out.width="50%"}
knitr::include_graphics("images/dscl_0206.png")
```

같은 파일에서 읽고 동시에 같은 파일에 쓰는 것을 주의하세요.
그렇게 하면 빈 파일만 남게 될 것입니다.
그 이유는 출력이 리다이렉션되는 도구가 즉시 파일을 쓰기 모드로 열면서 내용을 비워버리기 때문입니다.
이를 해결하는 방법은 두 가지가 있습니다. (1) 다른 파일에 쓴 다음 `mv`로 이름을 바꾸거나, (2) 입력을 모두 빨아들인 뒤 파일에 쓰는 `sponge` [@sponge] 도구를 사용하는 것입니다.
\@ref(fig:diagram-essential-sponge)는 이것이 어떻게 작동하는지 보여줍니다.

```{r diagram-essential-sponge, echo=FALSE, fig.cap="`sponge`를 사용하지 않으면 한 파이프라인 안에서 같은 파일을 읽고 쓸 수 없습니다", fig.align="center"}
knitr::include_graphics("images/dscl_0207.png")
```

예를 들어, `dseq` [@dseq]로 *dates.txt* 파일을 생성하고 `nl` [@nl]을 사용해 행 번호를 붙이고 싶다고 가정해 봅시다.
다음과 같이 실행하면 *dates.txt* 파일은 비어 있게 됩니다.

```{console}
dseq 5 > dates.txt
< dates.txt nl > dates.txt
bat dates.txt
```

대신 앞서 설명한 방법 중 하나를 사용할 수 있습니다.

```{console}
dseq 5 > dates.txt
< dates.txt nl > dates-nl.txt
bat dates-nl.txt
dseq 5 > dates.txt
< dates.txt nl | sponge dates.txt
bat dates.txt
```


### 파일과 디렉터리 다루기

데이터 과학자로서 우리는 수많은 데이터와 소통하며, 그 데이터는 주로 파일에 저장됩니다.
커맨드 라인에서 파일(그리고 파일이 담긴 디렉터리)을 다루는 법을 아는 것이 중요합니다.
GUI에서 할 수 있는 모든 동작(그리고 그 이상의 것들)을 커맨드 라인 도구로 수행할 수 있습니다.
이 절에서는 파일과 디렉터리를 나열하고, 생성하고, 이동하고, 복사하고, 이름을 바꾸고, 삭제하는 가장 중요한 도구들을 소개합니다.

디렉터리의 내용을 나열하는 것은 `ls`로 할 수 있습니다.
디렉터리를 지정하지 않으면 현재 디렉터리의 내용을 나열합니다.
저는 주로 긴 목록 형식으로 표시하고 디렉터리를 파일보다 먼저 그룹화하는 것을 선호합니다.
매번 옵션을 일일이 입력하는 대신, 별칭 `l`을 사용합니다.

```{console}
ls /data/ch10
alias l
l /data/ch10
```

이미 `>`나 `>>`를 사용하여 출력을 리다이렉션함으로써 새 파일을 만드는 방법을 보셨습니다.
파일을 다른 디렉터리로 옮겨야 한다면 `mv` [@mv]를 사용하면 됩니다.

```{console, eval=FALSE}
mv hello.txt /data/ch02
```

`mv`로 파일의 이름을 바꿀 수도 있습니다.

```{console, eval=FALSE}
cd data
mv hello.txt bye.txt
```

디렉터리 전체의 이름을 바꾸거나 이동할 수도 있습니다.
더 이상 필요 없는 파일은 `rm` [@rm]으로 삭제(또는 제거)합니다.

```{console, eval=FALSE}
rm bye.txt
```

디렉터리와 그 안의 모든 내용을 삭제하고 싶다면 재귀(recursive)를 의미하는 `-r` 옵션을 지정합니다.

```{console, eval=FALSE}
rm -r /data/ch02/old
```

파일을 복사하려면 `cp` [@cp]를 사용합니다. 백업본을 만들 때 유용합니다.

```{console, eval=FALSE}
cp server.log server.log.bak
```

디렉터리는 `mkdir` [@mkdir]을 사용하여 생성할 수 있습니다.

```{console}
cd /data
mkdir logs
l
```

```{block2, type="rmdtip"}
커맨드 라인 도구로 파일을 관리하는 것이 처음에는 무서울 수 있습니다. 파일 시스템의 시각적 개요를 바로 확인할 수 없기 때문입니다.
GNU Midnight Commander, Ranger, Vifm 같은 시각적 파일 관리자들이 도움이 될 수 있습니다.
이들은 Docker 이미지에 기본 설치되어 있지는 않지만, `sudo apt install` 뒤에 `mc`, `ranger`, `vifm` 중 하나를 입력하여 직접 설치할 수 있습니다.
```

위의 모든 커맨드 라인 도구들은 `-v` 옵션(verbose)을 지원하여 어떤 작업이 진행되는지 출력해 줍니다.
예를 들어 다음과 같습니다.

```{console}
mkdir -v backup
cp -v * backup
```

`mkdir`을 제외한 모든 도구는 `-i` 옵션(interactive)을 지원하여, 작업을 수행하기 전에 확인 과정을 거칩니다.
예를 들어 다음과 같습니다.

```{console}
rm -i *#! expect_prompt=FALSE
n#! enter=FALSE, expect_prompt=TRUE
```


### 출력 관리하기

가끔 도구나 파이프라인이 책에 싣기에는 너무 많은 양의 출력을 생성할 때가 있습니다.
출력을 수동으로 수정하는 대신, 헬퍼 도구로 파이프 연결을 하여 투명하게 처리하는 것을 선호합니다.
여러분이 직접 할 때는 전체 내용을 보고 싶다면 굳이 이렇게 할 필요는 없습니다.

제가 출력을 제어하기 위해 사용하는 도구들은 다음과 같습니다.

`trim`은 출력의 높이(줄 수)와 너비(글자 수)를 제한하기 위해 자주 사용합니다.
기본적으로 출력은 10줄과 터미널 너비로 잘립니다.
음수를 전달하면 높이나 너비 제한을 해제할 수 있습니다.
예를 들어 다음과 같습니다.

```{console}
cat /data/ch07/tips.csv | trim 5 25
```

출력을 다듬기 위해 사용하는 다른 도구로는 `head`, `tail`, `fold`, `paste`, `column` 등이 있습니다.
부록에 각각의 예제가 실려 있습니다.

쉼표로 구분된(CSV) 출력인 경우, 주로 `csvlook`으로 파이프하여 보기 좋은 표로 변환합니다.
그냥 `csvlook`을 실행하면 전체 표가 보일 것입니다.
저는 `trim`에 의해 표가 짧게 보이도록 `csvlook`을 재정의해 두었습니다.

```{console}
which csvlook
csvlook /data/ch07/tips.csv
```

줄 번호와 신택스 하이라이팅(구문 강조)이 중요한 소스 코드 등의 내용을 보여줄 때는 `bat`을 사용합니다.
예를 들어 소스 코드는 다음과 같습니다.

```{console}
bat /data/ch04/stream.py
```

파일의 공백, 탭, 줄바꿈 등을 명시적으로 가리키고 싶을 때는 `-A` 옵션을 추가하기도 합니다.

중간 분석 결과를 파일에 기록하는 것이 유용할 때가 있습니다.
이를 통해 파이프라인의 각 단계를 완료 후에 확인해 볼 수 있습니다.
파이프라인 안 어디든 원하는 만큼 `tee` 도구를 삽입할 수 있습니다.
저는 주로 최종 출력물의 일부를 확인하면서 동시에 전체 출력물을 파일에 저장하고 싶을 때 사용합니다(\@ref(fig:diagram-essential-tee) 참고).
여기서는 전체 출력이 *even.txt*에 기록되고, 동시에 처음 5줄이 `trim`을 통해 출력됩니다.

```{console}
seq 0 2 100 | tee even.txt | trim 5
```

```{r diagram-essential-tee, echo=FALSE, fig.cap="`tee`를 사용하면 중간 출력을 파일에 기록할 수 있습니다", fig.align="center"}
knitr::include_graphics("images/dscl_0208.png")
```

마지막으로, 커맨드 라인 도구에 의해 생성된 이미지(스크린샷과 다이어그램을 제외한 모든 이미지)를 삽입할 때는 `display`를 사용합니다.
지금 `display`를 실행해 보면 작동하지 않을 것입니다.
[7장](#chapter-7-exploring-data)에서 커맨드 라인에서 생성된 이미지를 표시하기 위한 네 가지 옵션을 설명하겠습니다.


### 도와주세요! (Help!)

커맨드 라인을 익히다 보면 도움이 필요할 때가 생깁니다.
아무리 숙련된 사용자라도 가끔은 도움이 필요합니다.
수많은 커맨드 라인 도구와 그 인자들을 모두 기억하는 것은 불가능하기 때문입니다.
다행히 커맨드 라인에서는 도움을 얻을 수 있는 여러 방법을 제공합니다.

도움을 얻는 가장 중요한 명령어는 아마도 *manual*의 줄임말인 `man` [@man]일 것입니다.
거의 모든 커맨드 라인 도구에 대한 정보를 담고 있습니다.
만약 `tar` 도구의 옵션을 잊어버렸다면(저도 자주 잊어버립니다), 다음 명령어로 매뉴얼 페이지를 확인할 수 있습니다.

```{console man_cat}
man tar | trim 20
```

모든 커맨드 라인 도구가 매뉴얼 페이지를 가지고 있는 것은 아닙니다.
`cd`를 예로 들어 봅시다.

```{console}
man cd
```

`cd`와 같은 쉘 내장 명령어의 경우 *zshbuiltins* 매뉴얼 페이지를 참고할 수 있습니다.

```{console}
man zshbuiltins | trim
```

**`/`**를 눌러 검색할 수 있고 **`q`**를 눌러 나갈 수 있습니다.
`cd`에 해당하는 섹션을 찾아보세요.

최신 커맨드 라인 도구들도 매뉴얼 페이지가 없는 경우가 많습니다.
그럴 때는 해당 도구를 `--help` (또는 `-h`) 옵션과 함께 실행해 보는 것이 최선입니다.
예를 들어 다음과 같습니다.

```{console}
jq --help | trim
```

`--help` 옵션을 지정하는 것은 `cat`과 같은 기존 도구들에서도 작동합니다.
하지만 매뉴얼 페이지가 더 많은 정보를 제공하는 경우가 많습니다.
이 세 가지 방법으로도 해결되지 않는다면 인터넷 검색을 활용하는 것도 전혀 문제없습니다.
부록에 이 책에서 사용된 모든 커맨드 라인 도구의 목록이 있습니다.
각 도구를 어떻게 설치하는지뿐만 아니라 어떻게 도움을 얻을 수 있는지도 나와 있습니다.

매뉴얼 페이지는 내용이 너무 길고 읽기 힘들 수 있습니다.
`tldr` [@tldr] 도구는 커뮤니티에서 관리하는 도움말 페이지 모음으로, 전통적인 매뉴얼 페이지보다 훨씬 단순하고 접근하기 쉽도록 만들어졌습니다.
다음은 `tar`에 대한 tldr 페이지 예시입니다.

```{console, include=FALSE}
tldr --update
```

```{console}
tldr tar | trim 20
```

보시다시피 `man`처럼 수많은 옵션을 알파벳순으로 나열하는 대신, `tldr`은 실질적인 예시 목록을 보여주어 핵심을 바로 짚어줍니다.


## 요약

이 장에서는 Docker 이미지를 설치하여 필요한 모든 커맨드 라인 도구를 확보하는 방법을 배웠습니다.
또한 필수적인 커맨드 라인 개념들과 도움을 얻는 방법들도 살펴보았습니다.
이제 모든 준비가 끝났으므로, 데이터 과학을 위한 OSEMN 모델의 첫 번째 단계인 데이터 획득을 시작할 준비가 되었습니다.


## 더 읽을거리

- 이 책의 부제는 Jerry Peek, Shelley Powers, Tim O'Reilly, Mike Loukides가 쓴 명저 *Unix Power Tools*에 경의를 표하는 의미를 담고 있습니다. 51개 장과 1000페이지 넘는 분량에 유닉스에 대해 알아야 할 거의 모든 것을 다루고 있습니다. 무게가 2kg 가까이 나가므로 전자책으로 보시는 것을 추천합니다.
- [explainshell](https://explainshell.com/) 웹사이트는 명령어나 명령어 시퀀스를 파싱하여 각 부분에 대해 짧은 설명을 제공합니다. 매뉴얼 페이지를 훑어보지 않고도 새로운 명령어와 옵션을 빠르게 이해하는 데 유용합니다.
- Docker는 정말 멋진 소프트웨어입니다. 이 장에서 Docker 이미지를 다운로드하고 컨테이너를 실행하는 법을 짧게 설명했지만, [여러분만의 Docker 이미지를 만드는 법을 배우는 것](https://www.docker.com/101-tutorial)도 가치가 있을 것입니다. Sean Kane과 Karl Matthias가 쓴 *Docker: Up & Running*도 좋은 자료입니다.


[^cat]: [일부 사용자들](http://porkmail.org/era/unix/award.html)은 이것을 `cat`의 잘못된 사용(useless use of cat)이라고 생각합니다. `cat`의 목적은 파일들을 연결(concatenate)하는 것이며, 이 목적이 아니라면 프로세스 낭비라고 주장합니다. 저는 이것이 사소한 논쟁이라고 생각합니다. 우리에겐 더 중요한 할 일들이 많으니까요!
