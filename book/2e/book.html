<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>커맨드 라인에서 시작하는 데이터 과학, 2판</title>

    <meta name="author" content="Jeroen Janssens" />
  
   <meta name="description" content="이 개정판 가이드는 커맨드 라인의 유연성이 어떻게 여러분을 더 효율적이고 생산적인 데이터 과학자로 만들어 줄 수 있는지 보여줍니다. 작지만 강력한 커맨드 라인 도구들을 결합하여 데이터를 빠르게 획득, 정제, 탐색 및 모델링하는 방법을 배우게 됩니다. 시작을 돕기 위해 저자 Jeroen Janssens는 Windows, macOS, Linux 어디서든 유용한 100개 이상의 유닉스 파워 도구가 포함된 Docker 이미지를 제공합니다." />
   <meta name="generator" content="placeholder" />
  <meta property="og:title" content="커맨드 라인에서 시작하는 데이터 과학, 2판" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://datascienceatthecommandline.com" />
  <meta property="og:image" content="https://datascienceatthecommandline.com/og.png" />
  <meta property="og:description" content="이 개정판 가이드는 커맨드 라인의 유연성이 어떻게 여러분을 더 효율적이고 생산적인 데이터 과학자로 만들어 줄 수 있는지 보여줍니다. 작지만 강력한 커맨드 라인 도구들을 결합하여 데이터를 빠르게 획득, 정제, 탐색 및 모델링하는 방법을 배우게 됩니다. 시작을 돕기 위해 저자 Jeroen Janssens는 Windows, macOS, Linux 어디서든 유용한 100개 이상의 유닉스 파워 도구가 포함된 Docker 이미지를 제공합니다." />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="커맨드 라인에서 시작하는 데이터 과학, 2판" />
  
  <meta name="twitter:description" content="이 개정판 가이드는 커맨드 라인의 유연성이 어떻게 여러분을 더 효율적이고 생산적인 데이터 과학자로 만들어 줄 수 있는지 보여줍니다. 작지만 강력한 커맨드 라인 도구들을 결합하여 데이터를 빠르게 획득, 정제, 탐색 및 모델링하는 방법을 배우게 됩니다. 시작을 돕기 위해 저자 Jeroen Janssens는 Windows, macOS, Linux 어디서든 유용한 100개 이상의 유닉스 파워 도구가 포함된 Docker 이미지를 제공합니다." />
  <meta name="twitter:image" content="https://datascienceatthecommandline.com/twitter.png" />
  <!-- JS -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script>
  <script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script>
    <script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet" />
    <script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script>
    <link href="libs/Source_Sans_Pro-0.4.10/font.css" rel="stylesheet" />
    <link href="https://fonts.googleapis.com/css2?family=Fira%20Mono:wght@400;600&amp;display=swap" rel="stylesheet"/>
    <script src="libs/bs3compat-0.10.0/transition.js"></script>
    <script src="libs/bs3compat-0.10.0/tabs.js"></script>
    <script src="libs/bs3compat-0.10.0/bs3compat.js"></script>
    <link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet" />
    <script src="libs/bs4_book-1.0.0/bs4_book.js"></script>
    <script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#d42d2d">
    <meta name="apple-mobile-web-app-title" content="Data Science at the Command Line">
    <meta name="application-name" content="Data Science at the Command Line">
    <meta name="msapplication-TileColor" content="#b91d47">
    <meta name="theme-color" content="#ffffff">
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-43246574-3', 'auto');
      ga('send', 'pageview');
    </script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script>

  <!-- CSS -->
    <link rel="stylesheet" href="dsatcl2e.css" />
  
</head>

<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<!--bookdown:title:start-->
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
<div class="row">
  <header class="col-sm-12 col-lg-2 sidebar sidebar-book">
    <a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <img id="cover" class="d-none d-lg-block" src="images/cover-small.png">
      <h1 class="d-lg-none">
        <a href="index.html" title="">커맨드 라인에서 시작하는 데이터 과학, 2판</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
      </form>
      <nav aria-label="Table of contents">
        <h2>Table of contents</h2>
        <div id="book-toc"></div>

        <div class="book-extra">
          <p><a id="book-repo" href="#">View book repository <i class="fab fa-github"></i></a></li></p>
        </div>

        <div>
          <a id="course-signup" href="/#course">Embrace the Command Line</a>
        </div>
      </nav>
    </div>
  </header>

  <main class="col-sm-12 col-md-9 col-lg-7" id="content">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->
<div id="환영합니다" class="section level1 unnumbered" number="">
<h1 class="unnumbered" number="">환영합니다</h1>
<div class="h1" style="margin-top: 1.5rem;">
커맨드 라인에서 시작하는 데이터 과학
</div>
<div class="h4">
유닉스 파워 도구로 데이터를 획득, 정제, 탐색 및 모델링하기
</div>
<div class="cover-in-text">
<p><img class="d-block d-lg-none" src="images/cover-small.png"></p>
</div>
<p>Jeroen Janssens가 집필하고 2021년 10월 O’Reilly Media에서 출판한 <em>커맨드 라인에서 시작하는 데이터 과학</em> 2판 웹사이트에 오신 것을 환영합니다. 이 웹사이트는 무료로 이용할 수 있습니다. 콘텐츠는 <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License</a> 라이선스를 따릅니다. 종이책은 <a href="https://www.amazon.com/Data-Science-Command-Line-Explore-dp-1492087912/dp/1492087912">Amazon</a>에서 주문하실 수 있습니다.</p>
<p>Jeroen에게 직접 배우고 싶으신가요? Jeroen은 자신의 회사인 Data Science Workshops를 통해 커맨드 라인 데이터 과학 및 Python, R, 머신러닝과 같은 관련 주제에 대한 사내 교육을 제공합니다. 자세한 정보는 <a href="https://datascienceworkshops.com">Data Science Workshops</a>를 방문하세요.</p>

<div class="rmdtip">
Jeroen은 현재 새로운 코스 <a href="/#course">Embrace the Command Line</a>를 준비 중입니다. 아직 커맨드 라인을 완전히 활용하지 못하고 있다면 이 코스가 도움이 될 것입니다. 베타 코호트는 2021년 1분기에 시작될 예정입니다. 이 코스에 대해 더 알아보고 Jeroen에게 의견을 전달하려면 <a href="/#course">여기</a>를 클릭하세요.
</div>
<div id="책-소개" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">책 소개</h2>
<p>이 개정판 가이드는 커맨드 라인의 유연성이 어떻게 여러분을 더 효율적이고 생산적인 데이터 과학자로 만들어 줄 수 있는지 보여줍니다. 작지만 강력한 커맨드 라인 도구들을 결합하여 데이터를 빠르게 획득, 정제, 탐색 및 모델링하는 방법을 배우게 됩니다. 시작을 돕기 위해 저자 Jeroen Janssens는 Windows, macOS, Linux 어디서든 유용한 100개 이상의 유닉스 파워 도구가 포함된 Docker 이미지를 제공합니다.</p>
<p>커맨드 라인이 왜 민첩하고 확장 가능하며 유연한 기술인지 빠르게 깨닫게 될 것입니다. Python이나 R로 데이터를 처리하는 데 익숙하더라도 커맨드 라인의 힘을 활용하여 데이터 과학 워크플로우를 크게 개선하는 방법을 배울 수 있습니다. 이 책은 데이터 과학자, 분석가, 엔지니어, 시스템 관리자 및 연구자에게 이상적입니다.</p>
<ul>
<li>웹사이트, API, 데이터베이스 및 스프레드시트에서 데이터 획득</li>
<li>텍스트, CSV, HTML, XML 및 JSON 파일에 대한 정제(scrub) 작업 수행</li>
<li>데이터 탐색, 기술 통계 계산 및 시각화 생성</li>
<li>데이터 과학 워크플로우 관리</li>
<li>한 줄 명령어(one-liners)와 기존 Python 또는 R 코드로 나만의 도구 만들기</li>
<li>데이터 집약적인 파이프라인의 병렬화 및 분산 처리</li>
<li>차원 축소, 회귀 및 분류 알고리즘으로 데이터 모델링</li>
<li>Python, Jupyter, R, RStudio 및 Apache Spark에서 커맨드 라인 활용</li>
</ul>

<div class="rmdnote">
이 책이 도움이 되었다면 주변에 널리 알려주세요! 예를 들어,
<a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fdatascienceatthecommandline.com&amp;via=jeroenhjanssens&amp;text=Data%20Science%20at%20the%20Command%20Line%2C%20second%20edition">Twitter</a>에 공유하거나,
<a href="https://www.amazon.com/Data-Science-Command-Line-Explore-dp-1492087912/dp/1492087912">Amazon</a>에 리뷰를 남기거나,
<a href="https://github.com/jeroenjanssens/data-science-at-the-command-line">Github 저장소</a>에 별을 눌러주세요. 미리 감사드립니다!
</div>
</div>
<div id="추천사" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">추천사</h2>
<blockquote>
<p>
전통적인 컴퓨터 및 데이터 과학 커리큘럼은 커맨드 라인을 현대적이고 필수적인 도구가 아닌 구시대의 유물로 오해하는 경우가 많습니다. 저는 경력을 쌓고 난 후에야 지저분한 데이터셋을 탐색하고 재현 가능한 데이터 파이프라인을 만드는 데 있어 커맨드 라인의 우아함과 강력함을 깨달았습니다. <em>커맨드 라인에서 시작하는 데이터 과학</em> 1판은 제가 초보였을 때 가장 포괄적이고 명확한 참고서 중 하나였으며, 이제 2판을 통해 다시 새로운 도구와 응용법을 배우고 있습니다.
</p>
<p data-type="attribution">
<strong>Dan Nguyen</strong>, 데이터 과학자, 전 ProPublica 뉴스 앱 개발자, 전 스탠포드 대학교 전문 저널리즘 객원 교수
</p>
</blockquote>
<blockquote>
<p>
각자 하나의 일을 잘 수행하는 단순한 도구들을 파이프로 연결하는 유닉스 철학이 커맨드 라인에 담겨 있습니다. Jeroen은 이러한 철학을 데이터 과학 업무에 어떻게 접목시키는지 숙련되게 설명하며, 커맨드 라인이 단순히 파일 입출력의 세계가 아니라 데이터 조작, 탐색, 심지어 모델링의 세계임을 보여줍니다.
</p>
<p data-type="attribution">
<strong>Chris H. Wiggins</strong>, 컬럼비아 대학교 응용 물리학 및 응용 수학과 부교수, <span class="plain">The New York Times</span> 수석 데이터 과학자
</p>
</blockquote>
<blockquote>
<p>
이 책은 일반적인 데이터 과학 태스크를 일관된 워크플로우로 통합하는 방법을 설명합니다. 단순히 문제를 분해하는 전술뿐만 아니라, 해결책의 조각들을 조립하는 전략에 대해서도 다룹니다.
</p>
<p data-type="attribution">
<strong>John D. Cook</strong>, 응용 수학, 통계 및 기술 컴퓨팅 컨설턴트
</p>
</blockquote>
<blockquote class="pagebreak-before">
<p>
많은 이야기들이 들리겠지만, 대부분의 실무 데이터 과학은 여전히 평면 파일(flat files)에서 유도된 흥미로운 시각화와 통찰에 집중되어 있습니다. Jeroen의 책은 이러한 현실을 파고들어, 검증된 커맨드 라인 도구들이 어떻게 데이터 과학용으로 재탄생할 수 있는지 보여줌으로써 데이터 실무자들의 복잡성을 줄여줍니다.
</p>
<p data-type="attribution">
<strong>Paige Bailey</strong>, Microsoft GitHub 코드 인텔리전스 수석 제품 매니저
</p>
</blockquote>
<blockquote>
<p>
데이터를 R, Python 또는 데이터베이스로 가져오기 전에도 커맨드 라인에서 수많은 데이터 작업을 얼마나 빠르게 수행할 수 있는지 놀랍습니다. sed와 awk 같은 오래된 기술들은 여전히 믿을 수 없을 정도로 강력하고 다재다능합니다. <em>커맨드 라인에서 시작하는 데이터 과학</em>을 읽기 전까지 저는 이 도구들에 대해 들어보기만 했지 그 진정한 위력을 본 적이 없었습니다. Jeroen 덕분에 이제 대용량 데이터를 다루는 비밀 무기를 갖게 된 기분입니다.
</p>
<p data-type="attribution">
<strong>Jared Lander</strong>, Lander Analytics 수석 데이터 과학자, New York Open Statistical Programming Meetup 운영자, <span class="plain">R for Everyone</span> 저자
</p>
</blockquote>
<blockquote>
<p>
커맨드 라인은 모든 데이터 과학자의 도구 상자에 있어야 할 필수 도구이며, 이를 잘 활용하면 데이터에 대한 질문을 실시간 통찰로 쉽게 전환할 수 있습니다. Jeroen은 복잡한 문제에 대한 단순한 해결책을 찾기 위해 단일 목적의 도구들을 함께 연결하는 기본 유닉스 철학을 설명할 뿐만 아니라, 데이터 정제, 분석, 시각화 및 모델링을 위한 새로운 커맨드 라인 도구들을 소개합니다.
</p>
<p data-type="attribution">
<strong>Jake Hofman</strong>, Microsoft Research 수석 연구원, 컬럼비아 대학교 응용 수학과 겸임 조교수
</p>
</blockquote>
</div>
<div id="헌사" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">헌사</h2>
<div style="text-align: center;">
<p><em>다시 한번 아내 Esther에게. 당신의 지속적인 격려와 지원, 그리고 인내가 없었다면 이 2판은 분명</em> /dev/null<em>로 사라졌을 것입니다.</em></p>
</div>
</div>
<div id="저자-소개" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">저자 소개</h2>
<p><strong>Jeroen Janssens</strong>는 독립 데이터 과학 컨설턴트이자 강사입니다. 데이터 시각화, 머신러닝 모델 구현, 그리고 Python, R, JavaScript, Bash를 사용한 솔루션 구축을 즐깁니다. Jeroen은 교육 및 코칭 회사인 <a href="https://datascienceworkshops.com">Data Science Workshops</a>를 운영하며 공개 워크숍, 사내 교육, 영감 세션, 해커톤 및 미트업을 조직합니다. 이전에는 Jheronimus Academy of Data Science의 조교수였으며, 암스테르담의 Elsevier와 뉴욕의 여러 스타트업에서 데이터 과학자로 근무했습니다. Jeroen은 Tilburg 대학교에서 머신러닝 전공 박사 학위를, Maastricht 대학교에서 인공지능 전공 석사 학위를 취득했습니다. 현재 네덜란드 로테르담에서 아내, 두 아이와 함께 살고 있습니다.
Twitter(<span class="citation"><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></span>(<a href="https://twitter.com/jeroenhjanssens" class="uri">https://twitter.com/jeroenhjanssens</a>)), <a href="https://github.com/jeroenjanssens">GitHub</a>, <a href="https://www.linkedin.com/in/jeroenjanssens/">LinkedIn</a>에서 Jeroen을 만날 수 있습니다.</p>
</div>
<div id="판권-정보" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">판권 정보</h2>
<p><em>커맨드 라인에서 시작하는 데이터 과학</em>의 표지에 있는 동물은 주름목코뿔새(<em>Rhytidoceros undulatus</em>)입니다. 동남아시아 본토와 인도 북동부, 부탄의 숲에서 발견되는 이 종은 ’bar-pouched wreathed hornbill’로도 알려져 있습니다. 코뿔새(Hornbills)라는 이름은 부리 윗부분에 형성되는 <em>투구(casques)</em> 모양 구조물에서 유래되었습니다. 이 속이 빈 각질 구조의 뚜렷한 목적은 밝혀지지 않았지만, 종 구성원 간의 인식 수단, 울음소리 증폭기, 또는 수컷의 투구가 암컷보다 더 크기 때문에 성별 인식 수단으로 쓰일 수 있습니다. 주름목코뿔새는 근연종인 ’plain-pouched hornbill’과 외형이 비슷하지만, 목 아래쪽의 어두운 줄무늬로 구분할 수 있습니다.</p>
<p>주름목코뿔새는 최대 400마리까지 무리를 지어 잠을 자지만, 짝짓기는 일부일처제로 평생을 함께합니다. 수컷의 도움을 받아 암컷은 배설물과 진흙으로 나무 구멍을 막고 그 안에서 알을 낳고 품습니다. 수컷은 부리가 겨우 들어갈 정도의 틈을 통해 암컷과 새끼에게 최장 4개월 동안 먹이를 나릅니다. 암컷과 새끼가 둥지를 떠나면 육식 위주의 식단은 주로 과일로 바뀝니다. 코뿔새 커플은 같은 둥지를 최장 9년 동안 사용하는 것으로 알려져 있습니다.</p>
<p>O’Reilly 표지에 등장하는 많은 동물들은 멸종 위기종입니다. 이들 모두는 세상에 중요한 존재들입니다.</p>
<p>컬러 일러스트레이션은 Braukhaus의 <em>Lexicon</em> 흑백 판화를 기초로 Karen Montgomery가 그렸습니다. 표지 서체는 Gilroy Semibold와 Guardian Sans입니다. 본문 및 제목 서체는 Source Sans Pro이며, 코드 서체는 Fira Mono입니다.</p>
<!--chapter:end:index.Rmd-->
<!--A[foreword]
A-->
</div>
</div>
<div id="추천의-글" class="section level1 unnumbered" number="">
<h1 class="unnumbered" number="">추천의 글</h1>
<p>그것은 첫눈에 반한 사랑이었습니다.</p>
<p>제가 유닉스를 처음 맛본 것은 1981년이나 1982년쯤이었을 것입니다.
단일 명령과 복잡한 프로그램에 동일한 언어를 사용하는 커맨드 라인 쉘은 제 세상을 바꾸어 놓았고, 저는 결코 뒤를 돌아보지 않았습니다.</p>
<p>저는 컴퓨팅의 즐거움을 발견한 작가였고, 정규 표현식은 저를 매료시킨 입문용 마약과도 같았습니다.
HP의 RTE 운영체제에 있는 텍스트 에디터에서 정규 표현식을 처음 써봤지만, 유닉스와 그 철학—작고 서로 협력하는 도구들을 커맨드 라인 쉘이라는 접착제로 묶는 방식—을 접하고 나서야 비로소 그 진정한 위력을 이해하게 되었습니다.</p>
<p><code>ed</code>, <code>ex</code>, <code>vi</code> (현재의 <code>vim</code>), 그리고 <code>emacs</code>의 정규 표현식은 강력했지만, <code>ex</code> 스크립트가 독립되어 유닉스 스트림 에디터인 <code>sed</code>가 되고, 다시 프로그래밍된 동작을 정규 표현식에 바인딩할 수 있게 해주는 <code>AWK</code>가 되는 과정을 지켜보면서 깨달음을 얻었습니다. 또한 쉘 스크립트를 통해 기존 도구뿐만 아니라 직접 만든 새로운 도구들로 파이프라인을 구축할 수 있다는 사실을 알게 되었을 때 비로소 저는 유닉스의 본질을 이해하게 되었습니다.
프로그래밍은 컴퓨터와 대화하는 방식이며, 컴퓨터에게 무엇을 하라고 지시하는 방법입니다. 단순히 한 번만 시키는 것이 아니라 지속되는 방식으로, 인간의 언어처럼 반복 가능한 구조를 가지면서도 동사와 목적어를 다양하게 바꿀 수 있는 방식으로 말입니다.</p>
<p>초보자였을 때, 다른 형태의 프로그래밍은 모든 것을 완벽하게 맞춰야 하는 정교한 주문이나 엄격히 따라야 할 조리법처럼 느껴졌습니다. 마치 선생님이 제가 쓴 에세이를 채점하기를 기다리는 기분이었죠.
쉘 프로그래밍에는 컴파일이나 기다림이 없었습니다.
그것은 마치 친구와 대화하는 것과 더 비슷했습니다.
친구가 이해하지 못하면 다시 시도해보기 쉬웠습니다.
게다가 할 말이 간단하다면 단어 하나로도 의사 표현이 가능했습니다.
이미 수많은 상황에 맞는 단어들이 준비되어 있었고, 없다면 새로운 단어를 쉽게 만들 수도 있었습니다.
그리고 배운 단어와 직접 만든 단어들을 엮어 점차 복잡한 문장과 단락을 만들고, 결국에는 설득력 있는 에세이를 작성할 수 있었습니다.</p>
<p>거의 모든 다른 프로그래밍 언어가 쉘과 그 관련 도구들보다 강력할지 모르지만, 적어도 제게는 프로그래밍적 사고방식으로 들어가는 더 쉬운 길을 제공하는 것도, 업무를 도와달라고 요청하는 기계와의 일상적인 대화를 위한 더 나은 환경을 제공하는 것도 없습니다.
AWK의 창시자 중 한 명이자 명저인 <em>The Unix Programming Environment</em>의 공동 저자인 브라이언 커니핸(Brian Kernighan)은 2019년 렉스 프리드먼(Lex Fridman)과의 인터뷰에서 “[유닉스는] 프로그램을 작성하기 정말 쉬운 환경이 되도록 의도되었습니다.”라고 말했습니다. <a href="https://www.happyscribe.com/public/lex-fridman-podcast-artificial-intelligence-ai/109-brian-kernighan-unix-c-awk-ampl-and-go-programming#paragraph_1371">[00:23:10]</a>
그는 데이터를 탐색할 때 왜 여전히 파이썬 프로그램을 작성하기보다 AWK를 자주 사용하는지 설명하며 덧붙였습니다.
“큰 프로그램에는 적합하지 않지만, 무언가 안에서 특정한 것들을 보고 싶을 때 수행하는 이런 작은 작업들에는 정말 기막히게 잘 돌아갑니다.” <a href="https://www.happyscribe.com/public/lex-fridman-podcast-artificial-intelligence-ai/109-brian-kernighan-unix-c-awk-ampl-and-go-programming#paragraph_2221">[00:37:01]</a></p>
<p><em>커맨드 라인에서 시작하는 데이터 과학</em>에서 Jeroen Janssens는 유닉스/리눅스 방식의 커맨드 라인이 오늘날에도 얼마나 강력한지 보여줍니다.
Jeroen이 이미 책에서 다루지 않았다면, 저는 여기서 왜 커맨드 라인이 데이터 과학에서 흔히 마주치는 작업들과 이토록 잘 어울리는 강력한 조합인지에 대해 에세이를 썼을 것입니다.
하지만 그는 이미 책의 시작 부분에서 이를 설명하고 있습니다.
그래서 저는 이 말만 전하겠습니다. 커맨드 라인을 더 많이 사용할수록, 그것이 업무의 상당 부분을 처리하는 가장 쉬운 방법임을 깨닫고 더 자주 돌아오게 될 것입니다.
쉘 입문자이든, 쉘 프로그래밍이 데이터 과학에 얼마나 적합한지 깊이 생각해보지 않은 분이든, 이 책은 여러분이 소중히 여기게 될 책이 될 것입니다.
Jeroen은 훌륭한 스승이며, 그가 다루는 내용은 귀중합니다.</p>
<p style="text-align: right; font-style: italic">
—팀 오라일리(Tim O’Reilly)<br />
2021년 5월
</p>
<!--chapter:end:foreword.Rmd-->
<!--A[preface]
A-->
</div>
<div id="서문" class="section level1 unnumbered" number="">
<h1 class="unnumbered" number="">서문</h1>
<p>데이터 과학은 일하기에 정말 흥미로운 분야입니다.
또한 여전히 상대적으로 젊은 분야이기도 하죠.
불행하게도 많은 사람들과 기업들이 데이터 과학이 제기하는 문제들을 해결하려면 새로운 기술이 필요하다고 믿습니다.
하지만 이 책에서 보여주듯이, 많은 일들이 커맨드 라인을 사용함으로써 해결될 수 있으며, 때로는 훨씬 더 효율적인 방식으로 이루어집니다.</p>
<p>박사 과정 동안 저는 서서히 마이크로소프트 윈도우에서 리눅스로 사용 환경을 옮겼습니다.
이 전환이 처음에는 조금 두려웠기 때문에, 두 운영체제를 나란히 설치하는 방식(듀얼 부트라고 알려진)으로 시작했습니다.
결국 윈도우와 리눅스를 왔다 갔다 하려는 욕구는 사라졌고, 어느 시점에는 나만의 맞춤형 리눅스 머신을 처음부터 빌드할 수 있는 아치 리눅스(Arch Linux)를 만지작거리기도 했습니다.
주어지는 것은 오직 커맨드 라인뿐이며, 그것으로 무엇을 할지는 여러분에게 달려 있습니다.
필요에 의해 저는 빠르게 커맨드 라인 사용에 익숙해졌습니다.
결국 여가 시간이 더 소중해지면서, 사용하기 쉽고 커뮤니티가 큰 우분투(Ubuntu)라는 리눅스 배포판에 정착하게 되었습니다.
하지만 여전히 제가 대부분의 시간을 보내는 곳은 커맨드 라인입니다.</p>
<p>사실 제가 커맨드 라인이 단순히 소프트웨어를 설치하고, 시스템을 설정하고, 파일을 검색하는 용도만이 아니라는 것을 깨달은 지는 그리 오래되지 않았습니다.
저는 <code>cut</code>, <code>sort</code>, <code>sed</code>와 같은 도구들을 배우기 시작했습니다.
이것들은 데이터를 입력받아 무언가를 수행하고 결과를 출력하는 커맨드 라인 도구들의 예시입니다.
우분투에는 이런 도구들이 꽤 많이 포함되어 있습니다.
이 작은 도구들을 결합했을 때의 잠재력을 이해하고 나자, 저는 완전히 매료되었습니다.</p>
<p>박사 학위를 받은 후 데이터 과학자가 되었을 때, 저는 가능한 한 이 방식을 데이터 과학에 사용하고 싶었습니다.
<code>xml2json</code>, <code>jq</code>, <code>json2csv</code>와 같은 몇 가지 새로운 오픈 소스 커맨드 라인 도구들 덕분에 웹사이트 스크래핑이나 대량의 JSON 데이터 처리와 같은 작업에도 커맨드 라인을 사용할 수 있었습니다.</p>
<p>2013년 9월, 저는 <a href="http://www.jeroenjanssens.com/2013/09/19/seven-command-line-tools-for-data-science.html">데이터 과학을 위한 7가지 커맨드 라인 도구</a>라는 제목의 블로그 포스트를 작성하기로 결심했습니다.
놀랍게도 이 블로그 포스트는 꽤 많은 관심을 받았고, 다른 커맨드 라인 도구들에 대한 수많은 제안을 받았습니다.
저는 이 블로그 포스트를 책으로 만들 수 있을지 궁금해지기 시작했습니다.
약 10개월 후, 많은 유능한 분들의 도움(감사의 글 참조)으로 그 대답이 ’예’가 되어 기뻤습니다.</p>
<p>제가 이런 개인적인 이야기를 공유하는 것은 이 책이 어떻게 탄생했는지 여러분이 알아야 한다고 생각해서라기보다, 저 역시 커맨드 라인을 배워야만 했다는 사실을 알려드리고 싶기 때문입니다.
커맨드 라인은 그래픽 사용자 인터페이스(GUI)를 사용하는 것과 매우 다르기 때문에 처음에는 무섭게 느껴질 수 있습니다.
하지만 제가 배울 수 있었다면 여러분도 할 수 있습니다.
현재 사용하는 운영체제가 무엇이든, 현재 데이터를 어떻게 다루든 관계없이 이 책을 읽고 나면 커맨드 라인에서 데이터 과학을 할 수 있게 될 것입니다.
이미 커맨드 라인에 익숙하거나 쉘 스크립트로 꿈을 꿀 정도인 분들이라도, 다음 데이터 과학 프로젝트에 사용할 만한 흥미로운 팁이나 도구를 몇 가지 발견하게 될 것입니다.</p>
<div id="이-책에서-기대할-수-있는-것" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">이 책에서 기대할 수 있는 것</h2>
<p>이 책에서 우리는 데이터를 획득(obtain), 정제(scrub), 탐색(explore), 모델링(model)할 것입니다. 그것도 아주 많이요.
이 책은 이러한 데이터 과학 작업 자체를 어떻게 하면 <em>더 잘</em> 할 수 있는지에 대한 책은 아닙니다.
예를 들어 어떤 통계 검정을 언제 적용해야 하는지나 데이터를 어떻게 가장 잘 시각화할 것인지를 논하는 훌륭한 리소스들은 이미 많이 있습니다.
대신, 이 실무 중심의 책은 커맨드 라인에서 이러한 데이터 과학 작업을 수행하는 방법을 가르쳐줌으로써 여러분을 더 <em>효율적</em>이고 <em>생산적</em>이게 만드는 것을 목표로 합니다.</p>
<p>이 책에서는 90개가 넘는 커맨드 라인 도구를 다루지만, 가장 중요한 것은 도구 그 자체가 아닙니다.
어떤 도구들은 아주 오랫동안 존재해 왔고, 어떤 도구들은 더 나은 것으로 대체될 것입니다.
여러분이 이 글을 읽는 동안에도 새로운 커맨드 라인 도구들이 만들어지고 있습니다.
지난 몇 년 동안 저는 놀라운 커맨드 라인 도구들을 많이 발견했습니다.
안타깝게도 그중 일부는 너무 늦게 발견되어 이 책에 포함되지 못했습니다.
요컨대, 커맨드 라인 도구는 생겨나고 사라집니다.
하지만 그것으로 괜찮습니다.</p>
<p>가장 중요한 것은 도구, 파이프, 그리고 데이터를 다루는 그 밑바탕의 아이디어입니다.
대부분의 커맨드 라인 도구는 한 가지 일을 하고 그것을 아주 잘 수행합니다.
이것은 책의 여러 곳에서 등장하는 유닉스 철학의 일부이기도 합니다.
일단 커맨드 라인에 익숙해지고, 도구들을 결합하는 방법을 알고, 심지어 새로운 도구를 만들 수 있게 된다면, 여러분은 매우 귀중한 기술을 갖게 된 것입니다.</p>
</div>
<div id="판의-변경-사항" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">2판의 변경 사항</h2>
<p>기술로서의 커맨드 라인과 그 작동 방식은 시대를 초월하지만, 1판에서 다루었던 일부 도구들은 더 새로운 도구들로 대체되거나(<code>csvkit</code>은 대개 <code>xsv</code>로 대체되었습니다), 개발자에 의해 방치되었거나(<code>drake</code>), 혹은 최적이 아닌 선택이었던 것들(<code>weka</code>)이 있었습니다.
2014년 10월 1판이 출간된 이후 저는 스스로의 경험이나 독자들의 유용한 피드백을 통해 많은 것을 배웠습니다.
이 책이 두 주제의 교차점에 있는 틈새 분야를 다루고 있음에도 불구하고, 거의 매일 제가 받는 수많은 긍정적인 메시지들이 증명하듯 데이터 과학 커뮤니티의 꾸준한 관심이 이어지고 있습니다.
1판을 업데이트함으로써 저는 이 책이 앞으로 최소 5년 동안은 유효한 가치를 지니기를 바랍니다.
다음은 제가 수정한 주요 변경 사항 목록입니다.</p>
<ul>
<li>가능한 한 <code>csvkit</code>을 <code>xsv</code>로 교체했습니다. <code>xsv</code>는 CSV 파일을 다루는 훨씬 빠른 대안입니다.</li>
<li>2.2절과 3.2절에서 VirtualBox 이미지를 Docker 이미지로 대체했습니다. Docker는 격리된 환경을 실행하는 데 있어 VirtualBox보다 빠르고 가벼운 방식입니다.</li>
<li>HTML을 다루기 위해 <code>scrape</code> 대신 <code>pup</code>을 사용합니다. <code>scrape</code>은 제가 직접 만든 파이썬 도구입니다. <code>pup</code>은 훨씬 빠르고 기능이 많으며 설치가 더 쉽습니다.</li>
<li><a href="#chapter-6-project-management-with-make">6장</a>을 처음부터 다시 썼습니다. 프로젝트 관리를 위해 <code>drake</code> 대신 <code>make</code>를 사용합니다. <code>drake</code>는 더 이상 유지보수되지 않으며 <code>make</code>는 훨씬 성숙하고 개발자들에게 매우 인기가 있습니다.</li>
<li><code>Rio</code>를 <code>rush</code>로 대체했습니다. <code>Rio</code>는 제가 직접 만든 투박한 Bash 스크립트였습니다. <code>rush</code>는 커맨드 라인에서 R을 사용하는 훨씬 더 안정적이고 유연한 방식인 R 패키지입니다.</li>
<li><a href="#chapter-9-modeling-data">9장</a>에서 Weka와 BigML을 Vowpal Wabbit(<code>vw</code>)으로 대체했습니다. Weka는 오래되었고 커맨드 라인에서 사용하는 방식이 투박합니다. BigML은 제가 더 이상 의존하고 싶지 않은 상용 API입니다. Vowpal Wabbit은 Yahoo!에서 개발되어 현재 Microsoft에서 관리하는 매우 성숙한 머신러닝 도구입니다.</li>
<li><a href="#chapter-10-polyglot-data-science">10장</a>은 파이썬, R, Apache Spark 등 기존 워크플로우에 커맨드 라인을 통합하는 방법을 다루는 완전히 새로운 장입니다. 1판에서는 커맨드 라인이 기존 워크플로우에 쉽게 통합될 수 있다는 점만 언급하고 깊이 다루지 못했습니다. 이 장이 그 부분을 해결해 줍니다.</li>
</ul>
</div>
<div id="이-책을-읽는-방법" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">이 책을 읽는 방법</h2>
<p>일반적으로 이 책을 순서대로 읽으시길 권장합니다.
한번 개념이나 커맨드 라인 도구가 소개되면, 이후의 장에서 그것을 활용할 가능성이 높습니다.
예를 들어 <a href="#chapter-9-modeling-data">9장</a>에서는 <a href="#chapter-8-parallel-pipelines">8장</a>에서 광범위하게 소개한 <code>parallel</code>을 집중적으로 사용합니다.</p>
<p>데이터 과학은 프로그래밍, 데이터 시각화, 머신러닝 등 수많은 다른 분야와 교차하는 넓은 분야입니다.
그 결과, 이 책은 많은 흥미로운 주제들을 다루지만 안타깝게도 모든 주제를 심도 있게 다루지는 못합니다.
책 곳곳의 각 장 끝에는 더 깊게 탐구할 수 있는 제안들이 있습니다.
책의 내용을 따라가기 위해 이 자료들을 반드시 읽어야 하는 것은 아니지만, 관심이 있다면 배울 것이 훨씬 더 많다는 것을 알게 될 것입니다.</p>
</div>
<div id="이-책의-대상-독자" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">이 책의 대상 독자</h2>
<p>이 책은 여러분에 대해 단 한 가지 가정만 합니다. 바로 여러분이 데이터를 다루는 분들이라는 점입니다.
현재 어떤 프로그래밍 언어나 통계 컴퓨팅 환경을 사용하고 있는지는 중요하지 않습니다.
이 책은 필요한 모든 개념을 기초부터 설명합니다.</p>
<p>또한 여러분의 운영체제가 마이크로소프트 윈도우인지, macOS인지, 혹은 어떤 종류의 리눅스인지도 중요하지 않습니다.
이 책은 설치하기 쉬운 가상 환경인 Docker 이미지를 함께 제공합니다.
이를 통해 커맨드 라인 도구를 실행하고 이 책이 작성된 것과 동일한 환경에서 코드 예제를 따라 해볼 수 있습니다.
수많은 커맨드 라인 도구와 그 의존성들을 어떻게 설치할지 고민하며 시간을 낭비할 필요가 없습니다.</p>
<p>이 책에는 Bash, 파이썬, R로 작성된 일부 코드가 포함되어 있어 프로그래밍 경험이 있다면 도움이 되겠지만, 예제를 따라가는 데 있어 반드시 필요한 것은 아닙니다.</p>
</div>
<div id="이-책에-사용된-표기-규칙" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">이 책에 사용된 표기 규칙</h2>
<p>이 책에서는 다음과 같은 서체 규칙을 사용합니다.</p>
<dl>
<dt><em>이탤릭(Italic)</em></dt>
<dd><p>새로운 용어, URL, 디렉터리 이름, 파일 이름을 나타냅니다.</p>
</dd>
<dt><code>고정 폭(Constant width)</code></dt>
<dd><p>코드와 명령어를 나타낼 때, 그리고 본문 내에서 커맨드 라인 도구와 옵션을 언급할 때 사용합니다.</p>
</dd>
<dt><strong><code>고정 폭 굵게(Constant width bold)</code></strong></dt>
<dd><p>사용자가 직접 입력해야 하는 명령어 나 텍스트를 나타냅니다.</p>
</dd>
</dl>

<div class="rmdtip">
이 요소는 팁이나 제안을 나타냅니다.
</div>

<div class="rmdnote">
이 요소는 일반적인 노트를 나타냅니다.
</div>

<div class="rmdcaution">
이 요소는 경고나 주의 사항을 나타냅니다.
</div>
<!--A
=== Using Code Examples

Supplemental material (code examples, exercises, etc.) is available for download at link:$$https://github.com/jeroenjanssens/data-science-at-the-command-line$$[].

This book is here to help you get your job done. In general, if example code is offered with this book, you may use it in your programs and documentation. You do not need to contact us for permission unless you’re reproducing a significant portion of the code. For example, writing a program that uses several chunks of code from this book does not require permission. Selling or distributing examples from O’Reilly books does require permission. Answering a question by citing this book and quoting example code does not require permission. Incorporating a significant amount of example code from this book into your product’s documentation does require permission.

We appreciate, but generally do not require, attribution. An attribution usually includes the title, author, publisher, and ISBN. For example: “Data Science at the Command Line by Jeroen Janssens (O’Reilly). Copyright 2021 Jeroen Janssens, 978-1-492-08791-5.”

If you feel your use of code examples falls outside fair use or the permission given above, feel free to contact us at pass:[<a class="email" href="mailto:permissions@oreilly.com"><em>permissions@oreilly.com</em></a>].

=== O'Reilly Online Learning

[role = "ormenabled"]
[NOTE]
====
For more than 40 years, pass:[<a href="http://oreilly.com" class="orm:hideurl"><em class="hyperlink">O’Reilly Media</em></a>] has provided technology and business training, knowledge, and insight to help companies succeed.
====

Our unique network of experts and innovators share their knowledge and expertise through books, articles, and our online learning platform. O’Reilly’s online learning platform gives you on-demand access to live training courses, in-depth learning paths, interactive coding environments, and a vast collection of text and video from O'Reilly and 200+ other publishers. For more information, visit pass:[<a href="http://oreilly.com" class="orm:hideurl"><em>http://oreilly.com</em></a>].

=== How to Contact Us

Please address comments and questions concerning this book to the publisher:

++++
<ul class="simplelist">
  <li>O’Reilly Media, Inc.</li>
  <li>1005 Gravenstein Highway North</li>
  <li>Sebastopol, CA 95472</li>
  <li>800-998-9938 (in the United States or Canada)</li>
  <li>707-829-0515 (international or local)</li>
  <li>707-829-0104 (fax)</li>
</ul>
++++

We have a web page for this book, where we list errata, examples, and any additional information. You can access this page at link:$$https://wwww.datascienceatthecommandline.com$$[].

Email pass:[<a class="email" href="mailto:bookquestions@oreilly.com"><em>bookquestions@oreilly.com</em></a>] to comment or ask technical questions about this book.

For news and information about our books and courses, visit link:$$http://oreilly.com$$[].

Find us on Facebook: link:$$http://facebook.com/oreilly$$[]

Follow us on Twitter: link:$$http://twitter.com/oreillymedia$$[]

Watch us on YouTube: link:$$http://www.youtube.com/oreillymedia$$[]



A-->
</div>
<div id="감사의-글" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">감사의 글</h2>
<div id="판을-위한-감사의-글-2021" class="section level3 unnumbered" number="">
<h3 class="unnumbered" number="">2판을 위한 감사의 글 (2021)</h3>
<p>1판이 출간된 지 7년이 지났습니다.
그동안, 특히 지난 13개월 동안 많은 분들이 저를 도와주셨습니다.
그분들이 없었다면 저는 결코 2판을 쓸 수 없었을 것입니다.</p>
<p>저는 이번에도 O’Reilly에서 세 분의 멋진 에디터들과 함께하게 된 행운을 누렸습니다.
Sarah “Embrace the deadline” Grey, Jess “Pedal to the metal” Haberman, 그리고 Kate “Let it go” Galloway에게 감사의 마음을 전합니다. 그들의 미들 네임(별명)이 모든 것을 말해줍니다. 그들의 믿을 수 없는 도움 덕분에 마감 시한을 받아들이고(embrace the deadlines), 중요한 순간에 가속 페달을 밟고(put the pedal to metal), 마침내 원고를 손에서 놓을(let it go) 수 있었습니다.
또한 O’Reilly와의 협업을 이토록 즐겁게 만들어준 그들의 동료들—Angela Rufino, Arthur Johnson, Cassandra Furtado, David Futato, Helen Monroe, Karen Montgomery, Kate Dullea, Kristen Brown, Marie Beaugureau, Marsee Henon, Nick Adams, Regina Wilkinson, Shannon Cutt, Shannon Turlington, Yasmina Greco—에게도 감사를 표합니다.</p>
<p>코드를 실행하고 그 결과를 다시 붙여넣는 자동화된 프로세스(R Markdown과 Docker 덕분)가 있음에도 불구하고, 제가 저지른 실수의 숫자는 정말 놀라울 정도였습니다.
이 숫자를 대폭 줄여주신 Aaditya Maruthi, Brian Eoff, Caitlin Hudon, Julia Silge, Mike Dewar, 그리고 Shane Reustle에게 감사드립니다.
물론 남아 있는 모든 실수는 저의 책임입니다.</p>
<p>Marc Canaleta는 특별한 감사를 받을 자격이 있습니다.
1판이 나온 직후인 2014년 10월, Marc는 바르셀로나에 있는 Social Point 팀을 위해 “커맨드 라인에서 시작하는 데이터 과학”을 주제로 한 하루짜리 워크숍에 저를 초대했습니다.
우리 둘 다 그토록 많은 워크숍이 이어지게 될 줄은 몰랐습니다.
그 경험은 결국 제가 직접 회사인 Data Science Workshops를 차리는 원동력이 되었습니다.
교육을 할 때마다 저는 새로운 것을 배웁니다.
아마 학생들은 모르겠지만, 모든 학생 한 명 한 명이 이 책에 각기 다른 방식으로 영향을 미쳤습니다.
그분들에게 감사의 인사를 전합니다.
저는 아주 오랫동안 학생들을 가르치고 싶습니다.</p>
<p>매혹적인 대화, 멋진 제안, 그리고 열정적인 풀 리퀘스트들.
다음에 열거된 아낌없이 베풀어준 분들의 모든 기여에 깊이 감사드립니다.
Adam Johnson, Andre Manook, Andrea Borruso, Andres Lowrie, Andrew Berisha, Andrew Gallant, Andrew Sanchez, Anicet Ebou, Anthony Egerton, Ben Isenhart, [.keep-together]#Chris Wiggins#, Chrys Wu, Dan Nguyen, Darryl Amatsetam, Dmitriy Rozhkov, Doug Needham, Edgar Manukyan, Erik Swan, Felienne Hermans, George Kampolis, Giel van Lankveld, Greg Wilson, Hay Kranen, Ioannis Cherouvim, Jake Hofman, Jannes Muenchow, Jared Lander, Jay Roaf, Jeffrey Perkel, Jim Hester, Joachim Hagege, Joel Grus, John Cook, John Sandall, Joost Helberg, Joost van Dijk, Joyce Robbins, Julian Hatwell, Karlo Guidoni, Karthik Ram, Lissa Hyacinth, Longhow Lam, Lui Pillmann, Lukas Schmid, Luke Reding, Maarten van Gompel, Martin Braun, Max Schelker, Max Shron, Nathan Furnal, Noah Chase, Oscar Chic, Paige Bailey, Peter Saalbrink, Rich Pauloo, Richard Groot, Rico Huijbers, Rob Doherty, Robbert van Vlijmen, Russell Scudder, Sylvain Lapoix, TJ Lavelle, Tan Long, Thomas Stone, Tim O’Reilly, Vincent Warmerdam, Yihui Xie.</p>
<p>책 전체에 걸쳐, 특히 각주와 부록에는 수백 개의 이름이 등장합니다.
이 이름들은 이 책의 근간이 된 수많은 도구, 서적 및 기타 리소스들의 저자들입니다.
그 작업이 50년 전의 것이든 50일 전의 것이든, 그분들의 노고에 무한한 감사를 드립니다.</p>
<p>무엇보다도, 무엇이 진정으로 중요한지 매일 일깨워주는 아내 Esther와 딸 Florien, 그리고 아들 Olivier에게 감사를 전합니다.
약속컨대 3판을 쓰기 전까지는 몇 년의 시간 여유가 있을 것입니다.</p>
</div>
<div id="판을-위한-감사의-글-2014" class="section level3 unnumbered" number="">
<h3 class="unnumbered" number="">1판을 위한 감사의 글 (2014)</h3>
<p>가장 먼저 저의 2013년 9월 블로그 포스트인 <a href="http://jeroenjanssens.com/2013/09/19/seven-command-line-tools-for-data-science.html">데이터 과학을 위한 7가지 커맨드 라인 도구</a>가 책으로 확장될 수 있다고 믿어준 Mike Dewar와 Mike Loukides에게 감사를 전합니다.</p>
<p>다양한 초안을 읽고, 모든 명령어를 세심하게 테스트하며 귀중한 피드백을 준 기술 검토자 Mike Dewar, Brian Eoff, Shane Reustle에게 특별한 감사를 전합니다.
여러분의 노력으로 책이 크게 향상되었습니다. 남아 있는 오역이나 오류는 전적으로 저의 책임입니다.</p>
<p>Ann Spencer, Julie Steele, 그리고 Marie Beaugureau라는 세 분의 놀라운 에디터와 함께 일할 수 있는 특권을 누렸습니다.
저를 잘 이끌어 주시고 O’Reilly의 유능한 많은 분들과 훌륭한 가교 역할을 해주셔서 감사합니다.
그분들 중에는 Laura Baldwin, Huguette Barriere, Sophia DeMartini, Yasmina Greco, Rachel James, Ben Lorica, Mike Loukides, Christopher Pappas가 포함됩니다.
무대 뒤에서 일하느라 제가 직접 만나보지 못한 다른 많은 분들도 있습니다.
그분들 모두 덕분에 O’Reilly와 함께 일하는 것이 진정한 즐거움이었습니다.</p>
<p>이 책은 80개가 넘는 커맨드 라인 도구를 다룹니다. 말할 필요도 없이, 이 도구들이 없었다면 이 책은 존재조차 할 수 없었을 것입니다.
따라서 이 도구들을 만들고 기여해주신 모든 저자분들께 깊은 감사를 드립니다. 전체 저자 목록은 안타깝게도 여기에 다 나열하기에 너무 길어 부록에 언급했습니다.
특히 Aaron Crow, Jehiah Czebotar, Christoph Groskopf, Dima Kogan, Sergey Lisitsyn, Francisco J. Martin, 그리고 Ole Tange에게 그들의 놀라운 도구들에 대해 도움을 주셔서 감사를 전합니다.</p>
<p>박사 과정 동안 저를 지도해주신 Eric Postma와 Jaap van den Herik 교수님께도 특별히 감사의 인사를 드립니다.
5년이 넘는 시간 동안 교수님들은 제게 많은 교훈을 주셨습니다.
기술 서적을 쓰는 것이 박사 학위 논문을 쓰는 것과는 꽤 다르지만, 그 교훈들 중 많은 부분이 지난 9개월 동안 매우 큰 도움이 되었습니다.</p>
<p>마지막으로 YPlan 동료들, 친구들, 가족들, 그리고 무엇보다 적절한 순간에 저를 커맨드 라인에서 떼어내 준 아내 Esther에게 고마움을 전합니다.</p>
<!--chapter:end:preface.Rmd-->
<!--A[role="pagenumrestart"]
A-->
</div>
</div>
</div>
<div id="chapter-1-introduction" class="section level1" number="1">
<h1 number="1"><span class="header-section-number">1</span> 서론</h1>
<p>이 책은 커맨드 라인에서 데이터 과학을 수행하는 것에 관한 책입니다.
저의 목표는 커맨드 라인의 힘을 활용하는 방법을 가르쳐드림으로써 여러분을 더 효율적이고 생산적인 데이터 과학자로 만드는 것입니다.</p>
<p>제목에 <em>데이터 과학</em>과 <em>커맨드 라인</em>이라는 두 용어가 함께 쓰인 것에 대해 설명이 필요할 것 같습니다.
어떻게 50년도 더 된 기술<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>이 이제 겨우 몇 년밖에 되지 않은 분야에 도움이 될 수 있을까요?</p>
<p>오늘날 데이터 과학자들은 파이썬, R, Julia, Apache Spark 등 흥미롭고 압도적인 기술과 프로그래밍 언어들 중에서 선택할 수 있습니다.
여러분은 이미 이들 중 하나 이상에 익숙할지도 모릅니다.
그렇다면 왜 여전히 데이터 과학을 위해 커맨드 라인에 관심을 가져야 할까요?
커맨드 라인이 다른 기술이나 프로그래밍 언어들이 제공하지 못하는 무엇을 가지고 있을까요?</p>
<p>이것들은 모두 타당한 질문입니다.
이 첫 번째 장에서 저는 다음과 같은 방식으로 그 답을 제시하고자 합니다.
먼저, 이 책의 근간이 될 데이터 과학의 실무적인 정의를 제공하겠습니다.
둘째로, 커맨드 라인이 가진 다섯 가지 중요한 장점을 나열하겠습니다.
이 장을 마칠 때쯤이면 여러분도 데이터 과학을 위해 커맨드 라인을 배울 가치가 충분하다는 점에 동의하시게 될 것입니다.</p>
<div id="데이터-과학은-osemnawesome하다" class="section level2" number="1.1">
<h2 number="1.1"><span class="header-section-number">1.1</span> 데이터 과학은 OSEMN(Awesome)하다</h2>
<p>데이터 과학 분야는 아직 초기 단계에 있으며, 따라서 데이터 과학이 무엇을 포함하는지에 대한 다양한 정의가 존재합니다.
이 책 전체에 걸쳐 저는<span class="citation"><a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></span> 제시한 매우 실무적인 정의를 따를 것입니다.
그들은 데이터 과학을 다음과 같은 다섯 단계로 정의합니다: (1) 데이터 획득(Obtaining), (2) 데이터 정제(Scrubbing), (3) 데이터 탐색(Exploring), (4) 데이터 모델링(Modeling), (5) 데이터 해석(Interpreting).
이 다섯 단계의 앞글자를 따서 OSEMN 모델이라고 부릅니다(발음은 <em>awesome</em>과 같습니다).
이 정의는 이 책의 뼈대 역할을 하는데, 아래에서 설명할 5단계 ’데이터 해석’을 제외한 각 단계가 별도의 장으로 구성되어 있기 때문입니다.</p>
<p>비록 이 다섯 단계가 선형적이고 점진적인 방식으로 논의되지만, 실제로는 각 단계 사이를 오가거나 여러 단계를 동시에 수행하는 것이 매우 일반적입니다.
Figure @ref(fig:diagram-osemn)은 데이터 과학을 수행하는 것이 반복적이고 비선형적인 과정임을 보여줍니다.
예를 들어, 데이터를 모델링하고 결과를 확인한 후, 데이터셋의 특징(features)을 조정하기 위해 정제 단계로 되돌아가기로 결정할 수도 있습니다.</p>
<p>아래에서는 각 단계가 무엇을 의미하는지 설명하겠습니다.</p>
<div id="데이터-획득-obtaining-data" class="section level3" number="1.1.1">
<h3 number="1.1.1"><span class="header-section-number">1.1.1</span> 데이터 획득 (Obtaining Data)</h3>
<p>데이터 없이는 데이터 과학을 할 수 없습니다.
따라서 첫 번째 단계는 데이터를 얻는 것입니다.
이미 데이터를 보유하고 있는 행운아가 아니라면, 다음과 같은 작업 중 하나 이상을 수행해야 할 수도 있습니다.</p>
<ul>
<li>다른 위치(예: 웹페이지나 서버)에서 데이터 다운로드</li>
<li>데이터베이스나 API(예: MySQL이나 Twitter)에서 데이터 쿼리</li>
<li>다른 파일(예: HTML 파일이나 스프레드시트)에서 데이터 추출</li>
<li>데이터 직접 생성(예: 센서 데이터 읽기나 설문 조사 수행)</li>
</ul>
<p><a href="#chapter-3-obtaining-data">3장</a>에서는 커맨드 라인을 사용하여 데이터를 획득하는 여러 가지 방법을 다룹니다.
획득한 데이터는 대부분 텍스트, CSV, JSON, HTML, XML 형식 중 하나일 것입니다.
다음 단계는 이 데이터를 정제하는 것입니다.</p>
</div>
<div id="데이터-정제-scrubbing-data" class="section level3" number="1.1.2">
<h3 number="1.1.2"><span class="header-section-number">1.1.2</span> 데이터 정제 (Scrubbing Data)</h3>
<p>획득한 데이터에 결측치, 불일치, 오류, 이상한 문자 또는 불필요한 열이 포함되어 있는 경우는 매우 흔합니다.
이 경우, 데이터로 무언가 흥미로운 작업을 하기 전에 데이터를 <em>정제(scrub)</em>하거나 깨끗하게(clean) 만들어야 합니다.
일반적인 정제 작업은 다음과 같습니다.</p>
<ul>
<li>행 필터링</li>
<li>특정 열 추출</li>
<li>값 치환</li>
<li>단어 추출</li>
<li>결측치 및 중복 처리</li>
<li>데이터를 한 형식에서 다른 형식으로 변환</li>
</ul>
<p>데이터 과학자로서 우리는 흥미로운 시각화와 통찰력 있는 모델을 만드는 것(3, 4단계)을 좋아하지만, 대개는 필요한 데이터를 먼저 획득하고 정제하는 데(1, 2단계) 훨씬 많은 노력을 들입니다.
<em>Data Jujitsu</em>에서<span class="citation"><a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></span> “어떤 데이터 프로젝트에서든 업무의 80%는 데이터를 청소하는 일이다”라고 언급했습니다.
<a href="#chapter-5-scrubbing-data">5장</a>에서는 커맨드 라인이 이러한 데이터 정제 작업을 완수하는 데 어떻게 도움이 되는지 보여줍니다.</p>
</div>
<div id="데이터-탐색-exploring-data" class="section level3" number="1.1.3">
<h3 number="1.1.3"><span class="header-section-number">1.1.3</span> 데이터 탐색 (Exploring Data)</h3>
<p>데이터를 정제했다면 이제 탐색할 준비가 되었습니다.
탐색을 통해 여러분은 데이터를 진정으로 알게 되므로 이 단계부터 흥미진진해집니다.
<a href="#chapter-7-exploring-data">7장</a>에서는 커맨드 라인을 사용하여 다음 작업을 수행하는 방법을 보여드립니다.</p>
<ul>
<li>데이터 살펴보기</li>
<li>데이터에서 통계량 도출</li>
<li>통찰력 있는 시각화 생성</li>
</ul>
<p><a href="#chapter-7-exploring-data">7장</a>에서 소개되는 커맨드 라인 도구에는 <code>csvstat</code><span class="citation"><a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></span>과 <code>rush</code><span class="citation"><a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></span>가 포함됩니다.</p>
</div>
<div id="데이터-모델링-modeling-data" class="section level3" number="1.1.4">
<h3 number="1.1.4"><span class="header-section-number">1.1.4</span> 데이터 모델링 (Modeling Data)</h3>
<p>데이터를 설명하거나 앞으로 일어날 일을 예측하고 싶다면, 데이터에 대한 통계 모델을 만들고 싶을 것입니다.
모델을 만드는 기법으로는 클러스터링, 분류, 회귀, 차원 축소 등이 있습니다.
커맨드 라인은 새로운 유형의 모델을 처음부터 프로그래밍하기에는 적합하지 않습니다.
하지만 커맨드 라인에서 모델을 빌드하는 것은 매우 유용합니다.
<a href="#chapter-9-modeling-data">9장</a>에서는 로컬에서 모델을 빌드하거나 API를 활용하여 클라우드에서 연산을 수행하는 여러 커맨드 라인 도구를 소개하겠습니다.</p>
</div>
<div id="데이터-해석-interpreting-data" class="section level3" number="1.1.5">
<h3 number="1.1.5"><span class="header-section-number">1.1.5</span> 데이터 해석 (Interpreting Data)</h3>
<p>OSEMN 모델의 마지막이자 어쩌면 가장 중요한 단계는 데이터를 해석하는 것입니다.
이 단계는 다음을 포함합니다.</p>
<ul>
<li>데이터에서 결론 도출</li>
<li>결과의 의미 평가</li>
<li>결과 공유 및 커뮤니케이션</li>
</ul>
<p>솔직히 말해서, 이 단계에서 컴퓨터의 역할은 거의 없으며 커맨드 라인도 딱히 개입할 여지가 없습니다.
일단 이 단계에 도달했다면, 그다음은 여러분에게 달려 있습니다.
이 장은 OSEMN 모델 중 유일하게 별도의 장이 없는 단계입니다.
대신<span class="citation"><a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></span> 명저 <em>Thinking with Data</em>를 참고하시길 권합니다.</p>
</div>
</div>
<div id="간주intermezzo-장들" class="section level2" number="1.2">
<h2 number="1.2"><span class="header-section-number">1.2</span> 간주(Intermezzo) 장들</h2>
<p>OSEMN 단계들을 다루는 장들 외에도 네 개의 간주(Intermezzo) 장이 있습니다.
각 장은 데이터 과학에 관한 보다 일반적인 주제와 이를 위해 커맨드 라인이 어떻게 사용되는지를 논의합니다.
이 주제들은 데이터 과학 프로세스의 어떤 단계에도 적용될 수 있습니다.</p>
<p><a href="#chapter-4-creating-command-line-tools">4장</a>에서는 커맨드 라인을 위한 재사용 가능한 도구를 만드는 방법을 다룹니다.
이런 개인용 도구는 커맨드 라인에 직접 입력했던 긴 명령어나 파이썬, R 등으로 작성했던 기존 코드에서 만들어질 수 있습니다.
직접 도구를 만들 수 있게 되면 효율성과 생산성이 크게 향상됩니다.</p>
<p>커맨드 라인은 데이터 과학을 위한 대화형 환경이기 때문에 전체 워크플로우를 추적하는 것이 어려울 수 있습니다.
<a href="#chapter-6-project-management-with-make">6장</a>에서는 작업과 작업 간의 의존성 관점에서 데이터 과학 워크플로우를 정의할 수 있게 해주는 <code>make</code>라는 커맨드 라인 도구를 소개합니다.
이 도구는 여러분뿐만 아니라 동료들의 워크플로우 재현성(reproducibility)을 높여줍니다.</p>
<p><a href="#chapter-8-parallel-pipelines">8장</a>에서는 명령어와 도구들을 병렬로 실행하여 속도를 높이는 방법을 설명합니다.
GNU Parallel<span class="citation"><a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></span>이라는 커맨드 라인 도구를 사용하면, 매우 큰 데이터셋에 도구들을 적용하고 여러 코어 또는 원격 머신에서 실행할 수 있습니다.</p>
<p><a href="#chapter-10-polyglot-data-science">10장</a>에서는 R, RStudio, 파이썬, Jupyter Notebook, 심지어 Apache Spark와 같은 다른 환경과 프로그래밍 언어에서 커맨드 라인의 힘을 활용하는 방법을 다룹니다.</p>
</div>
<div id="커맨드-라인이란-무엇인가" class="section level2" number="1.3">
<h2 number="1.3"><span class="header-section-number">1.3</span> 커맨드 라인이란 무엇인가?</h2>
<p>데이터 과학을 위해 왜 커맨드 라인을 사용해야 하는지 논의하기 전에, 커맨드 라인이 실제로 어떻게 생겼는지 잠시 살펴보겠습니다(이미 익숙하실 수도 있습니다).
Figure @ref(fig:mac-terminal)과 Figure @ref(fig:ubuntu-terminal)은 각각 macOS와 우분투에서 기본적으로 나타나는 커맨드 라인의 스크린샷입니다.
우분투는 GNU/리눅스의 특정 배포판이며, 이 책에서 제가 사용할 환경입니다.</p>
<p>두 스크린샷에 보이는 창을 <em>터미널(terminal)</em>이라고 부릅니다.
이것은 쉘(shell)과 상호작용할 수 있게 해주는 프로그램입니다.
그 쉘이 제가 입력한 명령어들을 실행합니다.
<a href="#chapter-2-getting-started">2장</a>에서 이 두 용어에 대해 더 자세히 설명하겠습니다.</p>

<div class="rmdnote">
마이크로소프트 윈도우의 커맨드 라인(명령 프롬프트 또는 PowerShell)은 이 책에서 제시하는 명령어들과 근본적으로 다르고 호환되지 않기 때문에 보여드리지 않습니다.
다행인 점은 윈도우에 Docker 이미지를 설치하여 내용을 따라올 수 있다는 것입니다.
Docker 이미지를 설치하는 방법은 <a href="#chapter-2-getting-started">2장</a>에서 설명합니다.
</div>
<p>명령어를 입력하는 것은 <em>그래픽 사용자 인터페이스</em>(GUI)를 통해 컴퓨터와 상호작용하는 것과는 매우 다른 방식입니다.
주로 마이크로소프트 엑셀 등으로 데이터를 처리하는 데 익숙하다면 이 방식이 처음에는 위협적으로 느껴질 수 있습니다.
두려워하지 마세요.
커맨드 라인 작업에 매우 빠르게 익숙해질 것이라는 제 말을 믿으셔도 좋습니다.</p>
<p>이 책에서 제가 입력하는 명령어와 그 결과물은 텍스트로 표시됩니다.
예를 들어, 두 스크린샷의 터미널 내용은 다음과 같이 보일 것입니다.</p>
<pre>whoami
date
echo 'The command line is awesome!' | cowsay -f tux</pre>
<p>또한 각 명령어 앞에 달러 표시(<strong><code>$</code></strong>)가 붙어 있는 것을 보실 수 있습니다.
이를 프롬프트(prompt)라고 부릅니다.
스크린샷의 프롬프트는 사용자 이름, 날짜, 펭귄 등 더 많은 정보를 보여주었습니다.
예제에서는 달러 표시만 보여주는 것이 관례인데, 그 이유는 프롬프트가 (1) 세션 중에 변경될 수 있고(디렉터리를 이동할 때), (2) 사용자가 커스터마이징할 수 있으며(예: 시간이나 현재 작업 중인 <code>git</code><span class="citation"><a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a></span> 브랜치를 표시할 수도 있음), (3) 명령어 자체와는 무관하기 때문입니다.</p>
<p>다음 장에서는 필수적인 커맨드 라인 개념들에 대해 훨씬 더 많이 설명하겠습니다.
이제 왜 데이터 과학을 위해 커맨드 라인을 배워야 하는지 먼저 알아볼 차례입니다.</p>
</div>
<div id="왜-커맨드-라인에서-데이터-과학을-하는가" class="section level2" number="1.4">
<h2 number="1.4"><span class="header-section-number">1.4</span> 왜 커맨드 라인에서 데이터 과학을 하는가?</h2>
<p>커맨드 라인은 여러분을 더 효율적이고 생산적인 데이터 과학자로 만들어 줄 수 있는 수많은 장점을 가지고 있습니다.
그 장점들을 크게 묶어보자면 커맨드 라인은 기민하고(agile), 보완적이며(augmenting), 확장 가능하고(scalable), 유연하며(extensible), 어디에나 존재(ubiquitous)합니다.
각 장점에 대해 아래에서 자세히 설명하겠습니다.</p>
<div id="커맨드-라인은-기민하다-agile" class="section level3" number="1.4.1">
<h3 number="1.4.1"><span class="header-section-number">1.4.1</span> 커맨드 라인은 기민하다 (Agile)</h3>
<p>커맨드 라인의 첫 번째 장점은 기민하게 움직일 수 있게 해준다는 점입니다.
데이터 과학은 매우 대화형이고 탐색적인 성격을 띠고 있으며, 여러분의 작업 환경도 이를 허용해야 합니다.
커맨드 라인은 두 가지 수단을 통해 이를 달성합니다.</p>
<p>첫째, 커맨드 라인은 소위 <em>반복적 실행 환경</em>(REPL: read-eval-print-loop)을 제공합니다.
이는 명령어를 입력하고 <strong><code>Enter</code></strong>를 누르면 명령이 즉시 평가된다는 의미입니다.
REPL은 스크립트, 대형 프로그램, Hadoop 작업 등에 수반되는 ‘편집-컴파일-실행-디버그’ 주기보다 데이터 과학을 수행하기에 훨씬 편리한 경우가 많습니다.
명령어는 즉시 실행되고, 마음대로 중단할 수 있으며, 빠르게 수정할 수 있습니다.
이러한 짧은 반복 주기는 데이터를 마음껏 다루어 볼 수 있게 해줍니다.</p>
<p>둘째, 커맨드 라인은 파일 시스템과 매우 밀접해 있습니다.
데이터가 데이터 과학의 주재료인 만큼, 데이터셋이 포함된 파일들을 쉽게 다룰 수 있는 것은 매우 중요합니다.
커맨드 라인은 이를 위한 수많은 편리한 도구들을 제공합니다.</p>
</div>
<div id="커맨드-라인은-보완적이다-augmenting" class="section level3" number="1.4.2">
<h3 number="1.4.2"><span class="header-section-number">1.4.2</span> 커맨드 라인은 보완적이다 (Augmenting)</h3>
<p>커맨드 라인은 다른 기술들과 잘 통합됩니다.
여러분의 데이터 과학 워크플로우가 현재 어떤 기술(R, 파이썬, 엑셀 등)을 포함하고 있든, 제가 그 워크플로우를 버리라고 제안하는 것이 아님을 알아주셨으면 합니다.
대신 커맨드 라인을 여러분이 현재 사용하는 기술들을 증폭시켜 주는 보완적인 기술로 생각해보세요.
이는 세 가지 방식으로 이루어질 수 있습니다.</p>
<p>첫째, 커맨드 라인은 서로 다른 많은 데이터 과학 도구들 사이의 접착제 역할을 할 수 있습니다.
도구들을 연결하는 한 가지 방법은 첫 번째 도구의 출력을 두 번째 도구의 입력으로 연결하는 것입니다.
<a href="#chapter-2-getting-started">2장</a>에서 이것이 어떻게 작동하는지 설명합니다.</p>
<p>둘째, 여러분의 작업 환경 내에서 작업의 일부를 커맨드 라인에 위임할 수 있습니다.
예를 들어 파이썬, R, Apache Spark에서는 커맨드 라인 도구를 실행하고 그 결과를 캡처할 수 있습니다.
<a href="#chapter-10-polyglot-data-science">10장</a>에서 예제와 함께 이를 보여드립니다.</p>
<p>셋째, 여러분의 코드(예: 파이썬이나 R 스크립트)를 재사용 가능한 커맨드 라인 도구로 변환할 수 있습니다.
그렇게 되면 그 도구가 어떤 언어로 작성되었는지는 더 이상 중요하지 않게 됩니다.
이제 커맨드 라인에서 직접 사용하거나, 앞서 언급한 대로 커맨드 라인과 통합되는 어떤 환경에서도 해당 도구를 사용할 수 있습니다.
<a href="#chapter-4-creating-command-line-tools">4장</a>에서 그 방법을 설명합니다.</p>
<p>결국 모든 기술에는 강점과 약점이 있으므로, 여러 가지를 알고 상황에 가장 적합한 것을 골라 쓰는 것이 좋습니다.
때로는 그것이 R일 수도 있고, 때로는 커맨드 라인일 수도 있으며, 때로는 펜과 종이일 수도 있습니다.
이 책을 마칠 때쯤이면 여러분은 언제 커맨드 라인을 사용해야 할지, 그리고 언제 즐겨 쓰는 프로그래밍 언어나 통계 컴퓨팅 환경을 계속 사용하는 것이 나을지에 대해 확고한 이해를 갖게 될 것입니다.</p>
</div>
<div id="커맨드-라인은-확장-가능하다-scalable" class="section level3" number="1.4.3">
<h3 number="1.4.3"><span class="header-section-number">1.4.3</span> 커맨드 라인은 확장 가능하다 (Scalable)</h3>
<p>앞서 말씀드렸듯이 커맨드 라인에서 작업하는 것은 GUI를 사용하는 것과 매우 다릅니다.
커맨드 라인에서는 타이핑을 통해 무언가를 하는 반면, GUI에서는 마우스로 가리키고 클릭함으로써 작업을 수행합니다.</p>
<p>커맨드 라인에서 수동으로 입력하는 모든 것은 스크립트와 도구를 통해 자동화될 수 있습니다.
덕분에 실수를 했거나, 입력 데이터가 바뀌었거나, 동료가 같은 분석을 수행하고 싶어 할 때 명령어를 다시 실행하기가 매우 쉬워집니다.
게다가 명령어는 특정 간격으로, 원격 서버에서, 그리고 데이터의 수많은 조각에 대해 병렬로 실행될 수 있습니다(<a href="#chapter-8-parallel-pipelines">8장</a>에서 더 자세히 다룹니다).</p>
<p>커맨드 라인은 자동화가 가능하기 때문에 확장성과 반복성을 갖게 됩니다.
가리키고 클릭하는 동작을 자동화하는 것은 쉽지 않으며, 이 때문에 GUI는 확장 가능하고 반복적인 데이터 과학을 하기에 덜 적합한 환경입니다.</p>
</div>
<div id="커맨드-라인은-유연하다-extensible" class="section level3" number="1.4.4">
<h3 number="1.4.4"><span class="header-section-number">1.4.4</span> 커맨드 라인은 유연하다 (Extensible)</h3>
<p>커맨드 라인 자체는 50년도 더 전에 발명되었습니다.
핵심 기능은 대체로 변하지 않았지만, 커맨드 라인의 핵심 일꾼들인 <em>도구들</em>은 매일같이 개발되고 있습니다.</p>
<p>커맨드 라인 그 자체는 언어에 종속되지 않습니다(language-agnostic).
덕분에 커맨드 라인 도구들은 수많은 서로 다른 프로그래밍 언어로 작성될 수 있습니다.
오픈 소스 커뮤니티는 우리가 데이터 과학을 위해 사용할 수 있는 수많은 무료 고품질 커맨드 라인 도구들을 내놓고 있습니다.</p>
<p>이러한 커맨드 라인 도구들은 서로 협력할 수 있으며, 이는 커맨드 라인을 매우 유연하게 만듭니다.
또한 여러분만의 도구를 만들 수도 있어 커맨드 라인의 실질적인 기능을 확장할 수 있습니다.</p>
</div>
<div id="커맨드-라인은-어디에나-존재한다-ubiquitous" class="section level3" number="1.4.5">
<h3 number="1.4.5"><span class="header-section-number">1.4.5</span> 커맨드 라인은 어디에나 존재한다 (Ubiquitous)</h3>
<p>커맨드 라인은 우분투 리눅스와 macOS를 포함한 모든 유닉스 계열 운영체제에 포함되어 있어 많은 곳에서 찾아볼 수 있습니다.
게다가 전 세계 상위 500대 슈퍼컴퓨터의 100%가 리눅스를 사용하고 있습니다.<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>
따라서 혹시라도 그런 슈퍼컴퓨터 중 하나를 만져볼 기회가 생긴다면(혹은 쥬라기 공원에서 문 잠금 장치가 작동하지 않는 상황에 처한다면), 커맨드 라인 사용법을 잘 알고 있는 편이 좋을 것입니다!</p>
<p>하지만 리눅스는 슈퍼컴퓨터에서만 돌아가는 것이 아닙니다.
서버, 노트북, 그리고 임베디드 시스템에서도 돌아갑니다.
요즘 많은 기업들이 클라우드 컴퓨팅을 제공하며, 즉석에서 새로운 머신을 쉽게 실행할 수 있습니다.
그런 머신(또는 일반적인 서버)에 접속하게 된다면, 거의 확실하게 커맨드 라인을 마주하게 될 것입니다.</p>
<p>또한 커맨드 라인이 단순히 일시적인 유행이 아니라는 점에 주목하는 것도 중요합니다.
이 기술은 50년 넘게 존재해 왔으며, 앞으로 50년 동안도 계속될 것이라고 확신합니다.
따라서 (데이터 과학을 위해서든 일반적인 용도를 위해서든) 커맨드 라인 사용법을 배우는 것은 투자할 만한 가치가 있는 일입니다.</p>
</div>
</div>
<div id="요약" class="section level2" number="1.5">
<h2 number="1.5"><span class="header-section-number">1.5</span> 요약</h2>
<p>이 장에서는 책 전체의 가이드로 사용할 데이터 과학을 위한 OSEMN 모델을 소개했습니다.
유닉스 커맨드 라인에 대한 몇 가지 배경 지식을 제공했으며, 커맨드 라인이 데이터 과학을 수행하기에 적합한 환경임을 납득해 주셨기를 바랍니다.
다음 장에서는 데이터셋과 도구들을 설치하고 기본적인 개념들을 설명하며 본격적으로 시작해보겠습니다.</p>
</div>
<div id="더-읽을거리" class="section level2" number="1.6">
<h2 number="1.6"><span class="header-section-number">1.6</span> 더 읽을거리</h2>
<ul>
<li>브라이언 커니핸(Brian W. Kernighan)의 저서 <em>UNIX: A History and a Memoir</em>는 유닉스가 무엇인지, 어떻게 개발되었는지, 그리고 왜 중요한지에 대한 이야기를 들려줍니다.</li>
<li>2018년 런던 Strata에서 저는 <em>50 Reasons to Learn the Shell for Doing Data Science</em>라는 제목으로 발표했습니다. 더 많은 설득이 필요하다면 <a href="https://datascienceatthecommandline.com/resources/50-reasons.pdf">슬라이드</a>를 읽어보세요.</li>
<li>Max Shron의 짧지만 알찬 책 <em>Thinking with Data</em>는 ’어떻게’보다 ’왜’에 집중하여, 올바른 질문을 던지고 올바른 문제를 해결하는 데 도움이 될 데이터 과학 프로젝트 정의를 위한 프레임워크를 제공합니다.</li>
</ul>
<!--chapter:end:01.Rmd-->
</div>
</div>
<div id="chapter-2-getting-started" class="section level1" number="2">
<h1 number="2"><span class="header-section-number">2</span> 시작하기</h1>
<p>이 장에서는 커맨드 라인에서 데이터 과학을 수행하기 위한 모든 전제 조건이 갖춰졌는지 확인할 것입니다.
전제 조건은 세 부분으로 나뉩니다. (1) 이 책에서 사용하는 것과 동일한 데이터셋 확보, (2) 이 책 전체에서 사용하는 모든 커맨드 라인 도구가 포함된 적절한 환경 구축, (3) 커맨드 라인을 사용할 때 작용하는 필수적인 개념들에 대한 이해입니다.</p>
<p>먼저 데이터셋을 다운로드하는 방법을 설명합니다.
둘째로, 필요한 모든 커맨드 라인 도구를 포함하고 있는 우분투 리눅스 기반 가상 환경인 Docker 이미지를 설치하는 방법을 설명합니다.
그다음에는 예제를 통해 필수적인 유닉스 개념들을 살펴볼 것입니다.</p>
<p>이 장을 마칠 때쯤이면 여러분은 데이터 과학의 첫 번째 단계인 데이터 획득을 계속하는 데 필요한 모든 것을 갖추게 될 것입니다.</p>
<div id="데이터-확보하기" class="section level2" number="2.1">
<h2 number="2.1"><span class="header-section-number">2.1</span> 데이터 확보하기</h2>
<p>이 책에서 사용하는 데이터셋은 다음과 같이 다운로드할 수 있습니다.</p>
<ol style="list-style-type: decimal">
<li><a href="https://www.datascienceatthecommandline.com/2e/data.zip" class="uri">https://www.datascienceatthecommandline.com/2e/data.zip</a> 에서 ZIP 파일을 다운로드합니다.</li>
<li>새 디렉터리를 만듭니다. 이름은 원하는 대로 지어도 되지만, 커맨드 라인에서 작업하기 편하도록 소문자, 숫자, 하이픈(-) 또는 언더스코어(_)만 사용하는 것을 권장합니다. 예를 들어 <em>dsatcl2e-data</em>와 같이 지을 수 있습니다. 이 디렉터리의 위치를 기억해 두세요.</li>
<li>ZIP 파일을 해당 디렉터리로 옮기고 압축을 풉니다.</li>
<li>이제 이 디렉터리에는 각 장별로 하나의 하위 디렉터리가 들어 있게 됩니다.</li>
</ol>
<p>다음 절에서는 이 데이터를 다루기 위한 모든 커맨드 라인 도구가 포함된 환경을 설치하는 방법을 설명합니다.</p>
</div>
<div id="docker-image" class="section level2" number="2.2">
<h2 number="2.2"><span class="header-section-number">2.2</span> Docker 이미지 설치하기</h2>
<p>이 책에서는 매우 다양한 커맨드 라인 도구를 사용합니다.
유닉스에는 이미 많은 도구가 기본으로 설치되어 있고, 관련 도구들을 포함하는 많은 패키지들도 제공됩니다.
이러한 패키지들을 직접 설치하는 것이 그리 어렵지는 않습니다.
하지만 패키지로 제공되지 않아 수동으로 복잡하게 설치해야 하는 도구들도 사용하게 될 것입니다.
일일이 설치 과정을 거치지 않고 필요한 도구들을 한꺼번에 갖추기 위해, 여러분이 윈도우, macOS, 리눅스 중 어떤 운영체제를 사용하든 이 책을 위해 특별히 제작된 Docker 이미지를 설치하시길 강력히 권장합니다.</p>
<p>Docker 이미지는 하나 이상의 애플리케이션과 그에 필요한 모든 의존성을 하나로 묶은 것입니다.
Docker 컨테이너는 이미지를 실행하는 격리된 환경입니다.
이후에 수행할 것처럼 <code>docker</code> 커맨드 라인 도구를 사용하거나 Docker GUI를 통해 이미지와 컨테이너를 관리할 수 있습니다.
어떤 면에서 Docker 컨테이너는 가상 머신과 비슷하지만, 자원을 훨씬 적게 사용합니다.
이 장의 끝에서 Docker에 대해 더 배울 수 있는 자료들을 제안하겠습니다.</p>

<div class="rmdtip">
Docker 컨테이너 내부가 아닌 로컬 환경에서 직접 커맨드 라인 도구들을 실행하고 싶다면, 물론 도구들을 개별적으로 직접 설치하셔도 됩니다.
다만 이 과정은 매우 많은 시간이 소요된다는 점을 유의해 주세요.
부록에 이 책에서 사용된 모든 커맨드 라인 도구의 목록이 있습니다.
설치 안내는 우분투 기준으로만 되어 있습니다.
책에서 사용된 스크립트와 데이터셋은 이 책의 <a href="https://github.com/datasciencetoolbox/datasciencetoolbox">GitHub 저장소</a>를 클론하여 얻을 수 있습니다.
</div>
<p>Docker 이미지를 설치하려면 먼저 <a href="https://www.docker.com/products/docker">Docker 웹사이트</a>에서 Docker를 다운로드하여 설치해야 합니다.
Docker가 설치되면 터미널(또는 명령 프롬프트)에서 다음 명령어를 입력하여 Docker 이미지를 다운로드합니다(달러 표시는 입력하지 마세요).</p>
<pre>docker pull datasciencetoolbox/dsatcl2e#! enter=FALSE</pre>
<p>Docker 이미지는 다음과 같이 실행할 수 있습니다.</p>
<pre>docker run --rm -it datasciencetoolbox/dsatcl2e#! enter=FALSE</pre>
<p>이제 필요한 모든 커맨드 라인 도구가 설치된 격리된 환경(<em>Docker 컨테이너</em>라고 불립니다) 내부에 들어와 있습니다.
다음 명령어를 입력했을 때 열정적인 소 한 마리가 나타난다면 모든 것이 제대로 작동하는 것입니다.</p>
<pre>cowsay "Let's moove\!"</pre>
<p>컨테이너 안팎으로 데이터를 주고받으려면 볼륨(volume)을 추가하여 로컬 디렉터리를 컨테이너 내부의 디렉터리에 매핑할 수 있습니다.
먼저 새로운 디렉터리를 만들고 해당 디렉터리로 이동한 뒤, macOS나 리눅스라면 다음 명령어를 실행하는 것을 추천합니다.</p>
<pre>docker run --rm -it -v "$(pwd)":/data datasciencetoolbox/dsatcl2e#! enter=FALSE</pre>
<p>윈도우에서 명령 프롬프트(<code>cmd</code>)를 사용 중이라면 다음과 같이 입력합니다.</p>
<pre>C:\&gt; docker run --rm -it -v "%cd%":/data datasciencetoolbox/dsatcl2e</pre>
<p>윈도우 PowerShell을 사용 중이라면 다음과 같이 입력합니다.</p>
<pre>PS C:\&gt; docker run --rm -it -v ${PWD}:/data datasciencetoolbox/dsatcl2e</pre>
<p>위의 명령어에서 <code>-v</code> 옵션은 <code>docker</code>에게 현재 디렉터리를 컨테이너 내부의 <em>/data</em> 디렉터리로 매핑하도록 지시합니다. 따라서 이곳이 Docker 컨테이너 안팎으로 데이터를 주고받는 통로가 됩니다.</p>

<div class="rmdnote">
Docker 이미지에 대해 더 자세히 알고 싶다면 <a href="https://hub.docker.com/r/datasciencetoolbox/dsatcl2e">Docker Hub 페이지</a>를 방문해 보세요.
</div>
<p>작업을 마쳤다면 <code>exit</code>를 입력하여 Docker 컨테이너를 종료할 수 있습니다.</p>
</div>
<div id="essential-concepts" class="section level2" number="2.3">
<h2 number="2.3"><span class="header-section-number">2.3</span> 필수 유닉스 개념</h2>
<p><a href="#chapter-1-introduction">1장</a>에서 커맨드 라인이 무엇인지 잠시 보여드렸습니다.
이제 여러분은 Docker 이미지를 실행하고 있으니, 본격적으로 시작할 수 있습니다.
이 절에서는 커맨드 라인에서 데이터 과학을 편안하게 수행하기 위해 꼭 알아야 할 몇 가지 개념과 도구들을 다룹니다.
지금까지 주로 그래픽 사용자 인터페이스(GUI)로 작업해 오셨다면 상당한 변화로 느껴질 수 있습니다.
하지만 걱정하지 마세요. 기초부터 시작해서 점진적으로 더 고급 주제로 나아갈 것입니다.</p>

<div class="rmdnote">
이 절은 유닉스에 대한 완전한 교육 과정이 아닙니다.
데이터 과학을 수행하는 데 꼭 필요한 개념과 도구들만 설명하겠습니다.
Docker 이미지의 장점 중 하나는 이미 많은 것들이 설정되어 있다는 점입니다.
더 자세히 알고 싶다면 이 장의 끝에 있는 ‘더 읽을거리’ 절을 참고해 주세요.
</div>
<div id="환경-the-environment" class="section level3" number="2.3.1">
<h3 number="2.3.1"><span class="header-section-number">2.3.1</span> 환경 (The Environment)</h3>
<p>여러분은 이제 막 새로운 환경에 로그인했습니다.
무언가를 시작하기 전에, 이 환경에 대해 전반적으로 이해하는 것이 좋습니다.
환경은 대략 네 개의 계층으로 정의되며, 위에서 아래 방향으로 간단히 살펴보겠습니다.</p>
<dl>
<dt>커맨드 라인 도구 (Command-line tools)</dt>
<dd><p>가장 먼저 여러분이 직접 다루게 될 커맨드 라인 도구들이 있습니다.
이 도구들은 해당 명령어를 입력하여 사용합니다.
커맨드 라인 도구에는 여러 유형이 있으며, 이에 대해서는 다음 절에서 자세히 다루겠습니다.
도구의 예로는 <code>ls</code><span class="citation"><a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a></span>, <code>cat</code><span class="citation"><a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a></span>, <code>jq</code><span class="citation"><a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a></span> 등이 있습니다.</p>
</dd>
<dt>터미널 (Terminal)</dt>
<dd><p>두 번째 계층인 터미널은 명령어를 입력하는 애플리케이션입니다. 책에서 다음과 같은 텍스트를 보게 된다면:</p>
<pre>seq 3</pre>
<p>터미널에 <code>seq 3</code>이라고 입력하고 <strong><code>Enter</code></strong>를 누르면 됩니다.
(커맨드 라인 도구 <code>seq</code><span class="citation"><a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a></span>는 보시다시피 일련의 숫자들을 생성합니다.) 달러 표시는 입력하지 않습니다.
그것은 단지 터미널에 입력할 수 있는 명령어임을 알려주는 표시일 뿐입니다.
이 달러 표시를 프롬프트(prompt)라고 부릅니다.
<code>seq 3</code> 아래에 있는 텍스트는 해당 명령어의 출력 결과입니다.</p>
</dd>
<dt>쉘 (Shell)</dt>
<dd><p>세 번째 계층은 쉘입니다. 명령어를 입력하고 <strong><code>Enter</code></strong>를 누르면 터미널은 그 명령어를 쉘로 보냅니다. <em>쉘</em>은 명령어를 해석하는 프로그램입니다. 저는 Z 쉘(Zsh)을 사용하지만, Bash나 Fish와 같은 다른 쉘들도 많이 있습니다.</p>
</dd>
<dt>운영체제 (Operating system)</dt>
<dd><p>네 번째 계층은 운영체제이며, 우리의 경우에는 GNU/리눅스입니다. 리눅스는 커널(kernel)의 이름으로, 운영체제의 심장과 같습니다. 커널은 CPU, 디스크 등 하드웨어와 직접 소통합니다. 또한 커널은 우리의 커맨드 라인 도구들을 실행합니다. GNU(GNU’s not UNIX의 약자)는 기본적인 도구들의 모음을 의미합니다. 우리가 사용하는 Docker 이미지는 우분투라는 특정 GNU/리눅스 배포판을 기반으로 합니다.</p>
</dd>
</dl>
</div>
<div id="커맨드-라인-도구-실행하기" class="section level3" number="2.3.2">
<h3 number="2.3.2"><span class="header-section-number">2.3.2</span> 커맨드 라인 도구 실행하기</h3>
<p>이제 환경에 대한 기본적인 이해가 생겼으니, 직접 명령어를 실행해 볼 차례입니다.
터미널에 다음을 입력하고(달러 표시 제외) <strong><code>Enter</code></strong>를 누르세요.</p>
<pre>pwd</pre>
<p>여러분은 방금 하나의 커맨드 라인 도구를 포함하는 명령어를 실행했습니다.
<code>pwd</code><span class="citation"><a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a></span> 도구는 현재 여러분이 위치한 디렉터리의 이름을 출력합니다.
로그인했을 때의 기본 위치는 홈 디렉터리입니다.</p>
<p>Z 쉘 내장 명령어인 <code>cd</code> 도구를 사용하면 다른 디렉터리로 이동할 수 있습니다.</p>
<pre>cd /data/ch02
pwd
cd ..
pwd
cd ch02</pre>
<p><span class="callout">&#10122;</span> <em>/data/ch02</em> 디렉터리로 이동합니다.
<br><span class="callout">&#10123;</span> 현재 디렉터리를 출력합니다.
<br><span class="callout">&#10124;</span> 상위 디렉터리로 이동합니다.
<br><span class="callout">&#10125;</span> 다시 현재 디렉터리를 출력합니다.
<br><span class="callout">&#10126;</span> 하위 디렉터리 <em>ch02</em>로 이동합니다.</p>
<p><code>cd</code> 뒤에 오는 부분은 이동하고자 하는 디렉터리를 지정합니다.
명령어 뒤에 오는 값들을 <em>커맨드 라인 인자(arguments)</em> 또는 <em>옵션(options)</em>이라고 부릅니다.
마침표 두 개(<code>..</code>)는 상위 디렉터리를 의미합니다.
참고로 마침표 하나(<code>.</code>)는 현재 디렉터리를 의미합니다.
<code>cd .</code>은 아무런 효과가 없겠지만, 마침표 하나가 다른 곳에서 쓰이는 것을 보게 될 것입니다.
다른 명령어를 시도해 봅시다.</p>
<pre>head -n 3 movies.txt</pre>
<p>여기서는 <code>head</code><span class="citation"><a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a></span>에 세 개의 커맨드 라인 인자를 전달했습니다.
첫 번째는 옵션입니다. 여기서는 짧은 옵션인 <code>-n</code>을 사용했습니다.
가끔 짧은 옵션은 긴 형태의 변형을 가지기도 하는데, 이 경우 <code>--lines</code>가 됩니다.
두 번째는 해당 옵션에 속하는 값입니다.
세 번째는 파일 이름입니다.
이 명령어는 <em>/data/ch02/movies.txt</em> 파일의 처음 세 줄을 출력합니다.</p>
</div>
<div id="다섯-가지-유형의-커맨드-라인-도구" class="section level3" number="2.3.3">
<h3 number="2.3.3"><span class="header-section-number">2.3.3</span> 다섯 가지 유형의 커맨드 라인 도구</h3>
<p>저는 ’커맨드 라인 도구’라는 용어를 많이 사용하지만, 지금까지 실제로 그것이 무엇을 의미하는지는 설명하지 않았습니다.
저는 이 용어를 커맨드 라인에서 실행할 수 있는 <em>모든 것</em>을 가리키는 포괄적인 용어로 사용합니다(@ref(fig:umbrella) 참고).
내부적으로 각 커맨드 라인 도구는 다음 다섯 가지 유형 중 하나에 속합니다.</p>
<ul>
<li>바이너리 실행 파일 (Binary executable)</li>
<li>쉘 내장 명령어 (Shell builtin)</li>
<li>해석되는 스크립트 (Interpreted script)</li>
<li>쉘 함수 (Shell function)</li>
<li>별칭 (Alias)</li>
</ul>
<p>각 유형 간의 차이를 아는 것이 좋습니다.
Docker 이미지에 미리 설치된 커맨드 라인 도구들은 대부분 처음 두 가지 유형(바이너리 실행 파일과 쉘 내장 명령어)으로 구성됩니다.
나머지 세 유형(해석되는 스크립트, 쉘 함수, 별칭)은 우리의 데이터 과학 도구 상자를 더욱 확장하고, 우리가 더 효율적이고 생산적인 데이터 과학자가 될 수 있게 해줍니다.</p>
<dl>
<dt>바이너리 실행 파일 (Binary Executable)</dt>
<dd><p>바이너리 실행 파일은 고전적인 의미의 프로그램입니다. 바이너리 실행 파일은 소스 코드를 기계어로 컴파일하여 만들어집니다. 즉, 텍스트 에디터로 파일을 열어도 내용을 읽을 수 없습니다.</p>
</dd>
<dt>쉘 내장 명령어 (Shell Builtin)</dt>
<dd><p>쉘 내장 명령어는 쉘(우리 환경에서는 Z 쉘 또는 <code>zsh</code>)이 제공하는 커맨드 라인 도구입니다. <code>cd</code>와 <code>pwd</code>가 그 예입니다. 내장 명령어는 쉘마다 다를 수 있습니다. 바이너리 실행 파일과 마찬가지로 내용을 쉽게 검사하거나 변경할 수 없습니다.</p>
</dd>
<dt>해석되는 스크립트 (Interpreted Script)</dt>
<dd><p>해석되는 스크립트는 바이너리 실행 파일에 의해 실행되는 텍스트 파일입니다. 파이썬, R, Bash 스크립트 등이 예입니다. 해석되는 스크립트의 큰 장점은 직접 읽고 수정할 수 있다는 것입니다. 아래의 스크립트가 파이썬에 의해 해석되는 이유는 확장자가 <em>.py</em>이기 때문이 아니라, 스크립트의 첫 번째 줄이 이를 실행해야 할 바이너리를 정의하고 있기 때문입니다.</p>
<pre>bat fac.py</pre>
<p>이 스크립트는 매개변수로 전달한 정수의 팩토리얼을 계산합니다. 커맨드 라인에서 다음과 같이 호출할 수 있습니다.</p>
<pre>./fac.py 5</pre>
<p><a href="#chapter-4-creating-command-line-tools">4장</a>에서는 해석되는 스크립트를 사용하여 재사용 가능한 커맨드 라인 도구를 만드는 방법을 아주 자세히 다룰 것입니다.</p>
</dd>
<dt>쉘 함수 (Shell Function)</dt>
<dd><p>쉘 함수는 우리 환경의 경우 <code>zsh</code>에 의해 실행되는 함수입니다. 스크립트와 유사한 기능을 제공하지만, 대개 스크립트보다는 크기가 작습니다(꼭 그래야 하는 것은 아니지만요). 또한 더 개인적인 용도로 쓰이는 경향이 있습니다. 다음 명령어는 <code>fac</code>이라는 함수를 정의하는데, 앞서 본 파이썬 스크립트와 마찬가지로 전달된 정수의 팩토리얼을 계산합니다. 이 함수는 <code>seq</code>로 숫자 목록을 생성하고, <code>paste</code><span class="citation"><a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a></span>를 사용해 숫자들 사이에 <code>*</code>를 넣어 한 줄로 만든 뒤, 이를 계산하여 결과를 출력하는 <code>bc</code><span class="citation"><a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a></span>로 전달함으로써 작동합니다.</p>
<pre>fac() { (echo 1; seq $1) | paste -s -d\* - | bc; }
fac 5</pre>
<p>Z 쉘의 설정 파일인 <em>~/.zshrc</em>는 쉘 함수를 정의하기에 좋은 곳입니다. 그렇게 하면 함수를 항상 사용할 수 있습니다.</p>
</dd>
<dt>별칭 (Alias)</dt>
<dd><p>별칭은 매크로와 같습니다. 어떤 명령어를 항상 같은 매개변수와 함께(혹은 명령어의 일부를) 실행하게 된다면, 시간을 아끼기 위해 별칭을 정의할 수 있습니다. 별칭은 특정 명령어를 계속 오타 낼 때도 매우 유용합니다(Chris Wiggins가 관리하는 <a href="https://github.com/chrishwiggins/mise/blob/master/sh/aliases-public.sh">유용한 별칭 목록</a>을 참고하세요). 다음 명령어는 그러한 별칭을 정의합니다.</p>
<pre>alias l='ls --color -lhF --group-directories-first'
alias les=less</pre>
<p>이제 커맨드 라인에 다음과 같이 입력하면, 쉘은 발견한 각 별칭을 해당 값으로 대체합니다.</p>
<pre>cd /data
l
cd ch02</pre>
<p>별칭은 매개변수를 허용하지 않으므로 쉘 함수보다 단순합니다. 앞서 정의한 <code>fac</code> 함수는 매개변수 때문에 별칭으로 정의할 수 없었습니다. 그럼에도 별칭은 수많은 키 입력을 줄여줍니다. 쉘 함수와 마찬가지로 별칭도 대개 홈 디렉터리에 있는 <em>.zshrc</em> 파일에 정의합니다. 현재 정의된 모든 별칭을 보려면 인자 없이 <code>alias</code>를 실행해 보세요. 무엇이 보이나요?</p>
</dd>
</dl>
<p>이 책에서는 마지막 세 가지 유형인 해석되는 스크립트, 쉘 함수, 별칭에 주로 집중할 것입니다.
이들은 쉽게 변경할 수 있기 때문입니다.
커맨드 라인 도구의 목적은 여러분의 삶을 편하게 만들고, 여러분을 더 생산적이고 효율적인 데이터 과학자로 만드는 것입니다.
명령어 <code>type</code>(그 자체로 쉘 내장 명령어입니다)을 사용하여 커맨드 라인 도구의 유형을 확인할 수 있습니다.</p>
<pre>type -a pwd
type -a cd
type -a fac
type -a l</pre>
<p><code>type</code>은 <code>pwd</code>에 대해 세 개의 커맨드 라인 도구를 반환합니다.
이 경우, 여러분이 <code>pwd</code>를 입력하면 목록에서 가장 먼저 보고된 도구가 사용됩니다.
다음 절에서는 커맨드 라인 도구들을 조합하는 방법을 살펴보겠습니다.</p>
</div>
<div id="combining-command-line-tools" class="section level3" number="2.3.4">
<h3 number="2.3.4"><span class="header-section-number">2.3.4</span> 커맨드 라인 도구 조합하기</h3>
<p>대부분의 커맨드 라인 도구는 유닉스 철학<span class="citation"><a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a></span>을 따르기 때문에, 한 가지 작업만 아주 잘하도록 설계되어 있습니다.
예를 들어, <code>grep</code><span class="citation"><a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a></span> 도구는 행을 필터링할 수 있고, <code>wc</code><span class="citation"><a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a></span>는 행의 개수를 셀 수 있으며, <code>sort</code><span class="citation"><a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a></span>는 행을 정렬할 수 있습니다.
커맨드 라인의 진정한 힘은 작지만 강력한 이러한 도구들을 조합하는 능력에서 나옵니다.</p>
<p>이러한 힘은 도구들 사이의 통신 스트림(communication streams)을 관리함으로써 가능해집니다.
각 도구는 세 가지 표준 통신 스트림을 가집니다: 표준 입력(standard input), 표준 출력(standard output), 표준 오류(standard error).
이들은 종종 <em><code>stdin</code></em>, <em><code>stdout</code></em>, <em><code>stderr</code></em>로 줄여서 부릅니다.</p>
<p>표준 출력과 표준 오류는 모두 기본적으로 터미널로 연결되어 있어, 일반적인 결과와 오류 메시지가 모두 화면에 출력됩니다.
Figure @ref(fig:diagram-essential-streams)는 <code>pwd</code>와 <code>rev</code><span class="citation"><a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a></span>를 예로 들어 이를 설명합니다.
<code>rev</code>를 실행하면 아무 일도 일어나지 않는 것을 볼 수 있습니다.
그 이유는 <code>rev</code>가 입력을 기다리고 있기 때문이며, 기본적으로는 키보드로 입력하는 값들이 입력값이 됩니다.
문장을 하나 입력하고 <strong><code>Enter</code></strong>를 눌러 보세요.
<code>rev</code>는 즉시 여러분의 입력을 거꾸로 뒤집어 응답할 것입니다.
입력 전송을 중단하려면 <strong><code>Ctrl-D</code></strong>를 누르면 되며, 그러면 <code>rev</code>가 멈춥니다.</p>
<p>실제로 여러분은 키보드를 입력 소스로 쓰기보다는, 다른 도구가 생성한 출력물이나 파일의 내용을 입력으로 사용하게 될 것입니다.
예를 들어 <code>curl</code>을 사용하여 루이스 캐럴의 <em>이상한 나라의 앨리스</em>를 다운로드하고, 그 결과를 다음 도구로 <em>파이프(pipe)</em>할 수 있습니다.
(<code>curl</code>에 대해서는 <a href="#chapter-3-obtaining-data">3장</a>에서 더 자세히 다룰 것입니다.)
도구 연결은 파이프 연산자(<code>|</code>)를 사용하여 수행합니다.</p>
<p>우리는 <code>curl</code>의 출력을 <code>grep</code>으로 <em>파이프</em>하여 특정 패턴으로 행을 필터링할 수 있습니다.
목차에 나열된 장(chapter) 목록을 보고 싶다고 가정해 봅시다.
다음과 같이 <code>curl</code>과 <code>grep</code>을 조합할 수 있습니다.</p>
<pre>curl -s "https://www.gutenberg.org/files/11/11-0.txt" | grep " CHAPTER"</pre>
<p>그리고 이 책에 <em>몇 개의</em> 장이 있는지 알고 싶다면, 개수를 세는 데 탁월한 <code>wc</code>를 사용할 수 있습니다.</p>
<pre>curl -s "https://www.gutenberg.org/files/11/11-0.txt" |
grep " CHAPTER" |
wc -l</pre>
<p><span class="callout">&#10122;</span> <code>-l</code> 옵션은 <code>wc</code>가 입력받은 행의 수만 출력하도록 지정합니다. 기본적으로는 글자 수와 단어 수도 함께 반환합니다.</p>
<p>파이프 연결은 자동화된 복사 및 붙여넣기라고 생각해도 좋습니다.
파이프 연산자를 사용해 도구들을 조합하는 요령을 터득하고 나면, 그 활용 가능성이 무궁무진하다는 것을 깨닫게 될 것입니다.</p>
</div>
<div id="입력과-출력-리다이렉션-redirecting-input-and-output" class="section level3" number="2.3.5">
<h3 number="2.3.5"><span class="header-section-number">2.3.5</span> 입력과 출력 리다이렉션 (Redirecting Input and Output)</h3>
<p>한 도구의 출력을 다른 도구로 파이프하는 것 외에도, 파일로 저장할 수 있습니다.
전체 경로를 지정하지 않으면 파일은 현재 디렉터리에 저장됩니다.
이것을 <em>출력 리다이렉션(output redirection)</em>이라고 하며, 다음과 같이 작동합니다.</p>
<pre>curl "https://www.gutenberg.org/files/11/11-0.txt" | grep " CHAPTER" &gt; chapters.txt
cat chapters.txt</pre>
<p>여기서는 <code>grep</code>의 출력을 <em>/data/ch02</em> 디렉터리에 <em>chapters.txt</em>라는 이름의 파일로 저장합니다.
파일이 아직 없으면 새로 생성됩니다. 이미 파일이 존재한다면 그 내용은 덮어쓰여집니다.
Figure @ref(fig:diagram-essential-redirect-stdout)는 출력 리다이렉션의 개념을 보여줍니다.
표준 오류는 여전히 터미널로 연결되어 있음에 유의하세요.</p>
<p>출력을 기존 파일 내용 뒤에 덧붙이려면 <code>&gt;&gt;</code>를 사용합니다.</p>
<pre>echo -n "Hello" &gt; greeting.txt
echo " World" &gt;&gt; greeting.txt</pre>
<p><code>echo</code> 도구는 지정한 값을 출력합니다.
<code>-n</code> 옵션은 출력 끝에 줄바꿈 문자를 붙이지 않도록 지정합니다.</p>
<p>출력을 파일에 저장하는 것은 중간 분석 결과를 보관했다가 나중에 분석을 이어가고자 할 때 유용합니다.
<em>greeting.txt</em> 파일의 내용을 다시 사용하려면, 파일을 읽어서 출력하는 <code>cat</code>을 사용하면 됩니다.</p>
<pre>cat greeting.txt
cat greeting.txt | wc -w</pre>
<p><span class="callout">&#10122;</span> <code>-w</code> 옵션은 <code>wc</code>가 단어 수만 세도록 합니다.</p>
<p>같은 결과를 작다 기호(<code>&lt;</code>)를 사용해서도 얻을 수 있습니다.</p>
<pre>&lt; greeting.txt wc -w</pre>
<p>이 방식은 별도의 프로세스를 실행하지 않고 파일을 <code>wc</code>의 표준 입력으로 직접 전달합니다<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a>.
Figure @ref(fig:diagram-essential-stdin-cat)는 이 두 가지 방식의 차이를 보여줍니다.
최종 결과는 동일합니다.</p>
<p>많은 커맨드 라인 도구들과 마찬가지로, <code>wc</code>는 하나 이상의 파일 이름을 인자로 받을 수 있습니다.
예를 들어 다음과 같습니다.</p>
<pre>wc -w greeting.txt movies.txt</pre>
<p>이 경우 <code>wc</code>는 각 파일의 이름도 함께 출력합니다.</p>
<p>어떤 도구의 출력이든 <em>/dev/null</em>이라는 특수 파일로 리다이렉션하여 출력을 억제할 수 있습니다.
저는 주로 오류 메시지를 보지 않기 위해 이 방법을 사용합니다(@ref(fig:diagram-essential-redirect-devnull) 참고).
다음 명령어는 <code>cat</code>이 <em>404.txt</em> 파일을 찾을 수 없어 오류 메시지를 생성하게 합니다.</p>
<pre>cat movies.txt 404.txt</pre>
<p>다음과 같이 표준 오류를 <em>/dev/null</em>로 리다이렉션할 수 있습니다.</p>
<pre>cat movies.txt 404.txt 2&gt; /dev/null</pre>
<p><span class="callout">&#10122;</span> <em><code>2</code></em>는 표준 오류를 의미합니다.</p>
<p>같은 파일에서 읽고 동시에 같은 파일에 쓰는 것을 주의하세요.
그렇게 하면 빈 파일만 남게 될 것입니다.
그 이유는 출력이 리다이렉션되는 도구가 즉시 파일을 쓰기 모드로 열면서 내용을 비워버리기 때문입니다.
이를 해결하는 방법은 두 가지가 있습니다. (1) 다른 파일에 쓴 다음 <code>mv</code>로 이름을 바꾸거나, (2) 입력을 모두 빨아들인 뒤 파일에 쓰는 <code>sponge</code><span class="citation"><a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a></span> 도구를 사용하는 것입니다.
Figure @ref(fig:diagram-essential-sponge)는 이것이 어떻게 작동하는지 보여줍니다.</p>
<p>예를 들어, <code>dseq</code><span class="citation"><a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a></span>로 <em>dates.txt</em> 파일을 생성하고 <code>nl</code><span class="citation"><a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a></span>을 사용해 행 번호를 붙이고 싶다고 가정해 봅시다.
다음과 같이 실행하면 <em>dates.txt</em> 파일은 비어 있게 됩니다.</p>
<pre>dseq 5 &gt; dates.txt
&lt; dates.txt nl &gt; dates.txt
bat dates.txt</pre>
<p>대신 앞서 설명한 방법 중 하나를 사용할 수 있습니다.</p>
<pre>dseq 5 &gt; dates.txt
&lt; dates.txt nl &gt; dates-nl.txt
bat dates-nl.txt
dseq 5 &gt; dates.txt
&lt; dates.txt nl | sponge dates.txt
bat dates.txt</pre>
</div>
<div id="파일과-디렉터리-다루기" class="section level3" number="2.3.6">
<h3 number="2.3.6"><span class="header-section-number">2.3.6</span> 파일과 디렉터리 다루기</h3>
<p>데이터 과학자로서 우리는 수많은 데이터와 소통하며, 그 데이터는 주로 파일에 저장됩니다.
커맨드 라인에서 파일(그리고 파일이 담긴 디렉터리)을 다루는 법을 아는 것이 중요합니다.
GUI에서 할 수 있는 모든 동작(그리고 그 이상의 것들)을 커맨드 라인 도구로 수행할 수 있습니다.
이 절에서는 파일과 디렉터리를 나열하고, 생성하고, 이동하고, 복사하고, 이름을 바꾸고, 삭제하는 가장 중요한 도구들을 소개합니다.</p>
<p>디렉터리의 내용을 나열하는 것은 <code>ls</code>로 할 수 있습니다.
디렉터리를 지정하지 않으면 현재 디렉터리의 내용을 나열합니다.
저는 주로 긴 목록 형식으로 표시하고 디렉터리를 파일보다 먼저 그룹화하는 것을 선호합니다.
매번 옵션을 일일이 입력하는 대신, 별칭 <code>l</code>을 사용합니다.</p>
<pre>ls /data/ch10
alias l
l /data/ch10</pre>
<p>이미 <code>&gt;</code>나 <code>&gt;&gt;</code>를 사용하여 출력을 리다이렉션함으로써 새 파일을 만드는 방법을 보셨습니다.
파일을 다른 디렉터리로 옮겨야 한다면 <code>mv</code><span class="citation"><a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a></span>를 사용하면 됩니다.</p>
<pre>mv hello.txt /data/ch02</pre>
<p><code>mv</code>로 파일의 이름을 바꿀 수도 있습니다.</p>
<pre>cd data
mv hello.txt bye.txt</pre>
<p>디렉터리 전체의 이름을 바꾸거나 이동할 수도 있습니다.
더 이상 필요 없는 파일은 <code>rm</code><span class="citation"><a href="#fn29" class="footnote-ref" id="fnref29"><sup>29</sup></a></span>으로 삭제(또는 제거)합니다.</p>
<pre>rm bye.txt</pre>
<p>디렉터리와 그 안의 모든 내용을 삭제하고 싶다면 재귀(recursive)를 의미하는 <code>-r</code> 옵션을 지정합니다.</p>
<pre>rm -r /data/ch02/old</pre>
<p>파일을 복사하려면 <code>cp</code><span class="citation"><a href="#fn30" class="footnote-ref" id="fnref30"><sup>30</sup></a></span>를 사용합니다. 백업본을 만들 때 유용합니다.</p>
<pre>cp server.log server.log.bak</pre>
<p>디렉터리는 <code>mkdir</code><span class="citation"><a href="#fn31" class="footnote-ref" id="fnref31"><sup>31</sup></a></span>을 사용하여 생성할 수 있습니다.</p>
<pre>cd /data
mkdir logs
l</pre>

<div class="rmdtip">
커맨드 라인 도구로 파일을 관리하는 것이 처음에는 무서울 수 있습니다. 파일 시스템의 시각적 개요를 바로 확인할 수 없기 때문입니다.
GNU Midnight Commander, Ranger, Vifm 같은 시각적 파일 관리자들이 도움이 될 수 있습니다.
이들은 Docker 이미지에 기본 설치되어 있지는 않지만, <code>sudo apt install</code> 뒤에 <code>mc</code>, <code>ranger</code>, <code>vifm</code> 중 하나를 입력하여 직접 설치할 수 있습니다.
</div>
<p>위의 모든 커맨드 라인 도구들은 <code>-v</code> 옵션(verbose)을 지원하여 어떤 작업이 진행되는지 출력해 줍니다.
예를 들어 다음과 같습니다.</p>
<pre>mkdir -v backup
cp -v * backup</pre>
<p><code>mkdir</code>을 제외한 모든 도구는 <code>-i</code> 옵션(interactive)을 지원하여, 작업을 수행하기 전에 확인 과정을 거칩니다.
예를 들어 다음과 같습니다.</p>
<pre>rm -i *#! expect_prompt=FALSE
n#! enter=FALSE, expect_prompt=TRUE</pre>
</div>
<div id="출력-관리하기" class="section level3" number="2.3.7">
<h3 number="2.3.7"><span class="header-section-number">2.3.7</span> 출력 관리하기</h3>
<p>가끔 도구나 파이프라인이 책에 싣기에는 너무 많은 양의 출력을 생성할 때가 있습니다.
출력을 수동으로 수정하는 대신, 헬퍼 도구로 파이프 연결을 하여 투명하게 처리하는 것을 선호합니다.
여러분이 직접 할 때는 전체 내용을 보고 싶다면 굳이 이렇게 할 필요는 없습니다.</p>
<p>제가 출력을 제어하기 위해 사용하는 도구들은 다음과 같습니다.</p>
<p><code>trim</code>은 출력의 높이(줄 수)와 너비(글자 수)를 제한하기 위해 자주 사용합니다.
기본적으로 출력은 10줄과 터미널 너비로 잘립니다.
음수를 전달하면 높이나 너비 제한을 해제할 수 있습니다.
예를 들어 다음과 같습니다.</p>
<pre>cat /data/ch07/tips.csv | trim 5 25</pre>
<p>출력을 다듬기 위해 사용하는 다른 도구로는 <code>head</code>, <code>tail</code>, <code>fold</code>, <code>paste</code>, <code>column</code> 등이 있습니다.
부록에 각각의 예제가 실려 있습니다.</p>
<p>쉼표로 구분된(CSV) 출력인 경우, 주로 <code>csvlook</code>으로 파이프하여 보기 좋은 표로 변환합니다.
그냥 <code>csvlook</code>을 실행하면 전체 표가 보일 것입니다.
저는 <code>trim</code>에 의해 표가 짧게 보이도록 <code>csvlook</code>을 재정의해 두었습니다.</p>
<pre>which csvlook
csvlook /data/ch07/tips.csv</pre>
<p>줄 번호와 신택스 하이라이팅(구문 강조)이 중요한 소스 코드 등의 내용을 보여줄 때는 <code>bat</code>을 사용합니다.
예를 들어 소스 코드는 다음과 같습니다.</p>
<pre>bat /data/ch04/stream.py</pre>
<p>파일의 공백, 탭, 줄바꿈 등을 명시적으로 가리키고 싶을 때는 <code>-A</code> 옵션을 추가하기도 합니다.</p>
<p>중간 분석 결과를 파일에 기록하는 것이 유용할 때가 있습니다.
이를 통해 파이프라인의 각 단계를 완료 후에 확인해 볼 수 있습니다.
파이프라인 안 어디든 원하는 만큼 <code>tee</code> 도구를 삽입할 수 있습니다.
저는 주로 최종 출력물의 일부를 확인하면서 동시에 전체 출력물을 파일에 저장하고 싶을 때 사용합니다(@ref(fig:diagram-essential-tee) 참고).
여기서는 전체 출력이 <em>even.txt</em>에 기록되고, 동시에 처음 5줄이 <code>trim</code>을 통해 출력됩니다.</p>
<pre>seq 0 2 100 | tee even.txt | trim 5</pre>
<p>마지막으로, 커맨드 라인 도구에 의해 생성된 이미지(스크린샷과 다이어그램을 제외한 모든 이미지)를 삽입할 때는 <code>display</code>를 사용합니다.
지금 <code>display</code>를 실행해 보면 작동하지 않을 것입니다.
<a href="#chapter-7-exploring-data">7장</a>에서 커맨드 라인에서 생성된 이미지를 표시하기 위한 네 가지 옵션을 설명하겠습니다.</p>
</div>
<div id="도와주세요-help" class="section level3" number="2.3.8">
<h3 number="2.3.8"><span class="header-section-number">2.3.8</span> 도와주세요! (Help!)</h3>
<p>커맨드 라인을 익히다 보면 도움이 필요할 때가 생깁니다.
아무리 숙련된 사용자라도 가끔은 도움이 필요합니다.
수많은 커맨드 라인 도구와 그 인자들을 모두 기억하는 것은 불가능하기 때문입니다.
다행히 커맨드 라인에서는 도움을 얻을 수 있는 여러 방법을 제공합니다.</p>
<p>도움을 얻는 가장 중요한 명령어는 아마도 <em>manual</em>의 줄임말인 <code>man</code><span class="citation"><a href="#fn32" class="footnote-ref" id="fnref32"><sup>32</sup></a></span>일 것입니다.
거의 모든 커맨드 라인 도구에 대한 정보를 담고 있습니다.
만약 <code>tar</code> 도구의 옵션을 잊어버렸다면(저도 자주 잊어버립니다), 다음 명령어로 매뉴얼 페이지를 확인할 수 있습니다.</p>
<pre>man tar | trim 20</pre>
<p>모든 커맨드 라인 도구가 매뉴얼 페이지를 가지고 있는 것은 아닙니다.
<code>cd</code>를 예로 들어 봅시다.</p>
<pre>man cd</pre>
<p><code>cd</code>와 같은 쉘 내장 명령어의 경우 <em>zshbuiltins</em> 매뉴얼 페이지를 참고할 수 있습니다.</p>
<pre>man zshbuiltins | trim</pre>
<p><strong><code>/</code></strong>를 눌러 검색할 수 있고 <strong><code>q</code></strong>를 눌러 나갈 수 있습니다.
<code>cd</code>에 해당하는 섹션을 찾아보세요.</p>
<p>최신 커맨드 라인 도구들도 매뉴얼 페이지가 없는 경우가 많습니다.
그럴 때는 해당 도구를 <code>--help</code> (또는 <code>-h</code>) 옵션과 함께 실행해 보는 것이 최선입니다.
예를 들어 다음과 같습니다.</p>
<pre>jq --help | trim</pre>
<p><code>--help</code> 옵션을 지정하는 것은 <code>cat</code>과 같은 기존 도구들에서도 작동합니다.
하지만 매뉴얼 페이지가 더 많은 정보를 제공하는 경우가 많습니다.
이 세 가지 방법으로도 해결되지 않는다면 인터넷 검색을 활용하는 것도 전혀 문제없습니다.
부록에 이 책에서 사용된 모든 커맨드 라인 도구의 목록이 있습니다.
각 도구를 어떻게 설치하는지뿐만 아니라 어떻게 도움을 얻을 수 있는지도 나와 있습니다.</p>
<p>매뉴얼 페이지는 내용이 너무 길고 읽기 힘들 수 있습니다.
<code>tldr</code><span class="citation"><a href="#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a></span> 도구는 커뮤니티에서 관리하는 도움말 페이지 모음으로, 전통적인 매뉴얼 페이지보다 훨씬 단순하고 접근하기 쉽도록 만들어졌습니다.
다음은 <code>tar</code>에 대한 tldr 페이지 예시입니다.</p>
<pre>tldr tar | trim 20</pre>
<p>보시다시피 <code>man</code>처럼 수많은 옵션을 알파벳순으로 나열하는 대신, <code>tldr</code>은 실질적인 예시 목록을 보여주어 핵심을 바로 짚어줍니다.</p>
</div>
</div>
<div id="요약-1" class="section level2" number="2.4">
<h2 number="2.4"><span class="header-section-number">2.4</span> 요약</h2>
<p>이 장에서는 Docker 이미지를 설치하여 필요한 모든 커맨드 라인 도구를 확보하는 방법을 배웠습니다.
또한 필수적인 커맨드 라인 개념들과 도움을 얻는 방법들도 살펴보았습니다.
이제 모든 준비가 끝났으므로, 데이터 과학을 위한 OSEMN 모델의 첫 번째 단계인 데이터 획득을 시작할 준비가 되었습니다.</p>
</div>
<div id="더-읽을거리-1" class="section level2" number="2.5">
<h2 number="2.5"><span class="header-section-number">2.5</span> 더 읽을거리</h2>
<ul>
<li>이 책의 부제는 Jerry Peek, Shelley Powers, Tim O’Reilly, Mike Loukides가 쓴 명저 <em>Unix Power Tools</em>에 경의를 표하는 의미를 담고 있습니다. 51개 장과 1000페이지 넘는 분량에 유닉스에 대해 알아야 할 거의 모든 것을 다루고 있습니다. 무게가 2kg 가까이 나가므로 전자책으로 보시는 것을 추천합니다.</li>
<li><a href="https://explainshell.com/">explainshell</a> 웹사이트는 명령어나 명령어 시퀀스를 파싱하여 각 부분에 대해 짧은 설명을 제공합니다. 매뉴얼 페이지를 훑어보지 않고도 새로운 명령어와 옵션을 빠르게 이해하는 데 유용합니다.</li>
<li>Docker는 정말 멋진 소프트웨어입니다. 이 장에서 Docker 이미지를 다운로드하고 컨테이너를 실행하는 법을 짧게 설명했지만, <a href="https://www.docker.com/101-tutorial">여러분만의 Docker 이미지를 만드는 법을 배우는 것</a>도 가치가 있을 것입니다. Sean Kane과 Karl Matthias가 쓴 <em>Docker: Up &amp; Running</em>도 좋은 자료입니다.</li>
</ul>
<!--chapter:end:02.Rmd-->
</div>
</div>
<div id="chapter-3-obtaining-data" class="section level1" number="3">
<h1 number="3"><span class="header-section-number">3</span> 데이터 획득하기</h1>
<p>이 장에서는 OSEMN 모델의 첫 번째 단계인 데이터 획득(Obtaining)을 다룹니다.
데이터 없이는 데이터 과학을 할 수 없기 때문입니다.
데이터 과학 문제를 해결하는 데 필요한 데이터가 이미 존재한다고 가정한다면, 여러분의 첫 번째 과제는 그 데이터를 여러분이 작업할 수 있는 형식으로 컴퓨터(혹은 가능하면 Docker 컨테이너 내부)에 가져오는 것입니다.</p>
<p>유닉스 철학에 따르면 텍스트는 범용 인터페이스입니다.
거의 모든 커맨드 라인 도구가 텍스트를 입력으로 받고, 텍스트를 출력으로 생성하거나 두 가지 모두를 수행합니다.
이것이 커맨드 라인 도구들이 서로 아주 잘 어울려 작동할 수 있는 주요 원인입니다.
하지만 앞으로 보겠지만, 텍스트 하나만 해도 여러 가지 형식이 있을 수 있습니다.</p>
<p>데이터는 서버에서 다운로드하거나, 데이터베이스에 쿼리하거나, 웹 API에 연결하는 등 여러 가지 방법으로 얻을 수 있습니다.
때로는 데이터가 압축된 형태이거나 마이크로소프트 엑셀 스프레드시트와 같은 바이너리 형식으로 오기도 합니다.
이 장에서는 커맨드 라인에서 이를 해결하는 데 도움이 되는 여러 도구를 다룹니다: <code>curl</code><span class="citation"><a href="#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a></span>, <code>in2csv</code><span class="citation"><a href="#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a></span>, <code>sql2csv</code><span class="citation"><a href="#fn36" class="footnote-ref" id="fnref36"><sup>36</sup></a></span>, <code>tar</code><span class="citation"><a href="#fn37" class="footnote-ref" id="fnref37"><sup>37</sup></a></span> 등이 포함됩니다.</p>
<div id="개요" class="section level2" number="3.1">
<h2 number="3.1"><span class="header-section-number">3.1</span> 개요</h2>
<p>이 장에서 여러분은 다음 내용을 배우게 됩니다.</p>
<ul>
<li>로컬 파일을 Docker 이미지로 복사하기</li>
<li>인터넷에서 데이터 다운로드하기</li>
<li>파일 압축 풀기</li>
<li>스프레드시트에서 데이터 추출하기</li>
<li>관계형 데이터베이스 쿼리하기</li>
<li>웹 API 호출하기</li>
</ul>
<p>이 장은 다음 파일들로 시작합니다.</p>
<pre>cd /data/ch03
l</pre>
<p>이 파일들을 얻는 방법은 <a href="#chapter-2-getting-started">2장</a>에 설명되어 있습니다.
그 외의 파일들은 커맨드 라인 도구를 사용하여 다운로드하거나 생성한 것들입니다.</p>
</div>
<div id="로컬-파일을-docker-컨테이너로-복사하기" class="section level2" number="3.2">
<h2 number="3.2"><span class="header-section-number">3.2</span> 로컬 파일을 Docker 컨테이너로 복사하기</h2>
<p>필요한 파일이 이미 여러분의 컴퓨터에 있는 경우가 흔합니다.
이 절에서는 그 파일들을 Docker 컨테이너 안으로 가져오는 방법을 설명합니다.</p>
<p><a href="#chapter-2-getting-started">2장</a>에서 말씀드렸듯이 Docker 컨테이너는 격리된 가상 환경입니다.
다행히 한 가지 예외가 있는데, Docker 컨테이너 안팎으로 파일을 전송할 수 있다는 점입니다.
여러분이 <code>docker run</code>을 실행했던 로컬 디렉터리가 Docker 컨테이너 내부의 한 디렉터리로 매핑됩니다.
그 디렉터리는 <em>/data</em>라고 부릅니다.
참고로 이곳은 홈 디렉터리(<em>/home/dst</em>)가 아닙니다.</p>
<p>로컬 컴퓨터에 있는 파일을 커맨드 라인 도구로 다루고 싶다면, 해당 파일을 매핑된 디렉터리로 복사하거나 이동하기만 하면 됩니다.
여러분의 ‘다운로드’ 디렉터리에 <em>logs.csv</em>라는 파일이 있다고 가정해 봅시다.</p>
<p>윈도우를 사용 중이라면 명령 프롬프트나 PowerShell을 열고 다음 두 명령어를 실행합니다.</p>
<pre>&gt; cd %UserProfile%\Downloads
&gt; copy logs.csv MyDataScienceToolbox\</pre>
<p>리눅스나 macOS를 사용 중이라면 터미널을 열고 운영체제의 쉘에서(Docker 컨테이너 내부가 아님) 다음 명령어를 실행합니다.</p>
<pre>cp ~/Downloads/logs.csv ~/my-data-science-toolbox#! enter=FALSE</pre>
<p>윈도우 파일 탐색기나 macOS의 Finder와 같은 그래픽 파일 관리자를 사용하여 파일을 해당 디렉터리로 드래그 앤 드롭할 수도 있습니다.</p>
</div>
<div id="인터넷에서-다운로드하기" class="section level2" number="3.3">
<h2 number="3.3"><span class="header-section-number">3.3</span> 인터넷에서 다운로드하기</h2>
<p>인터넷은 의심할 여지 없이 흥미로운 데이터를 위한 가장 큰 자원 저장소입니다.
커맨드 라인 도구 <code>curl</code>은 인터넷에서 데이터를 다운로드할 때 커맨드 라인의 맥가이버 칼과 같은 존재라고 할 수 있습니다.</p>
<div id="curl-소개" class="section level3" number="3.3.1">
<h3 number="3.3.1"><span class="header-section-number">3.3.1</span> <code>curl</code> 소개</h3>
<p>URL(uniform resource locator) 주소로 접속하면 브라우저는 다운로드한 데이터를 해석합니다.
예를 들어 브라우저는 HTML 파일을 렌더링하고, 비디오 파일을 자동으로 재생하며, PDF 파일을 보여줍니다.
하지만 <code>curl</code>로 URL에 접근하면 데이터를 다운로드하여 기본적으로 표준 출력으로 인쇄합니다.
<code>curl</code>은 데이터를 해석하지 않지만, 다행히 다른 커맨드 라인 도구를 사용하여 데이터를 추가로 처리할 수 있습니다.</p>
<p><code>curl</code>을 실행하는 가장 쉬운 방법은 URL을 커맨드 라인 인자로 지정하는 것입니다.
위키백과에서 문서를 하나 다운로드해 봅시다.</p>
<pre>curl "https://en.wikipedia.org/wiki/List_of_windmills_in_the_Netherlands" |
trim</pre>
<p><span class="callout">&#10122;</span> 기억하세요. <code>trim</code>은 출력 결과가 책에 잘 어울리게 들어가도록 하기 위해서만 사용합니다.</p>
<p>보시다시피 <code>curl</code>은 위키백과 서버가 반환한 가공되지 않은(raw) HTML을 다운로드합니다. 아무런 해석 과정 없이 전체 내용이 즉시 표준 출력으로 인쇄됩니다.
URL을 보면 이 문서가 네덜란드의 모든 풍차 목록을 담고 있을 것 같지만, 보아하니 풍차가 너무 많아서 각 주(province)마다 별도의 페이지가 있는 것 같습니다. 놀랍군요.</p>
<p>기본적으로 <code>curl</code>은 다운로드 속도와 예상 완료 시간을 보여주는 진행 표시기(progress meter)를 출력합니다.
이 출력은 표준 출력이 아닌 별도의 채널인 <em>표준 오류</em>로 전달되므로, 파이프라인에 다른 도구를 추가하더라도 방해되지 않습니다.
매우 큰 파일을 다운로드할 때는 이 정보가 유용할 수 있지만, 대개는 번거롭게 느껴지므로 저는 <code>-s</code> 옵션을 지정하여 이 출력을 끕니다(silence).</p>
<pre>curl -s "https://en.wikipedia.org/wiki/List_of_windmills_in_Friesland" |
pup -n 'table.wikitable tr' <span class="callout">&#10122;</span></pre>
<p><span class="callout">&#10122;</span> 웹사이트 스크래핑에 유용한 도구인 <code>pup</code><span class="citation"><a href="#fn38" class="footnote-ref" id="fnref38"><sup>38</sup></a></span>에 대해서는 <a href="#chapter-5-scrubbing-data">5장</a>에서 더 자세히 다루겠습니다.</p>
<p>보세요, 프리슬란트 주에만 자그마치 234개의 풍차가 있다고 하네요!</p>
</div>
<div id="파일로-저장하기" class="section level3" number="3.3.2">
<h3 number="3.3.2"><span class="header-section-number">3.3.2</span> 파일로 저장하기</h3>
<p><code>-O</code> 옵션을 추가하여 <code>curl</code>이 출력을 파일로 저장하게 할 수 있습니다.
파일 이름은 URL의 마지막 부분을 기반으로 결정됩니다.</p>
<pre>curl -s "https://en.wikipedia.org/wiki/List_of_windmills_in_Friesland" -O
l</pre>
<p>그 파일 이름이 마음에 들지 않는다면 <code>-o</code> 옵션과 함께 파일 이름을 지정하거나, 직접 출력을 파일로 리다이렉션할 수 있습니다.</p>
<pre>curl -s "https://en.wikipedia.org/wiki/List_of_windmills_in_Friesland" &gt; friesland.html</pre>
</div>
<div id="다른-프로토콜들" class="section level3" number="3.3.3">
<h3 number="3.3.3"><span class="header-section-number">3.3.3</span> 다른 프로토콜들</h3>
<p><code>curl</code>은 총 <a href="https://ec.haxx.se/protocols/protocols-curl">20개 이상의 프로토콜</a>을 지원합니다.
FTP(File Transfer Protocol) 서버에서 다운로드할 때도 동일한 방식으로 <code>curl</code>을 사용합니다.
여기서는 <em>ftp.gnu.org</em>에서 <em>welcome.msg</em> 파일을 다운로드해 보겠습니다.</p>
<pre>curl -s "ftp://ftp.gnu.org/welcome.msg" | trim</pre>
<p>지정된 URL이 디렉터리라면 <code>curl</code>은 해당 디렉터리의 내용을 나열합니다.
URL이 비밀번호로 보호되어 있다면 <code>-u</code> 옵션을 사용하여 사용자 이름과 비밀번호를 지정할 수 있습니다.</p>
<p>각종 사전과 용어 정의에 접근할 수 있게 해주는 DICT 프로토콜은 어떨까요?
Collaborative International Dictionary of English에 따른 “windmill”의 정의는 다음과 같습니다.</p>
<pre>curl -s "dict://dict.org/d:windmill" | trim</pre>
<p>하지만 인터넷에서 데이터를 다운로드할 때 사용하는 프로토콜은 대부분 HTTP일 것이므로, URL은 <em><a href="http://" class="uri">http://</a></em> 또는 *<a href="https://*로" class="uri">https://*로</a> 시작할 것입니다.</p>
</div>
<div id="리다이렉션-따라가기-following-redirects" class="section level3" number="3.3.4">
<h3 number="3.3.4"><span class="header-section-number">3.3.4</span> 리다이렉션 따라가기 (Following Redirects)</h3>
<p><em><a href="http://bit.ly/" class="uri">http://bit.ly/</a></em> 또는 *<a href="http://t.co/*로" class="uri">http://t.co/*로</a> 시작하는 단축 URL에 접근하면 브라우저는 자동으로 올바른 위치로 리다이렉션해 줍니다.
하지만 <code>curl</code>에서는 리다이렉션되도록 <code>-L</code> 또는 <code>--location</code> 옵션을 지정해야 합니다.
그렇지 않으면 다음과 같은 결과를 얻게 될 수도 있습니다.</p>
<pre>curl -s "https://bit.ly/2XBxvwK"</pre>
<p>때로는 우리가 방금 사용한 URL처럼 아무런 응답도 받지 못할 때가 있습니다.</p>
<pre>curl -s "https://youtu.be/dQw4w9WgXcQ"</pre>
<p><code>-I</code> 또는 <code>--head</code> 옵션을 지정하면 <code>curl</code>은 응답의 HTTP 헤더라고 불리는 부분만 가져옵니다. 이를 통해 서버가 반환한 상태 코드(status code)와 기타 정보를 확인할 수 있습니다.</p>
<pre>curl -sI "https://youtu.be/dQw4w9WgXcQ" | trim</pre>
<p>첫 번째 줄은 프로토콜과 HTTP 상태 코드를 보여주는데, 이 경우 303입니다.
또한 이 URL이 리다이렉션되는 위치(location)도 확인할 수 있습니다.
<code>curl</code>이 예상한 결과를 주지 않을 때 헤더를 검사하고 상태 코드를 확인하는 것은 유용한 디버깅 방법입니다.
다른 흔한 HTTP 상태 코드로는 404(찾을 수 없음)와 403(금지됨)이 있습니다.
위키백과에는 <a href="http://en.wikipedia.org/wiki/List_of_HTTP_status_codes">모든 HTTP 상태 코드</a>를 나열한 페이지가 있습니다.</p>
<p>요약하자면, <code>curl</code>은 인터넷에서 데이터를 다운로드하는 데 유용한 커맨드 라인 도구입니다.
가장 자주 쓰이는 세 가지 옵션은 진행 표시기를 끄는 <code>-s</code>, 사용자 이름과 비밀번호를 지정하는 <code>-u</code>, 그리고 자동으로 리다이렉션을 따라가는 <code>-L</code>입니다.
더 자세한 정보는 매뉴얼 페이지를 참고하세요(아마 머리가 어지러울 수 있습니다).</p>
<pre>man curl | trim 20</pre>
</div>
</div>
<div id="파일-압축-풀기" class="section level2" number="3.4">
<h2 number="3.4"><span class="header-section-number">3.4</span> 파일 압축 풀기</h2>
<p>원본 데이터셋이 매우 크거나 여러 파일의 모음인 경우, 압축된 아카이브 형태일 수 있습니다.
텍스트 파일의 단어들이나 JSON 파일의 키(key)들과 같이 반복되는 값이 많은 데이터셋은 특히 압축하기에 적합합니다.</p>
<p>압축 아카이브의 일반적인 확장자는 <em>.tar.gz</em>, <em>.zip</em>, <em>.rar</em> 등입니다.
이들의 압축을 풀기 위해서는 각각 <code>tar</code>, <code>unzip</code><span class="citation"><a href="#fn39" class="footnote-ref" id="fnref39"><sup>39</sup></a></span>, <code>unrar</code><span class="citation"><a href="#fn40" class="footnote-ref" id="fnref40"><sup>40</sup></a></span> 도구를 사용합니다.
(그리 흔하지는 않지만 다른 도구가 필요한 확장자들도 몇 가지 더 있습니다.)</p>
<p><em>.tar.gz</em>(“지집 타볼(gzipped tarball)”이라고 읽습니다)를 예로 들어 봅시다.
<em>logs.tar.gz</em>라는 아카이브를 추출하기 위해 다음 명령어를 사용할 수 있습니다.</p>
<pre>tar -xzf logs.tar.gz <span class="callout">&#10122;</span> #! enter=FALSE</pre>
<p><span class="callout">&#10122;</span> 제가 여기서 한 것처럼 이 세 개의 짧은 옵션을 결합하는 것이 일반적이지만, <code>-x -z -f</code>와 같이 따로 지정할 수도 있습니다.
사실 많은 커맨드 라인 도구들이 단일 문자로 구성된 옵션들을 결합해서 쓸 수 있도록 허용합니다.</p>
<p>과연 <code>tar</code>는 수많은 커맨드 라인 인자로 악명이 높습니다.
여기서 세 옵션 <code>-x</code>, <code>-z</code>, <code>-f</code>는 각각 <code>tar</code>가 아카이브에서 파일을 <em>추출(extract)</em>하고, 압축 해제 알고리즘으로 <em>gzip</em>을 사용하며, <em>logs.tar.gz</em> 파일을 사용하도록 지정합니다.</p>
<p>하지만 이 아카이브에 아직 익숙하지 않으므로 내용을 먼저 확인하는 것이 좋습니다.
이는 <code>-x</code> 옵션 대신 <code>-t</code> 옵션으로 할 수 있습니다.</p>
<pre>tar -tzf logs.tar.gz | trim</pre>
<p>이 아카이브에는 많은 파일이 들어 있는 것 같고, 디렉터리 안에 들어 있지는 않네요.
현재 디렉터리를 깨끗하게 유지하기 위해 우선 <code>mkdir</code>로 새 디렉터리를 만들고, <code>-C</code> 옵션을 사용해 그곳에 파일들을 추출하는 것이 좋습니다.</p>
<pre>mkdir logs
tar -xzf logs.tar.gz -C logs</pre>
<p>파일 수와 내용 일부를 확인해 봅시다.</p>
<pre>ls logs | wc -l
cat logs/* | trim</pre>
<p>아주 좋군요.
여러분이 이 로그 파일들을 정제하고 탐색하고 싶어 한다는 점은 이해하지만, 그 내용은 나중에 <a href="#chapter-5-scrubbing-data">5장</a>과 <a href="#chapter-7-exploring-data">7장</a>에서 다루겠습니다.</p>
<p>시간이 지나면 이 옵션들에 익숙해지겠지만, 편리할 수 있는 대안적인 옵션을 하나 보여드리고 싶습니다.
서로 다른 커맨드 라인 도구와 그 옵션들을 일일이 기억하는 대신, 여러 가지 형식을 알아서 풀어주는 <code>unpack</code><span class="citation"><a href="#fn41" class="footnote-ref" id="fnref41"><sup>41</sup></a></span>이라는 편리한 스크립트가 있습니다.
<code>unpack</code>은 압축을 풀고자 하는 파일의 확장자를 보고 적절한 커맨드 라인 도구를 호출합니다.
이제 동일한 파일의 압축을 풀기 위해 다음을 실행하면 됩니다.</p>
<pre>unpack logs.tar.gz #! enter=FALSE</pre>
</div>
<div id="마이크로소프트-엑셀-스프레드시트를-csv로-변환하기" class="section level2" number="3.5">
<h2 number="3.5"><span class="header-section-number">3.5</span> 마이크로소프트 엑셀 스프레드시트를 CSV로 변환하기</h2>
<p>많은 사람에게 마이크로소프트 엑셀은 소규모 데이터셋을 다루고 계산을 수행하는 직관적인 방법을 제공합니다.
그 결과, 엄청나게 많은 데이터가 마이크로소프트 엑셀 스프레드시트에 내포되어 있습니다.
이러한 스프레드시트는 파일 확장자에 따라 독자적인 바이너리 형식(<em>.xls</em>)이나 압축된 XML 파일들의 모음(<em>.xlsx</em>)으로 저장됩니다.
두 경우 모두 데이터가 대부분의 커맨드 라인 도구에서 즉시 사용하기에 적합하지 않습니다.
단지 이런 방식으로 저장되어 있다는 이유만으로 그 가치 있는 데이터셋들을 사용할 수 없다면 참 안타까운 일일 것입니다.</p>
<p>특히 커맨드 라인을 막 시작했을 때는 스프레드시트를 마이크로소프트 엑셀이나 리브레오피스(LibreOffice) Calc 같은 오픈 소스 프로그램으로 열어서 수동으로 CSV로 내보내고 싶은 유혹을 느낄 수 있습니다.
일회성 해결책으로는 괜찮을 수 있지만, 여러 파일로 확장하기 어렵고 자동화할 수 없다는 단점이 있습니다.
게다가 서버에서 작업할 때는 그런 애플리케이션을 사용할 수 없을 가능성이 큽니다.
저를 믿으세요, 곧 익숙해질 것입니다.</p>
<p>다행히 마이크로소프트 엑셀 스프레드시트를 CSV 파일로 변환해 주는 <code>in2csv</code>라는 커맨드 라인 도구가 있습니다.
CSV는 쉼표로 구분된 값(comma-separated values)을 의미합니다.
CSV는 공식적인 사양이 부족하기 때문에 다루기가 까다로울 수 있습니다.
Yakov Shafranovich는 CSV 형식을 다음 세 가지 포인트로 정의합니다.<span class="citation"><a href="#fn42" class="footnote-ref" id="fnref42"><sup>42</sup></a></span></p>
<ol style="list-style-type: decimal">
<li>각 레코드는 줄바꿈(<code>␊</code>)으로 구분되어 별도의 줄에 위치합니다. 예를 들어 닌자 거북이에 대한 중요한 정보가 담긴 다음 CSV 파일을 봅시다.</li>
</ol>
<pre>bat -A tmnt-basic.csv <span class="callout">&#10122;</span></pre>
<p><span class="callout">&#10122;</span> <code>-A</code> 옵션은 <code>bat</code>이 공백, 탭, 줄바꿈 같은 출력되지 않는 모든 문자를 보여주게 합니다.</p>
<ol start="2" style="list-style-type: decimal">
<li>파일의 마지막 레코드에는 끝 줄바꿈이 있을 수도 있고 없을 수도 있습니다. 예를 들면 다음과 같습니다.</li>
</ol>
<pre>bat -A tmnt-missing-newline.csv</pre>
<ol start="3" style="list-style-type: decimal">
<li>파일의 첫 번째 줄에 일반 레코드 줄과 동일한 형식의 헤더가 나타날 수 있습니다. 이 헤더는 파일의 필드에 대응하는 이름들을 포함하며, 파일의 나머지 부분에 있는 레코드들과 동일한 수의 필드를 가져야 합니다. 예를 들면 다음과 같습니다.</li>
</ol>
<pre>bat -A tmnt-with-header.csv</pre>
<p>보시다시피 CSV는 기본적으로 그리 읽기 편하지 않습니다.
데이터를 <code>csvlook</code><span class="citation"><a href="#fn43" class="footnote-ref" id="fnref43"><sup>43</sup></a></span>이라는 도구로 파이프하면 보기 좋은 표 형식으로 포맷해 줍니다.
만약 <em>tmnt-missing-newline.csv</em>처럼 CSV 데이터에 헤더가 없다면 <code>-H</code> 옵션을 추가해야 합니다. 그렇지 않으면 첫 번째 줄이 헤더로 해석됩니다.</p>
<pre>csvlook tmnt-with-header.csv
csvlook tmnt-basic.csv
csvlook -H tmnt-missing-newline.csv <span class="callout">&#10122;</span></pre>
<p><span class="callout">&#10122;</span> <code>-H</code> 옵션은 CSV 파일에 헤더가 없음을 지정합니다.</p>
<p>네덜란드의 연례 라디오 프로그램인 <a href="https://www.top2000nl.com">Top 2000</a>의 역대 인기곡 2000곡이 담긴 스프레드시트를 사용하여 <code>in2csv</code>를 시연해 보겠습니다.
데이터를 추출하려면 다음과 같이 <code>in2csv</code>를 호출합니다.</p>
<pre>curl "https://www.nporadio2.nl/data/download/TOP-2000-2020.xlsx" &gt; top2000.xlsx
in2csv top2000.xlsx | tee top2000.csv | trim</pre>
<p>Danny Vera가 누구죠? 가장 인기 있는 노래는 당연히 <em>Bohemian Rhapsody</em>여야 합니다.
음, 적어도 Queen은 Top 2000에 아주 많이 등장하니 불평할 수는 없겠네요.</p>
<pre>csvgrep top2000.csv --columns ARTIEST --regex '^Queen$' | csvlook -I</pre>
<p><span class="callout">&#10122;</span> <code>--regex</code> 옵션 뒤에 오는 값은 정규 표현식(regular expression, 줄여서 regex)입니다. 패턴을 정의하기 위한 특별한 구문입니다. 여기서는 아티스트 이름이 정확히 “Queen”인 것만 매칭하고 싶어서, ‘ARTIEST’ 컬럼 값의 시작과 끝을 나타내는 캐럿(<code>^</code>)과 달러 기호(<code>$</code>)를 사용했습니다.</p>
<p>참고로 <code>in2csv</code>, <code>csvgrep</code>, <code>csvlook</code> 도구들은 CSV 데이터를 다루기 위한 커맨드 라인 도구 모음인 CSVkit의 일부입니다.</p>
<p>파일 형식은 확장자에 의해 자동으로 결정되며, 이 경우 <em>.xlsx</em>입니다.
만약 데이터를 <code>in2csv</code>로 파이프한다면 형식을 명시적으로 지정해야 합니다.</p>
<p>스프레드시트는 여러 개의 워크시트를 포함할 수 있습니다.
<code>in2csv</code>는 기본적으로 첫 번째 워크시트를 추출합니다.
다른 워크시트를 추출하려면 <code>--sheet</code> 옵션에 워크시트 이름을 전달해야 합니다.
워크시트 이름이 무엇인지 확실하지 않다면 모든 워크시트의 이름을 출력하는 <code>--names</code> 옵션을 사용할 수 있습니다.
여기서 <em>top2000.xlsx</em>에는 <em>Blad1</em>(네덜란드어로 <em>Sheet1</em>이라는 뜻)이라는 이름의 시트가 하나만 있음을 확인할 수 있습니다.</p>
<pre>in2csv --names top2000.xlsx</pre>
</div>
<div id="관계형-데이터베이스-쿼리하기" class="section level2" number="3.6">
<h2 number="3.6"><span class="header-section-number">3.6</span> 관계형 데이터베이스 쿼리하기</h2>
<p>많은 기업이 데이터를 관계형 데이터베이스에 저장합니다.
스프레드시트와 마찬가지로, 커맨드 라인에서 그 데이터를 얻을 수 있다면 정말 좋을 것입니다.</p>
<p>관계형 데이터베이스의 예로는 MySQL, PostgreSQL, SQLite 등이 있습니다.
이 데이터베이스들은 모두 인터페이스하는 방식이 조금씩 다릅니다.
어떤 것들은 커맨드 라인 도구나 인터페이스를 제공하지만, 그렇지 않은 것들도 있습니다.
게다가 사용법과 출력 형식 면에서 일관성이 떨어지기도 합니다.</p>
<p>다행히 CSVkit 스위트의 일부인 <code>sql2csv</code>라는 커맨드 라인 도구가 있습니다.
이 도구는 MySQL, Oracle, PostgreSQL, SQLite, Microsoft SQL Server, Sybase를 포함한 다양한 데이터베이스와 공통된 인터페이스를 통해 작동합니다.
<code>sql2csv</code>의 출력은 이름에서 알 수 있듯이 CSV 형식입니다.</p>
<p>우리는 <em><code>SELECT</code></em> 쿼리를 실행하여 관계형 데이터베이스에서 데이터를 얻을 수 있습니다.
(<code>sql2csv</code>는 <em><code>INSERT</code></em>, <em><code>UPDATE</code></em>, <em><code>DELETE</code></em> 쿼리도 지원하지만, 이 장의 목적에는 맞지 않습니다.)</p>
<p><code>sql2csv</code>에는 두 가지 인자가 필요합니다: 데이터베이스 URL을 지정하는 <code>--db</code>(일반적인 형식은 <code>dialect+driver://username:password@host:port/database</code>입니다)와 <em><code>SELECT</code></em> 쿼리를 포함하는 <code>--query</code>입니다.
예를 들어, R의 표준 데이터셋이 담긴 SQLite 데이터베이스<a href="#fn44" class="footnote-ref" id="fnref44"><sup>44</sup></a>가 있다면, 다음과 같이 <em>mtcars</em> 테이블의 모든 행을 선택하고 <em>mpg</em> 컬럼을 기준으로 정렬할 수 있습니다.</p>
<pre>sql2csv --db 'sqlite:///r-datasets.db' \
--query 'SELECT row_names AS car, mpg FROM mtcars ORDER BY mpg' | csvlook</pre>
<p>이 SQLite 데이터베이스는 로컬 파일이므로 사용자 이름, 비밀번호, 호스트를 지정할 필요가 없습니다.
회사의 데이터베이스를 쿼리하고 싶다면 당연히 접근 방법과 권한이 필요할 것입니다.</p>
</div>
<div id="웹-api-호출하기" class="section level2" number="3.7">
<h2 number="3.7"><span class="header-section-number">3.7</span> 웹 API 호출하기</h2>
<p>앞 절에서는 인터넷에서 파일을 다운로드하는 방법을 설명했습니다.
인터넷에서 데이터를 얻는 또 다른 방법은 웹 API(Application Programming Interface)를 통하는 것입니다.
제공되는 API의 수는 점점 더 빠르게 늘어나고 있으며, 이는 우리 데이터 과학자들에게 흥미로운 데이터가 많아짐을 의미합니다.</p>
<p>웹 API는 웹사이트처럼 예쁜 레이아웃으로 보여주기 위한 것이 아닙니다.
대신 대부분의 웹 API는 JSON이나 XML 같은 구조화된 형식으로 데이터를 반환합니다.
구조화된 형식의 데이터를 가지면 <code>jq</code>와 같은 다른 도구로 데이터를 쉽게 처리할 수 있다는 장점이 있습니다.
예를 들어 George R.R. Martin의 가상 세계에 대한 풍부한 정보를 담고 있는 API of Ice and Fire(얼음과 불의 노래 API)는 다음과 같은 JSON 구조로 데이터를 반환합니다.</p>
<pre>curl -s "https://anapioficeandfire.com/api/characters/583" | jq '.'</pre>
<p><span class="callout">&#10122;</span> 스포일러 주의: 이 데이터는 완전히 최신 상태가 아닐 수 있습니다.</p>
<p>데이터를 보기 좋게 표시하기 위해 커맨드 라인 도구 <code>jq</code>로 파이프했습니다.
<code>jq</code>에는 정제와 탐색을 위한 훨씬 더 많은 가능성이 있으며, 이는 <a href="#chapter-5-scrubbing-data">5장</a>과 <a href="#chapter-7-exploring-data">7장</a>에서 살펴보겠습니다.</p>
<div id="인증-authentication" class="section level3" number="3.7.1">
<h3 number="3.7.1"><span class="header-section-number">3.7.1</span> 인증 (Authentication)</h3>
<p>일부 웹 API는 데이터를 사용하기 전에 인증(즉, 신원 증명)을 요구합니다.
이를 수행하는 몇 가지 방법이 있습니다.
어떤 웹 API는 API 키를 사용하고, 어떤 것들은 OAuth 프로토콜을 사용합니다.
헤드라인과 뉴스 기사를 제공하는 독립 자원인 News API가 훌륭한 예입니다.
API 키 없이 이 API에 접근하면 어떤 일이 일어나는지 봅시다.</p>
<pre>curl -s "http://newsapi.org/v2/everything?q=linux" | jq .</pre>
<p>음, 예상했던 결과군요.
참고로 물음표 뒤의 부분은 쿼리 매개변수를 전달하는 곳입니다.
API 키를 지정해야 하는 곳이기도 하죠.
제 API 키를 비밀로 유지하고 싶으므로, 명령어 치환(command substitution)을 사용하여 <em>/data/.secret/newsapi.org_apikey</em> 파일을 읽어서 입력하겠습니다.</p>
<pre>curl -s "http://newsapi.org/v2/everything?q=linux&amp;apiKey=$(&lt; /data/.secret/newsapi.org_apikey)" |
jq '.' | trim 30</pre>
<p>여러분만의 API 키는 <a href="https://newsapi.org">News API 웹사이트</a>에서 얻을 수 있습니다.</p>
</div>
<div id="스트리밍-api-streaming-apis" class="section level3" number="3.7.2">
<h3 number="3.7.2"><span class="header-section-number">3.7.2</span> 스트리밍 API (Streaming APIs)</h3>
<p>일부 웹 API는 데이터를 스트리밍 방식으로 반환합니다.
즉, 한 번 연결하면 연결이 끊길 때까지 데이터가 쉬지 않고 쏟아져 들어옵니다.
유명한 예로는 전 세계에서 전송되는 모든 트윗을 끊임없이 스트리밍하는 트위터의 “파이어호스(firehose)”가 있습니다.
다행히 대부분의 커맨드 라인 도구들도 스트리밍 방식으로 작동합니다.</p>
<p>예를 들어 위키미디어의 스트리밍 API 중 하나를 10초 동안 샘플링해 봅시다.</p>
<pre>curl -s "https://stream.wikimedia.org/v2/stream/recentchange" |
sample -s 10 &gt; wikimedia-stream-sample #! enter=FALSE</pre>
<p>이 특정 API는 위키백과와 위키미디어의 다른 속성들에 가해진 모든 변경 사항을 반환합니다.
커맨드 라인 도구 <code>sample</code>은 10초 후에 연결을 닫는 데 사용됩니다.
<strong><code>Ctrl-C</code></strong>를 눌러 인터럽트를 보냄으로써 연결을 수동으로 닫을 수도 있습니다.
출력은 <em>wikimedia-stream-sample</em> 파일에 저장됩니다.
<code>trim</code>을 사용해 살짝 엿볼까요?</p>
<pre>&lt; wikimedia-stream-sample trim</pre>
<p><code>sed</code>와 <code>jq</code>를 조금 사용해서 이 데이터를 정제하면 영어 위키백과에서 일어나는 변경 사항들을 엿볼 수 있습니다.</p>
<pre>&lt; wikimedia-stream-sample sed -n 's/^data: //p' |
jq 'select(.type == "edit" and .server_name == "en.wikipedia.org") | .title'</pre>
<p><span class="callout">&#10122;</span> 이 <code>sed</code> 표현식은 <em><code>data:</code></em>로 시작하는 줄만 출력하고 세미콜론 뒤의 부분만 인쇄하는데, 이것이 마침 JSON입니다.
<br><span class="callout">&#10123;</span> 이 <code>jq</code> 표현식은 특정 <em><code>type</code></em>과 <em><code>server_name</code></em>을 가진 JSON 객체의 <em><code>title</code></em> 키를 인쇄합니다.</p>
<p>스트리밍 이야기가 나와서 말인데, <code>telnet</code><span class="citation"><a href="#fn45" class="footnote-ref" id="fnref45"><sup>45</sup></a></span>을 사용해 <em>스타워즈 에피소드 4: 새로운 희망</em>을 무료로 스트리밍할 수 있다는 사실을 알고 계셨나요?</p>
<pre>telnet towel.blinkenlights.nl#! enter=FALSE</pre>
<p>그리고 시간이 좀 지나면, 한 솔로가 먼저 쐈다는 것을 알게 됩니다!</p>
<pre> cat towel.blinkenlights.nl</pre>
<p>물론 데이터로서 좋은 소스는 아니겠지만, 머신러닝 모델을 훈련시키면서 고전 명작을 즐기는 것도 나쁘지 않죠<a href="#fn46" class="footnote-ref" id="fnref46"><sup>46</sup></a>.</p>
</div>
</div>
<div id="요약-2" class="section level2" number="3.8">
<h2 number="3.8"><span class="header-section-number">3.8</span> 요약</h2>
<p>축하합니다, OSEMN 모델의 첫 번째 단계를 마쳤습니다.
다운로드부터 관계형 데이터베이스 쿼리까지 데이터를 얻는 다양한 방법을 배웠습니다.
다음 장은 막간 장으로, 여러분만의 커맨드 라인 도구를 만드는 방법을 가르쳐 드릴 것입니다.
데이터 정제에 대해 배우고 싶어 참을 수 없다면, 이 장을 건너뛰고 <a href="#chapter-5-scrubbing-data">5장</a> (OSEMN 모델의 두 번째 단계)으로 바로 가셔도 좋습니다.</p>
</div>
<div id="더-읽을거리-2" class="section level2" number="3.9">
<h2 number="3.9"><span class="header-section-number">3.9</span> 더 읽을거리</h2>
<ul>
<li>연습할 데이터셋을 찾고 계신가요? GitHub 저장소 <a href="https://github.com/awesomedata/awesome-public-datasets"><em>Awesome Public Datasets</em></a>에는 공개적으로 사용 가능한 수백 개의 고품질 데이터셋 목록이 있습니다.</li>
<li>아니면 API로 연습하고 싶으신가요? GitHub 저장소 <a href="https://github.com/public-apis/public-apis"><em>Public APIs</em></a>에는 흥미로운 무료 API들이 많이 나열되어 있습니다. <a href="http://api.citybik.es/v2/">City Bikes</a>와 <a href="https://the-one-api.dev/">The One API</a>는 제가 좋아하는 API들입니다.</li>
<li>관계형 데이터베이스에서 데이터를 얻기 위해 SQL 쿼리를 작성하는 것은 중요한 기술입니다. Ben Forta의 저서 <em>SQL in 10 Minutes a Day</em>의 처음 15개 장은 <em><code>SELECT</code></em> 문과 필터링, 그룹화, 정렬 기능을 잘 가르쳐 줍니다.</li>
</ul>
<!--chapter:end:03.Rmd-->
<!-- TODO: Remove dashes from filenames top-words.sh etc. -->
</div>
</div>
<div id="chapter-4-creating-command-line-tools" class="section level1" number="4">
<h1 number="4"><span class="header-section-number">4</span> 커맨드 라인 도구 만들기</h1>
<p>이 책 전반에 걸쳐 기본적으로 한 줄로 작성되는 많은 명령어와 파이프라인을 소개해 드릴 것입니다.
이들은 원라이너(one-liner) 또는 파이프라인으로 알려져 있습니다.
단 한 줄의 명령어만으로 복잡한 작업을 수행할 수 있다는 점이 커맨드 라인을 강력하게 만드는 대목입니다.
이는 전통적인 프로그램을 작성하고 사용하는 것과는 매우 다른 경험입니다.</p>
<p>어떤 작업은 단 한 번만 수행하지만, 어떤 작업은 더 자주 수행하게 됩니다.
또 어떤 작업은 매우 구체적이지만, 다른 작업은 일반화될 수 있습니다.
특정 원라이너를 정기적으로 반복해야 한다면, 이를 하나의 독립적인 커맨드 라인 도구로 만드는 것이 가치가 있습니다.
원라이너와 커맨드 라인 도구는 각자의 용도가 있습니다.
그 기회를 알아보는 데는 연습과 기술이 필요합니다.
커맨드 라인 도구의 장점은 원라이너 전체를 기억할 필요가 없다는 점과, 다른 파이프라인에 포함시켰을 때 가독성을 높여준다는 점입니다.
그런 의미에서 커맨드 라인 도구는 프로그래밍 언어의 함수와 비슷하다고 생각할 수 있습니다.</p>
<p>하지만 프로그래밍 언어로 작업할 때의 이점은 코드가 하나 이상의 파일에 담겨 있다는 점입니다.
이는 코드를 쉽게 수정하고 재사용할 수 있음을 의미합니다.
코드에 매개변수(parameter)가 있다면 일반화하여 비슷한 패턴의 문제들에 다시 적용할 수도 있습니다.</p>
<p>커맨드 라인 도구는 양쪽의 장점을 모두 가집니다. 커맨드 라인에서 사용할 수 있고, 매개변수를 받을 수 있으며, 단 한 번만 만들면 됩니다.
이 장에서는 두 가지 방식으로 커맨드 라인 도구를 만드는 법을 익힐 것입니다.
첫째로, 원라이너를 재사용 가능한 커맨드 라인 도구로 바꾸는 방법을 설명합니다.
명령어에 매개변수를 추가함으로써 프로그래밍 언어가 제공하는 것과 동일한 유연성을 더할 수 있습니다.
그다음에는 프로그래밍 언어로 작성된 코드로부터 재사용 가능한 커맨드 라인 도구를 만드는 방법을 시연하겠습니다.
유닉스 철학을 따름으로써, 여러분의 코드는 전혀 다른 언어로 작성된 다른 커맨드 라인 도구들과 조합될 수 있습니다.
이 장에서는 Bash, Python, R 세 가지 프로그래밍 언어에 집중할 것입니다.</p>
<p>재사용 가능한 커맨드 라인 도구를 만드는 것이 장기적으로 여러분을 더 효율적이고 생산적인 데이터 과학자로 만들어 줄 것이라고 믿습니다.
여러분은 기존 도구들을 꺼내어 이전에 마주했던 문제들에 적용할 수 있는 자신만의 데이터 과학 도구 상자를 점진적으로 구축해 나갈 것입니다.
원라이너나 기존 코드를 커맨드 라인 도구로 바꿀 기회를 포착하는 데는 연습이 필요합니다.</p>

<div class="rmdtip">
원라이너를 쉘 스크립트로 바꾸기 위해 아주 기초적인 쉘 스크립팅을 사용할 것입니다.
이 책에서는 변수, 조건문, 반복문 등 쉘 스크립팅의 아주 일부 개념들만 보여드립니다.
쉘 스크립팅 전체 과정은 그 자체로 책 한 권 분량이 될 수 있으므로, 이 책의 범위를 벗어납니다.
쉘 스크립팅에 대해 더 깊이 공부하고 싶다면 <span class="citation">Arnold Robbins and Nelson H. F. Beebe<a href="#fn47" class="footnote-ref" id="fnref47"><sup>47</sup></a></span> 가 쓴 <em>Classic Shell Scripting</em>을 추천합니다.
</div>
<div id="개요-1" class="section level2" number="4.1">
<h2 number="4.1"><span class="header-section-number">4.1</span> 개요</h2>
<p>이 장에서 여러분은 다음 내용을 배우게 됩니다.</p>
<ul>
<li>원라이너를 매개변수가 있는 쉘 스크립트로 변환하기</li>
<li>기존 Python 및 R 코드를 재사용 가능한 커맨드 라인 도구로 바꾸기</li>
</ul>
<p>이 장은 다음 파일들로 시작합니다.</p>
<pre>cd /data/ch04
l</pre>
<p>이 파일들을 얻는 방법은 <a href="#chapter-2-getting-started">2장</a>에 설명되어 있습니다.
그 외의 파일들은 커맨드 라인 도구를 사용하여 다운로드하거나 생성한 것들입니다.</p>
</div>
<div id="원라이너를-쉘-스크립트로-변환하기" class="section level2" number="4.2">
<h2 number="4.2"><span class="header-section-number">4.2</span> 원라이너를 쉘 스크립트로 변환하기</h2>
<p>이 절에서는 원라이너를 재사용 가능한 커맨드 라인 도구로 만드는 방법을 설명하겠습니다.
텍스트 한 조각에서 가장 자주 등장하는 단어들을 구하고 싶다고 해봅시다.
가장 훌륭한 다른 책들처럼 프로젝트 구텐베르크에서 무료로 제공되는 루이스 캐럴의 <em>이상한 나라의 앨리스</em>를 가져와 보겠습니다.</p>
<pre>curl -sL "https://www.gutenberg.org/files/11/11-0.txt" | trim</pre>
<p>다음과 같은 도구의 시퀀스 혹은 <em>파이프라인</em>이 그 작업을 해줄 것입니다.</p>
<pre>curl -sL "https://www.gutenberg.org/files/11/11-0.txt" | <span class="callout">&#10122;</span>
tr '[:upper:]' '[:lower:]' | <span class="callout">&#10123;</span>
grep -oE "[a-z\']{2,}" | <span class="callout">&#10124;</span>
sort | <span class="callout">&#10125;</span>
uniq -c | <span class="callout">&#10126;</span>
sort -nr | <span class="callout">&#10127;</span>
head -n 10 <span class="callout">&#10128;</span></pre>
<p><span class="callout">&#10122;</span> <code>curl</code>을 사용하여 전자책을 다운로드합니다.
<br><span class="callout">&#10123;</span> <code>tr</code><span class="citation"><a href="#fn48" class="footnote-ref" id="fnref48"><sup>48</sup></a></span>을 사용하여 전체 텍스트를 소문자로 변환합니다.
<br><span class="callout">&#10124;</span> <code>grep</code><span class="citation"><a href="#fn49" class="footnote-ref" id="fnref49"><sup>49</sup></a></span>을 사용하여 모든 단어를 추출하고 각 단어를 별도의 줄에 놓습니다.
<br><span class="callout">&#10125;</span> <code>sort</code><span class="citation"><a href="#fn50" class="footnote-ref" id="fnref50"><sup>50</sup></a></span>를 사용하여 이 단어들을 알파벳 순으로 정렬합니다.
<br><span class="callout">&#10126;</span> <code>uniq</code><span class="citation"><a href="#fn51" class="footnote-ref" id="fnref51"><sup>51</sup></a></span>를 사용하여 모든 중복을 제거하고 각 단어가 목록에 몇 번이나 나타나는지 셉니다.
<br><span class="callout">&#10127;</span> <code>sort</code>를 사용하여 이 고유 단어 목록을 빈도수에 따라 내림차순으로 정렬합니다.
<br><span class="callout">&#10128;</span> <code>head</code>를 사용하여 상위 10개 행(단어)만 남깁니다.</p>
<p>이러한 단어들이 실제로 텍스트에서 가장 자주 나타납니다.
이 단어들은 (“alice”를 제외하고) 많은 영어 텍스트에서 매우 빈번하게 나타나기 때문에 의미를 거의 담고 있지 않습니다.
사실 이러한 단어들을 <em>불용어(stopwords)</em>라고 부릅니다.
이들을 제거한다면 우리는 이 텍스트와 관련된 가장 빈번한 단어들을 얻게 될 것입니다.</p>
<p>찾아둔 불용어 목록은 다음과 같습니다.</p>
<pre>curl -sL "https://raw.githubusercontent.com/stopwords-iso/stopwords-en/master/stopwords-en.txt" |
sort | tee stopwords | trim 20</pre>
<p><code>grep</code>을 사용하여 빈도수를 세기 직전에 불용어들을 필터링할 수 있습니다.</p>
<pre>curl -sL "https://www.gutenberg.org/files/11/11-0.txt" |
tr '[:upper:]' '[:lower:]' |
grep -oE "[a-z\']{2,}" |
sort |
grep -Fvwf stopwords |
uniq -c |
sort -nr |
head -n 10</pre>
<p><span class="callout">&#10122;</span> <code>-f</code>를 사용하여 파일(우리의 경우 <em>stopwords</em>)에서 한 줄에 하나씩 패턴을 가져옵니다. <code>-F</code>를 사용하여 이 패턴들을 고정 문자열로 해석합니다. <code>-w</code>를 사용하여 전체 단어를 형성하는 일치 항목들만 선택합니다. <code>-v</code>를 사용하여 일치하지 않는 줄들을 선택합니다.</p>

<div class="rmdtip">
이 원라이너에 사용된 각 커맨드 라인 도구들은 매뉴얼 페이지를 제공합니다.
따라서 <code>grep</code>에 대해 더 알고 싶다면 커맨드 라인에서 <code>man grep</code>을 실행하면 됩니다.
<code>tr</code>, <code>grep</code>, <code>uniq</code>, <code>sort</code> 도구들은 다음 장에서 더 자세히 다루겠습니다.
</div>
<p>이 원라이너를 단 한 번만 실행하는 데는 아무런 문제가 없습니다.
하지만 프로젝트 구텐베르크의 모든 전자책에 대해 상위 10개 단어를 얻고 싶다고 상상해 보세요.
혹은 뉴스 웹사이트의 상위 10개 단어를 매시간 얻고 싶다고 상상해 보세요.
그럴 경우에는 이 원라이너를 더 큰 무언가의 일부가 될 수 있는 별도의 빌딩 블록으로 가지는 것이 가장 좋습니다.
매개변수 측면에서 이 원라이너에 유연성을 더하기 위해, 이를 쉘 스크립트로 바꿔봅시다.</p>
<p>이를 통해 원라이너를 출발점으로 삼아 점진적으로 개선해 나갈 수 있습니다.
이 원라이너를 재사용 가능한 커맨드 라인 도구로 바꾸기 위해, 다음의 6단계를 안내해 드리겠습니다.</p>
<ol style="list-style-type: decimal">
<li>원라이너를 파일에 복사하여 붙여넣습니다.</li>
<li>실행 권한을 추가합니다.</li>
<li>소위 쉬뱅(shebang)을 정의합니다.</li>
<li>고정된 입력 부분을 제거합니다.</li>
<li>매개변수를 추가합니다.</li>
<li>(선택 사항) PATH를 확장합니다.</li>
</ol>
<div id="단계-파일-생성" class="section level3" number="4.2.1">
<h3 number="4.2.1"><span class="header-section-number">4.2.1</span> 1단계: 파일 생성</h3>
<p>첫 번째 단계는 새 파일을 만드는 것입니다.
평소 즐겨 쓰는 텍스트 에디터를 열고 원라이너를 붙여넣으세요.
우리의 새로운 커맨드 라인 도구를 향한 첫걸음이라는 의미로 파일 이름을 <em>top-words-1.sh</em>라고 지읍시다. 만약 커맨드 라인에 머물고 싶다면, 내장 명령어인 <code>fc</code>(<em>fix command</em>의 줄임말)를 사용할 수 있습니다. <code>fc</code>는 마지막으로 실행한 명령어를 수정하거나 <em>편집</em>할 수 있게 해줍니다.</p>
<pre>fc #! enter=FALSE</pre>
<p><code>fc</code>를 실행하면 환경 변수 <em>EDITOR</em>에 저장된 기본 텍스트 에디터가 실행됩니다.
Docker 컨테이너에서는 이것이 사용하기 쉬운 텍스트 에디터인 <code>nano</code>로 설정되어 있습니다.
보시다시피 이 파일에는 우리의 원라이너가 들어 있습니다.</p>
<pre>Enter #! literal=FALSE, hold=0.2, wait=0.2</pre>
<p><strong><code>Ctrl-O</code></strong>를 누르고 임시 파일 이름을 지운 뒤 <code>top-words-1.sh</code>를 입력하여 이 임시 파일에 제대로 된 이름을 붙여줍시다.</p>
<pre>C-O BSpace BSpace BSpace BSpace BSpace BSpace BSpace BSpace BSpace BSpace BSpace BSpace BSpace BSpace BSpace BSpace BSpace BSpace BSpace BSpace BSpace #! literal=FALSE
top-words-1.sh#! enter=FALSE</pre>
<p><strong><code>Enter</code></strong>를 누르세요.</p>
<pre>Enter #! literal=FALSE</pre>
<p>다른 이름으로 저장할 것인지 묻는 확인창에서 <strong><code>Y</code></strong>를 누릅니다.</p>
<pre>Y #! literal=FALSE</pre>
<p><strong><code>Ctrl-X</code></strong>를 눌러 <code>nano</code>를 종료하고 원래 있던 곳으로 돌아갑니다.</p>
<p>쉘 스크립트를 만들고 있다는 것을 분명히 하기 위해 파일 확장자 <em>.sh</em>를 사용하고 있습니다.
하지만 커맨드 라인 도구에 확장자가 꼭 필요한 것은 아닙니다.
실제로 커맨드 라인 도구는 확장자를 거의 갖지 않습니다.</p>
<p>파일의 내용을 확인합니다.</p>
<pre>pwd
l
bat top-words-1.sh</pre>
<p>이제 <code>bash</code><span class="citation"><a href="#fn52" class="footnote-ref" id="fnref52"><sup>52</sup></a></span>를 사용하여 파일의 명령어를 해석하고 실행할 수 있습니다.</p>
<pre>bash top-words-1.sh</pre>
<p>이렇게 하면 다음에 다시 원라이너를 입력할 필요가 없습니다.</p>
<p>하지만 파일이 스스로 독립적으로 실행될 수 없으므로, 아직은 <em>진정한</em> 커맨드 라인 도구라고 할 수 없습니다.
다음 단계에서 이를 바꿔봅시다.</p>
</div>
<div id="단계-실행-권한-부여" class="section level3" number="4.2.2">
<h3 number="4.2.2"><span class="header-section-number">4.2.2</span> 2단계: 실행 권한 부여</h3>
<p>파일을 직접 실행할 수 없는 이유는 올바른 접근 권한이 없기 때문입니다.
특히 여러분이라는 사용자가 파일에 대한 실행 권한을 가지고 있어야 합니다.
이 절에서는 파일의 접근 권한을 변경합니다.</p>
<p>각 단계 간의 차이를 비교하기 위해 <code>cp -v top-words-{1,2}.sh</code>를 사용하여 파일을 <em>top-words-2.sh</em>로 복사합니다.</p>

<div class="rmdtip">
중괄호 확장(brace expansion)이나 다른 형태의 파일 확장이 어떤 결과로 이어지는지 확인하고 싶다면, 명령어를 <code>echo</code>로 바꿔서 결과를 인쇄만 해보세요.
예를 들어 <code>echo book_{draft,final}.md</code>나 <code>echo agent-{001..007}</code>과 같이 할 수 있습니다.
</div>
<p>파일의 접근 권한을 변경하려면 <code>chmod</code><span class="citation"><a href="#fn53" class="footnote-ref" id="fnref53"><sup>53</sup></a></span>(<em>change mode</em>의 줄임말)라는 커맨드 라인 도구를 사용해야 합니다.
이 도구는 특정 파일의 파일 모드 비트를 변경합니다.
다음 명령어는 여러분이라는 사용자에게 <em>top-words-2.sh</em>에 대한 실행 권한을 부여합니다.</p>
<pre>cp -v top-words-{1,2}.sh
chmod u+x top-words-2.sh</pre>
<p>인자 <code>u+x</code>는 세 문자로 구성됩니다. (1) <code>u</code>는 파일을 소유한 사용자(파일을 만든 여러분)를 위해 권한을 변경하고 싶음을 나타내고, (2) <code>+</code>는 권한을 추가하고 싶음을 나타내며, (3) <code>x</code>는 실행 권한을 나타냅니다.</p>
<p>이제 두 파일의 접근 권한을 살펴봅시다.</p>
<pre>l top-words-{1,2}.sh</pre>
<p>첫 번째 컬럼은 각 파일에 대한 접근 권한을 보여줍니다.
<em>top-words-2.sh</em>의 경우 <em><code>-rwxrw-r--</code></em>입니다.
첫 번째 문자 <em><code>-</code></em>(하이픈)는 파일 형식을 나타냅니다.
<em><code>-</code></em>는 일반 파일을, <em><code>d</code></em>는 디렉터리를 의미합니다.
그다음 세 문자 <em><code>rwx</code></em>는 파일을 소유한 사용자에 대한 접근 권한을 나타냅니다.
<em><code>r</code></em>과 <em><code>w</code></em>는 각각 <em>읽기(read)</em>와 <em>쓰기(write)</em>를 의미합니다.
(보시다시피 <em>top-words-1.sh</em>는 <em><code>x</code></em> 대신 <em><code>-</code></em>를 가지고 있는데, 이는 그 파일을 <em>실행</em>할 수 없음을 의미합니다.) 그다음 세 문자 <em><code>rw-</code></em>는 파일을 소유한 그룹의 모든 구성원에 대한 접근 권한을 나타냅니다.
마지막 세 문자 <em><code>r--</code></em>는 다른 모든 사용자에 대한 접근 권한을 나타냅니다.</p>
<p>이제 다음과 같이 파일을 실행할 수 있습니다.</p>
<pre>./top-words-2.sh</pre>
<p>만약 <em>top-words-1.sh</em>처럼 올바른 접근 권한이 없는 파일을 실행하려고 하면 다음과 같은 오류 메시지가 보일 것입니다.</p>
<pre>./top-words-1.sh</pre>
</div>
<div id="단계-쉬뱅shebang-정의" class="section level3" number="4.2.3">
<h3 number="4.2.3"><span class="header-section-number">4.2.3</span> 3단계: 쉬뱅(Shebang) 정의</h3>
<p>파일을 독립적으로 실행할 수는 있지만, 파일에 소위 쉬뱅(shebang)이라고 불리는 것을 추가해야 합니다.
<em>쉬뱅</em>은 시스템에 명령어를 해석하는 데 어떤 실행 파일을 사용해야 하는지 알려주는 명령 스크립트의 특별한 줄입니다.</p>
<p><em>쉬뱅</em>이라는 이름은 해시(she)와 느낌표(bang)인 처음 두 문자 <code>#!</code>에서 유래했습니다.
이전 단계에서 했던 것처럼 이를 빠뜨리는 것은 좋지 않은데, 각 쉘마다 기본 실행 파일이 다르기 때문입니다.
책 전체에서 사용하고 있는 Z 쉘(Z shell)은 쉬뱅이 정의되지 않은 경우 기본적으로 <em>/bin/sh</em> 실행 파일을 사용합니다.
이 경우에는 <code>bash</code>가 명령어를 해석하도록 하고 싶은데, 이는 <code>sh</code>보다 더 많은 기능을 제공하기 때문입니다.</p>
<p>다시 말하지만, 어떤 에디터를 사용하든 자유지만 저는 Docker 이미지에 설치된 <code>nano</code><span class="citation"><a href="#fn54" class="footnote-ref" id="fnref54"><sup>54</sup></a></span>를 계속 사용하겠습니다.</p>
<pre>cp -v top-words-{2,3}.sh
nano top-words-3.sh #! enter=FALSE</pre>
<pre>Enter #! literal=FALSE</pre>
<p>가서 <em><code>#!/usr/bin/env bash</code></em>를 타이핑하고 <strong><code>Enter</code></strong>를 누르세요.
준비가 되면 <strong><code>Ctrl-X</code></strong>를 눌러 저장하고 종료합니다.</p>
<pre># ! #! literal=FALSE
/usr/bin/env bash #! expect_prompt=FALSE
C-X #! literal=FALSE</pre>
<p>파일을 저장할 것인지 묻는 확인창에서 <strong><code>Y</code></strong>를 누릅니다.</p>
<pre>Y #! literal=FALSE</pre>
<p><em>top-words-3.sh</em>가 어떻게 생겼는지 확인해 봅시다.</p>
<pre>bat top-words-3.sh</pre>
<p>우리가 필요한 바로 그 모습입니다. 원래의 파이프라인 앞에 쉬뱅이 붙어 있습니다.</p>
<p>가끔 <em><code>#!/usr/bin/bash</code></em>나 <em><code>#!/usr/bin/python</code></em>(다음 절에서 보게 될 파이썬의 경우) 형태의 쉬뱅을 가진 스크립트를 보게 될 것입니다.
대개는 잘 작동하지만, 만약 <code>bash</code>나 <code>python</code><span class="citation"><a href="#fn55" class="footnote-ref" id="fnref55"><sup>55</sup></a></span> 실행 파일이 <em>/usr/bin</em>이 아닌 다른 위치에 설치되어 있다면 그 스크립트는 더 이상 작동하지 않습니다.
제가 여기서 보여드린 형태인 <em><code>#!/usr/bin/env bash</code></em>나 <em><code>#!/usr/bin/env python</code></em>을 사용하는 것이 더 좋습니다. 왜냐하면 <code>env</code><span class="citation"><a href="#fn56" class="footnote-ref" id="fnref56"><sup>56</sup></a></span> 실행 파일은 <code>bash</code>와 <code>python</code>이 어디에 설치되어 있는지 알고 있기 때문입니다.
즉, <code>env</code>를 사용하는 것이 여러분의 스크립트를 더 이식성 있게(portable) 만듭니다.</p>
</div>
<div id="단계-고정된-입력-제거" class="section level3" number="4.2.4">
<h3 number="4.2.4"><span class="header-section-number">4.2.4</span> 4단계: 고정된 입력 제거</h3>
<p>이제 커맨드 라인에서 실행할 수 있는 유효한 커맨드 라인 도구를 갖게 되었습니다.
하지만 여기서 더 개선할 수 있습니다.
우리의 커맨드 라인 도구를 더 재사용 가능하게 만들 수 있습니다.
파일의 첫 번째 명령어는 <code>curl</code>인데, 가장 자주 쓰이는 10개 단어를 얻고자 하는 텍스트를 다운로드합니다.
즉, 데이터와 작업이 하나로 합쳐져 있습니다.</p>
<p>다른 전자책이나 다른 텍스트에서 상위 10개 단어를 얻고 싶다면 어떻게 될까요? 입력 데이터가 도구 자체 내에 고정되어 있습니다.
입력 데이터를 커맨드 라인 도구에서 분리하는 것이 더 낫습니다.</p>
<p>커맨드 라인 도구의 사용자가 텍스트를 제공한다고 가정하면, 도구는 범용적으로 적용될 수 있게 됩니다.
따라서 해결책은 스크립트에서 <code>curl</code> 명령어를 제거하는 것입니다.
<em>top-words-4.sh</em>라는 이름의 업데이트된 스크립트는 다음과 같습니다.</p>
<pre>cp -v top-words-{3,4}.sh
sed -i '2d' top-words-4.sh
bat top-words-4.sh</pre>
<p>이것이 작동하는 이유는 <code>tr</code>과 같이 표준 입력으로부터 데이터를 필요로 하는 명령어로 스크립트를 시작하면, 커맨드 라인 도구에 전달된 입력을 그대로 받기 때문입니다.
예를 들면 다음과 같습니다.</p>
<pre>curl -sL 'https://www.gutenberg.org/files/11/11-0.txt' | ./top-words-4.sh
curl -sL 'https://www.gutenberg.org/files/12/12-0.txt' | ./top-words-4.sh
man bash | ./top-words-4.sh</pre>

<div class="rmdtip">
비록 우리 스크립트에서는 그렇게 하지 않았지만, 데이터를 저장하는 경우에도 동일한 원칙이 적용됩니다.
일반적으로 스크립트가 특정 파일에 쓰도록 하는 것보다 출력 리다이렉션을 사용하여 사용자가 알아서 처리하게 하는 것이 좋습니다.
물론 오직 여러분의 프로젝트에서만 사용할 도구라면 얼마나 구체적이어야 하는지에 제한은 없습니다.
</div>
</div>
<div id="단계-인자argument-추가" class="section level3" number="4.2.5">
<h3 number="4.2.5"><span class="header-section-number">4.2.5</span> 5단계: 인자(Argument) 추가</h3>
<p>커맨드 라인 도구를 더욱 재사용 가능하게 만들기 위한 한 단계가 더 남았습니다: 바로 매개변수입니다.
우리의 커맨드 라인 도구에는 몇 가지 고정된 커맨드 라인 인자가 있습니다. 예를 들어 <code>sort</code>를 위한 <code>-nr</code>이나 <code>head</code>를 위한 <code>-n 10</code> 같은 것들입니다.
전자의 인자는 고정된 상태로 두는 것이 좋을 것입니다.
하지만 <code>head</code> 명령어에 대해 서로 다른 값을 허용하는 것은 매우 유용할 것입니다.
이렇게 하면 최종 사용자가 출력할 “가장 자주 사용되는 단어의 개수”를 직접 설정할 수 있습니다.
파일 <em>top-words-5.sh</em>의 모습은 다음과 같습니다.</p>
<pre>bat top-words-5.sh</pre>
<ul>
<li>변수 <em>NUM_WORDS</em>는 Bash의 특별한 변수인 <em>$1</em> 값으로 설정됩니다. 이는 커맨드 라인 도구에 전달된 첫 번째 커맨드 라인 인자를 담고 있습니다. 아래 표는 Bash가 제공하는 다른 특수 변수들을 나열합니다. 만약 값이 지정되지 않으면 기본값으로 “10”을 가지게 됩니다.</li>
<li><em>$NUM_WORDS</em> 변수의 값을 <em>사용</em>하려면 앞에 달러 기호를 붙여야 한다는 점에 유의하세요. 값을 <em>설정</em>할 때는 달러 기호를 쓰지 않습니다.</li>
</ul>
<p><code>head</code>의 인자로 <em>$1</em>을 직접 사용할 수도 있고 <em>NUM_WORDS</em>와 같은 추가 변수를 만드는 수고를 하지 않아도 됩니다.
하지만 스크립트가 커지고 <em>$2</em>, <em>$3</em>과 같은 더 많은 커맨드 라인 인자가 생길 때는 이름이 붙은 변수를 사용하는 것이 코드의 가독성을 높여줍니다.</p>
<p>이제 텍스트의 상위 20개 단어를 보고 싶다면 다음과 같이 커맨드 라인 도구를 호출하면 됩니다.</p>
<pre>curl -sL "https://www.gutenberg.org/files/11/11-0.txt" &gt; alice.txt
&lt; alice.txt ./top-words-5.sh 20</pre>
<p>만약 사용자가 숫자를 지정하지 않으면 스크립트는 상위 10개 단어를 보여줍니다.</p>
<pre>&lt; alice.txt ./top-words-5.sh</pre>
</div>
<div id="단계-path-확장" class="section level3" number="4.2.6">
<h3 number="4.2.6"><span class="header-section-number">4.2.6</span> 6단계: PATH 확장</h3>
<p>앞선 5단계를 거쳐 마침내 재사용 가능한 커맨드 라인 도구 구축을 마쳤습니다.
하지만 매우 유용할 수 있는 단계가 하나 더 있습니다.
이 선택적인 단계에서는 여러분의 커맨드 라인 도구를 어디에서나 실행할 수 있도록 보장할 것입니다.</p>
<p>현재로서는 커맨드 라인 도구를 실행하고 싶을 때, 해당 도구가 있는 디렉터리로 이동하거나 2단계에서 보여드린 것처럼 전체 경로 이름을 포함해야 합니다.
커맨드 라인 도구가 가령 특정 프로젝트만을 위해 만들어진 것이라면 괜찮습니다.
하지만 도구가 여러 상황에서 적용될 수 있다면, 우분투와 함께 제공되는 도구들처럼 어디서나 실행할 수 있는 것이 유용합니다.</p>
<p>이를 달성하기 위해 Bash는 여러분의 커맨드 라인 도구를 어디서 찾아야 할지 알아야 합니다.
Bash는 <em>PATH</em>라 불리는 환경 변수에 저장된 디렉터리 목록을 탐색함으로써 이 작업을 수행합니다.
새로 생성된 Docker 컨테이너에서 <em>PATH</em>는 다음과 같습니다.</p>
<pre>echo $PATH</pre>
<p>디렉터리들은 콜론으로 구분됩니다.
콜론을 줄바꿈으로 <em>변환(translating)</em>하여 디렉터리 목록으로 출력할 수 있습니다.</p>
<pre>echo $PATH | tr ':' '\n'</pre>
<p><em>PATH</em>를 영구적으로 변경하려면 홈 디렉터리에 있는 <em>.bashrc</em> 또는 <em>.profile</em> 파일을 편집해야 합니다.
모든 사용자 지정 커맨드 라인 도구를 한 디렉터리(예: <em>~/tools</em>)에 모아둔다면 <em>PATH</em>를 한 번만 변경하면 됩니다.
그러면 이제 더 이상 <em>./</em>를 붙일 필요 없이 파일 이름만 사용할 수 있습니다.
나아가 도구가 어디에 위치해 있는지 기억할 필요도 없습니다.</p>
<pre>cp -v top-words{-5.sh,}
export PATH="${PATH}:/data/ch04"
echo $PATH
curl "https://www.gutenberg.org/files/11/11-0.txt" |
top-words 10</pre>
</div>
</div>
<div id="python과-r로-커맨드-라인-도구-만들기" class="section level2" number="4.3">
<h2 number="4.3"><span class="header-section-number">4.3</span> Python과 R로 커맨드 라인 도구 만들기</h2>
<p>앞 절에서 우리가 만든 커맨드 라인 도구는 Bash로 작성되었습니다.
(Bash 프로그래밍 언어의 모든 기능이 사용된 것은 아니지만, 해석기는 여전히 <code>bash</code>였습니다.) 이제 아시다시피 커맨드 라인은 언어에 구애받지 않으므로 커맨드 라인 도구를 만드는 데 반드시 Bash를 사용해야 하는 것은 아닙니다.</p>
<p>이 절에서는 커맨드 라인 도구가 다른 프로그래밍 언어로도 만들어질 수 있음을 보여드리겠습니다.
데이터 과학 커뮤니티에서 가장 인기 있는 두 언어인 Python과 R에 집중하겠습니다.
두 언어에 대한 완전한 입문을 제공할 수는 없으므로, 여러분이 Python이나 R에 어느 정도 익숙하다고 가정하겠습니다.
Java, Go, Julia와 같은 다른 언어들도 커맨드 라인 도구를 만드는 데 있어서는 비슷한 패턴을 따릅니다.</p>
<p>Bash가 아닌 다른 언어로 커맨드 라인 도구를 만드는 데는 세 가지 주요 이유가 있습니다.
첫째, 커맨드 라인에서 사용하고 싶은 기존 코드가 이미 있을 수 있습니다.
둘째, 커맨드 라인 도구가 수백 줄의 Bash 코드로 구성될 정도로 복잡해질 수 있습니다.
셋째, 도구가 더 안전하고 견고해야 할 때입니다(Bash는 타입 체크와 같은 많은 기능이 부족합니다).</p>
<p>이전 절에서 논의한 6단계는 다른 언어로 커맨드 라인 도구를 만들 때도 대략적으로 적용됩니다.
하지만 첫 번째 단계는 커맨드 라인에서 복사해서 붙여넣는 것이 아니라, 관련 코드를 새 파일에 복사해서 붙여넣는 것이 될 것입니다.
Python과 R로 작성된 커맨드 라인 도구는 쉬뱅 뒤에 각각 <code>python</code>과 <code>Rscript</code><span class="citation"><a href="#fn57" class="footnote-ref" id="fnref57"><sup>57</sup></a></span>를 해석기로 지정해야 합니다.</p>
<p>Python과 R을 사용하여 커맨드 라인 도구를 만들 때 특히 주의를 기울여야 할 두 가지 측면이 더 있습니다.
첫째, 쉘 스크립트에는 자연스러운 표준 입력 처리를 Python과 R에서는 명시적으로 처리해야 합니다.
둘째, Python과 R로 작성된 커맨드 라인 도구는 더 복잡해지는 경향이 있으므로 사용자에게 더 정교한 커맨드 라인 인자를 지정할 수 있는 기능을 제공하고 싶을 수 있습니다.</p>
<div id="쉘-스크립트-포팅하기" class="section level3" number="4.3.1">
<h3 number="4.3.1"><span class="header-section-number">4.3.1</span> 쉘 스크립트 포팅하기</h3>
<p>시작점으로, 방금 만든 쉘 스크립트를 Python과 R로 어떻게 포팅하는지 살펴봅시다.
다시 말해, 어떤 Python과 R 코드가 표준 입력으로부터 가장 자주 쓰이는 단어들을 우리에게 줄까요? 먼저 <em>top-words.py</em>와 <em>top-words.R</em> 두 파일을 보여드리고 쉘 코드와의 차이점을 논의하겠습니다.
Python에서 코드는 다음과 같을 것입니다.</p>
<pre>cd /data/ch04
bat top-words.py</pre>
<p>이 Python 예제는 서드파티 패키지를 사용하지 않았음에 유의하세요.
고급 텍스트 처리를 원한다면 NLTK 패키지<span class="citation"><a href="#fn58" class="footnote-ref" id="fnref58"><sup>58</sup></a></span>를 확인해 보기를 권장합니다.
많은 수치 데이터를 다룰 예정이라면 Pandas 패키지<span class="citation"><a href="#fn59" class="footnote-ref" id="fnref59"><sup>59</sup></a></span> 사용을 추천합니다.</p>
<p>그리고 R에서 코드는 다음과 같을 것입니다.</p>
<pre>bat top-words.R</pre>
<p>세 가지 구현(Bash, Python, R)이 동일한 빈도수로 동일한 상위 5개 단어를 반환하는지 확인해 봅시다.</p>
<pre>time &lt; alice.txt top-words 5
time &lt; alice.txt top-words.py 5
time &lt; alice.txt top-words.R 5</pre>
<p>훌륭합니다! 물론 출력 결과물 자체가 매우 흥미진진한 것은 아닙니다.
흥미로운 점은 우리가 여러 언어로 동일한 과업을 완수할 수 있다는 사실입니다.
접근 방식 간의 차이점을 살펴봅시다.</p>
<p>우선 즉각적으로 명백한 것은 코드의 양 차이입니다.
이 특정 과업에 대해서는 Python과 R 모두 Bash보다 훨씬 더 많은 코드를 요구합니다.
이는 어떤 작업에는 커맨드 라인을 사용하는 것이 더 낫다는 점을 잘 보여줍니다.
다른 작업에는 프로그래밍 언어를 사용하는 것이 더 나을 것입니다.
커맨드 라인에서 더 많은 경험을 쌓을수록 언제 어떤 접근 방식을 사용해야 할지 인식하기 시작할 것입니다.
모든 것이 커맨드 라인 도구일 때는 과업을 하위 과업으로 나누어 Bash 커맨드 라인 도구와 예를 들어 Python 커맨드 라인 도구를 결합할 수도 있습니다.
당면한 과제에 가장 잘 맞는 접근 방식을 사용하면 됩니다.</p>
</div>
<div id="표준-입력으로부터-스트리밍-데이터-처리하기" class="section level3" number="4.3.2">
<h3 number="4.3.2"><span class="header-section-number">4.3.2</span> 표준 입력으로부터 스트리밍 데이터 처리하기</h3>
<p>이전의 두 코드 조각에서 Python과 R은 모두 표준 입력 전체를 한 번에 읽었습니다.
커맨드 라인에서 대부분의 도구는 데이터를 스트리밍 방식으로 다음 도구로 파이프합니다.
<code>sort</code>와 같이 표준 출력에 데이터를 쓰기 전에 전체 데이터를 필요로 하는 도구들이 몇몇 있습니다.
이는 파이프라인이 그런 도구들에 의해 막힌다는 것을 의미합니다.
파일과 같이 입력 데이터가 유한하다면 이는 문제가 되지 않을 수 있습니다.
하지만 입력 데이터가 끊이지 않는 스트림일 때, 그런 블로킹(blocking) 커맨드 라인 도구들은 쓸모가 없습니다.</p>
<p>다행히 Python과 R은 스트리밍 데이터 처리를 지원합니다.
예를 들어 줄 단위로 함수를 적용할 수 있습니다.
여기 Python과 R에서 이것이 어떻게 작동하는지 보여주는 최소한의 예제 두 가지가 있습니다.</p>
<p>Python과 R 도구 모두 이제는 악명 높은 Fizz Buzz 문제를 해결합니다. 이 문제의 정의는 다음과 같습니다: 1부터 100까지 숫자를 출력하되, 3으로 나누어지면 “fizz”를, 5로 나누어지면 “buzz”를, 15로 나누어지면 “fizzbuzz”를 대신 출력합니다. 여기 파이썬 코드입니다<a href="#fn60" class="footnote-ref" id="fnref60"><sup>60</sup></a>.</p>
<pre>bat fizzbuzz.py</pre>
<p>그리고 여기 R 코드입니다.</p>
<pre>bat fizzbuzz.R</pre>
<p>두 도구를 테스트해 봅시다(공간을 절약하기 위해 출력을 <code>column</code>으로 파이프합니다).</p>
<pre>seq 30 | fizzbuzz.py | column -x
seq 30 | fizzbuzz.R | column -x</pre>
<p>출력이 정확해 보이네요!
이 두 도구가 실제로 스트리밍 방식으로 작동한다는 것을 증명하기는 어렵습니다.
입력 데이터를 <code>sample -d 100</code>으로 파이프한 뒤 Python이나 R 도구로 넘김으로써 이를 직접 확인할 수 있습니다.
그렇게 하면 각 줄 사이에 약간의 지연이 추가되어 도구들이 모든 입력 데이터를 기다리지 않고 줄 단위로 작동한다는 것을 더 쉽게 확인할 수 있습니다.</p>
</div>
</div>
<div id="요약-3" class="section level2" number="4.4">
<h2 number="4.4"><span class="header-section-number">4.4</span> 요약</h2>
<p>이 막간 장에서 여러분만의 커맨드 라인 도구를 만드는 방법을 보여드렸습니다.
여러분의 코드를 재사용 가능한 빌딩 블록으로 바꾸는 데는 단 6단계면 충분합니다.
그것이 여러분을 훨씬 더 생산적으로 만들어 준다는 것을 알게 될 것입니다.
여러분만의 도구를 만들 기회를 계속해서 찾아보시기를 조언합니다.
다음 장에서는 데이터 과학을 위한 OSEMN 모델의 두 번째 단계인 데이터 정제를 다룹니다.</p>
</div>
<div id="더-읽을거리-3" class="section level2" number="4.5">
<h2 number="4.5"><span class="header-section-number">4.5</span> 더 읽을거리</h2>
<ul>
<li>도구에 기억해야 할 옵션이 많아지고 다른 사람들과 도구를 공유하고 싶을 때 도움말 문서를 추가하는 것이 중요해집니다. <code>docopt</code>는 도움말을 제공하고 도구가 허용하는 가능한 옵션을 정의하기 위한 언어 중립적인 프레임워크입니다. Bash, Python, R을 포함한 거의 모든 언어에서 구현체를 사용할 수 있습니다.</li>
<li>Bash 프로그래밍에 대해 더 알고 싶다면 Arnold Robbins와 Nelson Beebe의 <em>Classic Shell Programming</em>과 Carl Albing과 JP Vossen의 <em>Bash Cookbook</em>을 추천합니다.</li>
<li>견고하고 안전한 Bash 스크립트를 작성하는 것은 꽤 까다롭습니다. <a href="https://www.shellcheck.net/">ShellCheck</a>는 여러분의 Bash 코드에서 실수와 취약점을 점검해 주는 온라인 도구입니다. 커맨드 라인 도구로도 사용 가능합니다.</li>
<li>Joel Grus의 저서 <em>Ten Essays on Fizz Buzz</em>는 파이썬으로 Fizz Buzz를 해결하는 10가지 서로 다른 방식에 대한 통찰력 있고 재미있는 모음집입니다.</li>
</ul>
<!--chapter:end:04.Rmd-->
</div>
</div>
<div id="chapter-5-scrubbing-data" class="section level1" number="5">
<h1 number="5"><span class="header-section-number">5</span> 데이터 정제하기</h1>
<p>두 장 전, 데이터 과학을 위한 OSEMN 모델의 첫 번째 단계에서 우리는 다양한 소스로부터 데이터를 <em>획득(obtaining)</em>하는 방법을 살펴보았습니다.
이번 장은 두 번째 단계인 데이터를 <em>정제(scrubbing)</em>하는 것에 관한 모든 내용을 다룹니다.
데이터를 얻자마자 즉시 <em>탐색(exploring)</em>하거나 <em>모델링(modeling)</em>을 계속할 수 있는 경우는 매우 드뭅니다.
데이터에 먼저 약간의 청소, 즉 정제가 필요한 이유는 수없이 많습니다.</p>
<p>우선, 데이터가 원하는 형식이 아닐 수 있습니다.
예를 들어, API에서 JSON 데이터를 얻었지만 시각화를 만들기 위해 CSV 형식이 필요할 수 있습니다.
다른 일반적인 형식으로는 일반 텍스트(plain text), HTML, XML 등이 있습니다.
대부분의 커맨드 라인 도구는 한두 가지 형식만 지원하므로, 데이터를 한 형식에서 다른 형식으로 변환할 수 있는 능력을 갖추는 것이 중요합니다.</p>
<p>데이터가 원하는 형식이 되었더라도 결측치(missing values), 불일치(inconsistencies), 이상한 문자, 또는 불필요한 부분과 같은 문제가 여전히 남아 있을 수 있습니다.
필터를 적용하고, 값을 바꾸고, 여러 파일을 결합함으로써 이를 해결할 수 있습니다.
커맨드 라인은 이러한 종류의 변환에 특히 잘 어울립니다. 사용 가능한 전문 도구가 많고, 그중 대부분은 대량의 데이터를 처리할 수 있기 때문입니다.
이 장에서는 <code>grep</code><span class="citation"><a href="#fn61" class="footnote-ref" id="fnref61"><sup>61</sup></a></span>과 <code>awk</code><span class="citation"><a href="#fn62" class="footnote-ref" id="fnref62"><sup>62</sup></a></span> 같은 고전적인 도구부터 <code>jq</code><span class="citation"><a href="#fn63" class="footnote-ref" id="fnref63"><sup>63</sup></a></span>와 <code>pup</code><span class="citation"><a href="#fn64" class="footnote-ref" id="fnref64"><sup>64</sup></a></span> 같은 최신 도구까지 다룰 것입니다.</p>
<p>가끔은 동일한 커맨드 라인 도구를 사용하여 여러 작업을 수행하거나, 여러 도구가 사용하여 동일한 작업을 수행할 수도 있습니다.
이 장은 커맨드 라인 도구 자체를 깊게 파고들기보다는 문제나 레시피(recipe)에 초점을 맞춘 요리책(cookbook)과 같은 구조로 되어 있습니다.</p>
<div id="개요-2" class="section level2" number="5.1">
<h2 number="5.1"><span class="header-section-number">5.1</span> 개요</h2>
<!-- #TODO: SHOULD: Review the list below once the chapter is complete -->
<p>이 장에서 여러분은 다음 내용을 배우게 됩니다.</p>
<ul>
<li>데이터를 한 형식에서 다른 형식으로 변환하기</li>
<li>CSV에 직접 SQL 쿼리 적용하기</li>
<li>행(line) 필터링하기</li>
<li>값 추출 및 교체하기</li>
<li>열(column) 분할, 병합, 추출하기</li>
<li>여러 파일 결합하기</li>
</ul>
<p>이 장은 다음 파일들로 시작합니다.</p>
<pre>cd /data/ch05
l</pre>
<p>이 파일들을 얻는 방법은 <a href="#chapter-2-getting-started">2장</a>에 설명되어 있습니다.
그 외의 파일들은 커맨드 라인 도구를 사용하여 다운로드하거나 생성한 것들입니다.</p>
<p>실제 변환 작업을 살펴보기 전에, 커맨드 라인에서 작업할 때 이러한 변환이 얼마나 도처에 널려 있는지 보여드리고 싶습니다.</p>
</div>
<div id="변환-어디에나-있는-변환들" class="section level2" number="5.2">
<h2 number="5.2"><span class="header-section-number">5.2</span> 변환, 어디에나 있는 변환들</h2>
<p><a href="#chapter-1-introduction">1장</a>에서 실제 데이터 과학의 OSEMN 모델 단계들이 선형적으로만 따라가지는 않는다고 언급했습니다.
이러한 맥락에서, 정제(scrubbing)가 OSEMN 모델의 두 번째 단계이긴 하지만, 단지 획득한 데이터만이 정제가 필요한 것은 아니라는 점을 알아두셨으면 합니다.
이 장에서 배울 변환 기술들은 파이프라인의 어느 부분에서든, 그리고 OSEMN 모델의 어느 단계에서든 유용할 수 있습니다.
일반적으로 한 커맨드 라인 도구가 다음 도구에서 즉시 사용 가능한 출력을 생성한다면, 파이프 연산자(<code>|</code>)를 사용하여 두 도구를 연결할 수 있습니다.
그렇지 않다면, 파이프라인 중간에 변환 도구를 삽입하여 데이터에 변환을 먼저 적용해야 합니다.</p>
<p>이를 더 구체적으로 만들기 위해 예시를 하나 들어보겠습니다.
여러분에게 <em>fizzbuzz</em> 시퀀스의 처음 100개 항목이 있고(<a href="#chapter-4-creating-command-line-tools">4장</a> 참조), <em>fizz</em>, <em>buzz</em>, <em>fizzbuzz</em>라는 단어가 얼마나 자주 나타나는지 막대 그래프로 시각화하고 싶다고 가정해 봅시다.
아직 익숙하지 않은 도구가 사용되더라도 걱정하지 마세요. 나중에 모두 자세히 다룰 것입니다.</p>
<p>먼저 시퀀스를 생성하여 데이터를 얻고 이를 <em>fb.seq</em>에 씁니다.</p>
<pre>seq 100 |
/data/ch04/fizzbuzz.py |
tee fb.seq | trim</pre>
<p><span class="callout">&#10122;</span> 사용자 정의 도구인 <code>fizzbuzz.py</code>는 <a href="#chapter-4-creating-command-line-tools">4장</a>에서 가져온 것입니다.</p>
<p>그런 다음 <code>grep</code>을 사용하여 <em>fizz</em> 또는 <em>buzz</em> 패턴과 일치하는 행만 남기고, <code>sort</code>와 <code>uniq</code><span class="citation"><a href="#fn65" class="footnote-ref" id="fnref65"><sup>65</sup></a></span>를 사용하여 각 단어의 빈도를 셉니다.</p>
<pre>grep -E "fizz|buzz" fb.seq | <span class="callout">&#10122;</span>
sort | uniq -c | sort -nr &gt; fb.cnt <span class="callout">&#10123;</span>
bat -A fb.cnt</pre>
<p><span class="callout">&#10122;</span> 이 정규 표현식은 <em>fizzbuzz</em>와도 일치합니다.
<br><span class="callout">&#10123;</span> <code>sort</code>와 <code>uniq</code>를 이런 식으로 사용하는 것은 행의 개수를 세고 내림차순으로 정렬하는 일반적인 방법입니다. 개수를 추가하는 것은 <code>-c</code> 옵션입니다.</p>
<p><code>sort</code>가 두 번 사용된 점에 주목하세요. 첫 번째는 <code>uniq</code>가 정렬된 데이터를 입력으로 기대하기 때문이고, 두 번째는 개수를 숫자순으로 정렬하기 위함입니다.
어떤 의미에서 이는 미묘하긴 하지만 중간 변환 과정입니다.</p>
<p>다음 단계는 <code>rush</code><span class="citation"><a href="#fn66" class="footnote-ref" id="fnref66"><sup>66</sup></a></span>를 사용하여 빈도를 시각화하는 것입니다.
하지만 <code>rush</code>는 입력 데이터가 CSV 형식일 것으로 예상하므로, 그전에 명확한 변환 과정이 필요합니다.
<code>awk</code>를 사용하면 헤더를 추가하고 두 필드의 순서를 바꾸고 쉼표를 삽입하는 작업을 한 번에 수행할 수 있습니다.</p>
<pre>&lt; fb.cnt awk 'BEGIN { print "value,count" } { print $2","$1 }' &gt; fb.csv
bat fb.csv
csvlook fb.csv</pre>
<p>이제 <code>rush</code>를 사용하여 막대 그래프를 만들 준비가 되었습니다.
결과는 Figure @ref(fig:fb-image)를 확인하세요.
(<code>rush</code>의 이 구문은 <a href="#chapter-7-exploring-data">7장</a>에서 자세히 다룰 것입니다.)</p>
<pre>rush plot -x value -y count --geom col --height 2 fb.csv &gt; fb.png
display fb.png</pre>
<p>이 예제는 약간 인위적이긴 하지만 커맨드 라인에서 작업할 때 흔히 나타나는 패턴을 보여줍니다.
데이터를 획득하거나 시각화하거나 모델을 학습시키는 등의 핵심 도구들은 파이프라인으로 연결되기 위해 중간 변환을 필요로 하는 경우가 많습니다.
그런 의미에서 파이프라인을 작성하는 것은 핵심 조각들이 서로 맞물리기 위해 도우미 조각들을 필요로 하는 퍼즐을 맞추는 것과 같습니다.</p>
<p>이제 데이터 정제의 중요성을 확인했으니, 실제 변환 기술들에 대해 배울 준비가 되었습니다.</p>
</div>
<div id="일반-텍스트-plain-text" class="section level2" number="5.3">
<h2 number="5.3"><span class="header-section-number">5.3</span> 일반 텍스트 (Plain Text)</h2>
<p>엄밀히 말하면, <em>일반 텍스트</em>는 사람이 읽을 수 있는 문자들의 시퀀스와 선택적으로 탭이나 줄바꿈 같은 특정 유형의 제어 문자들을 의미합니다<span class="citation"><a href="#fn67" class="footnote-ref" id="fnref67"><sup>67</sup></a></span>.
로그, 전자책, 이메일, 소스 코드 등이 그 예입니다.
일반 텍스트는 바이너리 데이터에 비해 다음과 같은 많은 이점을 가집니다<span class="citation"><a href="#fn68" class="footnote-ref" id="fnref68"><sup>68</sup></a></span>.</p>
<ul>
<li>어떤 텍스트 에디터로도 열고 수정하고 저장할 수 있습니다.</li>
<li>자기 기술적(self-describing)이며 이를 생성한 애플리케이션으로부터 독립적입니다.</li>
<li>데이터를 처리하는 데 추가적인 지식이나 애플리케이션이 필요하지 않으므로 다른 데이터 형식보다 더 오래 살아남을 것입니다.</li>
</ul>
<p>하지만 가장 중요한 점은, 유닉스 철학이 일반 텍스트를 커맨드 라인 도구 간의 보편적인 인터페이스로 간주한다는 점입니다<span class="citation"><a href="#fn69" class="footnote-ref" id="fnref69"><sup>69</sup></a></span>.
즉, 대부분의 도구는 일반 텍스트를 입력으로 받고 일반 텍스트를 출력으로 내보냅니다.</p>
<p>이것만으로도 제가 일반 텍스트부터 시작할 이유는 충분합니다.
이 장에서 다룰 다른 형식들인 CSV, JSON, XML, HTML 또한 사실 일반 텍스트입니다.
우선은 일반 텍스트가 (CSV처럼) 명확한 표 구조나 (JSON, XML, HTML처럼) 중첩된 구조를 가지고 있지 않다고 가정하겠습니다.
이 장의 뒷부분에서 이러한 형식들을 다루기 위해 특별히 설계된 도구들을 소개하겠습니다.</p>
<!-- #TODO: SHOULD: What to do with this part? -->
<!-- Although the tools in this section can also be applied to these other formats (because they're still text), -->
<!-- keep in mind that the tools treat the data as plain text, and don't interpret the tabular or nested structure. -->
<!-- Sometimes you can get away with this,  -->
<div id="행-필터링하기" class="section level3" number="5.3.1">
<h3 number="5.3.1"><span class="header-section-number">5.3.1</span> 행 필터링하기</h3>
<p>첫 번째 정제 작업은 행을 필터링하는 것입니다.
이는 입력 데이터에서 각 행을 유지할지 버릴지 평가하는 것을 의미합니다.</p>
<div id="위치에-기반한-필터링" class="section level4" number="5.3.1.1">
<h4 number="5.3.1.1"><span class="header-section-number">5.3.1.1</span> 위치에 기반한 필터링</h4>
<p>행을 필터링하는 가장 간단한 방법은 위치에 기반하는 것입니다.
이는 파일의 첫 10행을 검사하고 싶거나, 다른 커맨드 라인 도구의 출력에서 특정 행을 추출하고 싶을 때 유용할 수 있습니다.
위치 기반 필터링을 설명하기 위해 10개의 행을 가진 더미 파일을 만들어 봅시다.</p>
<pre>seq -f "Line %g" 10 | tee lines</pre>
<p><code>head</code><span class="citation"><a href="#fn70" class="footnote-ref" id="fnref70"><sup>70</sup></a></span>, <code>sed</code><span class="citation"><a href="#fn71" class="footnote-ref" id="fnref71"><sup>71</sup></a></span>, 또는 <code>awk</code>를 사용하여 처음 3행을 인쇄할 수 있습니다.</p>
<pre>&lt; lines head -n 3
&lt; lines sed -n '1,3p'
&lt; lines awk 'NR &lt;= 3'</pre>
<p><span class="callout">&#10122;</span> <code>awk</code>에서 <em>NR</em>은 지금까지 확인한 총 입력 레코드 수를 나타냅니다.</p>
<p>마찬가지로 <code>tail</code><span class="citation"><a href="#fn72" class="footnote-ref" id="fnref72"><sup>72</sup></a></span>을 사용하여 마지막 3행을 인쇄할 수 있습니다.</p>
<pre>&lt; lines tail -n 3</pre>
<p>이 작업에도 <code>sed</code>나 <code>awk</code>를 사용할 수 있지만 <code>tail</code>이 훨씬 빠릅니다.
처음 3행을 제거하는 방법은 다음과 같습니다.</p>
<pre>&lt; lines tail -n +4
&lt; lines sed '1,3d'
&lt; lines sed -n '1,3!p'</pre>
<p><code>tail</code>에서는 출력하고 싶은 행 번호에 1을 더해서 지정해야 한다는 점에 유의하세요.
인쇄를 시작하고 싶은 행이라고 생각하면 됩니다.
<code>head</code>를 사용하여 마지막 3행을 지울 수도 있습니다.</p>
<pre>&lt; lines head -n -3</pre>
<p><code>sed</code>, <code>awk</code>, 또는 <code>head</code>와 <code>tail</code>의 조합을 사용하여 특정 행들을 인쇄할 수 있습니다.
여기서는 4, 5, 6행을 인쇄합니다.</p>
<pre>&lt; lines sed -n '4,6p'
&lt; lines awk '(NR&gt;=4) &amp;&amp; (NR&lt;=6)'
&lt; lines head -n 6 | tail -n 3</pre>
<p><code>sed</code>에서 시작 지점과 단계를 지정하거나 <code>awk</code>에서 머듈로(modulo) 연산자를 사용하여 홀수 행만 인쇄할 수 있습니다.</p>
<pre>&lt; lines sed -n '1~2p'
&lt; lines awk 'NR%2'</pre>
<p>짝수 행 인쇄도 비슷한 방식으로 작동합니다.</p>
<pre>&lt; lines sed -n '0~2p'
&lt; lines awk '(NR+1)%2'</pre>
<!-- #TODO: SHOULD: Mention somewhere in the book that Linux doesn't care about file extensions -->

<div class="rmdnote">
이 예제들의 상당수는 작음 기호(<code>&lt;</code>) 뒤에 파일 이름을 붙여서 시작합니다.
이렇게 하면 파이프라인을 왼쪽에서 오른쪽으로 읽을 수 있기 때문입니다.
이는 제 개인적인 선호임을 알아두세요.
파일의 내용을 파이프로 넘기기 위해 <code>cat</code>을 사용할 수도 있습니다.
또한, 많은 커맨드 라인 도구는 파일 이름을 인자로 직접 받기도 합니다.
</div>
</div>
<div id="패턴에-기반한-필터링" class="section level4" number="5.3.1.2">
<h4 number="5.3.1.2"><span class="header-section-number">5.3.1.2</span> 패턴에 기반한 필터링</h4>
<p>가끔은 내용에 따라 행을 유지하거나 버리고 싶을 때가 있습니다.
행을 필터링하는 표준적인 커맨드 라인 도구인 <code>grep</code>을 사용하면 특정 패턴이나 정규 표현식과 일치하는 모든 행을 인쇄할 수 있습니다.
예를 들어, <em>이상한 나라의 앨리스</em>에서 모든 장(chapter)의 제목을 추출해 보겠습니다.</p>
<pre>&lt; alice.txt grep -i chapter</pre>
<p><span class="callout">&#10122;</span> <code>-i</code> 옵션은 대소문자를 구분하지 않고 매칭하도록 지정합니다.</p>
<p>정규 표현식을 지정할 수도 있습니다.
예를 들어, <em>The</em>로 시작하는 제목만 인쇄하고 싶다면 다음과 같이 합니다.</p>
<pre>&lt; alice.txt grep -E '^CHAPTER (.*)\. The'</pre>
<p>정규 표현션을 활성화하려면 <code>-E</code> 옵션을 지정해야 한다는 점에 유의하세요.
그렇지 않으면 <code>grep</code>은 패턴을 리터럴 문자열로 해석하여 검색 결과가 나오지 않을 가능성이 큽니다.</p>
<pre>&lt; alice.txt grep '^CHAPTER (.*)\. The'</pre>
<p><code>-v</code> 옵션을 사용하면 일치 항목을 반전시켜서 패턴과 일치하지 <em>않는</em> 행들을 인쇄합니다.
아래의 정규 표현식은 공백 문자만 포함된 행과 일치합니다.
따라서 이를 반전 시키고 <code>wc -l</code>을 사용하면 비어있지 않은 행의 개수를 셀 수 있습니다.</p>
<pre>&lt; alice.txt grep -Ev '^\s$' | wc -l</pre>
</div>
<div id="무작위성에-기반한-필터링" class="section level4" number="5.3.1.3">
<h4 number="5.3.1.3"><span class="header-section-number">5.3.1.3</span> 무작위성에 기반한 필터링</h4>
<p>데이터 파이프라인을 구성하는 과정에서 데이터 양이 아주 많다면 파이프라인을 디버깅하는 것이 번거로울 수 있습니다.
그럴 때 데이터에서 더 작은 샘플을 생성하는 것이 유용할 수 있습니다.
이때 <code>sample</code><span class="citation"><a href="#fn73" class="footnote-ref" id="fnref73"><sup>73</sup></a></span>이 요긴하게 쓰입니다.
<code>sample</code>의 주요 목적은 입력 데이터에서 각 행마다 일정 비율만큼만 출력하여 데이터의 부분 집합을 얻는 것입니다.</p>
<pre>seq -f "Line %g" 1000 | sample -r 1%</pre>
<p>여기서는 모든 입력 행이 인쇄될 확률이 1%입니다.
이 백분율은 분수(예: <code>1/100</code>)나 확률(예: <code>0.01</code>)로도 지정할 수 있습니다.</p>
<p><code>sample</code>은 파이프라인을 디버깅할 때 유용한 두 가지 다른 용도가 있습니다.
첫째, 출력에 약간의 지연을 추가할 수 있습니다.
이는 입력이 지속적인 스트림일 때(예: <a href="#chapter-3-obtaining-data">3장</a>에서 본 위키피디아 스트림), 데이터가 너무 빨리 들어와서 무슨 일이 일어나고 있는지 확인하기 어려울 때 유용합니다.
둘째, <code>sample</code>에 타이머를 설정하여 진행 중인 프로세스를 수동으로 종료할 필요가 없게 할 수 있습니다.
예를 들어, 각 행이 인쇄될 때 1초의 지연을 추가하고 5초 동안만 실행하려면 다음과 같이 입력합니다.</p>
<pre>seq -f "Line %g" 1000 | sample -r 1% -d 1000 -s 5 | ts</pre>
<p><span class="callout">&#10122;</span> <code>ts</code><span class="citation"><a href="#fn74" class="footnote-ref" id="fnref74"><sup>74</sup></a></span> 도구는 각 행의 맨 앞에 타임스탬프를 추가합니다.</p>
<p>불필요한 계산을 방지하기 위해 파이프라인에서 가능한 한 앞부분에 <code>sample</code>을 배치하도록 하세요.
사실 이 논리는 <code>head</code>나 <code>tail</code>처럼 데이터를 줄여주는 모든 커맨드 라인 도구에 적용됩니다.
파이프라인이 제대로 작동한다는 확신이 들면 파이프라인에서 이를 제거하면 됩니다.</p>
</div>
</div>
<div id="값-추출하기" class="section level3" number="5.3.2">
<h3 number="5.3.2"><span class="header-section-number">5.3.2</span> 값 추출하기</h3>
<p>앞의 예제에서 실제 장 제목을 추출하려면, <code>grep</code>의 출력을 <code>cut</code>으로 파이핑하는 간단한 접근 방식을 사용할 수 있습니다.</p>
<pre>grep -i chapter alice.txt | cut -d ' ' -f 3-</pre>
<p>여기서 <code>cut</code>으로 전달된 각 행은 공백을 기준으로 필드(field)로 나뉘고, 세 번째 필드부터 마지막 필드까지 인쇄됩니다.
필드의 총 개수는 입력 행마다 다를 수 있습니다.
<code>sed</code>를 사용하면 훨씬 더 복잡한 방식으로 동일한 작업을 수행할 수 있습니다.</p>
<pre>sed -rn 's/^CHAPTER ([IVXLCDM]{1,})\. (.*)$/\2/p' alice.txt | trim 3</pre>
<p>(출력이 동일하므로 3행으로 잘랐습니다.) 이 방식은 정규 표현식과 후방 참조(back reference)를 사용합니다.
여기서 <code>sed</code>는 <code>grep</code>이 하던 작업까지 도맡았습니다.
더 간단한 방법으로는 해결되지 않을 정도로 복잡한 상황에서만 이 방식을 사용하는 것을 권장합니다.
예를 들어, <em>chapter</em>라는 단어가 단순히 새 장의 시작을 알리는 용도뿐만 아니라 텍스트 자체의 일부로 쓰인 경우가 있을 때 그렇습니다.
물론 이를 해결할 수 있는 다양한 수준의 복잡한 방법이 있겠지만, 여기서는 매우 엄격한 접근 방식을 예로 보여 드린 것입니다.
실제로 중요한 과제는 복잡성과 유연성 사이에서 균형을 잘 잡는 파이프라인을 고안하는 것입니다.</p>
<p><code>cut</code>은 문자 위치를 기준으로도 나눌 수 있다는 점을 언급할 가치가 있습니다.
이는 입력 행마다 동일한 위치의 문자 집합을 추출(또는 제거)하고 싶을 때 유용합니다.</p>
<pre>grep -i chapter alice.txt | cut -c 9-</pre>
<p><code>grep</code>은 <code>-o</code> 옵션을 사용하여 모든 일치 항목을 별도의 행으로 출력하는 훌륭한 기능을 가지고 있습니다.</p>
<pre>&lt; alice.txt grep -oE '\w{2,}' | trim</pre>
<p>그렇다면 <em>a</em>로 시작하고 <em>e</em>로 끝나는 모든 단어의 데이터셋을 만들고 싶다면 어떻게 해야 할까요?
당연히 이를 위한 파이프라인도 있습니다.</p>
<pre>&lt; alice.txt tr '[:upper:]' '[:lower:]' |
grep -oE '\w{2,}' |
grep -E '^a.*e$' |
sort | uniq | sort -nr | trim</pre>
<p><span class="callout">&#10122;</span> 여기서 텍스트를 소문자로 만들기 위해 <code>tr</code>을 사용합니다. 다음 절에서 <code>tr</code>을 더 자세히 살펴보겠습니다.</p>
<p>두 개의 <code>grep</code> 명령어를 하나로 합칠 수도 있었겠지만, 이 경우에는 이전 파이프라인을 재사용하고 조정하는 것이 더 쉽다고 판단했습니다.
일을 완수하기 위해 실용적인 태도를 취하는 것은 전혀 부끄러운 일이 아닙니다!</p>
</div>
<div id="값-교체-및-삭제하기" class="section level3" number="5.3.3">
<h3 number="5.3.3"><span class="header-section-number">5.3.3</span> 값 교체 및 삭제하기</h3>
<p><em>반전(translate)</em>의 약자인 커맨드 라인 도구 <code>tr</code><span class="citation"><a href="#fn75" class="footnote-ref" id="fnref75"><sup>75</sup></a></span>을 사용하여 개별 문자를 교체하거나 삭제할 수 있습니다.
예를 들어, 공백을 다음과 같이 언더스코어로 바꿀 수 있습니다.</p>
<pre>echo 'hello world!' | tr ' ' '_'</pre>
<p>둘 이상의 문자를 교체해야 한다면 다음과 같이 조합할 수 있습니다.</p>
<pre>echo 'hello world!' | tr ' !' '_?'</pre>
<p><code>tr</code>에 <code>-d</code> 인자를 지정하여 개별 문자를 삭제할 수도 있습니다.</p>
<pre>echo 'hello world!' | tr -d ' !'
echo 'hello world!' | tr -d -c '[a-z]'</pre>
<p>이 경우 위 두 명령어는 동일한 결과를 냅니다.
하지만 두 번째 명령어는 두 가지 추가 기능을 사용합니다.
대괄호와 하이픈(<code>[-]</code>)을 사용하여 문자 <em>범위</em>(모든 소문자)를 지정했고, <code>-c</code> 옵션은 그에 대한 보집합(complement)을 사용함을 나타냅니다.
즉, 이 명령어는 소문자만 남깁니다.
<code>tr</code>을 사용하여 텍스트를 대문자로 변환할 수도 있습니다.</p>
<pre>echo 'hello world!' | tr '[a-z]' '[A-Z]'
echo 'hello world!' | tr '[:lower:]' '[:upper:]'</pre>
<p>하지만 ASCII가 아닌 문자를 번역해야 한다면 <code>tr</code>이 작동하지 않을 수 있습니다. <code>tr</code>은 단일 바이트 문자에서만 작동하기 때문입니다. 그런 경우에는 대신 <code>sed</code>를 사용해야 합니다.</p>
<pre>echo 'hello world!' | tr '[a-z]' '[A-Z]'
echo 'hallo wêreld!' | tr '[a-z]' '[A-Z]'
echo 'hallo wêreld!' | tr '[:lower:]' '[:upper:]'
echo 'hallo wêreld!' | sed 's/[[:lower:]]*/\U&amp;/g'
echo 'helló világ' | tr '[:lower:]' '[:upper:]'
echo 'helló világ' | sed 's/[[:lower:]]*/\U&amp;/g'</pre>
<!-- #TODO: SHOULD: Give a proper intro about sed -->
<p>개별 문자 이상의 것을 조작해야 한다면 <code>sed</code>가 유용하다는 사실을 알게 될 것입니다.
이미 <em>alice.txt</em>에서 장 제목을 추출하는 <code>sed</code> 예제를 보셨습니다.
추출, 삭제, 교체는 사실 <code>sed</code>에서 모두 동일한 작업입니다.
단지 서로 다른 정규 표현식을 지정할 뿐입니다.
예를 들어, 단어를 바꾸거나 반복된 공백을 제거하고 앞부분의 공백을 제거하려면 다음과 같이 합니다.</p>
<pre>echo ' hello     world!' |
sed -re 's/hello/bye/' |
sed -re 's/\s+/ /g' |
sed -re 's/\s+//'</pre>
<p><span class="callout">&#10122;</span> <em>hello</em>를 <em>bye</em>로 바꿉니다.
<br><span class="callout">&#10123;</span> 임의의 공백을 하나의 공백으로 바꿉니다. 플래그 <code>g</code>는 글로벌(global)의 약자로, 동일한 행에서 동일한 치환을 여러 번 적용할 수 있음을 의미합니다.
<br><span class="callout">&#10124;</span> 여기서는 <code>g</code> 플래그를 지정하지 않았으므로 맨 앞의 공백만 제거합니다.</p>
<p>이전의 <code>grep</code> 예제와 마찬가지로, 이 세 개의 <code>sed</code> 명령어는 하나로 합쳐질 수 있습니다.</p>
<pre>echo ' hello     world!' |
sed -re 's/hello/bye/;s/\s+/ /g;s/\s+//'</pre>
<p>글쎄요, 여러분은 어느 쪽이 읽기 더 편하신가요?</p>
</div>
</div>
<div id="csv" class="section level2" number="5.4">
<h2 number="5.4"><span class="header-section-number">5.4</span> CSV</h2>
<!-- #TODO: MUST: ### Canonical Format -->
<!-- The `csvkit` documentation[@csvkit] opens with: [...] CSV, the king of tabular file formats. -->
<!-- Canonical format. The format that we want to convert to. -->
<!-- Two properties. it's plain text and it has a rectangular shape, meaning in consists of rows and columns. -->
<!-- As a format, -->
<!-- As a shape, -->
<!-- Even kings have their flaws. -->
<!-- CSV definitely has its flaws. No meta data. No rules regarding quoting, the delimiter, header. -->
<!-- Writing a robust CSV parser is really hard. Nevertheless, CSV has many advantages. -->
<!-- CSV, which is the main format I'll be working with in this chapter, is actually not the easiest format to work with. Many CSV datasets are broken or incompatible with each other because there is no standard syntax, unlike XML and JSON. -->
<!-- Export from Database, spreadsheets, rectangular. -->
<!-- - It's still plain text, so can be read, edited, and even created in any text editor. -->
<!-- - CSV can be imported by many programming languages such as Python, R, and JavaScript and many software such as Excel, Tableau, and Power BI. -->
<!-- - Related to the previous point, but worth mentioning separately: a CSV directly translates to a data frame in Python (with the pandas package), R, and Julia. This means that can immediately continue scrubbing, exploring, and modeling in those languages. -->
<!-- - Speaking of modeling, most machine learning algorithms expect data to be in a rectangular format, or more precisely, a matrix of numerical values where each row is a data point and each column is a feature. More on this in Chapter 9. -->
<!-- makes assumptions, same number of fields per row. -->
<!-- flat. not nested. -->
<!-- CVS is not nested structure -->
<!-- If you build an API, use JSON -->
<!-- If you -->
<!-- You rarely have to covert CSV to anything else when you're doing data analysis. -->
<div id="본문bodies과-헤더headers와-열columns" class="section level3" number="5.4.1">
<h3 number="5.4.1"><span class="header-section-number">5.4.1</span> 본문(Bodies)과 헤더(Headers)와 열(Columns)</h3>
<p>일반 텍스트를 정제하기 위해 사용했던 <code>tr</code>이나 <code>grep</code> 같은 커맨드 라인 도구가 CSV에 항상 적용될 수 있는 것은 아닙니다.
그 이유는 이러한 커맨드 라인 도구들이 헤더, 본문, 열에 대한 개념이 없기 때문입니다.
만약 <code>grep</code>을 사용하여 행을 필터링하면서 항상 출력에 헤더를 포함하고 싶다면 어떻게 해야 할까요?
혹은 <code>tr</code>을 사용하여 다른 열은 건드리지 않고 특정 열의 값만 대문자로 바꾸고 싶다면 어떻게 해야 할까요?</p>
<p>이를 위한 여러 단계의 우회 방법이 있긴 하지만 매우 번거롭습니다.
더 좋은 방법이 있습니다.
일반적인 커맨드 라인 도구를 CSV에 활용하기 위해 <code>body</code><span class="citation"><a href="#fn76" class="footnote-ref" id="fnref76"><sup>76</sup></a></span>, <code>header</code><span class="citation"><a href="#fn77" class="footnote-ref" id="fnref77"><sup>77</sup></a></span>, <code>cols</code><span class="citation"><a href="#fn78" class="footnote-ref" id="fnref78"><sup>78</sup></a></span>라는 이름의 세 가지 도구를 소개하겠습니다.</p>
<p>첫 번째 도구인 <code>body</code>부터 시작해 보겠습니다.
<code>body</code>를 사용하면 CSV 파일의 헤더를 제외한 나머지 부분, 즉 본문에 임의의 커맨드 라인 도구를 적용할 수 있습니다.
예를 들어 다음과 같습니다.</p>
<pre>echo -e "value\n7\n2\n5\n3" | body sort -n</pre>
<p>이 도구는 CSV 파일의 헤더가 한 줄이라고 가정합니다.
작동 방식은 다음과 같습니다.</p>
<ul>
<li>표준 입력에서 한 줄을 가져와 <em>$header</em>라는 변수에 저장합니다.</li>
<li>헤더를 출력합니다.</li>
<li>표준 입력에 남은 데이터에 대해 <code>body</code>에 전달된 모든 커맨드 라인 인자를 실행합니다.</li>
</ul>
<p>또 다른 예입니다.
다음 CSV 파일의 행 개수를 세고 싶다고 가정해 봅시다.</p>
<pre>seq 5 | header -a count</pre>
<p><code>wc -l</code>을 사용하면 모든 행의 개수를 셀 수 있습니다.</p>
<pre>seq 5 | header -a count | wc -l</pre>
<p>본문의 행만 고려하고 싶다면(즉, 헤더를 제외한 모든 것), <code>body</code>를 추가합니다.</p>
<pre>seq 5 | header -a count | body wc -l</pre>
<p>헤더는 계산에 포함되지 않으며 출력에 다시 인쇄됩니다.</p>
<p>두 번째 도구인 <code>header</code>를 사용하면 CSV 파일의 헤더를 조작할 수 있습니다.
인자를 제공하지 않으면 CSV 파일의 헤더가 인쇄됩니다.</p>
<pre>&lt; tips.csv header</pre>
<p>이는 <code>head -n 1</code>과 같습니다.
헤더가 두 줄 이상인 경우(권장되지는 않음) <code>-n 2</code>를 지정할 수 있습니다.
CSV 파일에 헤더를 추가할 수도 있습니다.</p>
<pre>seq 5 | header -a count</pre>
<p>이는 <code>echo "count" | cat - &lt;(seq 5)</code>와 동일합니다.
헤더 삭제는 <code>-d</code> 옵션으로 수행합니다.</p>
<pre>&lt; iris.csv header -d | trim</pre>
<p>이는 <code>tail -n +2</code>와 비슷하지만 기억하기 조금 더 쉽습니다.
헤더 교체는 <code>-r</code> 옵션으로 수행합니다. 이는 내부적으로 헤더를 먼저 삭제한 다음 추가하는 방식입니다. 여기서는 <code>body</code>와 결합해 보겠습니다.</p>
<pre>seq 5 | header -a line | body wc -l | header -r count</pre>
<p>마지막으로, <code>body</code> 도구가 본문에 하는 것처럼 헤더에만 명령을 적용할 수 있습니다.
예를 들어 다음과 같습니다.</p>
<pre>seq 5 | header -a line | header -e "tr '[a-z]' '[A-Z]'"</pre>
<p>세 번째 도구는 <code>cols</code>로, 특정 열의 부분 집합에만 명령을 적용할 수 있게 해줍니다.
예를 들어, tips 데이터셋에서 다른 열과 헤더는 건드리지 않고 day 열의 값만 대문자로 바꾸고 싶다면 다음과 같이 <code>cols</code>와 <code>body</code>를 조합하여 사용합니다.</p>
<pre>&lt; tips.csv cols -c day body "tr '[a-z]' '[A-Z]'" | head -n 5 | csvlook</pre>
<p><code>header -e</code>, <code>body</code>, <code>cols</code>에 여러 커맨드 라인 도구와 인자를 명령어로 전달할 때 따옴표 처리가 까다로울 수 있다는 점에 유의하세요.
이런 문제가 발생하면 별도의 커맨드 라인 도구를 만들어서 그 명령어를 전달하는 것이 가장 좋습니다.</p>
<p>결론적으로, CSV 데이터를 위해 특별히 제작된 커맨드 라인 도구를 사용하는 것이 일반적으로 바람직하지만, <code>body</code>, <code>header</code>, <code>cols</code>를 사용하면 필요한 경우 고전적인 커맨드 라인 도구들을 CSV 파일에도 적용할 수 있습니다.</p>
</div>
<div id="csv에서-sql-쿼리-수행하기" class="section level3" number="5.4.2">
<h3 number="5.4.2"><span class="header-section-number">5.4.2</span> CSV에서 SQL 쿼리 수행하기</h3>
<p>만약 이번 장에서 언급된 커맨드 라인 도구들이 충분한 유연성을 제공하지 못한다면, 커맨드 라인에서 데이터를 정제하는 또 다른 접근 방식이 있습니다.
<code>csvsql</code><span class="citation"><a href="#fn79" class="footnote-ref" id="fnref79"><sup>79</sup></a></span> 도구는 CSV 파일에서 직접 SQL 쿼리를 실행할 수 있게 해줍니다.
SQL은 데이터 정제 작업을 정의하는 강력한 언어이며, 개별 커맨드 라인 도구를 사용하는 것과는 매우 다른 방식입니다.</p>

<div class="rmdnote">
만약 데이터가 원래 관계형 데이터베이스에서 온 것이라면, 가능하면 그 데이터베이스에서 SQL 쿼리를 실행한 다음 결과를 CSV로 추출하는 것이 좋습니다. <a href="#chapter-3-obtaining-data">3장</a>에서 논의했듯이 이를 위해 <code>sql2csv</code> 도구를 사용할 수 있습니다. 데이터베이스에서 CSV 파일로 먼저 내보낸 다음 다시 SQL을 적용하는 것은 속도가 느릴 뿐만 아니라, CSV 데이터로부터 열 유형(column types)이 올바르게 유추되지 않을 가능성도 있기 때문입니다.
</div>
<p>아래의 정제 작업들에는 <code>csvsql</code>을 포함한 몇 가지 솔루션을 소개하겠습니다. 기본적인 명령어는 다음과 같습니다.</p>
<pre>seq 5 | header -a val | csvsql --query "SELECT SUM(val) AS sum FROM stdin"</pre>
<p>표준 입력을 <code>csvsql</code>로 전달하면 테이블 이름은 <em>stdin</em>이 됩니다.
열의 유형은 데이터로부터 자동으로 유추됩니다.
나중에 CSV 파일 결합 섹션에서 보겠지만, 여러 개의 CSV 파일을 지정할 수도 있습니다.
<!-- #TODO: MUST: Reference SQLite -->
<code>csvsql</code>은 SQL 표준과 약간의 차이가 있는 SQLite 방식을 사용한다는 점을 유념하세요.
SQL은 일반적으로 다른 솔루션보다 장황하긴 하지만 훨씬 더 유연합니다.
만약 이미 SQL로 정제 문제를 해결하는 방법을 알고 있다면 커맨드 라인에서도 이를 사용하지 않을 이유가 없습니다.</p>
</div>
<div id="열-추출-및-재정렬하기" class="section level3" number="5.4.3">
<h3 number="5.4.3"><span class="header-section-number">5.4.3</span> 열 추출 및 재정렬하기</h3>
<!-- #TODO: MUST: Replace csvcut with xsv select -->
<p><code>csvcut</code><span class="citation"><a href="#fn80" class="footnote-ref" id="fnref80"><sup>80</sup></a></span> 도구를 사용하여 열을 추출하고 재정렬할 수 있습니다.
예를 들어, Iris 데이터셋에서 숫자 값이 포함된 열만 남기고 가운데 두 열의 순서를 바꾸려면 다음과 같이 합니다.</p>
<pre>&lt; iris.csv csvcut -c sepal_length,petal_length,sepal_width,petal_width | csvlook</pre>
<p>또는 <code>-C</code>(complement) 옵션을 사용하여 제외할 열을 지정할 수도 있습니다.</p>
<pre>&lt; iris.csv csvcut -C species | csvlook</pre>
<p>이 경우 포함된 열들은 원래 순서를 유지합니다.
열 이름 대신 1부터 시작하는 열 인덱스를 지정할 수도 있습니다.
예를 들어, 홀수 번째 열만 선택하는 것도 가능합니다.</p>
<pre>echo 'a,b,c,d,e,f,g,h,i\n1,2,3,4,5,6,7,8,9' |
csvcut -c $(seq 1 2 9 | paste -sd,)</pre>
<p>만약 어떤 값에도 쉼표가 포함되어 있지 않다는 확신이 있다면 <code>cut</code>을 사용하여 열을 추출할 수도 있습니다.
하지만 <code>cut</code>은 다음 명령어에서 볼 수 있듯이 열의 순서를 바꾸지 못한다는 점에 주의하세요.</p>
<pre>echo 'a,b,c,d,e,f,g,h,i\n1,2,3,4,5,6,7,8,9' | cut -d, -f 5,1,3</pre>
<p>보시다시피 <code>-f</code> 옵션으로 열을 어떤 순서로 지정하든 상관없습니다. <code>cut</code>을 사용하면 항상 원래 순서대로 나타납니다.
완전성을 위해, Iris 데이터셋의 숫자 열을 추출하고 재정렬하는 SQL 방식도 살펴보겠습니다.</p>
<pre>&lt; iris.csv csvsql --query "SELECT sepal_length, petal_length, "\
"sepal_width, petal_width FROM stdin" | head -n 5 | csvlook</pre>
</div>
<div id="행-필터링하기-1" class="section level3" number="5.4.4">
<h3 number="5.4.4"><span class="header-section-number">5.4.4</span> 행 필터링하기</h3>
<p>CSV 파일에서 행(rows)을 필터링하는 것이 일반 텍스트 파일에서 행(lines)을 필터링하는 것과 다른 점은, 특정 열의 값에만 기반하여 필터링하고 싶을 수 있다는 것입니다.
위치 기반 필터링은 기본적으로 동일하지만, CSV 파일의 첫 번째 행이 대개 헤더라는 점을 고려해야 합니다.
헤더를 유지하고 싶다면 항상 <code>body</code> 도구를 사용할 수 있다는 점을 기억하세요.</p>
<!-- #TODO: #MUST use xsv slice and xsv search -->
<pre>seq 5 | sed -n '3,5p'
seq 5 | header -a count | body sed -n '3,5p'</pre>
<p>특정 열 내의 특정 패턴에 따라 필터링하려는 경우 <code>csvgrep</code><span class="citation"><a href="#fn81" class="footnote-ref" id="fnref81"><sup>81</sup></a></span>, <code>awk</code>, 또는 <code>csvsql</code>을 사용할 수 있습니다.
예를 들어, 일행의 수(party size)가 5명 미만인 모든 영수증을 제외하려면 다음과 같이 합니다.</p>
<pre>csvgrep -c size -i -r "[1-4]" tips.csv</pre>
<p><code>awk</code>와 <code>csvsql</code>은 숫자 비교도 수행할 수 있습니다.
예를 들어, 토요일이나 일요일에 40달러가 넘는 모든 영수증을 가져오려면 다음과 같이 합니다.</p>
<pre>&lt; tips.csv awk -F, 'NR==1 || ($1 &gt; 40.0) &amp;&amp; ($5 ~ /^S/)'</pre>
<p><code>csvsql</code> 솔루션은 더 장황하지만 인덱스 대신 열 이름을 사용하므로 더 견고합니다.</p>
<pre>csvsql --query "SELECT * FROM tips WHERE bill &gt; 40 AND day LIKE 'S%'" tips.csv</pre>
<p>SQL의 <em>WHERE</em> 절은 날짜나 집합에 대해 작동할 수 있고 복잡한 절의 조합을 형성할 수 있기 때문에, 그 유연성은 다른 커맨드 라인 도구들이 쉽게 따라가기 어렵습니다.</p>
</div>
<div id="열-병합하기" class="section level3" number="5.4.5">
<h3 number="5.4.5"><span class="header-section-number">5.4.5</span> 열 병합하기</h3>
<p>열 병합은 관심 있는 값이 여러 열에 분산되어 있을 때 유용합니다.
날짜(연, 월, 일이 별도의 열인 경우)나 이름(이름과 성이 별도의 열인 경우)에서 이런 일이 발생할 수 있습니다.
두 번째 상황을 살펴보겠습니다.</p>
<!-- #TODO: Must use composers.csv -->
<p>입력 CSV는 작곡가 목록입니다.
여러분의 과제는 이름(first name)과 성(last name)을 합쳐서 전체 이름(full name)을 만드는 것이라고 가정해 봅시다.
이 과제를 해결하기 위해 <code>sed</code>, <code>awk</code>, <code>cols</code> + <code>tr</code>, <code>csvsql</code>의 네 가지 접근 방식을 제시하겠습니다.
먼저 입력 CSV를 살펴보겠습니다.</p>
<pre>csvlook -I names.csv</pre>
<p>첫 번째 방식인 <code>sed</code>는 두 개의 문(statement)을 사용합니다.
첫 번째는 헤더를 교체하는 것이고, 두 번째는 두 번째 행부터 적용되는 후방 참조를 포함한 정규 표현식입니다.</p>
<pre>&lt; names.csv sed -re '1s/.*/id,full_name,born/g;2,$s/(.*),(.*),(.*),(.*)/\1,\3 \2,\4/g' |
csvlook -I</pre>
<p><code>awk</code> 접근 방식은 다음과 같습니다.</p>
<pre>&lt; names.csv awk -F, 'BEGIN{OFS=","; print "id,full_name,born"} {if(NR &gt; 1) {print $1,$3" "$2,$4}}' |
csvlook -I</pre>
<p><code>tr</code>과 결합한 <code>cols</code> 방식입니다.</p>
<pre>&lt; names.csv |
cols -c first_name,last_name tr \",\" \" \" |
header -r full_name,id,born |
csvcut -c id,full_name,born |
csvlook -I</pre>
<p><code>csvsql</code>은 쿼리를 실행하기 위해 SQLite 데이터베이스를 사용하며, <code>||</code>는 문자열 연결(concatenation)을 의미한다는 점에 유의하세요.</p>
<pre>&lt; names.csv csvsql --query "SELECT id, first_name || ' ' || last_name "\
"AS full_name, born FROM stdin" | csvlook -I</pre>
<p>만약 <em>last_name</em>에 쉼표가 포함되어 있다면 어떻게 될까요? 명확성을 위해 가공되지 않은 입력 CSV를 살펴보겠습니다.</p>
<!-- Ludwig van Beethoven enters the party -->
<!-- ```{console} -->
<!-- echo 'Ludwig,"Beethoven, van",1770,"Bonn,\nGermany"' >> composers.csv -->
<!-- ``` -->
<!-- bat -A composers.csv -->
<!-- //# cat composers.csv | csvquote | tr -d $'\x1f'   # comma (unit separator in unicode) -->
<!-- //# cat composers.csv | csvquote | tr $'\x1e' ' '  # new line (record separator in unicode) -->
<pre>cat names-comma.csv</pre>
<p>글쎄요, 처음 세 가지 방식은 모두 각기 다른 이유로 실패하는 것 같군요. 오직 <code>csvsql</code>만이 first_name과 full_name을 제대로 결합할 수 있습니다.</p>
<pre>&lt; names-comma.csv sed -re '1s/.*/id,full_name,born/g;2,$s/(.*),(.*),(.*),(.*)/\1,\3 \2,\4/g' | tail -n 1</pre>
<pre>&lt; names-comma.csv awk -F, 'BEGIN{OFS=","; print "id,full_name,born"} {if(NR &gt; 1) {print $1,$3" "$2,$4}}' | tail -n 1</pre>
<pre>&lt; names-comma.csv | cols -c first_name,last_name tr \",\" \" \" |
header -r full_name,id,born | csvcut -c id,full_name,born | tail -n 1</pre>
<pre>&lt; names-comma.csv csvsql --query "SELECT id, first_name || ' ' || last_name AS full_name, born FROM stdin" | tail -n 1</pre>
<pre>&lt; names-comma.csv rush run -t 'unite(df, full_name, first_name, last_name, sep = " ")' - | tail -n 1</pre>
<p>잠깐만요! 저 마지막 명령어는 무엇인가요? R인가요? 사실 그렇습니다.
<code>rush</code>라는 커맨드 라인 도구를 통해 실행된 R 코드입니다. 지금 말씀드릴 수 있는 것은 이 방식 또한 두 개의 열을 병합하는 데 성공했다는 점입니다.
이 멋진 도구에 대해서는 나중에 다시 다루겠습니다.</p>
<!-- ```{console} -->
<!-- shuf -ri 0-9999 -n 24 | nl -v0 -w1 -s, | header -a hour,value > 2021-01-01.csv -->
<!-- shuf -ri 0-9999 -n 24 | nl -v0 -w1 -s, | header -a hour,value > 2021-01-02.csv -->
<!-- shuf -ri 0-9999 -n 24 | nl -v0 -w1 -s, | header -a hour,value > 2021-01-03.csv -->
<!-- head -n 3 2021-*.csv -->
<!-- ``` -->
<!-- ```{console} -->
<!-- csvstack --group-name date --filenames 2021-*.csv | sed 's/\.csv,/,/' | csvlook -->
<!-- ``` -->
<!-- ```{console} -->
<!-- awk 'NR==1 {H=$0; print "date,"$0} $0!=H {print FILENAME","$0}' 2021-01-0*.csv | csvlook -->
<!-- ``` -->
<div id="가로로-결합하기" class="section level4" number="5.4.5.1">
<h4 number="5.4.5.1"><span class="header-section-number">5.4.5.1</span> 가로로 결합하기</h4>
<p>나란히 붙이고 싶은 세 개의 CSV 파일이 있다고 가정해 봅시다. 파이프라인 중간에 <code>csvcut</code>의 결과를 저장하기 위해 <code>tee</code><span class="citation"><a href="#fn82" class="footnote-ref" id="fnref82"><sup>82</sup></a></span>를 사용합니다.</p>
<pre>&lt; tips.csv csvcut -c bill,tip | tee bills.csv | head -n 3 | csvlook
&lt; tips.csv csvcut -c day,time | tee datetime.csv |
head -n 3 | csvlook -I
&lt; tips.csv csvcut -c sex,smoker,size | tee customers.csv |
head -n 3 | csvlook</pre>
<p>행들이 서로 일치한다고 가정하면, <code>paste</code><span class="citation"><a href="#fn83" class="footnote-ref" id="fnref83"><sup>83</sup></a></span>를 사용하여 파일들을 하나로 합칠 수 있습니다.</p>
<pre>paste -d, {bills,customers,datetime}.csv | head -n 3 | csvlook -I</pre>
<p>여기서 커맨드 라인 인자 <code>-d</code>는 <code>paste</code>가 구분자로 쉼표를 사용하도록 지시합니다.</p>
</div>
<div id="결합joining" class="section level4" number="5.4.5.2">
<h4 number="5.4.5.2"><span class="header-section-number">5.4.5.2</span> 결합(Joining)</h4>
<p>가끔은 데이터를 세로로나 가로로 단순히 이어 붙이는 것만으로는 합칠 수 없습니다.
특히 관계형 데이터베이스의 경우, 중복을 최소화하기 위해 데이터가 여러 테이블(또는 파일)에 분산되어 있는 경우가 있습니다.
Iris 데이터셋에 세 가지 붓꽃 종류에 대한 더 많은 정보(예: USDA 식별자)를 추가하여 확장하고 싶다고 가정해 봅시다.
마침 이러한 식별자가 포함된 별도의 CSV 파일이 있습니다.</p>
<pre>csvlook irismeta.csv</pre>
<p>이 데이터셋과 Iris 데이터셋의 공통점은 <em>species</em> 열입니다.
<code>csvjoin</code><span class="citation"><a href="#fn84" class="footnote-ref" id="fnref84"><sup>84</sup></a></span>을 사용하여 두 데이터셋을 결합할 수 있습니다.</p>
<pre>csvjoin -c species iris.csv irismeta.csv | csvcut -c sepal_length,sepal_width,species,usda_id | sed -n '1p;49,54p' | csvlook</pre>
<p>물론 <code>csvsql</code>을 사용하여 SQL 방식으로 접근할 수도 있습니다. 평소와 같이 조금 더 길지만, 잠재적으로 훨씬 더 유연합니다.</p>
<pre>csvsql --query 'SELECT i.sepal_length, i.sepal_width, i.species, m.usda_id FROM iris i JOIN irismeta m ON (i.species = m.species)' iris.csv irismeta.csv | sed -n '1p;49,54p' | csvlook</pre>
</div>
</div>
</div>
<div id="xmlhtml-및-json-작업하기" class="section level2" number="5.5">
<h2 number="5.5"><span class="header-section-number">5.5</span> XML/HTML 및 JSON 작업하기</h2>
<p>이 섹션에서는 데이터를 한 형식에서 다른 형식으로 변환할 수 있는 몇 가지 커맨드 라인 도구를 시연하겠습니다.
데이터를 변환하는 데에는 두 가지 이유가 있습니다.</p>
<p>첫째, 많은 시각화 및 머신러닝 알고리즘이 표 형식의 데이터를 요구하기 때문에, 데이터를 데이터베이스 테이블이나 스프레드시트와 같은 표 형태로 만들어야 하는 경우가 많습니다.
CSV는 본래 표 형식이지만, JSON과 HTML/XML 데이터는 깊게 중첩된 구조를 가질 수 있습니다.</p>
<p>둘째, <code>cut</code>이나 <code>grep</code> 같은 고전적인 커맨드 라인 도구들은 대부분 일반 텍스트를 대상으로 작동합니다.
텍스트는 커맨드 라인 도구 간의 보편적인 인터페이스로 간주되기 때문입니다.
게다가 다른 형식들은 비교적 나중에 등장했습니다. 이러한 각 형식을 일반 텍스트로 취급하면 고전적인 커맨드 라인 도구들을 다른 형식에도 적용할 수 있습니다.</p>
<p>가끔은 구조화된 데이터에 고전적인 도구들을 적용하여 문제를 해결할 수 있습니다.
예를 들어, 아래의 JSON 데이터를 일반 텍스트로 취급하여 <code>sed</code>를 사용해 <em>gender</em> 속성을 <em>sex</em>로 바꿀 수 있습니다.</p>
<pre>sed -e 's/"gender":/"sex":/g' users.json | jq | trim</pre>
<p>다른 많은 커맨드 라인 도구와 마찬가지로 <code>sed</code>는 데이터의 구조를 활용하지 않습니다.
구조를 활용하는 도구(아래에서 설명할 <code>jq</code> 등)를 사용하거나, 데이터를 먼저 CSV와 같은 표 형식으로 변환한 다음 적절한 커맨드 라인 도구를 적용하는 것이 더 좋습니다.</p>
<p>실제 사용 사례를 통해 XML/HTML 및 JSON을 CSV로 변환하는 과정을 보여드리겠습니다.
여기서 사용할 커맨드 라인 도구는 <code>curl</code>, <code>pup</code><span class="citation"><a href="#fn85" class="footnote-ref" id="fnref85"><sup>85</sup></a></span>, <code>xml2json</code><span class="citation"><a href="#fn86" class="footnote-ref" id="fnref86"><sup>86</sup></a></span>, <code>jq</code>, <code>json2csv</code><span class="citation"><a href="#fn87" class="footnote-ref" id="fnref87"><sup>87</sup></a></span>입니다.</p>
<p>위키피디아에는 방대한 정보가 담겨 있습니다. 이 정보의 상당 부분은 표(table)로 정리되어 있으며, 이는 데이터셋으로 간주될 수 있습니다.
예를 들어, <a href="http://en.wikipedia.org/wiki/List_of_countries_and_territories_by_border/area_ratio">이 페이지</a>에는 국가 및 영토 목록과 함께 국경 길이, 면적, 그리고 그 둘 사이의 비율이 포함되어 있습니다.</p>
<p>이 데이터를 분석하는 데 관심이 있다고 가정해 봅시다. 이 섹션에서는 필요한 모든 단계와 그에 해당하는 명령어를 안내해 드리겠습니다. 세세한 부분까지 모두 설명하지는 않으므로 모든 것을 즉시 이해하지 못할 수도 있습니다. 걱정하지 마세요. 핵심 내용은 파악하실 수 있을 것입니다. 이 섹션의 목적은 커맨드 라인의 활용 능력을 보여주는 것임을 기억하세요. 이 섹션에서 사용된 모든 도구와 개념(그 이상)은 이후 장에서 설명될 것입니다.</p>
<p>관심 있는 데이터셋은 HTML에 포함되어 있습니다.
여러분의 목표는 작업하기 편한 형태의 데이터셋 표현을 얻는 것입니다.
가장 먼저 할 일은 <code>curl</code>을 사용하여 HTML을 다운로드하는 것입니다.</p>
<pre>curl -sL 'http://en.wikipedia.org/wiki/List_of_countries_and_territories_by_border/area_ratio' &gt; wiki.html</pre>
<p>HTML은 <em>wiki.html</em>이라는 파일로 저장됩니다.
처음 10행이 어떻게 생겼는지 확인해 봅시다.</p>
<pre>&lt; wiki.html trim</pre>
<p>제대로 된 것 같습니다.
관심 있는 루트 HTML 요소가 <em>wikitable</em> 클래스를 가진 <em>&lt;table&gt;</em>이라는 것을 알아냈다고 가정해 봅시다.
그러면 <code>grep</code>을 사용하여 관심 있는 부분을 살펴볼 수 있습니다(<code>-A</code> 옵션은 일치하는 행 이후에 인쇄할 행의 수를 지정합니다).</p>
<pre>grep wikitable -A 21 wiki.html</pre>
<p>이제 실제 국가들과 그 값들이 보입니다.
다음 단계는 HTML 파일에서 필요한 요소를 추출하는 것입니다.
이를 위해 <code>pup</code>을 사용할 수 있습니다.</p>
<pre>&lt; wiki.html pup 'table.wikitable tbody' | tee table.html | trim</pre>
<p><code>pup</code>에 전달된 표현식은 CSS 선택자(selector)입니다.
이 구문은 보통 웹 페이지의 스타일을 지정하는 데 사용되지만, HTML에서 특정 요소를 선택하는 데에도 사용할 수 있습니다.
이 경우 <em>wikitable</em> 클래스를 가진 <em>table</em>의 <em>tbody</em>를 선택하려고 합니다.
그다음은 XML(및 HTML)을 JSON으로 변환하는 <code>xml2json</code>입니다.</p>
<pre>&lt; table.html xml2json &gt; table.json
jq . table.json | trim 20</pre>
<p>HTML을 JSON으로 변환하는 이유는 JSON 데이터를 처리하는 매우 강력한 도구인 <code>jq</code>가 있기 때문입니다.
다음 명령어는 JSON 데이터의 특정 부분을 추출하고 우리가 작업할 수 있는 형태로 재구성합니다.</p>
<pre>&lt; table.json jq -r '.tbody.tr[1:][] | [.td[]["$t"]] | @csv' | header -a rank,country,border,surface,ratio &gt; countries.csv</pre>
<p>이제 데이터가 작업하기 편한 형태가 되었습니다.
위키피디아 페이지에서 CSV 데이터셋을 얻기까지 꽤 많은 단계를 거쳤습니다.
하지만 위의 모든 명령어를 하나로 합치면 실제로는 매우 간결하고 표현력이 풍부하다는 것을 알 수 있습니다.</p>
<pre>csvlook --max-column-width 28 countries.csv</pre>
<p>이로써 XML/HTML에서 JSON을 거쳐 CSV로 변환하는 시연을 마칩니다.
<code>jq</code>는 훨씬 더 많은 작업을 수행할 수 있고 XML 데이터를 다루는 전문 도구들도 존재하지만, 제 경험상 가능한 한 빨리 데이터를 CSV 형식으로 변환하는 것이 잘 작동하는 경향이 있습니다.
이렇게 하면 특정 도구보다는 범용적인 커맨드 라인 도구에 능숙해지는 데 더 많은 시간을 할애할 수 있습니다.</p>
</div>
<div id="요약-4" class="section level2" number="5.6">
<h2 number="5.6"><span class="header-section-number">5.6</span> 요약</h2>
<p>이 장에서는 데이터를 청소하거나 정제하는 과정을 살펴보았습니다.
보셨듯이 데이터의 모든 지저분함을 마법처럼 없애주는 단일 도구는 없습니다. 원하는 결과를 얻기 위해 여러 가지 서로 다른 도구들을 결합해야 하는 경우가 많습니다.
<code>cut</code>이나 <code>sort</code> 같은 고전적인 커맨드 라인 도구들은 구조화된 데이터를 해석할 수 없다는 점을 기억하세요.
다행히 JSON이나 XML 같은 데이터 형식을 CSV 같은 다른 데이터 형식으로 변환해 주는 도구들이 있습니다.
다음 장은 다시 한 번 막간을 이용한 장으로, <code>make</code>를 사용하여 프로젝트를 관리하는 방법을 보여드리겠습니다.
<a href="#chapter-7-exploring-data">7장</a>에서 데이터 탐색과 시각화를 시작하는 것이 너무 기다려진다면 이 장은 건너뛰어도 좋습니다.</p>
</div>
<div id="더-읽어보기" class="section level2" number="5.7">
<h2 number="5.7"><span class="header-section-number">5.7</span> 더 읽어보기</h2>
<ul>
<li><code>awk</code>에 대해 더 많이 설명할 수 있었다면 좋았을 것입니다. <code>awk</code>는 매우 강력한 도구이자 프로그래밍 언어입니다. 시간을 내어 배워보시길 강력히 추천합니다. 좋은 자료로는 Doherty와 Robbins가 쓴 <em>sed &amp; awk</em> 책과 온라인 <a href="https://www.gnu.org/software/gawk/manual/gawk.html">GNU Awk User’s Guide</a>가 있습니다.</li>
<li>이 장의 몇 군데에서 정규 표현식을 사용했습니다. 아쉽게도 정규 표현식에 대한 튜토리얼은 이 책의 범위를 벗어납니다. 정규 표현식은 많은 서로 다른 도구에서 사용될 수 있으므로 배워두시는 것을 추천합니다. 좋은 책으로는 Jan Goyvaerts와 Steven Levithan이 쓴 <em>Regular Expressions Cookbook</em>이 있습니다.</li>
</ul>
<!--chapter:end:05.Rmd-->
</div>
</div>
<div id="chapter-6-project-management-with-make" class="section level1" number="6">
<h1 number="6"><span class="header-section-number">6</span> Make으로 프로젝트 관리하기</h1>
<p>이제 여러분도 커맨드 라인이 데이터를 다루기에 매우 편리한 환경이라는 것을 체감하셨으리라 생각합니다.
커맨드 라인에서 작업하면서 우리는 다음과 같은 상황을 겪게 된다는 것을 눈치채셨을 것입니다.</p>
<ul>
<li>수많은 서로 다른 명령어를 호출합니다.</li>
<li>다양한 디렉터리에서 작업합니다.</li>
<li>우리만의 커맨드 라인 도구를 개발합니다.</li>
<li>많은 (중간) 파일들을 획득하고 생성합니다.</li>
</ul>
<p>이 과정은 탐색적인 성격이 강하기 때문에, 우리의 워크플로우는 다소 혼란스러워지는 경향이 있으며, 그로 인해 우리가 무엇을 했는지 추적하기가 어려워집니다.
우리가 거쳐온 단계들은 본인이나 타인에 의해 재현될 수 있어야 합니다.
얼마간의 시간이 흐른 뒤 프로젝트를 다시 시작할 때, 어떤 명령어를 어떤 디렉터리에서, 어떤 파일을 대상으로, 어떤 매개변수와 함께, 그리고 어떤 순서로 실행했는지 잊어버릴 가능성이 큽니다.
이런 상황에서 협업자와 프로젝트를 공유하는 것은 얼마나 힘들지 상상해 보십시오.</p>
<p><code>history</code> 명령어의 출력을 뒤져서 일부 명령어를 복구할 수도 있겠지만, 이는 당연히 신뢰할 수 있는 방법이 아닙니다.
그보다 나은 방법은 명령어를 쉘 스크립트에 저장하는 것입니다.
최소한 이 방법을 통해 여러분과 협업자들은 프로젝트를 재현할 수 있습니다.
하지만 쉘 스크립트 역시 다음과 같은 이유로 최선의 방법은 아닙니다.</p>
<ul>
<li>읽고 유지보수하기가 어렵습니다.</li>
<li>단계들 사이의 의존성이 불분명합니다.</li>
<li>매번 모든 단계가 실행되는데, 이는 비효율적이며 때로는 바람직하지 않습니다.</li>
</ul>
<p>이것이 바로 <code>make</code>가 정말 빛을 발하는 지점입니다<span class="citation"><a href="#fn88" class="footnote-ref" id="fnref88"><sup>88</sup></a></span>. <code>make</code>는 다음과 같은 작업을 가능하게 해주는 커맨드 라인 도구입니다.</p>
<ul>
<li>입력과 출력의 의존성 관점에서 데이터 워크플로우 단계를 공식화합니다.</li>
<li>워크플로우의 특정 단계만 실행합니다.</li>
<li>인라인 코드를 사용합니다.</li>
<li>외부 소스로부터 데이터를 저장하고 가져옵니다.</li>
</ul>

<div class="rmdnote">
초판에서 이 장은 <code>make</code> 대신 <code>drake</code><span class="citation"><a href="#fn89" class="footnote-ref" id="fnref89"><sup>89</sup></a></span>를 사용했습니다.
드레이크(Drake)는 데이터를 다루기 위한 추가 기능을 갖춘 <code>make</code>의 후계자가 될 예정이었습니다.
안타깝게도 드레이크는 2016년에 해결되지 않은 많은 버그를 남긴 채 개발진에 의해 중단되었습니다.
그래서 저는 대신 <code>make</code>를 사용하기로 결정했습니다.
</div>
<p>중요한 관련 주제로 <em>버전 관리(version control)</em>가 있습니다. 이는 프로젝트의 변경 사항을 추적하고, 프로젝트를 서버에 백업하며, 다른 사람들과 협업하고, 문제가 생겼을 때 이전 버전으로 되돌릴 수 있게 해줍니다.
버전 관리를 위한 대중적인 커맨드 라인 도구는 <code>git</code><span class="citation"><a href="#fn90" class="footnote-ref" id="fnref90"><sup>90</sup></a></span>입니다.
Git은 흔히 분산 버전 관리를 위한 온라인 서비스인 GitHub와 함께 사용됩니다.
<a href="https://github.com/jeroenjanssens/data-science-at-the-command-line">이 책</a>을 포함한 많은 오픈 소스 프로젝트가 GitHub에서 호스팅되고 있습니다.
버전 관리라는 주제는 이 책의 범위를 벗어나지만, 특히 다른 사람들과 협업을 시작하게 된다면 이를 꼭 살펴보시길 강력히 추천합니다.
이 장의 끝부분에서 더 배울 수 있는 몇 가지 자료를 추천해 드리겠습니다.</p>
<div id="개요-3" class="section level2" number="6.1">
<h2 number="6.1"><span class="header-section-number">6.1</span> 개요</h2>
<p><code>make</code>로 데이터 워크플로우를 관리하는 것이 이 장의 주요 주제입니다.
이에 대해 다음 내용을 배우게 됩니다.</p>
<ul>
<li><em>Makefile</em>을 사용하여 워크플로우를 정의하기.</li>
<li>입력 및 출력 의존성의 관점에서 워크플로우 생각하기.</li>
<li>작업(task)을 실행하고 타겟(target)을 빌드하기.</li>
</ul>
<pre>cd /data/ch06
l</pre>
<p>이 파일들을 가져오는 방법은 <a href="#chapter-2-getting-started">2장</a>에 설명되어 있습니다.
그 외의 파일들은 커맨드 라인 도구를 사용하여 다운로드하거나 생성한 것들입니다.</p>
</div>
<div id="make-소개" class="section level2" number="6.2">
<h2 number="6.2"><span class="header-section-number">6.2</span> Make 소개</h2>
<p><code>make</code>는 데이터와 그 의존성을 중심으로 명령어 실행을 조직화합니다.
데이터 처리 단계는 별도의 텍스트 파일(워크플로우)에 공식화됩니다.
각 단계는 입력과 출력을 가질 수 있습니다.
<code>make</code>는 그들의 의존성을 자동으로 해결하고 어떤 명령어를 어떤 순서로 실행해야 하는지 결정합니다.</p>
<p>예를 들어, 10분 정도 걸리는 SQL 쿼리가 있다고 할 때, 이는 결과 파일이 없거나 쿼리가 나중에 변경되었을 때만 실행됩니다.
또한 특정 단계를 (재)실행하고 싶을 때, <code>make</code>는 해당 단계가 의존하는 단계들만 재실행합니다.
이는 시간을 대폭 절약해 줍니다.</p>
<p>공식화된 워크플로우를 갖추면 몇 주 후에 프로젝트를 다시 시작하거나 다른 사람들과 협업하기가 훨씬 수월해집니다.
일회성 프로젝트라고 생각하더라도 이를 수행하시기를 강력히 권장합니다.
언제 특정 단계를 다시 실행해야 하거나 다른 프로젝트에서 재사용하게 될지 누구도 모르기 때문입니다.</p>
</div>
<div id="작업task-실행하기" class="section level2" number="6.3">
<h2 number="6.3"><span class="header-section-number">6.3</span> 작업(Task) 실행하기</h2>
<p>기본적으로 <code>make</code>는 현재 디렉터리에서 <em>Makefile</em>이라는 설정 파일을 찾습니다.
파일 이름을 <em>makefile</em>(소문자)로 할 수도 있지만, 더 일반적이고 디렉터리 목록의 상단에 나타나도록 <em>Makefile</em>로 지정하는 것을 추천합니다.
보통 프로젝트당 하나의 설정 파일만 가집니다.
이 장에서는 여러 장을 논의하기 때문에 각각 <em>.make</em> 확장자를 가진 다른 파일 이름을 부여했습니다.
다음 <em>Makefile</em>부터 시작해 보겠습니다.</p>
<pre>bat -A numbers.make</pre>
<p>이 <em>Makefile</em>은 <em><code>numbers</code></em>라는 하나의 <em>타겟(target)</em>을 포함하고 있습니다.
<em>타겟</em>은 하나의 작업과 같습니다.
보통 생성하고자 하는 파일의 이름이지만, 그보다 더 일반적인 것일 수도 있습니다.
그 아래 줄인 <em><code>seq 7</code></em>은 <em>규칙(rule)</em>으로 알려져 있습니다.
규칙은 요리 레시피(recipe)라고 생각하면 됩니다. 타겟을 어떻게 빌드할지 명시하는 하나 이상의 명령어입니다.</p>
<p>규칙 앞의 공백은 하나의 탭(tab) 문자입니다.
<code>make</code>는 공백에 매우 민감합니다.
일부 에디터는 <strong><code>TAB</code></strong> 키를 눌렀을 때 소프트 탭(soft tab)이라고 불리는 공백들을 삽입하는데, 이는 <code>make</code> 에러를 유발할 수 있으니 주의하십시오.
다음 코드는 탭을 8개의 공백으로 확장하여 이를 보여줍니다.</p>
<pre>&lt; numbers.make expand &gt; spaces.make
bat -A spaces.make
make -f spaces.make
rm spaces.make</pre>
<p><span class="callout">&#10122;</span> 설정 파일의 이름이 기본값인 <em>Makefile</em>이 아니기 때문에 <code>--makefile</code> 옵션의 약어인 <code>-f</code> 옵션을 추가해야 합니다.
<br><span class="callout">&#10123;</span> 커맨드 라인에서 볼 수 있는 매우 친절한 에러 메시지 중 하나입니다!</p>
<p>이제부터는 실제 사용 사례와 더 비슷하도록 해당 파일의 이름을 <em>Makefile</em>로 바꿀 것입니다.
그냥 <code>make</code>를 실행해 보겠습니다.</p>
<pre>cp numbers.make Makefile
make</pre>
<p>그러면 <code>make</code>가 먼저 규칙 자체(<em><code>seq 7</code></em>)를 출력한 다음, 규칙에 의해 생성된 출력을 인쇄하는 것을 볼 수 있습니다.
이 과정을 타겟을 <em>빌드(building)</em>한다고 합니다.
타겟의 이름을 지정하지 않으면 <code>make</code>는 <em>Makefile</em>에 정의된 첫 번째 타겟을 빌드합니다.
실제로는 빌드하고 싶은 타겟을 직접 지정하는 경우가 더 많습니다.</p>
<pre>make numbers</pre>

<div class="rmdnote">
<code>make</code>는 원래 소스 코드의 컴파일을 쉽게 하기 위해 만들어졌기 때문에 <em>타겟</em>, <em>규칙</em>, <em>빌드</em>와 같은 용어가 사용됩니다.
</div>
<p>이 경우 실제로는 아무것도 빌드하지 않았습니다. 즉, 새로운 파일을 생성하지 않았습니다.
<code>make</code>는 <em>numbers</em>라는 파일을 찾지 못하므로 기꺼이 <code>numbers</code> 타겟을 다시 <em>빌드</em>할 것입니다.
다음 섹션에서 이에 대해 자세히 다루겠습니다.</p>
<p>가끔은 동일한 이름의 파일 존재 여부와 상관없이 무조건 빌드되는 타겟이 필요할 때가 있습니다.
프로젝트의 일부로 수행해야 하는 작업들을 생각해 보십시오.
그러한 타겟들은 <em>Makefile</em>의 최상단에 <code>.PHONY</code>라는 특수 타겟을 사용하고 그 뒤에 가짜(phony) 타겟들의 이름을 나열하여 가짜 타겟으로 선언하는 것이 좋은 관례입니다.
다음은 가짜 타겟의 사용법을 보여주는 예시 <em>Makefile</em>입니다.</p>
<pre>bat tasks.make</pre>
<p><span class="callout">&#10122;</span> <em><code>$(pwd)</code></em> 앞의 달러 기호가 하나 더 있다는 점에 주목하십시오. 이는 <code>make</code>가 단일 달러 기호를 나중에 설명할 다양한 특수 변수를 참조하는 데 사용하기 때문에 필요합니다.</p>
<p>위 내용은 제가 이 책을 작업하면서 사용하는 <em>Makefile</em>에서 가져온 것입니다.
제가 <code>make</code>를 고성능 작업 실행기(task runner)로 사용하고 있다고 말할 수도 있습니다.
이것이 <code>make</code>의 주된 목적은 아니었지만, 제가 어떤 명령어를 사용했는지 기억하거나 찾아볼 필요가 없기 때문에 여전히 큰 가치가 있습니다.
대신 <code>make publish</code>를 입력하면 책의 최신 버전이 발행됩니다.
<em>Makefile</em>에 시간이 오래 걸리는 명령어를 넣는 것도 전혀 문제가 되지 않습니다.</p>
<p>그리고 <code>make</code>는 우리를 위해 훨씬 더 많은 일을 할 수 있습니다!</p>
</div>
<div id="본격적으로-빌드하기" class="section level2" number="6.4">
<h2 number="6.4"><span class="header-section-number">6.4</span> 본격적으로 빌드하기</h2>
<p>규칙의 출력이 파일 <em>numbers</em>에 기록되도록 <em>Makefile</em>을 수정해 보겠습니다.</p>
<pre>cp numbers-write.make Makefile
bat Makefile
make numbers
bat numbers</pre>
<p>이제 <code>make</code>가 실제로 무언가를 빌드하고 있다고 말할 수 있습니다.
또한, 이를 다시 실행하면 <code>make</code>는 <code>numbers</code> 타겟이 이미 최신 상태(up-to-date)라고 보고합니다.</p>
<pre>make numbers</pre>
<p>파일 <em>numbers</em>가 이미 존재하기 때문에 <code>numbers</code> 타겟을 다시 빌드할 필요가 없습니다.
<code>make</code>가 불필요한 작업을 반복하지 않음으로써 우리의 시간을 절약해 주는 것입니다.</p>
<p><code>make</code>에서는 모든 것이 파일에 관한 것입니다.
하지만 <code>make</code>는 타겟의 <em>이름</em>에만 신경 쓴다는 점을 명심하십시오.
해당 이름의 파일이 실제로 규칙에 의해 생성되었는지 여부는 확인하지 않습니다.
만약 우리가 “문자”라는 뜻의 네덜란드어인 <em>nummers</em> 파일에 쓰고 타겟 이름이 여전히 <code>numbers</code>라면, <code>make</code>는 항상 이 타겟을 빌드할 것입니다. 반대로, 자동이든 수동이든 다른 프로세스에 의해 <em>numbers</em> 파일이 생성되었다면, <code>make</code>는 여전히 해당 타겟이 최신 상태라고 간주할 것입니다.</p>
<p>타겟의 이름으로 확장되는 자동 변수 <code>$@</code>를 사용하여 중복을 피할 수 있습니다.</p>
<pre>cp numbers-write-var.make Makefile
200: bat Makefile
201: ```

*numbers* 파일을 삭제하고 `make`를 다시 호출하여 제대로 작동하는지 확인해 보겠습니다.
</pre>
<pre>rm numbers
make numbers
bat numbers</pre>
<p><code>make</code>가 타겟을 다시 빌드하는 또 다른 이유는 의존성(dependencies) 때문입니다. 이에 대해 다음에서 논의해 보겠습니다.</p>
</div>
<div id="의존성-추가하기" class="section level2" number="6.5">
<h2 number="6.5"><span class="header-section-number">6.5</span> 의존성 추가하기</h2>
<p>지금까지는 개별적으로 존재하는 타겟들을 살펴보았습니다.
전형적인 데이터 과학 워크플로우에서 많은 단계는 다른 단계들에 의존합니다.
<em>Makefile</em>에서 의존성에 대해 제대로 이야기하기 위해, 스타워즈 캐릭터에 대한 데이터셋을 다루는 두 가지 작업을 예로 들어보겠습니다.</p>
<p>데이터셋의 일부 내용을 살펴보겠습니다.</p>
<pre>curl -sL 'https://raw.githubusercontent.com/tidyverse/dplyr/master/data-raw/starwars.csv' |
xsv select name,height,mass,homeworld,species |
csvlook</pre>
<p>첫 번째 작업은 키가 가장 큰 인간 10명을 계산하는 것입니다.</p>
<pre>curl -sL 'https://raw.githubusercontent.com/tidyverse/dplyr/master/data-raw/starwars.csv' |
grep Human |
cut -d, -f 1,2 |
sort -t, -k2 -nr |
head</pre>
<p><span class="callout">&#10122;</span> 패턴 <em><code>Human</code></em>을 포함하는 행만 유지합니다.
<br><span class="callout">&#10123;</span> 처음 두 열을 추출합니다.
<br><span class="callout">&#10124;</span> 두 번째 열을 기준으로 숫자 역순으로 행을 정렬합니다.
<br><span class="callout">&#10125;</span> 기본적으로 <code>head</code>는 처음 10개 행을 출력합니다. <code>-n</code> 옵션으로 이를 변경할 수 있습니다.</p>
<p>두 번째 작업은 종(species)별 키 분포를 보여주는 박스 플롯을 생성하는 것입니다(@ref(fig:starwars-image) 참조).</p>
<pre>curl -sL 'https://raw.githubusercontent.com/tidyverse/dplyr/master/data-raw/starwars.csv' |
rush plot --x height --y species --geom boxplot &gt; heights.png
display heights.png</pre>
<p>이 두 작업을 <em>Makefile</em>에 넣어보겠습니다.
이를 하나씩 점진적으로 하는 대신, 완성된 <em>Makefile</em>이 어떤 모습인지 먼저 보여준 다음 모든 구문을 단계별로 설명하겠습니다.</p>
<pre>cp starwars.make Makefile
bat Makefile</pre>
<p>이 <em>Makefile</em>을 단계별로 살펴보겠습니다.
처음 세 줄은 <code>make</code> 자체와 관련된 몇 가지 기본 설정을 변경하기 위한 것입니다.</p>
<ol style="list-style-type: decimal">
<li>모든 규칙은 쉘에서 실행되며, 기본값은 <code>sh</code>입니다. <em><code>SHELL</code></em> 변수를 사용하여 이를 <code>bash</code>와 같은 다른 쉘로 변경할 수 있습니다. 이렇게 하면 Bash가 제공하는 for 루프와 같은 모든 기능을 사용할 수 있습니다.</li>
<li>기본적으로 규칙의 각 줄은 쉘로 별도로 전송됩니다. <em><code>.ONESHELL</code></em>이라는 특수 타겟을 사용하면 이를 무시할 수 있으며, 이 덕분에 <em><code>top10</code></em> 타겟의 규칙이 제대로 작동합니다.</li>
<li><em><code>.SHELLFLAGS</code></em> 줄은 Bash를 더 엄격하게 만드는데, 이는 <a href="http://redsymbol.net/articles/unofficial-bash-strict-mode/">모범 사례(best practice)</a>로 간주됩니다. 예를 들어, 이 설정 덕분에 <em><code>top10</code></em> 타겟 규칙의 파이프라인은 오류가 발생하는 즉시 중단됩니다.</li>
</ol>
<p>우리는 <em><code>URL</code></em>이라는 사용자 정의 변수를 정의합니다.
이 변수가 한 번만 사용되기는 하지만, 파일의 시작 부분 부분에 이러한 정보를 배치하면 나중에 설정을 쉽게 변경할 수 있어 도움이 됩니다.</p>
<p>특수 타겟 <em><code>.PHONY</code></em>를 사용하면 어떤 타겟이 파일로 나타나지 않는지 나타낼 수 있습니다. 이 예제에서는 <em><code>all</code></em>과 <em><code>top10</code></em> 타겟이 이에 해당합니다. 이제 이 타겟들은 디렉터리에 동일한 이름의 파일이 있는지 여부와 상관없이 항상 실행됩니다.</p>
<p>타겟은 <em><code>all</code></em>, <em><code>data</code></em>, <em><code>data/starwars.csv</code></em>, <em><code>top10</code></em>, <em><code>heights.png</code></em>의 다섯 가지가 있습니다.
Figure @ref(fig:dependencies)에서는 이러한 타겟들과 그들 사이의 의존성을 개괄적으로 보여줍니다.</p>
<p>각 타겟을 차례대로 살펴보겠습니다.</p>
<ol style="list-style-type: decimal">
<li>타겟 <em><code>all</code></em>은 두 개의 의존성을 갖지만 규칙은 없습니다. 이는 지정된 순서대로 하나 이상의 타겟을 실행하기 위한 지름길과 같습니다. 이 경우 <em><code>top10</code></em>과 <em><code>heights.png</code></em>입니다. 타겟 <em><code>all</code></em>은 <em>Makefile</em>에서 첫 번째 타겟으로 나타나므로, 우리가 <code>make</code>를 실행하면 이 타겟이 빌드됩니다.</li>
<li>타겟 <em><code>data</code></em>는 <em>data</em> 디렉터리를 생성합니다. 앞에서 <code>make</code>는 파일에 관한 것이라고 말씀드렸지만, 디렉터리에 관한 것이기도 합니다. 이 타겟은 <em>data</em> 디렉터리가 아직 존재하지 않을 때만 실행됩니다.</li>
<li>타겟 <em><code>data/starwars.csv</code></em>는 타겟 <em><code>data</code></em>에 의존합니다. 만약 <em><code>data</code></em> 디렉터리가 없다면 먼저 생성될 것입니다. 모든 의존성이 충족되면 규칙이 실행되며, 여기에는 파일을 다운로드하여 타겟과 동일한 이름의 파일로 저장하는 과정이 포함됩니다.</li>
<li>타겟 <em><code>top10</code></em>은 가짜 타겟으로 표시되어 있으므로 지정되면 항상 빌드됩니다. 이 타겟은 <em><code>data/starwars.csv</code></em> 타겟에 의존합니다. 첫 번째 전제 조건인 <em>data/starwars.csv</em>로 확장되는 특수 변수 <em><code>$&lt;</code></em>를 사용합니다.</li>
<li>타겟 <em><code>heights.png</code></em>는 <em><code>top10</code></em> 타겟과 마찬가지로 <em><code>data/starwars.csv</code></em>에 의존하며, 이 장에서 살펴본 두 가지 자동 변수를 모두 사용합니다. 다른 자동 변수에 대해 더 알고 싶다면 <a href="https://www.gnu.org/software/make/manual/html_node/Automatic-Variables.html">온라인 문서</a>를 참조하십시오.</li>
</ol>
<p>마지막으로 이 <em>Makefile</em>이 제대로 작동하는지 확인해 보겠습니다.</p>
<pre>make</pre>
<p>놀라운 일은 없군요. 타겟을 지정하지 않았으므로 <em><code>all</code></em> 타겟이 빌드되고, 결과적으로 <em><code>top10</code></em>과 <em><code>heights.png</code></em> 타겟이 모두 빌드됩니다. 전자의 출력은 표준 출력으로 인쇄되고 후자는 <em>heights.png</em> 파일을 생성합니다. <em>data</em> 디렉터리는 한 번만 생성되며, CSV 파일 역시 한 번만 다운로드됩니다.</p>
<p>데이터를 가지고 놀다 보면 다른 모든 것을 잊어버리는 것보다 더 즐거운 일은 없습니다.
하지만 <em>Makefile</em>을 사용하여 작업 내용을 기록해 두는 것이 가치 있다는 제 말을 믿으셔야 합니다.
그것이 여러분의 삶을 더 편하게 만들어줄 뿐만 아니라(말장난입니다), 여러분이 데이터 워크플로우를 단계별로 생각하기 시작하는 데 도움을 줄 것입니다.
시간이 지나면서 여러분만의 커맨드 라인 도구 상자가 확장되는 것처럼, <code>make</code> 워크플로우도 마찬가지입니다.
정의된 단계가 많을수록 특정 단계들을 재사용할 수 있는 경우가 매우 많기 때문에 작업을 꾸준히 해나가기가 더 쉬워집니다.
여러분이 <code>make</code>에 익숙해지고, 그것이 여러분의 삶을 더 풍요롭게(make your life easier) 만들기를 바랍니다.</p>
</div>
<div id="요약-5" class="section level2" number="6.6">
<h2 number="6.6"><span class="header-section-number">6.6</span> 요약</h2>
<p>커맨드 라인의 묘미 중 하나는 데이터를 마음껏 가지고 놀 수 있다는 점입니다.
다양한 명령어를 쉽게 실행하고 여러 데이터 파일을 처리할 수 있습니다.
이는 매우 상호작용적이고 반복적인 과정입니다.
시간이 지나면 원하는 결과를 얻기 위해 어떤 단계를 거쳤는지 잊어버리기 쉽습니다.
따라서 이따금 여러분이 수행한 단계들을 기록해 두는 것이 매우 중요합니다.
그래야 나중에 여러분이나 동료가 다시 프로젝트를 시작했을 때, 동일한 단계를 실행하여 같은 결과를 만들어낼 수 있습니다.</p>
<p>이 장에서는 모든 명령어를 하나의 Bash 스크립트에 몰아넣는 것이 최선이 아님을 보여드렸습니다.
대신 데이터 워크플로우를 관리하기 위한 커맨드 라인 도구로 <code>make</code>를 사용할 것을 제안했습니다.
다음 장은 데이터 과학을 위한 OSEMN 모델의 세 번째 단계인 데이터 탐색(Exploring data)을 다룹니다.</p>
</div>
<div id="더-읽어보기-1" class="section level2" number="6.7">
<h2 number="6.7"><span class="header-section-number">6.7</span> 더 읽어보기</h2>
<ul>
<li>Robert Mecklenburg의 저서 <em>Managing Projects with GNU Make</em>와 온라인 <em>GNU Make Manual</em>은 <code>make</code>에 대한 포괄적이고 고급스러운 내용을 제공합니다.</li>
<li><code>make</code> 외에도 수많은 워크플로우 관리자가 존재합니다. 구문과 기능은 다르지만 타겟, 규칙, 의존성과 같은 개념을 공통적으로 사용합니다. 대표적인 예로 <a href="https://luigi.readthedocs.io">Luigi</a>, <a href="https://airflow.apache.org">Apache Airflow</a>, <a href="https://www.nextflow.io">Nextflow</a> 등이 있습니다.</li>
<li>버전 관리, 특히 <code>git</code>과 GitHub에 대해 더 자세히 알고 싶다면 Scott Chacon과 Ben Straub이 쓴 <em>Pro Git</em>을 추천합니다. <a href="https://git-scm.com/book/en/v2">무료로 제공</a>됩니다. <a href="https://docs.github.com/en/get-started">온라인 GitHub 문서</a> 또한 좋은 시작점입니다.</li>
</ul>
<!--chapter:end:06.Rmd-->
</div>
</div>
<div id="chapter-7-exploring-data" class="section level1" number="7">
<h1 number="7"><span class="header-section-number">7</span> 데이터 탐색하기</h1>
<p>그 모든 고된 작업 끝에 (이미 정제된 데이터가 준비되어 있지 않았다면 말이죠), 이제 즐거운 시간을 보낼 때입니다.
데이터를 획득하고 정제했으니, 이제 OSEMN 모델의 세 번째 단계인 데이터 탐색(explore)으로 넘어갈 수 있습니다.</p>
<p>데이터 탐색은 데이터와 친숙해지는 과정입니다.
데이터를 잘 아는 것은 그로부터 가치를 추출하는 데 필수적입니다.
예를 들어, 데이터가 어떤 특성(features)을 가지고 있는지 알면, 어떤 특성을 더 깊이 파고들 가치가 있는지, 그리고 가지고 있는 질문에 답하기 위해 어떤 특성을 사용할 수 있을지 알 수 있게 됩니다.</p>
<p>데이터 탐색은 세 가지 관점에서 진행할 수 있습니다.
첫 번째 관점은 데이터와 그 속성을 검사(inspect)하는 것입니다.
여기서는 원시 데이터가 어떻게 생겼는지, 데이터셋에 데이터 포인트가 몇 개인지, 어떤 특성들이 있는지 등을 파악하고자 합니다.</p>
<p>두 번째는 기술 통계량(descriptive statistics)을 계산하는 것입니다. 이 관점은 개별 특성에 대해 더 자세히 배우는 데 유용합니다.
출력 결과는 대게 짧은 텍스트 형태이므로 커맨드 라인에 바로 출력할 수 있습니다.</p>
<p>세 번째 관점은 데이터 시각화(visualizations)를 생성하는 것입니다. 이 관점을 통해 여러 특성이 서로 어떻게 상호작용하는지에 대한 통찰을 얻을 수 있습니다. 커맨드 라인에 출력할 수 있는 시각화 생성 방법을 설명하겠지만, 시각화는 그래픽 사용자 인터페이스(GUI)에 표시하는 것이 가장 적합합니다. 기술 통계량과 비교했을 때 데이터 시각화의 장점은 더 유연하고 훨씬 더 많은 정보를 전달할 수 있다는 점입니다.</p>
<div id="개요-4" class="section level2" number="7.1">
<h2 number="7.1"><span class="header-section-number">7.1</span> 개요</h2>
<p>이 장에서 여러분은 다음 내용을 배우게 됩니다.</p>
<ul>
<li>데이터와 그 속성 검사하기</li>
<li>기술 통계량 계산하기</li>
<li>커맨드 라인 안팎에서 데이터 시각화 생성하기</li>
</ul>
<p>이 장은 다음 파일들로 시작합니다.</p>
<pre>cd /data/ch07
l</pre>
<p>이 파일들을 가져오는 방법은 <a href="#chapter-2-getting-started">2장</a>에 설명되어 있습니다.
그 외의 파일들은 커맨드 라인 도구를 사용하여 다운로드하거나 생성한 것들입니다.</p>
</div>
<div id="데이터와-그-속성-검사하기" class="section level2" number="7.2">
<h2 number="7.2"><span class="header-section-number">7.2</span> 데이터와 그 속성 검사하기</h2>
<p>이 섹션에서는 데이터셋과 그 속성을 검사하는 방법을 보여드리겠습니다. 앞으로 다룰 시각화 및 모델링 기술들은 데이터가 표(rectangular) 형태일 것으로 예상하므로, 데이터가 CSV 형식이라고 가정하겠습니다. 필요한 경우 <a href="#chapter-5-scrubbing-data">5장</a>에서 설명한 기술을 사용하여 데이터를 CSV로 변환할 수 있습니다.</p>
<p>편의상 데이터에 헤더(header)가 있다고 가정하겠습니다.
첫 번째 하위 섹션에서는 실제로 헤더가 있는지 확인하는 방법을 보여드리겠습니다.
헤더가 있다는 것을 알게 되면 다음과 같은 질문들에 답할 수 있습니다.</p>
<ul>
<li>데이터셋에 데이터 포인트와 특성이 몇 개나 있는가?</li>
<li>원시 데이터는 어떻게 생겼는가?</li>
<li>데이터셋에는 어떤 종류의 특성들이 있는가?</li>
<li>이러한 특성 중 일부를 범주형(categorical)으로 취급할 수 있는가?</li>
</ul>
<div id="헤더의-유무-확인하기" class="section level3" number="7.2.1">
<h3 number="7.2.1"><span class="header-section-number">7.2.1</span> 헤더의 유무 확인하기</h3>
<p><code>head</code>를 사용하여 처음 몇 줄을 출력함으로써 파일에 헤더가 있는지 확인할 수 있습니다.</p>
<pre>head -n 5 venture.csv</pre>
<p>행이 너무 길어 화면을 넘어간다면 <code>nl</code>을 사용하여 행 번호를 추가해 보세요.</p>
<pre>head -n 3 venture.csv | nl</pre>
<p>또는 <code>trim</code>을 사용할 수도 있습니다.</p>
<pre>&lt; venture.csv trim 5</pre>
<p>이 경우에는 첫 번째 행이 대문자 이름만 포함하고 있고 그 다음 행들은 숫자를 포함하고 있으므로 헤더임이 분명합니다.
이는 사실 상당히 주관적인 과정이며, 첫 번째 행을 헤더로 볼지 아니면 첫 번째 데이터 포인트로 볼지는 여러분의 판단에 달려 있습니다.
데이터셋에 헤더가 없는 경우, <a href="#chapter-5-scrubbing-data">5장</a>에서 다룬 <code>header</code> 도구를 사용하여 이를 바로잡는 것이 가장 좋습니다.</p>
</div>
<div id="모든-데이터-검사하기" class="section level3" number="7.2.2">
<h3 number="7.2.2"><span class="header-section-number">7.2.2</span> 모든 데이터 검사하기</h3>
<p>원시 데이터를 자신의 속도에 맞춰 검토하고 싶다면 <code>cat</code>을 사용하는 것은 좋은 생각이 아닙니다. 모든 데이터가 한꺼번에 출력되기 때문입니다.
커맨드 라인에서 데이터를 상호작용적으로 검사할 수 있게 해주는 <code>less</code><span class="citation"><a href="#fn91" class="footnote-ref" id="fnref91"><sup>91</sup></a></span>를 사용하는 것을 추천합니다.
<code>-S</code> 옵션을 지정하면 (<em>venture.csv</em>처럼) 긴 행이 줄바꿈되는 것을 방지할 수 있습니다.</p>
<pre>less -S venture.csv#! enter=FALSE</pre>
<pre>Enter Right Left#! literal=FALSE, hold=0.1, wait=0.1</pre>
<p>오른쪽의 크다 기호(<code>&gt;</code>)는 가로로 스크롤할 수 있음을 나타냅니다.
<strong><code>위</code></strong> 및 <strong><code>아래</code></strong> 방향키를 눌러 위아래로 스크롤할 수 있습니다.
<strong><code>스페이스바</code></strong>를 누르면 한 화면씩 아래로 스크롤됩니다.
가로 스크롤은 <strong><code>왼쪽</code></strong> 및 <strong><code>오른쪽</code></strong> 방향키를 사용합니다.
<strong><code>g</code></strong>와 <strong><code>G</code></strong>를 누르면 각각 파일의 시작과 끝으로 이동합니다.
<code>less</code>를 종료하려면 <strong><code>q</code></strong>를 누르면 됩니다.
매뉴얼 페이지(manual page)에는 사용 가능한 모든 키 바인딩이 나열되어 있습니다.</p>
<p><code>less</code>의 장점 중 하나는 파일 전체를 메모리에 로드하지 않는다는 점입니다. 즉, 대용량 파일을 볼 때도 매우 빠릅니다.</p>
</div>
<div id="특성-이름과-데이터-유형" class="section level3" number="7.2.3">
<h3 number="7.2.3"><span class="header-section-number">7.2.3</span> 특성 이름과 데이터 유형</h3>
<p>열(또는 특성) 이름은 특성의 의미를 나타낼 수 있습니다.
다음과 같은 <code>head</code>와 <code>tr</code> 조합을 사용할 수 있습니다.</p>
<pre>&lt; venture.csv head -n 1 | tr , '\n'</pre>
<p>이 기본적인 명령어는 파일이 쉼표로 구분되어 있다고 가정합니다.
더 견고한 접근 방식은 <code>csvcut</code>을 사용하는 것입니다.</p>
<pre>csvcut -n venture.csv</pre>
<p>단순히 열 이름을 출력하는 것보다 한 걸음 더 나아갈 수 있습니다.
열 이름 외에도 각 열이 문자열, 숫자, 또는 날짜와 같이 어떤 유형의 값을 포함하고 있는지 아는 것이 매우 유용할 것입니다.
다음과 같은 장난감 데이터셋이 있다고 가정해 봅시다.</p>
<pre>bat -A datatypes.csv</pre>
<p><code>csvlook</code>은 이를 다음과 같이 해석합니다.</p>
<pre>csvlook datatypes.csv</pre>
<p><a href="#chapter-5-scrubbing-data">5장</a>에서 CSV 데이터에 직접 SQL 쿼리를 실행하기 위해 <code>csvsql</code>을 이미 사용해 보았습니다.
커맨드 라인 인자를 전달하지 않으면, 이 데이터를 실제 데이터베이스에 삽입할 때 필요한 SQL 문을 생성합니다.
이 출력을 사용하여 유추된 열 유형이 무엇인지 검사할 수도 있습니다.
데이터 유형 뒤에 <em>NOT NULL</em> 문자열이 인쇄되어 있다면 해당 열에는 결측치가 없다는 뜻입니다.</p>
<pre>csvsql datatypes.csv</pre>
<p>이 출력은 <code>csvgrep</code>, <code>csvsort</code>, <code>csvsql</code>과 같은 <code>csvkit</code> 제품군의 다른 도구들을 사용할 때 특히 유용합니다.
<em>venture.csv</em>의 경우 열 유형은 다음과 같이 유추됩니다.</p>
<pre>csvsql venture.csv</pre>
</div>
<div id="고유-식별자-연속형-변수-그리고-요인factors" class="section level3" number="7.2.4">
<h3 number="7.2.4"><span class="header-section-number">7.2.4</span> 고유 식별자, 연속형 변수, 그리고 요인(Factors)</h3>
<p>각 특성의 데이터 유형을 아는 것만으로는 충분하지 않습니다.
각 특성이 무엇을 나타내는지 아는 것도 필수적입니다.
도메인 지식이 있으면 매우 유용하겠지만, 데이터 자체를 살펴봄으로써 맥락을 파악할 수도 있습니다.</p>
<p>문자열과 정수 모두 고유 식별자일 수도 있고 범주를 나타낼 수도 있습니다.
후자의 경우 시각화에서 색상을 할당하는 데 사용될 수 있습니다.
하지만 정수가 우편번호 등을 나타낸다면 평균을 계산하는 것은 의미가 없습니다.</p>
<p>특성을 고유 식별자로 취급해야 할지 아니면 범주형 변수로 취급해야 할지 결정하기 위해, 특정 열의 고유 값(unique values) 개수를 세어볼 수 있습니다.</p>
<pre>wc -l tips.csv
&lt; tips.csv csvcut -c day | header -d | sort | uniq | wc -l</pre>
<p><code>csvkit</code>의 일부인 <code>csvstat</code><span class="citation"><a href="#fn92" class="footnote-ref" id="fnref92"><sup>92</sup></a></span>을 사용하여 각 열의 고유 값 개수를 얻을 수 있습니다.</p>
<pre>csvstat tips.csv --unique
csvstat venture.csv --unique</pre>
<p>고유 값이 단 하나만 있다면 (<em>OBS_STATUS</em>처럼), 해당 열은 어떠한 가치도 제공하지 못하므로 삭제할 가능성이 큽니다.
그러한 모든 열을 자동으로 삭제하고 싶다면 다음과 같은 파이프라인을 사용할 수 있습니다.</p>
<pre>&lt; venture.csv csvcut -C $(
  csvstat venture.csv --unique |
  grep ': 1$' |
  cut -d. -f 1 |
  tr -d ' ' |
  paste -sd,
) | trim</pre>
<p><span class="callout">&#10122;</span> <code>-C</code> 옵션은 명령 대치(command substitution)를 통해 제공된 위치(또는 이름)의 열을 선택 해제합니다.
<br><span class="callout">&#10123;</span> <em>venture.csv</em>의 각 열에 대한 고유 값 개수를 얻습니다.
<br><span class="callout">&#10124;</span> 고유 값이 1개인 열만 남깁니다.
<br><span class="callout">&#10125;</span> 열의 위치를 추출합니다.
<br><span class="callout">&#10126;</span> 모든 공백을 제거합니다.
<br><span class="callout">&#10127;</span> 모든 열 위치를 쉼표로 구분된 한 줄로 만듭니다.
<br><span class="callout">&#10128;</span> 처음 10행만 보여줍니다.</p>
<p>그렇긴 하지만, 일단은 그 열들을 유지하도록 하겠습니다.</p>
<p>일반적으로 고유 값의 개수가 전체 행 수에 비해 적다면, 해당 특성은 범주형으로 취급될 수 있습니다 (<em>venture.csv</em>의 <em>GEO</em>처럼).
만약 개수가 행 수와 같다면 고유 식별자일 수도 있지만 수치형 값일 수도 있습니다.
이를 알아낼 수 있는 유일한 방법은 더 깊이 파고드는 것입니다.</p>
</div>
</div>
<div id="기술-통계량-계산하기" class="section level2" number="7.3">
<h2 number="7.3"><span class="header-section-number">7.3</span> 기술 통계량 계산하기</h2>
<div id="열-통계column-statistics" class="section level3" number="7.3.1">
<h3 number="7.3.1"><span class="header-section-number">7.3.1</span> 열 통계(Column Statistics)</h3>
<p>커맨드 라인 도구인 <code>csvstat</code>은 많은 정보를 제공합니다. 각 특성(열)에 대해 다음과 같은 내용을 보여줍니다.</p>
<ul>
<li>데이터 유형</li>
<li>결측치(nulls)의 존재 여부</li>
<li>고유 값의 개수</li>
<li>해당 특성에 적합한 다양한 기술 통계량 (최솟값, 최댓값, 합계, 평균, 표준 편차, 중앙값)</li>
</ul>
<p><code>csvstat</code>을 다음과 같이 실행합니다.</p>
<pre>csvstat venture.csv | trim 32</pre>
<p>내용이 매우 많기 때문에 처음 32행만 보여드리고 있습니다. 이 출력을 <code>less</code>로 연결해서 보는 것이 좋습니다.
특정 통계량에만 관심이 있다면 다음 옵션 중 하나를 사용할 수도 있습니다.</p>
<ul>
<li><code>--max</code> (최댓값)</li>
<li><code>--min</code> (최솟값)</li>
<li><code>--sum</code> (합계)</li>
<li><code>--mean</code> (평균)</li>
<li><code>--median</code> (중앙값)</li>
<li><code>--stdev</code> (표준 편차)</li>
<li><code>--nulls</code> (결측치 포함 여부)</li>
<li><code>--unique</code> (고유 값 개수)</li>
<li><code>--freq</code> (빈번한 값)</li>
<li><code>--len</code> (최대 값 길이)</li>
</ul>
<p>예를 들어 다음과 같습니다.</p>
<pre>csvstat venture.csv --freq | trim</pre>
<p>정수와 열 이름을 모두 사용할 수 있는 <code>-c</code> 옵션으로 특정 특성들만 선택할 수 있습니다.</p>
<pre>csvstat venture.csv -c 3,GEO</pre>

<div class="rmdtip">
<code>csvstat</code>은 <code>csvsql</code>과 마찬가지로 휴리스틱을 사용하여 데이터 유형을 결정하므로 항상 정확하지는 않을 수 있다는 점을 명심하십시오.
항상 이전 하위 섹션에서 다룬 것처럼 수동으로 직접 검사해 보는 것이 좋습니다.
또한 데이터 유형이 문자열이나 정수일지라도, 그것이 데이터를 어떻게 사용해야 하는지에 대해서는 아무것도 알려주지 않습니다.
</div>
<p>참고로 <code>csvstat</code>은 맨 마지막에 전체 데이터 포인트(행)의 수도 출력합니다.
값 내부의 줄바꿈과 쉼표도 올바르게 처리됩니다.
마지막 줄만 보고 싶다면 <code>tail</code>을 사용할 수 있습니다.
또는 실제 행의 개수만 반환하는 <code>xsv</code>를 사용할 수도 있습니다.</p>
<pre>csvstat venture.csv | tail -n 1
xsv count venture.csv</pre>
<p>이 두 가지 옵션은 줄바꿈 횟수를 세는 (따라서 헤더도 포함하는) <code>wc -l</code>과 결과가 다르다는 점에 유의하십시오.</p>
</div>
<div id="쉘에서의-r-한-줄-명령어" class="section level3" number="7.3.2">
<h3 number="7.3.2"><span class="header-section-number">7.3.2</span> 쉘에서의 R 한 줄 명령어</h3>
<p>이 섹션에서는 커맨드 라인에서 직접 통계 프로그래밍 환경인 <code>R</code><span class="citation"><a href="#fn93" class="footnote-ref" id="fnref93"><sup>93</sup></a></span>을 활용할 수 있게 해주는 <code>rush</code><span class="citation"><a href="#fn94" class="footnote-ref" id="fnref94"><sup>94</sup></a></span>라는 커맨드 라인 도구를 소개해 드리고자 합니다.
<code>rush</code>가 무엇을 하고 왜 존재하는지 설명하기 전에, 먼저 <code>R</code> 자체에 대해 잠깐 이야기해 보겠습니다.</p>
<p><code>R</code>은 데이터 과학을 하기에 매우 강력한 통계 소프트웨어 패키지입니다.
패키지 모음이 방대하고 자체적인 REPL을 제공하는 인터프리터 언어이므로, 커맨드 라인과 비슷하게 데이터를 가지고 놀 수 있습니다.
<code>R</code>을 시작하면 유닉스 커맨드 라인과는 분리된 상호작용 세션에 들어가게 됩니다.</p>
<p><em>tips.csv</em>라는 CSV 파일이 있고, 팁 비율(tip percentage)을 계산하여 그 결과를 저장하고 싶다고 가정해 봅시다.
이를 <code>R</code>에서 수행하려면 먼저 <code>R</code>을 실행합니다.</p>
<pre>R --quiet</pre>
<p><span class="callout">&#10122;</span> 긴 시작 메시지를 생략하기 위해 <code>--quiet</code> 옵션을 사용했습니다.</p>
<p>그 다음 아래의 코드를 실행합니다.</p>
<pre>library(tidyverse)                            <span class="callout">&#10122;</span>
df &lt;- read_csv("tips.csv")                    <span class="callout">&#10123;</span>
df &lt;- mutate(df, percent = tip / bill * 100)  <span class="callout">&#10124;</span>
write_csv(df, "percent.csv")                  <span class="callout">&#10125;</span>
q("no")                                       <span class="callout">&#10126;</span></pre>
<p><span class="callout">&#10122;</span> 필요한 패키지를 로드합니다.
<br><span class="callout">&#10123;</span> CSV 파일을 읽어 들여 <code>df</code> 변수에 할당합니다.
<br><span class="callout">&#10124;</span> 새로운 <em>percent</em> 열을 계산합니다.
<br><span class="callout">&#10125;</span> 결과를 디스크에 저장합니다.
<br><span class="callout">&#10126;</span> <code>R</code>을 종료합니다.</p>
<p>그 후에 커맨드 라인에서 저장된 <em>percent.csv</em> 파일로 작업을 계속할 수 있습니다.</p>
<pre>&lt; percent.csv trim 5</pre>
<p>여기서 세 번째 줄만이 여러분이 구체적으로 달성하고자 하는 작업과 관련이 있다는 점에 주목하십시오.
나머지 줄들은 필요한 상용구(boilerplate)일 뿐입니다.
단순한 작업을 위해 이런 상용구들을 일일이 입력하는 것은 번거롭고 워크플로우를 방해합니다.
때로는 데이터에 대해 한두 가지만 하고 싶을 때가 있습니다.
<code>R</code>의 위력을 커맨드 라인에서 바로 사용할 수 있다면 정말 좋지 않을까요?</p>
<p>이것이 바로 <code>rush</code>가 등장하는 지점입니다.
방금 전과 똑같은 작업을 <code>rush</code>를 사용하여 수행해 보겠습니다.</p>
<pre>rm percent.csv
rush run -t 'mutate(df, percent = tip / bill * 100)' tips.csv &gt; percent.csv
&lt; percent.csv trim 5</pre>
<p><code>rush</code>가 모든 상용구를 대신 처리해주기 때문에 이러한 짧은 한 줄 명령어가 가능합니다.
여기서는 <code>run</code> 서브 명령어를 사용하고 있습니다. 다음 섹션에서 데이터 시각화를 빠르게 생성할 때 사용할 <code>plot</code> 서브 명령어도 있습니다.
입력 데이터를 전달할 때 <code>rush</code>는 기본적으로 헤더가 있고 쉼표로 구분된 CSV 형식이라고 가정합니다.
또한 열 이름은 작업하기 쉽도록 정리(sanitized)됩니다.
이러한 기본값들은 각각 <code>--no-header</code> (또는 <code>-H</code>), <code>--delimiter</code> (또는 <code>-d</code>), <code>--no-clean-names</code> (또는 <code>-C</code>) 옵션을 사용하여 변경할 수 있습니다.
도움말을 보면 <code>run</code> 서브 명령어에서 사용 가능한 옵션들을 잘 확인할 수 있습니다.</p>
<pre>rush run --help</pre>
<p>내부적으로 <code>rush</code>는 <code>R</code> 스크립트를 생성하고 바로 실행합니다.
<code>--dry-run</code> (또는 <code>-n</code>) 옵션을 지정하면 이렇게 생성된 스크립트를 확인할 수 있습니다.</p>
<pre>rush run -n --tidyverse 'mutate(df, percent = tip / bill * 100)' tips.csv</pre>
<p>생성된 스크립트는 다음과 같은 일을 합니다.</p>
<ul>
<li>커맨드 라인에서 <code>R</code> 스크립트를 실행하는 데 필요한 쉬뱅(<em><code>#!</code></em>; <a href="#chapter-4-creating-command-line-tools">4장</a> 참조)을 작성합니다.</li>
<li><em>tidyverse</em>와 <em>glue</em> 패키지를 임포트합니다.</li>
<li><em>tips.csv</em>를 데이터 프레임으로 로드하고 열 이름을 정리한 뒤 <code>df</code> 변수에 할당합니다.</li>
<li>지정된 표현식을 실행합니다.</li>
<li>결과를 표준 출력으로 인쇄합니다.</li>
</ul>
<p>생성된 스크립트를 파일로 리다이렉션하면 쉬뱅 덕분에 아주 쉽게 새로운 커맨드 라인 도구로 만들 수 있습니다.</p>
<p><code>rush</code>의 출력이 반드시 CSV 형식이어야 할 필요는 없습니다. 여기서는 평균 팁 비율, 최대 일행 인원수, 시간 열의 고유 값들, 전체 금액과 팁 사이의 상관관계를 계산합니다. 마지막으로 열 하나를 통째로 추출합니다 (처음 10개 값만 보여줍니다).</p>
<pre>&lt; percent.csv rush run 'mean(df$percent)' -
&lt; percent.csv rush run 'max(df$size)' -
&lt; percent.csv rush run 'unique(df$time)' -
&lt; percent.csv rush run 'cor(df$bill, df$tip)' -
&lt; percent.csv rush run 'df$tip' - | trim</pre>
<p>마지막의 대시(<code>-</code>) 기호는 <code>rush</code>가 표준 입력을 읽어야 함을 의미합니다.</p>
<p>이제 여러분의 데이터셋에 <code>R</code>로 한두 가지 작업을 하고 싶을 때, 이를 한 줄 명령어로 지정하고 계속해서 커맨드 라인에서 작업을 이어 나갈 수 있습니다.
여러분이 이미 알고 있는 <code>R</code>에 대한 모든 지식을 이제 커맨드 라인에서 사용할 수 있습니다. <code>rush</code>를 사용하면 다음 섹션에서 보여드릴 것처럼 정교한 시각화도 만들 수 있습니다.</p>
</div>
</div>
<div id="시각화-생성하기" class="section level2" number="7.4">
<h2 number="7.4"><span class="header-section-number">7.4</span> 시각화 생성하기</h2>
<p>이 섹션에서는 커맨드 라인에서 데이터 시각화를 생성하는 방법을 보여드리겠습니다.
<code>rush plot</code>을 사용하여 막대 그래프, 산점도, 박스 플롯을 만들어 볼 것입니다.
본격적으로 시작하기 전에, 생성한 시각화를 어떻게 표시(display)할 수 있는지 먼저 설명하겠습니다.</p>
<div id="커맨드-라인에서-이미지-표시하기" class="section level3" number="7.4.1">
<h3 number="7.4.1"><span class="header-section-number">7.4.1</span> 커맨드 라인에서 이미지 표시하기</h3>
<p><em>tips.png</em> 이미지를 예로 들어보겠습니다.
<code>rush</code>와 <em>tips.csv</em> 데이터셋을 사용하여 생성한 데이터 시각화인 Figure @ref(fig:plot-demo)를 살펴보십시오.
(<code>rush</code> 구문은 잠시 후에 설명하겠습니다.)
저는 책에 이미지를 삽입하기 위해 <code>display</code> 도구를 사용하지만, 여러분이 직접 <code>display</code> 명령어를 실행하면 작동하지 않을 수도 있습니다.
커맨드 라인에서 이미지를 표시하는 것은 사실 꽤나 까다로운 일이기 때문입니다.</p>
<p>환경 설정에 따라 이미지를 표시하는 몇 가지 옵션이 있습니다.
제가 아는 네 가지 옵션은 각각 장단점이 있습니다.
(1) 텍스트 표현으로 표시,
(2) 인라인(inline) 이미지로 표시,
(3) 이미지 뷰어 사용,
(4) 브라우저 사용.
이들을 빠르게 훑어봅시다.</p>
<p>옵션 1은 Figure @ref(fig:screenshot-display-ansi-and-inline)의 상단에 표시된 것처럼 터미널 내부에 이미지를 표시하는 것입니다.
표준 출력이 파일로 리다이렉션되지 않을 때 <code>rush</code>가 이 출력을 생성합니다.
이는 ASCII 문자와 ANSI 이스케이프 시퀀스를 기반으로 하므로 모든 터미널에서 사용 가능합니다.
이 책을 읽는 방식에 따라, 코드를 실행했을 때 얻는 출력이 Figure @ref(fig:screenshot-display-ansi-and-inline)의 스크린샷과 일치할 수도 있고 아닐 수도 있습니다.</p>
<pre>rush plot --x bill --y tip --color size --facets '~day' tips.csv</pre>
<p>만약 ASCII 문자만 보인다면, 이 책을 읽고 있는 매체가 색상을 담당하는 ANSI 이스케이프 시퀀스를 지원하지 않는다는 뜻입니다.
다행히 위 명령어를 직접 실행해 보면 스크린샷과 똑같이 보일 것입니다.</p>
<p>옵션 2는 Figure @ref(fig:screenshot-display-ansi-and-inline)의 하단에서 볼 수 있듯이 터미널 내부에 이미지를 바로 표시합니다.
이는 macOS에서만 사용 가능한 iTerm2 터미널이며, 작은 스크립트(제가 <code>display</code>라고 이름 붙인)를 통해 <a href="https://iterm2.com/documentation-images.html">인라인 이미지 프로토콜(Inline Images Protocol)</a>을 사용합니다.
이 스크립트는 Docker 이미지에 포함되어 있지 않지만 쉽게 설치할 수 있습니다.</p>
<pre>curl -s "https://iterm2.com/utilities/imgcat" &gt; display &amp;&amp; chmod u+x display#!enter=FALSE
C-C#!literal=FALSE</pre>
<p>macOS에서 iTerm2를 사용하지 않더라도 인라인으로 이미지를 표시할 수 있는 다른 옵션이 있을 수 있습니다.
선호하는 검색 엔진을 통해 확인해 보시기 바랍니다.</p>
<p>옵션 3은 이미지(이 예제에서는 <em>tips.csv</em> [역주: <em>tips.png</em>의 오타로 보임])를 이미지 뷰어에서 수동으로 여는 것입니다.
Figure @ref(fig:screenshot-display-preview-and-browser)의 왼쪽은 macOS의 파일 탐색기(Finder)와 이미지 뷰어(Preview)를 보여줍니다.
로컬에서 작업할 때는 이 옵션이 항상 작동합니다.
Docker 컨테이너 안에서 작업할 때는 <code>-v</code> 옵션을 사용하여 로컬 디렉터리를 매핑한 경우에만 운영체제에서 생성된 이미지에 접근할 수 있습니다.
방법에 대해서는 <a href="#chapter-2-getting-started">2장</a>을 참조하십시오.
이 옵션의 장점은 이미지가 변경되었을 때 대부분의 이미지 뷰어가 자동으로 화면을 갱신해준다는 것입니다. 덕분에 시각화를 미세 조정하면서 빠르게 반복 작업을 할 수 있습니다.</p>
<p>옵션 4는 브라우저에서 이미지를 여는 것입니다.
Figure @ref(fig:screenshot-display-preview-and-browser)의 오른쪽은 *<a href="http://localhost:8000/tips.png*를" class="uri">http://localhost:8000/tips.png*를</a> 보여주는 파이어폭스(Firefox) 스크린샷입니다.
어떤 브라우저든 상관없지만, 이 옵션을 사용하려면 두 가지 전제 조건이 필요합니다.
첫째, <code>-p</code> 옵션을 사용하여 Docker 컨테이너의 포트(이 예제에서는 8000번 포트)를 열어두어야 합니다.
(역시 <a href="#chapter-2-getting-started">2장</a>에 설명되어 있습니다.)
둘째, 웹 서버를 실행해야 합니다.
이를 위해 Docker 컨테이너에는 파이썬을 사용하여 현재 작업 디렉터리를 서비스하는 <code>servewd</code><span class="citation"><a href="#fn95" class="footnote-ref" id="fnref95"><sup>95</sup></a></span>라는 작은 도구가 들어 있습니다.</p>
<pre>bat $(which servewd)</pre>
<p>디렉터리(예: <em>/data/</em>)에서 <code>servewd</code>를 한 번만 실행해 두면 백그라운드에서 계속 실행됩니다.
그림을 그린 뒤에는 브라우저에서 <em>localhost:8000</em>에 접속하여 해당 디렉터리와 모든 하위 디렉터리의 내용에 접근할 수 있습니다.
기본 포트는 8000번이지만 <code>servewd</code>에 인자로 지정하여 변경할 수도 있습니다.</p>
<pre>servewd 9999#!enter=FALSE
C-C#!literal=FALSE</pre>
<p>해당 포트에 접근 가능한지만 확인하면 됩니다.
<code>servewd</code>는 백그라운드에서 실행되므로 다음과 같이 종료해야 합니다.</p>
<pre>pkill -f http.server</pre>
<p>옵션 4는 원격 시스템에서도 작동할 수 있습니다.</p>
<p>이제 이미지를 표시하는 네 가지 옵션을 다루었으니, 실제로 시각화를 만들어 봅시다.</p>
</div>
<div id="서둘러-그림-그리기" class="section level3" number="7.4.2">
<h3 number="7.4.2"><span class="header-section-number">7.4.2</span> 서둘러 그림 그리기</h3>
<p>데이터 시각화를 생성할 때 가질 수 있는 선택지는 매우 많습니다.
개인적으로 저는 R의 시각화 패키지인 <code>ggplot2</code>를 강력하게 지지합니다.
기저에 흐르는 ’그래픽 문법(grammar of graphics)’과 그를 따르는 일관된 API 덕분에, 매번 문서를 찾아볼 필요 없이 아름다운 데이터 시각화를 빠르고 반복적으로 만들어낼 수 있습니다.
이는 데이터를 탐색할 때 매우 환영할 만한 특성입니다.</p>
<p>지금 당장 급한(in a rush) 것은 아니지만, 하나의 시각화에 너무 많은 시간을 쏟고 싶지는 않습니다.
또한 가능한 한 커맨드 라인에 머물고 싶습니다.
다행히 우리에게는 커맨드 라인에서 <code>ggplot2</code>를 사용할 수 있게 해주는 <code>rush</code>가 있습니다.
Figure @ref(fig:plot-demo)의 시각화는 다음과 같이 만들 수 있었습니다.</p>
<pre>rush run --library ggplot2 'ggplot(df, aes(x = bill, y = tip, color = size)) + geom_point() + facet_wrap(~day)' tips.csv &gt; tips.png#!enter=FALSE
C-C#!literal=FALSE</pre>
<p>하지만 눈치채셨겠지만, 저는 <em>tips.png</em>를 만들기 위해 아주 다른 명령어를 사용했습니다.</p>
<pre>rush plot --x bill --y tip --color size --facets '~day' tips.csv &gt; tips.png#!enter=FALSE
C-C#!literal=FALSE</pre>
<p><code>ggplot2</code>의 구문이 유연성에 비해 상당히 간결하긴 하지만, 기본적인 그래프를 빠르게 생성할 수 있는 지름길이 있습니다.
이 지름길은 <code>rush</code>의 <code>plot</code> 서브 명령어를 통해 제공됩니다.
덕분에 R이나 그래픽 문법을 배우지 않고도 아름다운 기초 그래프를 만들 수 있습니다.</p>
<p>내부적으로 <code>rush plot</code>은 <code>ggplot2</code> 패키지의 <code>qplot</code> 함수를 사용합니다.
다음은 해당 함수의 문서 중 일부입니다.</p>
<pre>R -q -e '?ggplot2::qplot' | trim 14</pre>
<p>저도 이 조언에 동의합니다. 이 책을 다 읽고 나면 <code>ggplot2</code>를 배울 가치가 충분하며, 특히 탐색용 시각화를 외부에 전달하기 적합한 수준으로 업그레이드하고 싶다면 더욱 그렇습니다.
지금은 커맨드 라인에 있으니 지름길을 택해 봅시다.</p>
<p>Figure @ref(fig:screenshot-display-ansi-and-inline)에서 이미 보았듯이, <code>rush plot</code>은 동일한 구문으로 그래픽 시각화(픽셀로 구성)와 텍스트 시각화(ASCII 문자와 ANSI 이스케이프 시퀀스로 구성)를 모두 만들 수 있습니다.
<code>rush</code>가 자신의 출력이 다른 명령어로 파이프되거나(예: <code>display</code>) 파일로 리다이렉션되는 것을 감지하면 그래픽 시각화를 생성하고, 그렇지 않으면 텍스트 시각화를 생성합니다.</p>
<p>잠시 시간을 내어 <code>rush plot</code>의 그래프 생성 및 저장 옵션들을 읽어봅시다.</p>
<pre>rush plot --help</pre>
<p>가장 중요한 옵션은 <em><code>&lt;name&gt;</code></em>을 인자로 받는 그래프 옵션들입니다.
예를 들어 <code>--x</code> 옵션은 x축을 따라 물체들이 놓일 위치를 결정하는 데 어떤 열을 사용할지 지정해 줍니다.
<code>--y</code> 옵션도 마찬가지입니다.
<code>--color</code>와 <code>--fill</code> 옵션은 색상을 입히는 데 사용할 열을 지정합니다.
<code>--size</code>와 <code>--alpha</code> 옵션이 무엇에 관한 것인지는 아마 짐작하실 수 있을 것입니다.
기타 공통 옵션들은 다양한 시각화를 직접 만들어 보면서 각 섹션에서 설명하겠습니다.
각 시각화에 대해 먼저 텍스트 표현(ASCII 및 ANSI 문자)을 보여드린 다음, 실제 그래픽 표현(픽셀)을 보여드리겠습니다.</p>
</div>
<div id="막대-그래프bar-charts-생성하기" class="section level3" number="7.4.3">
<h3 number="7.4.3"><span class="header-section-number">7.4.3</span> 막대 그래프(Bar Charts) 생성하기</h3>
<p>막대 그래프는 범주형 특성의 값 개수(counts)를 표시하는 데 특히 유용합니다.
다음은 tips 데이터셋의 <em>time</em> 특성에 대한 텍스트 시각화입니다.</p>
<pre>rush plot --x time tips.csv</pre>
<p>Figure @ref(fig:plot-bar-image)는 출력이 파일로 리다이렉션될 때 <code>rush plot</code>이 생성하는 그래픽 시각화입니다.</p>
<pre>rush plot --x time tips.csv &gt; plot-bar.png
display plot-bar.png</pre>
<p>이 막대 그래프로부터 내릴 수 있는 결론은 간단합니다. 점심(lunch)보다 저녁(dinner) 데이터 포인트가 두 배 이상 많다는 것입니다.</p>
</div>
<div id="히스토그램histograms-생성하기" class="section level3" number="7.4.4">
<h3 number="7.4.4"><span class="header-section-number">7.4.4</span> 히스토그램(Histograms) 생성하기</h3>
<p>연속형 변수의 개수는 히스토그램으로 시각화할 수 있습니다.
여기서는 <em>time</em> 특성을 사용하여 채우기(fill) 색상을 설정했습니다.
그 결과, <code>rush plot</code>은 편리하게도 누적 히스토그램(stacked histogram)을 생성합니다.</p>
<pre>rush plot --x tip --fill time tips.csv</pre>
<p>Figure @ref(fig:plot-histogram-image)는 그래픽 시각화를 보여줍니다.</p>

<div class="rmdtip">
유용하게 쓰일 수 있는 두 가지 구문 지름길(shortcuts)을 보여드리겠습니다.
두 개의 느낌표(<code>!!</code>)는 이전 명령어로 대체됩니다.
느낌표와 달러 기호(<code>!$</code>)는 이전 명령어의 마지막 부분인 파일명 <em>plot-histogram.png</em>로 대체됩니다.
보시는 것처럼, Z 쉘이 업데이트된 명령어를 먼저 출력해주므로 무엇이 실행되는지 정확히 알 수 있습니다.
이 두 지름길은 타이핑 양을 크게 줄여주지만, 기억하기가 쉽지는 않습니다.
</div>
<pre>!! &gt; plot-histogram.png
display !$</pre>
<p>이 히스토그램은 대부분의 팁이 2.5달러 근처임을 보여줍니다.
저녁과 점심 두 그룹이 서로 겹쳐 쌓여 있고 절대적인 개수를 보여주기 때문에 서로 비교하기가 어렵습니다.
아마도 밀도 그래프(density plot)가 도움이 될 수 있을 것 같습니다.</p>
</div>
<div id="밀도-그래프density-plots-생성하기" class="section level3" number="7.4.5">
<h3 number="7.4.5"><span class="header-section-number">7.4.5</span> 밀도 그래프(Density Plots) 생성하기</h3>
<p>밀도 그래프는 연속형 변수의 분포를 시각화하는 데 유용합니다.
<code>rush plot</code>은 적절한 도형(geometry)을 결정하기 위해 휴리스틱을 사용하지만, <code>geom</code> 옵션을 사용하여 이를 직접 지정할 수 있습니다.</p>
<pre>rush plot --x tip --fill time --geom density tips.csv</pre>
<p>이 경우에는 텍스트 시각화가 Figure @ref(fig:plot-density-image)의 그래픽 시각화와 비교했을 때 확실히 한계가 있음을 보여줍니다.</p>
<pre>rush plot --x tip --fill time --geom density tips.csv &gt; plot-density.png
display plot-density.png</pre>
</div>
<div id="행복한-사고happy-little-accidents" class="section level3" number="7.4.6">
<h3 number="7.4.6"><span class="header-section-number">7.4.6</span> 행복한 사고(Happy Little Accidents)</h3>
<p>여러분은 이미 세 가지 유형의 시각화를 보았습니다.
<code>ggplot2</code>에서 이들은 각각 <code>geom_bar</code>, <code>geom_histogram</code>, <code>geom_density</code> 함수에 해당합니다.
<em>geom</em>은 기하학(geometry)의 약자로, 실제로 무엇을 그릴지 지시합니다.
이 <a href="https://ggplot2.tidyverse.org/"><code>ggplot2</code> 컨닝 페이퍼</a>는 사용 가능한 도형 유형에 대한 좋은 개요를 제공합니다.
사용할 수 있는 도형 유형은 지정한 열(및 그 유형)에 따라 달라집니다.
모든 조합이 의미가 있는 것은 아닙니다.
이 선 그래프(line plot)를 예로 들어보겠습니다.</p>
<pre>rush plot --x tip --y bill --color size --size day --geom path tips.csv</pre>
<p>이 행복한 사고(역주: 밥 로스가 말하던 ’Happy Accident’를 인용한 듯함)는 Figure @ref(fig:plot-accident-image)의 그래픽 표현에서 더 분명해집니다.</p>
<pre>rush plot --x tip --y bill --color size --size day --geom path tips.csv &gt; plot-accident.png
display plot-accident.png</pre>
<p><em>tips.csv</em>의 행들은 독립적인 관측치인 반면, 데이터 포인트 사이에 선을 긋는 것은 그들이 서로 연결되어 있다고 가정하는 것입니다.
<em>tip</em>과 <em>bill</em> 사이의 관계를 시각화하려면 산점도(scatter plot)를 사용하는 것이 더 낫습니다.</p>
</div>
<div id="산점도scatter-plots-생성하기" class="section level3" number="7.4.7">
<h3 number="7.4.7"><span class="header-section-number">7.4.7</span> 산점도(Scatter Plots) 생성하기</h3>
<p>산점도는 도형이 점(point)인 그래프로, 두 개의 연속형 특성을 지정했을 때 기본적으로 선택됩니다.</p>
<pre>rush plot --x bill --y tip --color time tips.csv</pre>
<p>각 점의 색상은 <code>--color</code> 옵션(채우기 옵션인 <code>--fill</code>이 아닙니다)으로 지정된다는 점에 유의하십시오.
그래픽 표현은 Figure @ref(fig:plot-scatter-image)를 참조하십시오.</p>
<pre>rush plot --x bill --y tip --color time tips.csv &gt; plot-scatter.png
display plot-scatter.png</pre>
<p>이 산점도로부터 우리는 전체 금액(bill)과 팁(tip) 사이에 관계가 있다는 결론을 내릴 수 있습니다.
아마도 추세선(trend lines)을 만들어 더 높은 수준에서 이 데이터를 검토하는 것이 유용할 것입니다.</p>
</div>
<div id="추세선trend-lines-생성하기" class="section level3" number="7.4.8">
<h3 number="7.4.8"><span class="header-section-number">7.4.8</span> 추세선(Trend Lines) 생성하기</h3>
<p>기본 도형을 <em><code>smooth</code></em>로 변경하면 추세선을 시각화할 수 있습니다.
이는 전체적인 그림을 파악하는 데 유용합니다.</p>
<pre>rush plot --x bill --y tip --color time --geom smooth tips.csv</pre>
<p><code>rush plot</code>은 투명도를 처리할 수 없으므로, 이 경우에는 Figure @ref(fig:plot-trend-image)와 같은 그래픽 표현이 훨씬 낫습니다.</p>
<pre>rush plot --x bill --y tip --color time --geom smooth tips.csv &gt; plot-trend.png
display plot-trend.png</pre>
<p>추세선과 함께 원래의 점들도 시각화하고 싶다면 <code>rush run</code>을 사용하여 직접 <code>ggplot2</code> 코드를 작성해야 합니다 (@ref(fig:plot-trend-points-image) 참조).</p>
<pre>rush run --library ggplot2 'ggplot(df, aes(x = bill, y = tip, color = time)) + geom_point() + geom_smooth()' tips.csv &gt; plot-trend-points.png
display plot-trend-points.png</pre>
</div>
<div id="박스-플롯box-plots-생성하기" class="section level3" number="7.4.9">
<h3 number="7.4.9"><span class="header-section-number">7.4.9</span> 박스 플롯(Box Plots) 생성하기</h3>
<p>박스 플롯은 하나 이상의 특성에 대해 다섯 수치 요약(최솟값, 최댓값, 표본 중앙값, 제1 및 제3 사분위수)을 시각화합니다.
이 경우 <em>size</em> 특성을 <code>factor()</code> 함수를 사용하여 범주형으로 변환해야 합니다. 그렇지 않으면 <em>bill</em> 특성의 모든 값이 하나로 뭉쳐지게 됩니다.</p>
<pre>rush plot --x 'factor(size)' --y bill --geom boxplot tips.csv</pre>
<p>텍스트 표현도 나쁘지는 않지만, 그래픽 표현이 훨씬 더 명확합니다 (@ref(fig:plot-boxplot-image) 참조).</p>
<pre>rush plot --x 'factor(size)' --y bill --geom boxplot tips.csv &gt; plot-boxplot.png
display plot-boxplot.png</pre>
<p>당연하게도, 이 박스 플롯은 평균적으로 일행 인원수가 많을수록 전체 금액이 더 높아짐을 보여줍니다.</p>
</div>
<div id="레이블-추가하기" class="section level3" number="7.4.10">
<h3 number="7.4.10"><span class="header-section-number">7.4.10</span> 레이블 추가하기</h3>
<p>기본 레이블은 열 이름(또는 명세)을 기반으로 합니다.
이전 이미지에서 <em><code>factor(size)</code></em>라는 레이블은 개선될 필요가 있습니다.
<code>--xlab</code> 및 <code>--ylab</code> 옵션을 사용하여 x축과 y축의 레이블을 변경할 수 있습니다.
제목은 <code>--title</code> 옵션으로 추가할 수 있습니다.
다음은 이를 보여주는 바이올린 플롯(박스 플롯과 밀도 그래프를 혼합한 것)입니다 (@ref(fig:plot-labels-image) 참조).</p>
<pre>rush plot --x 'factor(size)' --y bill --geom violin --title '일행 인원수별 전체 금액 분포' --xlab '일행 인원수' --ylab '전체 금액 (USD)' tips.csv</pre>
<pre>rush plot --x 'factor(size)' --y bill --geom violin --title '일행 인원수별 전체 금액 분포' --xlab '일행 인원수' --ylab '전체 금액 (USD)' tips.csv &gt; plot-labels.png
display plot-labels.png</pre>
<p>적절한 레이블과 제목을 시각화에 추가하는 것은 다른 사람(또는 미래의 자신)과 공유할 때 무엇을 보여주고 있는지 더 쉽게 이해할 수 있게 해주므로 특히 유용합니다.</p>
</div>
<div id="기초적인-그래프-그-이상으로" class="section level3" number="7.4.11">
<h3 number="7.4.11"><span class="header-section-number">7.4.11</span> 기초적인 그래프 그 이상으로</h3>
<p>데이터를 탐색할 때 기초적인 그래프를 만드는 데는 <code>rush plot</code>이 적합하지만, 분명히 한계가 있습니다.
때로는 여러 도형을 겹쳐 그리거나 좌표계 변환, 테마 적용과 같이 더 유연하고 정교한 옵션이 필요할 때가 있습니다.
그럴 경우에는 <code>rush plot</code>의 기능이 기반하고 있는 R 패키지인 <code>ggplot2</code>에 대해 더 배워보는 것이 가치 있을 것입니다.
만약 R보다 파이썬을 더 좋아하신다면 파이썬용 <code>ggplot2</code> 재구현체인 <a href="https://plotnine.readthedocs.io"><code>plotnine</code> 패키지</a>가 있습니다.</p>
</div>
</div>
<div id="요약-6" class="section level2" number="7.5">
<h2 number="7.5"><span class="header-section-number">7.5</span> 요약</h2>
<p>이 장에서는 데이터를 탐색하는 다양한 방법을 살펴보았습니다.
텍스트 기반 시각화와 그래픽 기반 시각화 모두 장단점이 있습니다.
그래픽 시각화는 분명히 품질이 훨씬 높지만 커맨드 라인에서 보기가 까다로울 수 있습니다.
이때 텍스트 시각화가 유용하게 쓰입니다.
최소한 <code>rush</code>는 <code>R</code>과 <code>ggplot2</code> 덕분에 두 가지 유형 모두에 대해 일관된 구문을 제공합니다.</p>
<p>다음 장은 다시 한번 ‘인터메조(intermezzo)’ 장으로, 명령어와 파이프라인의 속도를 높이는 방법을 다룹니다.
<a href="#chapter-9-modeling-data">9장</a>에서 데이터 모델링을 시작하고 싶어 견딜 수 없다면 이 장은 나중에 읽으셔도 좋습니다.</p>
</div>
<div id="더-읽어보기-2" class="section level2" number="7.6">
<h2 number="7.6"><span class="header-section-number">7.6</span> 더 읽어보기</h2>
<ul>
<li>아쉽게도 제대로 된 <code>ggplot2</code> 튜토리얼은 이 책의 범위를 벗어납니다. 데이터 시각화 능력을 키우고 싶다면 그래픽 문법의 힘과 아름다움을 이해하는 데 시간을 투자하시기를 강력히 권장합니다. Hadley Wickham과 Garrett Grolemund의 저서 <a href="https://r4ds.had.co.nz/"><em>R for Data Science</em></a>의 3장과 28장은 훌륭한 자료입니다.</li>
<li>3장과 28장 이야기가 나와서 말인데, 만약 R보다 파이썬을 선호하신다면 제가 <a href="https://datascienceworkshops.com/blog/plotnine-grammar-of-graphics-for-python/">Plotnine과 Pandas를 사용하여 해당 장들을 파이썬으로 번역해둔 자료</a>가 있습니다.</li>
</ul>
<!--chapter:end:07.Rmd-->
</div>
</div>
<div id="chapter-8-parallel-pipelines" class="section level1" number="8">
<h1 number="8"><span class="header-section-number">8</span> 병렬 파이프라인</h1>
<!-- #TODO: SHOULD: Dicuss progress bar -->
<p>이전 장들에서 우리는 전체 작업을 한 번에 처리하는 명령어와 파이프라인을 다루었습니다.
하지만 실제로는 동일한 명령어 또는 파이프라인을 여러 번 실행해야 하는 작업에 직면하게 될 수도 있습니다.
예를 들어 다음과 같은 상황입니다.</p>
<ul>
<li>수백 개의 웹 페이지 스크래핑하기</li>
<li>수십 개의 API를 호출하고 그 출력을 변환하기</li>
<li>다양한 매개변수 값에 대해 분류기(classifier) 훈련하기</li>
<li>데이터셋의 모든 특성 쌍에 대해 산점도 생성하기</li>
</ul>
<p>위의 예시들에는 모두 특정한 형태의 반복 작업이 포함되어 있습니다.
여러분은 선호하는 스크립트나 프로그래밍 언어에서 <code>for</code> 루프나 <code>while</code> 루프를 통해 이를 처리했을 것입니다.
커맨드 라인에서 가장 먼저 하고 싶은 일은 아마 <strong><code>위</code></strong> 방향키를 눌러 이전 명령어를 불러온 뒤, 필요한 경우 수정하고 <strong><code>엔터</code></strong>를 눌러 다시 실행하는 것일지도 모릅니다.
두세 번 정도는 괜찮겠지만, 이를 수십 번 한다고 상상해 보십시오.
그러한 접근 방식은 금세 번거롭고 효율적이지 않으며 오류가 발생하기 쉬워집니다.
다행인 점은 이러한 루프를 커맨드 라인에서도 작성할 수 있다는 것입니다.
이것이 바로 이번 장에서 다룰 주제입니다.</p>
<p>때로는 빠른 명령어를 하나씩 차례대로(<em>순차적으로</em>) 반복하는 것만으로도 충분합니다.
하지만 데이터 집약적인 작업에 처했을 때, 여러 개의 코어(혹은 여러 대의 컴퓨터)가 있다면 이를 활용할 수 있으면 좋을 것입니다.
여러 코어나 장비를 사용하면 전체 실행 시간을 크게 단축할 수 있습니다.
이번 장에서는 바로 이러한 작업을 처리해 주는 <code>parallel</code><span class="citation"><a href="#fn96" class="footnote-ref" id="fnref96"><sup>96</sup></a></span>이라는 매우 강력한 도구를 소개해 드리겠습니다. 이 도구를 사용하면 숫자, 텍스트 줄(lines), 파일과 같은 다양한 인자(arguments) 범위에 대해 명령어 또는 파이프라인을 적용할 수 있습니다.
게다가 이름에서 알 수 있듯이, 명령어를 <em>병렬</em>로 실행할 수 있게 해줍니다.</p>
<div id="개요-5" class="section level2" number="8.1">
<h2 number="8.1"><span class="header-section-number">8.1</span> 개요</h2>
<p>이번 인터메조(intermezzo) 장에서는 명령어와 파이프라인을 여러 번 실행해야 하는 작업의 속도를 높이는 여러 가지 접근 방식을 다룹니다.
저의 주된 목표는 <code>parallel</code>의 유연함과 강력함을 보여드리는 것입니다.
이 도구는 이 책에서 다루는 다른 어떤 도구와도 결합될 수 있으므로, 데이터 과학을 위해 커맨드 라인을 사용하는 여러분의 방식을 긍정적으로 바꿔놓을 것입니다.
이번 장에서 여러분은 다음 내용을 배우게 됩니다.</p>
<ul>
<li>숫자, 텍스트 줄, 파일 범위에 대해 명령어를 순차적으로 실행하기</li>
<li>큰 작업을 여러 개의 작은 작업으로 쪼개기</li>
<li>파이프라인을 병렬로 실행하기</li>
<li>파이프라인을 여러 대의 컴퓨터로 분산하기</li>
</ul>
<p>이번 장은 다음 파일들로 시작합니다.</p>
<pre>cd /data/ch08
l</pre>
<p>이 파일들을 가져오는 방법은 <a href="#chapter-2-getting-started">2장</a>에 설명되어 있습니다.
그 외의 파일들은 커맨드 라인 도구를 사용하여 다운로드하거나 생성한 것들입니다.</p>
</div>
<div id="순차-처리serial-processing" class="section level2" number="8.2">
<h2 number="8.2"><span class="header-section-number">8.2</span> 순차 처리(Serial Processing)</h2>
<p>병렬화에 대해 깊이 파고들기 전에, 순차적인 방식으로 루프를 실행하는 것에 대해 짧게 다루어 보겠습니다.
이 기능을 알아두는 가치가 있는 이유는 항상 사용 가능한 기능이고, 구문이 다른 프로그래밍 언어의 루프와 매우 비슷하며, 무엇보다 나중에 <code>parallel</code>의 소중함을 정말로 깨닫게 해주기 때문입니다.</p>
<p>이번 장의 서론에서 제공한 예시들로부터 루프를 돌릴 세 가지 유형의 항목을 추출할 수 있습니다. 바로 숫자, 텍스트 줄, 그리고 파일입니다.
이 세 가지 유형에 대해 다음 세 개의 하위 섹션에서 각각 논의하겠습니다.</p>
<div id="숫자에-대해-루프-돌리기" class="section level3" number="8.2.1">
<h3 number="8.2.1"><span class="header-section-number">8.2.1</span> 숫자에 대해 루프 돌리기</h3>
<p>0에서 100 사이의 모든 짝수의 제곱을 계산해야 한다고 상상해 봅시다. <code>bc</code><span class="citation"><a href="#fn97" class="footnote-ref" id="fnref97"><sup>97</sup></a></span>라는 도구가 있는데, 이는 수식을 파이프로 전달할 수 있는 ’기본 계산기(basic calculator)’입니다.
4의 제곱을 계산하는 명령어는 다음과 같습니다.</p>
<pre>echo "4^2" | bc</pre>
<p>일회성 계산이라면 이것으로 충분합니다.
하지만 서론에서 언급했듯이, <strong><code>위</code></strong> 방향키를 누르고 숫자를 바꾼 뒤 <strong><code>엔터</code></strong>를 누르는 짓을 50번이나 반복하는 것은 제정신이 아닐 것입니다!
이런 경우에는 <code>for</code> 루프를 사용하여 쉘이 대신 고된 일을 하도록 만드는 것이 좋습니다.</p>
<pre>for i in {0..100..2}  <span class="callout">&#10122;</span>
do
echo "$i^2" | bc      <span class="callout">&#10123;</span>
done | trim</pre>
<p><span class="callout">&#10122;</span> Z 쉘에는 중괄호 확장(brace expansion)이라는 기능이 있어, <em><code>{0..100..2}</code></em>를 공백으로 구분된 목록인 <em><code>0 2 4 … 98 100</code></em>으로 변환합니다. 변수 <em><code>i</code></em>에는 첫 번째 반복에서 “0”, 두 번째 반복에서 “1” [역주: 여기서는 2씩 증가하므로 “2”] 등의 값이 할당됩니다.
<br><span class="callout">&#10123;</span> 이 변수의 값은 앞에 달러 기호(<em><code>$</code></em>)를 붙여서 사용할 수 있습니다. 쉘은 <code>echo</code>가 실행되기 전에 <em><code>$i</code></em>를 그 값으로 교체합니다. <em><code>do</code></em>와 <em><code>done</code></em> 사이에는 하나 이상의 명령어가 올 수 있다는 점에 유의하십시오.</p>
<p>비록 구문이 여러분이 선호하는 프로그래밍 언어에 비해 조금 이상해 보일 수 있지만, 쉘에서 항상 사용할 수 있는 기능이므로 기억해 둘 가치가 있습니다.
잠시 후에 명령어를 반복하는 더 좋고 유연한 방법을 소개해 드리겠습니다.</p>
</div>
<div id="텍스트-줄lines에-대해-루프-돌리기" class="section level3" number="8.2.2">
<h3 number="8.2.2"><span class="header-section-number">8.2.2</span> 텍스트 줄(Lines)에 대해 루프 돌리기</h3>
<p>두 번째로 루프를 돌릴 수 있는 항목 유형은 텍스트 줄입니다.
이 줄들은 파일에서 올 수도 있고 표준 입력에서 올 수도 있습니다.
이 항목들은 숫자, 날짜, 이메일 주소 등 무엇이든 포함할 수 있으므로 매우 일반적인 접근 방식입니다.</p>
<p>모든 연락처에 이메일을 보내고 싶다고 상상해 봅시다.
먼저 무료 <a href="https://randomuser.me">Random User Generator API</a>를 사용하여 가짜 사용자 데이터를 생성해 보겠습니다.</p>
<pre>curl -s "https://randomuser.me/api/1.2/?results=5&amp;seed=dsatcl2e" &gt; users.json
&lt; users.json jq -r '.results[].email' &gt; emails
bat emails</pre>
<p><code>while</code> 루프를 사용하여 <em>emails</em> 파일의 줄들에 대해 루프를 돌릴 수 있습니다.</p>
<pre>while read line                         <span class="callout">&#10122;</span>
do
echo "Sending invitation to ${line}."   <span class="callout">&#10123;</span>
done &lt; emails                           <span class="callout">&#10124;</span></pre>
<p><span class="callout">&#10122;</span> 이 경우에는 Z 쉘이 입력이 몇 줄로 구성되어 있는지 미리 알 수 없으므로 <code>while</code> 루프를 사용해야 합니다.
<br><span class="callout">&#10123;</span> 이 경우 <em>line</em> 변수 주위의 중괄호는 필수적이지 않지만 (변수 이름에 마침표가 포함될 수 없으므로), 그래도 중괄호를 사용하는 것은 좋은 습관입니다.
<br><span class="callout">&#10124;</span> 이 리다이렉션은 <code>while</code> 앞에 올 수도 있습니다.</p>
<p>표준 입력 장치인 <em>/dev/stdin</em>을 지정하여 상호작용적으로 <code>while</code> 루프에 입력을 제공할 수도 있습니다. 작업이 끝나면 <strong><code>Ctrl-D</code></strong>를 누르십시오.</p>
<pre>while read line; do echo "You typed: ${line}."; done &lt; /dev/stdin#! expect_prompt=FALSE
one#! expect_prompt=FALSE
two#! expect_prompt=FALSE
three#! expect_prompt=FALSE
C-D#! literal=FALSE, expect_prompt=TRUE</pre>
<p>하지만 이 방식은 <strong><code>엔터</code></strong>를 누르는 즉시 해당 입력 줄에 대해 <em><code>do</code></em>와 <em><code>done</code></em> 사이의 명령어가 바로 실행된다는 단점이 있습니다. 되돌릴 수 없습니다.</p>
</div>
<div id="파일에-대해-루프-돌리기" class="section level3" number="8.2.3">
<h3 number="8.2.3"><span class="header-section-number">8.2.3</span> 파일에 대해 루프 돌리기</h3>
<p>이 섹션에서는 우리가 자주 루프를 돌려야 하는 세 번째 항목인 파일에 대해 논의합니다.</p>
<p>특수 문자를 처리하려면 <code>ls</code><span class="citation"><a href="#fn98" class="footnote-ref" id="fnref98"><sup>98</sup></a></span> 대신 글로빙(globbing, 즉 경로명 확장)을 사용하십시오.</p>
<pre>for chapter in /data/*
do
echo "Processing Chapter ${chapter}."
done</pre>
<p>중괄호 확장과 마찬가지로, <em><code>/data/*</code></em> 표현식은 <code>for</code> 루프에 의해 처리되기 전에 Z 쉘에 의해 목록으로 먼저 확장됩니다.</p>
<p>파일 목록을 작성하는 더 정교한 대안은 <code>find</code><span class="citation"><a href="#fn99" class="footnote-ref" id="fnref99"><sup>99</sup></a></span>입니다. 이 도구는 다음과 같은 특징이 있습니다.</p>
<ul>
<li>하위 디렉터리까지 탐색할 수 있음</li>
<li>크기, 접근 시간, 권한 등 속성에 대한 정교한 검색 가능</li>
<li>공백이나 줄바꿈과 같은 특수 문자 처리 가능</li>
</ul>
<p>예를 들어, 다음 <code>find</code> 실행은 <em>/data</em> 디렉터리 아래에 있는 파일 중 확장자가 <em>csv</em>이고 크기가 2킬로바이트 미만인 모든 파일을 나열합니다.</p>
<pre>find /data -type f -name '*.csv' -size -2k</pre>
</div>
</div>
<div id="병렬-처리parallel-processing" class="section level2" number="8.3">
<h2 number="8.3"><span class="header-section-number">8.3</span> 병렬 처리(Parallel Processing)</h2>
<p>여기에 있는 것처럼 매우 오래 실행되는 도구가 있다고 가정해 봅시다.</p>
<pre>bat slow.sh</pre>
<p><span class="callout">&#10122;</span> <code>ts</code><span class="citation"><a href="#fn100" class="footnote-ref" id="fnref100"><sup>100</sup></a></span>는 타임스탬프를 추가합니다.
<br><span class="callout">&#10123;</span> 마법 변수 <em><code>RANDOM</code></em>은 0에서 32767 사이의 의사 난수 개수를 반환하는 내부 Bash 함수를 호출합니다. 그 정수를 5로 나눈 나머지에 1을 더하면 <em>duration</em>이 1에서 5 사이가 되도록 보장합니다.
<br><span class="callout">&#10124;</span> <code>sleep</code>은 주어진 초 동안 실행을 일시 중지합니다.</p>
<p>이 프로세스는 아마 모든 가용 리소스를 다 쓰지는 않을 것입니다.
그런데 이 명령어를 아주 많이 실행해야 하는 상황이 생겼다고 해봅시다.
예를 들어, 일련의 파일 전체를 다운로드해야 하는 경우입니다.</p>
<p>병렬화하는 순진한 방법은 명령어를 백그라운드에서 실행하는 것입니다.
<code>slow.sh</code>를 세 번 실행해 보겠습니다.</p>
<pre>for i in {A..C}; do
./slow.sh $i &amp;
done#! hold=7</pre>
<p><span class="callout">&#10122;</span> 앰퍼샌드(<code>&amp;</code>)는 명령어를 백그라운드로 보내어, <code>for</code> 루프가 즉시 다음 반복으로 계속 진행할 수 있게 합니다.
<br><span class="callout">&#10123;</span> 이 줄은 Z 쉘이 부여한 작업 번호와 프로세스 ID를 보여주며, 이는 더 세밀한 작업 제어에 사용될 수 있습니다. 이 주제는 강력하지만 이 책의 범위를 벗어납니다.</p>

<div class="rmdnote">
모든 것이 병렬화될 수 있는 것은 아니라는 점을 명심하십시오.
API 호출 횟수가 제한되어 있을 수도 있고, 어떤 명령어는 한 번에 하나의 인스턴스만 실행 가능할 수도 있습니다.
</div>
<p>Figure @ref(fig:diagram-parallel-processing)은 개념적인 수준에서 순차 처리, 순진한 병렬 처리, 그리고 GNU Parallel을 사용한 병렬 처리 사이의 차이를 동시에 실행되는 프로세스 수와 전체 실행 시간 측면에서 보여줍니다.</p>
<p>이 순진한 접근 방식에는 두 가지 문제가 있습니다.
첫째, 동시에 실행되는 프로세스의 수를 제어할 방법이 없습니다.
너무 많은 작업을 한꺼번에 시작하면 CPU, 메모리, 디스크 액세스, 네트워크 대역폭과 같은 동일한 리소스를 놓고 서로 경쟁하게 될 수 있습니다.
이는 오히려 전체 실행 시간을 늘리는 결과를 초래할 수 있습니다.
둘째, 어떤 출력이 어떤 입력에 속하는지 구분하기 어렵습니다.
이제 더 나은 접근 방식을 살펴보겠습니다.</p>
<div id="gnu-parallel-소개" class="section level3" number="8.3.1">
<h3 number="8.3.1"><span class="header-section-number">8.3.1</span> GNU Parallel 소개</h3>
<p>명령어와 파이프라인을 병렬화하고 분산할 수 있게 해주는 커맨드 라인 도구인 <code>parallel</code>을 소개하겠습니다.
이 도구의 장점은 기존 도구들을 있는 그대로 사용할 수 있다는 것입니다. 도구들을 수정할 필요가 없습니다.</p>

<div class="rmdcaution">
커맨드 라인 도구 중에 이름이 <code>parallel</code>인 것이 두 개 있다는 점에 유의하십시오.
Docker 이미지를 사용하고 있다면 이미 올바른 도구가 설치되어 있습니다.
그렇지 않다면 <code>parallel --version</code>을 실행하여 올바른 도구인지 확인할 수 있습니다.
출력에 “GNU parallel”이라고 표시되어야 합니다.
</div>
<p><code>parallel</code>의 세부 사항을 살펴보기 전에, 이전의 <code>for</code> 루프를 얼마나 쉽게 대체할 수 있는지 보여드리는 짧은 예시를 보십시오.</p>
<pre>seq 0 2 100 | parallel "echo {}^2 | bc" | trim</pre>
<p>이것이 <code>parallel</code>의 가장 단순한 형태입니다. 루프를 돌릴 항목들은 표준 입력을 통해 전달되며, <code>parallel</code>이 실행해야 할 명령어 외에는 다른 인자가 없습니다.
<code>parallel</code>이 어떻게 입력을 프로세스들에 동시에 분산하고 그 출력들을 수집하는지에 대한 그림은 Figure @ref(fig:diagram-parallel-output)를 참조하십시오.</p>
<p>보시다시피 기본적으로 <code>for</code> 루프 역할을 합니다.
이전 섹션의 <code>for</code> 루프를 대체하는 또 다른 예시입니다.</p>
<pre>parallel --jobs 2 ./slow.sh ::: {A..C}</pre>
<p>여기서는 <code>--jobs</code> 옵션을 사용하여 <code>parallel</code>이 동시에 최대 두 개의 작업을 실행하도록 지정했습니다. <code>slow.sh</code>에 전달할 인자들은 표준 입력 대신 명령문의 인자로 지정되었습니다 (<code>:::</code> 사용).</p>
<p><code>parallel</code>은 무려 159개의 서로 다른 옵션을 제공하여 매우 방대한 기능을 갖추고 있습니다.
(아마도 너무 많을지도 모릅니다.)
다행히 효과적으로 사용하기 위해 알아야 할 옵션은 몇 개 되지 않습니다.
덜 일반적인 옵션을 사용해야 할 경우 매뉴얼 페이지가 아주 유용합니다.</p>
</div>
<div id="입력-지정하기" class="section level3" number="8.3.2">
<h3 number="8.3.2"><span class="header-section-number">8.3.2</span> 입력 지정하기</h3>
<p><code>parallel</code>에서 가장 중요한 인자는 모든 입력에 대해 실행하고 싶은 명령어 또는 파이프라인입니다.
여기서 질문은, 입력 항목이 명령어의 어느 위치에 삽입되어야 하느냐는 것입니다.
아무것도 지정하지 않으면 입력 항목이 파이프라인의 맨 끝에 추가됩니다.</p>
<pre>seq 3 | parallel cowsay#! enter=FALSE
C-C#! literal=FALSE
parallel --jobs 1 --keep-order cowsay ::: 1 2 3</pre>
<p>위의 명령어는 다음과 같이 실행하는 것과 같습니다.</p>
<pre>cowsay 1 &gt; /dev/null <span class="callout">&#10122;</span>
cowsay 2 &gt; /dev/null
cowsay 3 &gt; /dev/null</pre>
<p><span class="callout">&#10122;</span> 출력이 이전과 같으므로 출력을 억제하기 위해 <em>/dev/null</em>로 리다이렉션했습니다.</p>
<p>이 방식이 작동할 때도 많지만, 플레이스홀더(placeholders)를 사용하여 명령어의 어느 부분에 입력 항목이 삽입되어야 하는지 명시하는 것이 좋습니다.
이 경우 입력 줄 전체(숫자 하나)를 한 번에 사용하고 싶으므로 하나의 플레이스홀더만 있으면 됩니다.
플레이스홀더, 즉 입력 항목을 넣을 위치는 한 쌍의 중괄호(<code>{}</code>)로 지정합니다.</p>
<pre>seq 3 | parallel cowsay {} &gt; /dev/null</pre>

<div class="rmdnote">
<code>parallel</code>에 입력을 제공하는 다른 방법들도 있습니다.
저는 (이번 장에서 계속하는 것처럼) 입력을 파이프로 연결하는 방식을 선호하는데, 이는 대부분의 커맨드 라인 도구가 파이프라인으로 연결되는 방식이기 때문입니다.
다른 방식들은 다른 곳에서는 보기 힘든 구문을 포함하기도 합니다.
그렇긴 하지만, 여러 목록의 모든 가능한 조합에 대해 루프를 돌리는 것과 같은 추가 기능을 제공하므로, 더 자세히 알고 싶다면 <code>parallel</code>의 매뉴얼 페이지를 읽어보시기 바랍니다.
</div>
<p>입력 항목이 파일 이름인 경우, 파일 이름의 일부만 사용할 수 있는 몇 가지 수식어(modifiers)가 있습니다.
예를 들어 <code>{/}</code>를 사용하면 파일 이름의 베이스 이름(basename)만 사용됩니다.</p>
<pre>find /data/ch03 -type f | parallel echo '{#}\) \"{}\" has basename \"{/}\"'</pre>
<p><span class="callout">&#10122;</span> 괄호(<code>)</code>)나 따옴표(<code>"</code>) 같은 문자는 쉘에서 특별한 의미를 갖습니다. 이를 문자 그대로 사용하려면 앞에 백슬래시(<code>\</code>)를 붙입니다. 이를 이스케이프(escaping)라고 합니다.</p>
<p>입력 줄이 구분자로 나뉜 여러 부분으로 구성된 경우 플레이스홀더에 번호를 추가할 수 있습니다. 예를 들어 다음과 같습니다.</p>
<pre>touch input.csv
&lt; input.csv parallel --colsep , "mv {2} {1}" &gt; /dev/null#! enter=FALSE
C-C#! literal=FALSE</pre>
<p>여기에 똑같은 플레이스홀더 수식어를 적용할 수 있습니다.
동일한 입력 항목을 재사용하는 것도 가능합니다.
만약 <code>parallel</code>의 입력이 헤더가 있는 CSV 파일이라면, 열 이름을 플레이스홀더로 사용할 수 있습니다.</p>
<pre>&lt; input.csv parallel -C, --header : "invite {name} {email}"#! enter=FALSE
C-C#! literal=FALSE</pre>

<div class="rmdtip">
플레이스홀더가 올바르게 설정되었는지 궁금하다면 <code>--dry-run</code> 옵션을 추가해 보십시오.
명령어를 실제로 실행하는 대신, <code>parallel</code>은 실행될 모든 명령어를 마치 실제로 실행될 것처럼 출력해 줍니다.
</div>
</div>
<div id="동시-실행-작업-수-제어하기" class="section level3" number="8.3.3">
<h3 number="8.3.3"><span class="header-section-number">8.3.3</span> 동시 실행 작업 수 제어하기</h3>
<p>기본적으로 <code>parallel</code>은 CPU 코어당 하나의 작업을 실행합니다.
동시에 실행되는 작업 수는 <code>--jobs</code> 또는 <code>-j</code> 옵션으로 제어할 수 있습니다.
숫자를 지정하면 해당 숫자만큼의 작업이 동시에 실행됩니다.
숫자 앞에 플러스 기호(<code>+</code>)를 붙이면 CPU 코어 수에 해당 숫자를 더한 만큼의 작업을 실행합니다. 마이너스 기호(<code>-</code>)를 붙이면 CPU 코어 수에서 해당 숫자를 뺀 만큼의 작업을 실행합니다.
여기서 CPU 코어 수는 <code>N</code>을 의미합니다.
퍼센트를 지정할 수도 있으며, 기본값은 CPU 코어 수의 100%입니다.
동시에 실행할 최적의 작업 수는 여러분이 실행하고 있는 실제 명령어에 따라 달라집니다.</p>
<pre>seq 5 | parallel -j0 "echo Hi {}"</pre>
<pre>seq 5 | parallel -j200% "echo Hi {}"</pre>
<p><code>-j1</code>을 지정하면 명령어가 한 번에 하나씩 순차적으로 실행됩니다. 비록 도구 이름의 의미를 무색하게 만들긴 하지만, 여전히 유용할 때가 있습니다. 예를 들어, 한 번에 하나의 연결만 허용하는 API에 접근해야 할 때입니다. <code>-j0</code>을 지정하면 <code>parallel</code>은 가능한 한 많은 작업을 병렬로 실행합니다. 이는 루프 끝에 앰퍼샌드를 붙여서 실행하는 것과 비슷합니다. 이 방식은 권장되지 않습니다.</p>
</div>
<div id="로깅과-출력" class="section level3" number="8.3.4">
<h3 number="8.3.4"><span class="header-section-number">8.3.4</span> 로깅과 출력</h3>
<p>각 명령어의 출력을 저장하고 싶을 때, 아마 다음과 같은 방식을 생각할 수도 있습니다.</p>
<pre>seq 5 | parallel "echo \"Hi {}\" &gt; hi-{}.txt"</pre>
<p>이렇게 하면 출력이 각각의 개별 파일로 저장됩니다.
혹은 모든 내용을 하나의 큰 파일에 저장하고 싶다면 다음과 같이 할 수 있습니다.</p>
<pre>seq 5 | parallel "echo Hi {}" &gt;&gt; one-big-file.txt</pre>
<p>하지만 <code>parallel</code>은 출력을 개별 파일로 저장해 주는 <code>--results</code> 옵션을 제공합니다.
각 작업에 대해 <code>parallel</code>은 세 가지 파일을 생성합니다. 작업 번호를 담은 <em>seq</em>, 작업에 의해 생성된 표준 출력을 담은 <em>stdout</em>, 그리고 작업 중에 발생한 오류를 담은 <em>stderr</em>입니다.
이 세 파일은 입력 값에 기반한 하위 디렉터리에 배치됩니다.</p>
<p><code>parallel</code>은 여전히 모든 출력을 인쇄하는데, 이 경우에는 불필요합니다.
다음과 같이 표준 입력과 표준 출력 모두를 넘길 수 있습니다.</p>
<pre>seq 10 | parallel --results outdir "curl 'https://anapioficeandfire.com/api/characters/{}' | jq -r '.aliases[0]'" 2&gt;/dev/null 1&gt;&amp;2
tree outdir | trim</pre>
<p><code>--results</code> 옵션이 어떻게 작동하는지에 대한 그림은 Figure @ref(fig:diagram-parallel-results)를 참조하십시오.</p>
<p>여러 작업을 병렬로 실행할 때, 작업이 실행되는 순서는 입력 순서와 일치하지 않을 수 있습니다.
따라서 작업의 출력도 섞이게 됩니다.
순서를 동일하게 유지하려면 <code>--keep-order</code> 또는 <code>-k</code> 옵션을 지정하십시오.</p>
<p>가끔 어떤 입력이 어떤 출력을 생성했는지 기록하는 것이 유용할 때가 있습니다.
<code>parallel</code>은 <code>--tag</code> 옵션을 통해 출력에 ’태그’를 달 수 있게 해주는데, 이는 각 줄의 앞에 입력 항목을 붙여줍니다.</p>
<pre>seq 5 | parallel --tag "echo 'sqrt({})' | bc -l"
parallel --tag --keep-order "echo '{1}*{2}' | bc -l" ::: 3 4 ::: 5 6 7</pre>
</div>
<div id="병렬-도구-만들기" class="section level3" number="8.3.5">
<h3 number="8.3.5"><span class="header-section-number">8.3.5</span> 병렬 도구 만들기</h3>
<p>본 장의 서두에서 사용했던 <code>bc</code> 도구는 그 자체로는 병렬로 작동하지 않습니다.
하지만 <code>parallel</code>을 사용하여 병렬화할 수 있습니다.
Docker 이미지에는 <code>pbc</code><span class="citation"><a href="#fn101" class="footnote-ref" id="fnref101"><sup>101</sup></a></span>라는 도구가 포함되어 있습니다.
해당 코드는 다음과 같습니다.</p>
<pre>bat $(which pbc)</pre>
<p>이 도구를 사용하면 본 장 서두에서 사용한 코드를 단순화할 수 있습니다.
또한 쉼표로 구분된 값들을 동시에 처리할 수 있습니다.</p>
<pre>seq 100 | pbc '{1}^2' | trim
paste -d, &lt;(seq 4) &lt;(seq 4) &lt;(seq 4) | pbc 'sqrt({1}+{2})^{3}'</pre>
</div>
</div>
<div id="분산-처리distributed-processing" class="section level2" number="8.4">
<h2 number="8.4"><span class="header-section-number">8.4</span> 분산 처리(Distributed Processing)</h2>
<p>가끔은 모든 코어를 다 쓴다 하더라도 로컬 머신이 제공할 수 있는 것보다 더 많은 컴퓨팅 성능이 필요할 때가 있습니다.
다행히 <code>parallel</code>은 원격 머신의 성능도 활용할 수 있게 해주어, 파이프라인의 속도를 비약적으로 높여줍니다.</p>
<p>대단한 점은 원격 머신에 <code>parallel</code>이 반드시 설치되어 있을 필요가 없다는 것입니다.
원격 머신에 <em>보안 쉘(Secure Shell)</em> 프로토콜(즉, SSH)로 접속할 수만 있으면 됩니다. <code>parallel</code>은 이 SSH를 사용하여 파이프라인을 분산시킵니다.
(<code>parallel</code>이 원격 머신에 설치되어 있다면 각 원격 머신에서 몇 개의 코어를 고용할지 결정하는 데 도움이 되므로 설치되어 있는 것이 좋습니다. 이에 대해서는 나중에 더 자세히 다루겠습니다.)</p>
<p>먼저, 실행 중인 AWS EC2 인스턴스 목록을 가져오겠습니다.
원격 머신이 없더라도 걱정하지 마십시오. <code>parallel</code>에게 어떤 원격 머신을 사용할지 알려주는 <code>--slf hostnames</code> 옵션이 나올 때마다 이를 <code>--sshlogin :</code>으로 바꾸면 됩니다.
이렇게 하면 이 섹션의 예제들을 여전히 따라 할 수 있습니다.</p>
<p>사용할 원격 머신들을 파악했다면, 다음 세 가지 방식의 분산 처리를 고려해 볼 것입니다.</p>
<ul>
<li>원격 머신에서 일반 명령어 실행하기</li>
<li>로컬 데이터를 직접 원격 머신들로 분산하기</li>
<li>원격 머신으로 파일을 보내고, 처리한 뒤, 결과를 가져오기</li>
</ul>
<div id="실행-중인-aws-ec2-인스턴스-목록-가져오기" class="section level3" number="8.4.1">
<h3 number="8.4.1"><span class="header-section-number">8.4.1</span> 실행 중인 AWS EC2 인스턴스 목록 가져오기</h3>
<p>이 섹션에서는 원격 머신의 호스트네임을 한 줄에 하나씩 담고 있는 <em>hostnames</em>라는 파일을 만들 것입니다.
여기서는 아마존 웹 서비스(AWS)를 예로 들겠습니다.
여러분에게 AWS 계정이 있고 인스턴스를 시작하는 방법을 알고 있다고 가정합니다.
다른 클라우드 컴퓨팅 서비스(예: 구글 클라우드 플랫폼 또는 마이크로소프트 애저)를 사용 중이거나 독자적인 서버를 보유하고 있다면, 다음 섹션으로 넘어가기 전에 직접 <em>hostnames</em> 파일을 만드시기 바랍니다.</p>
<p>AWS API의 커맨드 라인 인터페이스인 <code>aws</code><span class="citation"><a href="#fn102" class="footnote-ref" id="fnref102"><sup>102</sup></a></span>를 사용하여 실행 중인 AWS EC2 인스턴스 목록을 가져올 수 있습니다.
<code>aws</code>를 사용하면 온라인 AWS 관리 콘솔에서 할 수 있는 거의 모든 일을 할 수 있습니다.</p>
<p><code>aws ec2 describe-instances</code> 명령어는 모든 EC2 인스턴스에 대한 방대한 정보를 JSON 형식으로 반환합니다 (자세한 내용은 <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ec2/describe-instances.html">온라인 문서</a>를 참조하십시오).
<code>jq</code>를 사용하여 관련 필드만 추출할 수 있습니다.</p>
<pre>aws ec2 describe-instances | jq '.Reservations[].Instances[] | {public_dns: .PublicDnsName, state: .State.Name}'#! enter=FALSE
C-C#!literal=FALSE
echo '{' &amp;&amp;
echo '  "state": "running",' &amp;&amp;
echo '  "public_dns": "ec2-54-88-122-140.compute-1.amazonaws.com"' &amp;&amp;
echo '}' &amp;&amp;
echo '{' &amp;&amp;
echo '  "state": "stopped",' &amp;&amp;
echo '  "public_dns": null' &amp;&amp;
echo '}' &amp;&amp;</pre>
<p>EC2 인스턴스의 가능한 상태는 <em><code>pending</code></em>, <em><code>running</code></em>, <em><code>shutting-down</code></em>, <em><code>terminated</code></em>, <em><code>stopping</code></em>, 그리고 <em><code>stopped</code></em>입니다.
실행 중인(running) 인스턴스에만 파이프라인을 분산할 수 있으므로, 다음과 같이 실행 중이 아닌 인스턴스들은 걸러냅니다.</p>
<pre>aws ec2 describe-instances | jq -r '.Reservations[].Instances[] | select(.State.Name=="running") | .PublicDnsName' | tee hostnames#! enter=FALSE
C-C#! literal=FALSE
echo 'ec2-54-88-122-140.compute-1.amazonaws.com' &amp;&amp;
echo 'ec2-54-88-89-208.compute-1.amazonaws.com'</pre>
<p>(<code>-r</code> 또는 <code>--raw-output</code> 옵션이 없으면 호스트네임 주위에 큰따옴표가 붙게 됩니다.)
출력은 <em>hostnames</em>에 저장하여 나중에 <code>parallel</code>에 전달할 수 있게 합니다.</p>
<p>언급했듯이 <code>parallel</code>은 원격 머신에 접속하기 위해 <code>ssh</code><span class="citation"><a href="#fn103" class="footnote-ref" id="fnref103"><sup>103</sup></a></span>를 고용합니다.
매번 자격 증명을 입력하지 않고 EC2 인스턴스에 접속하고 싶다면, <em>~/.ssh/config</em> 파일에 다음과 같은 내용을 추가할 수 있습니다.</p>
<pre>bat ~/.ssh/config</pre>
<p>여러분이 어떤 배포판을 실행 중이냐에 따라 사용자 이름은 <em><code>ubuntu</code></em>가 아닐 수 있습니다.</p>
</div>
<div id="원격-머신에서-명령어-실행하기" class="section level3" number="8.4.2">
<h3 number="8.4.2"><span class="header-section-number">8.4.2</span> 원격 머신에서 명령어 실행하기</h3>
<p>분산 처리의 첫 번째 방식은 원격 머신에서 일반 명령어를 실행하는 것입니다.
우선 각 EC2 인스턴스에서 <code>hostname</code><span class="citation"><a href="#fn104" class="footnote-ref" id="fnref104"><sup>104</sup></a></span> 도구를 실행하여 <code>parallel</code>이 제대로 작동하는지 확인해 봅시다.</p>
<pre>parallel --nonall --sshloginfile hostnames hostname#! enter=FALSE
C-C#! literal=FALSE
echo 'ip-172-31-23-204\nip-172-31-23-205'</pre>
<p>여기서 <code>--sshloginfile</code> 또는 <code>--slf</code> 옵션은 <em>hostnames</em> 파일을 참조하는 데 사용됩니다.
<code>--nonall</code> 옵션은 <code>parallel</code>에게 매개변수를 사용하지 않고 <em>hostnames</em> 파일에 있는 모든 원격 머신에서 동일한 명령어를 한 번씩 실행하라고 지시합니다.
기억하십시오. 활용할 원격 머신이 없다면 <code>--slf hostnames</code>를 <code>--sshlogin :</code>으로 바꾸어 명령어가 로컬 머신에서 실행되도록 할 수 있습니다.</p>
<pre>parallel --nonall --sshlogin : hostname#! enter=FALSE
C-C#! literal=FALSE
echo 'data-science-toolbox'</pre>
<p>모든 원격 머신에서 동일한 명령어를 한 번씩 실행하는 데는 머신당 하나의 코어만 있으면 됩니다. 만약 <code>parallel</code>에 전달된 인자 목록을 분산시키려 한다면 잠재적으로 하나 이상의 코어를 사용할 수 있습니다. 코어의 수가 명시적으로 지정되지 않았다면, <code>parallel</code>은 이를 스스로 파악하려고 시도할 것입니다.</p>
<pre>alias fake=echo
seq 2 | parallel --slf hostnames echo 2&gt;&amp;1#! enter=FALSE
C-C#! literal=FALSE
fake 'bash: parallel: command not found' &amp;&amp;
fake -n 'parallel: Warning: Could not figure out number of cpus on' &amp;&amp;
fake ' ec2-54-88-122-140.compute-1.amazonaws.com (). Using 1.' &amp;&amp;
fake '1' &amp;&amp;
fake '2'</pre>
<p>이 경우에는 두 대의 원격 머신 중 한 대에만 <code>parallel</code>이 설치되어 있습니다.
그중 하나에서 <code>parallel</code>을 찾을 수 없다는 경고 메시지가 뜹니다.
그 결과, <code>parallel</code>은 코어의 수를 파악할 수 없어 기본값으로 코어 하나만 사용하게 됩니다.
이런 경고 메시지를 받으면 다음 네 가지 중 하나를 할 수 있습니다.</p>
<ul>
<li>걱정하지 말고, 머신당 코어 하나만 쓰는 것에 만족하기</li>
<li><code>--jobs</code> 또는 <code>-j</code> 옵션을 통해 각 머신에 대한 작업 수 지정하기</li>
<li><em>hostnames</em> 파일에서 각 호스트네임 앞에 예를 들어 <em>2/</em> 라고 적어 머신당 사용할 코어 수 지정하기 (이 경우 2개의 코어)</li>
<li>패키지 관리자를 사용하여 <code>parallel</code> 설치하기. 예를 들어 원격 머신들이 모두 우분투(Ubuntu)를 실행 중이라면 다음과 같습니다.</li>
</ul>
<pre>parallel --nonall --slf hostnames "sudo apt-get install -y parallel"#! enter=FALSE
C-C#! literal=FALSE</pre>
</div>
<div id="로컬-데이터를-원격-머신들로-분산하기" class="section level3" number="8.4.3">
<h3 number="8.4.3"><span class="header-section-number">8.4.3</span> 로컬 데이터를 원격 머신들로 분산하기</h3>
<p>분산 처리의 두 번째 방식은 로컬 데이터를 직접 원격 머신들로 분산하는 것입니다.
여러 대의 원격 머신을 사용하여 처리하고 싶은 아주 큰 데이터셋이 하나 있다고 상상해 봅시다.
간단하게 1부터 1000까지의 모든 정수를 더해 보겠습니다.
먼저, <code>hostname</code>과 <code>wc</code>를 사용하여 입력이 실제로 분산되고 있는지, 그리고 각 원격 머신이 받은 입력의 길이(줄 수)는 얼마인지 출력해 확인해 보겠습니다.</p>
<pre>seq 1000 | parallel -N100 --pipe --slf hostnames "(hostname; wc -l) | paste -sd:"#! enter=FALSE
C-C#! literal=FALSE
echo 'ip-172-31-23-204:100' &amp;&amp;
echo 'ip-172-31-23-205:100' &amp;&amp;
echo 'ip-172-31-23-205:100' &amp;&amp;
echo 'ip-172-31-23-204:100' &amp;&amp;
echo 'ip-172-31-23-205:100' &amp;&amp;
echo 'ip-172-31-23-204:100' &amp;&amp;
echo 'ip-172-31-23-205:100' &amp;&amp;
echo 'ip-172-31-23-204:100' &amp;&amp;
echo 'ip-172-31-23-205:100' &amp;&amp;
echo 'ip-172-31-23-204:100'</pre>
<p>훌륭합니다. 1000개의 숫자가 100개씩 묶여서 (<code>-N100</code>으로 지정) 골고루 분산되는 것을 볼 수 있습니다.
이제 이 모든 숫자들을 더할 준비가 되었습니다.</p>
<pre>seq 1000 | parallel -N100 --pipe --slf hostnames "paste -sd+ | bc" | paste -sd+ | bc#! enter=FALSE
C-C#! literal=FALSE
echo '500500'</pre>
<p>여기서는 원격 머신들로부터 돌려받은 10개의 합계를 즉시 다시 합산했습니다.
<code>parallel</code> 없이 계산했을 때와 결과가 같은지 확인해 봅시다.</p>
<pre>seq 1000 | paste -sd+ | bc</pre>
<p>네, 잘 작동합니다.
원격 머신에서 실행하고 싶은 더 큰 파이프라인이 있다면, 이를 별도의 스크립트에 담아 <code>parallel</code>을 통해 업로드할 수도 있습니다.
<code>add</code>라는 아주 간단한 커맨드 라인 도구를 만들어 이를 시연해 보겠습니다.</p>
<pre>echo '#!/usr/bin/env bash' &gt; add
echo 'paste -sd+ | bc' &gt;&gt; add
bat add
chmod u+x add
seq 1000 | ./add</pre>
<p><code>--basefile</code> 옵션을 사용하면 <code>parallel</code>은 작업을 실행하기 전에 <em>add</em> 파일을 모든 원격 머신에 먼저 업로드합니다.</p>
<pre>seq 1000 |
parallel -N100 --basefile add --pipe --slf hostnames './add' |
./add #! enter=FALSE
C-C#! literal=FALSE
echo '500500'</pre>
<p>1000개의 숫자를 합산하는 것은 물룬 장난감 수준의 예제일 뿐입니다.
게다가 이를 로컬에서 수행하는 것이 훨씬 더 빨랐을 것입니다.
그래도 <code>parallel</code>이 얼마나 믿기 힘들 정도로 강력할 수 있는지 이 예제를 통해 명확해졌기를 바랍니다.</p>
</div>
<div id="원격-머신에서-파일-처리하기" class="section level3" number="8.4.4">
<h3 number="8.4.4"><span class="header-section-number">8.4.4</span> 원격 머신에서 파일 처리하기</h3>
<p>분산 처리의 세 번째 방식은 원격 머신으로 파일을 보내고, 처리한 뒤, 결과를 가져오는 것입니다.
뉴욕시의 각 구(borough)별로 311 서비스 호출이 얼마나 자주 발생하는지 집계하고 싶다고 가정해 봅시다.
아직 로컬 머신에 해당 데이터가 없으므로, 먼저 무료 <a href="https://data.cityofnewyork.us/">NYC Open Data API</a>에서 데이터를 가져오겠습니다.</p>
<pre>seq 0 100 900 | parallel  "curl -sL 'http://data.cityofnewyork.us/resource/erm2-nwe9.json?\$limit=100&amp;\$offset={}' | jq -c '.[]' | gzip &gt; nyc-{#}.json.gz"</pre>
<p>이제 압축된 JSON 데이터를 포함하는 10개의 파일이 생겼습니다.</p>
<pre>l nyc*json.gz</pre>
<p><code>jq -c '.[]'</code>가 JSON 객체 배열을 평탄화(flatten)하여 한 줄에 하나의 객체가 오도록 하며, 파일당 총 100줄이 되도록 한다는 점에 유의하십시오.
<code>zcat</code><span class="citation"><a href="#fn105" class="footnote-ref" id="fnref105"><sup>105</sup></a></span>을 사용하면 압축된 파일의 내용을 직접 출력할 수 있습니다.</p>
<pre>zcat nyc-1.json.gz | trim</pre>
<p>JSON의 한 줄이 어떻게 생겼는지 확인해 봅시다.</p>
<pre>zcat nyc-1.json.gz | head -n 1</pre>
<p>로컬 머신에서 각 구별 서비스 호출 총 횟수를 구하려면 다음과 같은 명령어를 실행할 것입니다.</p>
<pre>zcat nyc*json.gz |
jq -r '.borough' |
tr '[A-Z] ' '[a-z]_' |
sort | uniq -c | sort -nr |
awk '{print $2","$1}' |
header -a borough,count |
csvlook</pre>
<p><span class="callout">&#10122;</span> <code>zcat</code>을 사용하여 모든 압축 파일을 확장합니다.
<br><span class="callout">&#10123;</span> 각 호출에 대해 <code>jq</code>를 사용하여 구의 이름을 추출합니다.
<br><span class="callout">&#10124;</span> 구 이름을 소문자로 변환하고 공백을 언더스코어(<code>_</code>)로 바꿉니다 (<code>awk</code>가 기본적으로 공백을 기준으로 분리하기 때문입니다).
<br><span class="callout">&#10125;</span> <code>sort</code>와 <code>uniq</code>를 사용하여 각 구의 발생 횟수를 집계합니다.
<br><span class="callout">&#10126;</span> 두 열의 순서를 바꾸고 <code>awk</code>를 사용하여 쉼표로 구분합니다.
<br><span class="callout">&#10127;</span> <code>header</code>를 사용하여 헤더를 추가합니다.</p>
<p>잠시, 여러분의 머신이 너무 느려서 이 파이프라인을 로컬에서 도저히 수행할 수 없다고 상상해 봅시다.
<code>parallel</code>을 사용하여 로컬 파일을 원격 머신들로 분산하고, 원격 머신에서 처리를 수행한 뒤 그 결과를 가져올 수 있습니다.</p>
<pre>ls *.json.gz |
parallel -v --basefile jq \
--trc {.}.csv \
--slf hostnames \
"zcat {} | ./jq -r '.borough' | tr '[A-Z] ' '[a-z]_' | sort | uniq -c | awk '{print \$2\",\"\$1}' &gt; {.}.csv"#! enter=FALSE
C-C#! literal=FALSE</pre>
<p><span class="callout">&#10122;</span> 파일 목록을 출력하고 이를 <code>parallel</code>로 파이프합니다.
<br><span class="callout">&#10123;</span> <code>jq</code> 바이너리를 각 원격 머신으로 전송합니다. 다행히 <code>jq</code>는 의존성이 없습니다. 이 파일은 <code>--trc</code> 옵션(이는 <code>--cleanup</code> 옵션을 포함합니다)을 지정했으므로 나중에 원격 머신에서 제거됩니다. 파이프라인에서 <code>jq</code> 대신 <code>./jq</code>를 사용하는 점에 유의하십시오. 파이프라인이 검색 경로(search path)에 있을지도 모르는 버전이 아니라 업로드된 버전을 사용해야 하기 때문입니다.
<br><span class="callout">&#10124;</span> 커맨드 라인 인자 <code>--trc {.}.csv</code>는 <code>--transfer --return {.}.csv --cleanup</code>의 약어입니다. (치환 문자열 <em><code>{.}</code></em>은 입력 파일명에서 마지막 확장자를 제외한 것으로 치환됩니다.) 여기서 이 옵션은 JSON 파일이 원격 머신으로 전송되고, CSV 파일이 로컬 머신으로 반환되며, 각 작업이 끝난 후 원격 머신에서 두 파일이 모두 삭제됨을 의미합니다.
<br><span class="callout">&#10125;</span> 호스트네임 목록을 지정합니다. 로컬에서 직접 시도해보고 싶다면 <code>--slf hostnames</code> 대신 <code>--sshlogin :</code>을 지정할 수도 있습니다.
<br><span class="callout">&#10126;</span> <code>awk</code> 표현식의 이스케이프 처리에 유의하십시오. 따옴표 처리는 가끔 까다로울 수 있습니다. 여기서는 달러 기호와 큰따옴표가 이스케이프되었습니다. 따옴표 처리가 너무 혼란스러워진다면, <code>add</code> 도구에서 했던 것처럼 파이프라인을 별도의 커맨드 라인 도구로 만드는 것을 기억하십시오.</p>
<p>이 과정 중에 원격 머신 중 하나에서 <code>ls</code>를 실행해 본다면, <code>parallel</code>이 실제로 바이너리 <code>jq</code>, JSON 파일, 그리고 CSV 파일을 전송(하고 정리)하는 것을 볼 수 있을 것입니다.</p>
<pre>ssh $(head -n 1 hostnames) ls#! enter=FALSE
C-C#! literal=FALSE
echo 'nyc-1.json.csv' &amp;&amp;
echo 'nyc-1.json.gz' &amp;&amp;
echo 'jq' &amp;&amp;</pre>
<p>각 CSV 파일은 다음과 같이 생겼습니다.</p>
<pre>cat nyc-1.json.csv #! enter=FALSE
C-C#! literal=FALSE
echo 'bronx,3' &amp;&amp;
echo 'brooklyn,5' &amp;&amp;
echo 'manhattan,24' &amp;&amp;
echo 'queens,3' &amp;&amp;
echo 'staten_island,2'</pre>
<p><code>rush</code><span class="citation"><a href="#fn106" class="footnote-ref" id="fnref106"><sup>106</sup></a></span>와 tidyverse를 사용하여 각 CSV 파일의 합계를 집계할 수 있습니다.</p>
<pre>cat nyc*csv | header -a borough,count |
rush run -t 'group_by(df, borough) %&gt;% summarize(count = sum(count))' - |
csvsort -rc count | csvlook</pre>
<p>또는 결과 집계에 SQL을 사용하고 싶다면, <a href="#chapter-5-scrubbing-data">5장</a>에서 다룬 <code>csvsql</code>을 사용할 수 있습니다.</p>
<pre>cat nyc*csv | header -a borough,count |
csvsql --query 'SELECT borough, SUM(count) AS count FROM stdin GROUP BY borough ORDER BY count DESC' |
csvlook</pre>
</div>
</div>
<div id="요약-7" class="section level2" number="8.5">
<h2 number="8.5"><span class="header-section-number">8.5</span> 요약</h2>
<p>데이터 과학자로서 여러분은 데이터, 때로는 아주 많은 양의 데이터를 다룹니다.
이는 가끔 명령어를 여러 번 실행하거나 데이터 집약적인 명령어를 여러 코어에 분산해야 함을 의미합니다.
이번 장에서 저는 명령어를 병렬화하는 것이 얼마나 쉬운지 보여드렸습니다.
<code>parallel</code>은 일반적인 커맨드 라인 도구의 속도를 높이고 이를 분산하는 매우 강력하고 유연한 도구입니다.
<code>parallel</code>은 아주 많은 기능을 제공하며 이번 장에서 저는 그 겉핥기 정도만 할 수 있었습니다.
다음 장에서는 OSEMN 모델의 네 번째 단계인 데이터 모델링을 다루겠습니다.</p>
</div>
<div id="더-읽어보기-3" class="section level2" number="8.6">
<h2 number="8.6"><span class="header-section-number">8.6</span> 더 읽어보기</h2>
<ul>
<li><code>parallel</code>과 그 주요 옵션들에 대해 기본적인 이해를 마쳤다면, <a href="https://www.gnu.org/software/parallel/parallel_tutorial.html">온라인 튜토리얼</a>을 살펴보실 것을 권장합니다. 입력을 지정하는 다양한 방법, 모든 작업의 로그 유지, 타임아웃, 재개(resume), 그리고 작업 재시도(retry) 방법 등을 배울 수 있습니다. <code>parallel</code>의 제작자인 Ole Tange는 이 튜토리얼에서 이렇게 말합니다. “여러분의 커맨드 라인이 당신을 아주 좋아하게 될 것입니다(Your command line will love you for it).”</li>
</ul>
<!--chapter:end:08.Rmd-->
</div>
</div>
<div id="chapter-9-modeling-data" class="section level1" number="9">
<h1 number="9"><span class="header-section-number">9</span> 데이터 모델링</h1>
<p>이 장에서는 OSEMN 모델의 네 번째 단계인 데이터 모델링을 수행할 것입니다.
일반적으로 모델은 여러분이 가진 데이터에 대한 추상적이거나 상위 수준의 설명(description)입니다.
모델링은 개별 데이터 포인트에서 한 걸음 물러나 큰 그림을 본다는 점에서 시각화를 만드는 것과 약간 비슷합니다.</p>
<p>시각화는 모양, 위치, 색상으로 특징지어집니다. 우리는 그것들을 직접 눈으로 보고 해석할 수 있습니다.
반면 모델은 내부적으로 숫자로 특징지어지며, 이는 컴퓨터가 새로운 데이터 포인트에 대한 예측을 수행하는 등의 작업에 모델을 사용할 수 있음을 의미합니다.
(모델이 어떻게 작동하고 성능이 어떠한지 이해하기 위해 여전히 모델을 시각화할 수 있습니다.)</p>
<p>이 장에서 저는 데이터를 모델링하는 데 흔히 사용되는 세 가지 유형의 알고리즘을 살펴볼 것입니다.</p>
<ul>
<li>차원 축소(Dimensionality reduction)</li>
<li>회귀(Regression)</li>
<li>분류(Classification)</li>
</ul>
<p>이 알고리즘들은 통계학과 머신러닝 분야에서 온 것이므로, 용어를 조금 바꾸어 사용하겠습니다.
우리가 <em>데이터셋</em>이라고도 불리는 CSV 파일을 가지고 있다고 가정해 봅시다.
헤더를 제외한 각 행은 하나의 <em>데이터 포인트</em>로 간주됩니다.
각 데이터 포인트는 하나 이상의 <em>특성(features)</em> 또는 측정된 속성들을 가집니다.
때로는 데이터 포인트가 <em>레이블(label)</em>을 가지기도 하는데, 이는 일반적으로 판단 결과나 성과를 의미합니다.
아래에서 와인 데이터셋을 소개할 때 이 개념이 더 구체화될 것입니다.</p>
<p>첫 번째 유형의 알고리즘(차원 축소)은 대부분 비지도 학습(unsupervised)입니다. 즉, 데이터셋의 특성만을 기반으로 모델을 생성합니다.
마지막 두 유형의 알고리즘(회귀 및 분류)은 정의상 지도 학습(supervised) 알고리즘이며, 이는 모델에 레이블 정보도 포함시킨다는 의미입니다.</p>

<div class="rmdcaution">
이 장은 결코 머신러닝 입문서가 아닙니다.
따라서 많은 세부 사항을 생략하고 넘어갈 수밖에 없습니다.
일반적인 권고 사항은, 여러분의 데이터에 알고리즘을 적용하기 전에 해당 알고리즘에 익숙해지는 시간을 갖는 것입니다.
이 장의 끝에서 머신러닝에 관한 몇 권의 책을 추천해 드립니다.
</div>
<div id="개요-6" class="section level2" number="9.1">
<h2 number="9.1"><span class="header-section-number">9.1</span> 개요</h2>
<p>이 장에서 여러분은 다음 방법을 배우게 됩니다.</p>
<ul>
<li><code>tapkee</code><span class="citation"><a href="#fn107" class="footnote-ref" id="fnref107"><sup>107</sup></a></span>를 사용하여 데이터셋의 차원 축소하기</li>
<li><code>vw</code><span class="citation"><a href="#fn108" class="footnote-ref" id="fnref108"><sup>108</sup></a></span>를 사용하여 화이트 와인의 품질 예측하기</li>
<li><code>skll</code><span class="citation"><a href="#fn109" class="footnote-ref" id="fnref109"><sup>109</sup></a></span>을 사용하여 와인을 레드 또는 화이트로 분류하기</li>
</ul>
<p>이 장은 다음 파일로 시작합니다.</p>
<pre>cd /data/ch09
l</pre>
<p>이 파일들을 가져오는 방법은 <a href="#chapter-2-getting-started">2장</a>에 설명되어 있습니다.
그 외의 파일들은 커맨드 라인 도구를 사용하여 다운로드하거나 생성한 것들입니다.</p>
</div>
<div id="와인-좀-더-주세요" class="section level2" number="9.2">
<h2 number="9.2"><span class="header-section-number">9.2</span> 와인 좀 더 주세요!</h2>
<p>이 장 전반에 걸쳐 ’비뉴 베르드(vinho verde)’라고 불리는 포르투갈 와인의 레드 및 화이트 품종에 대한 와인 감별사들의 기록 데이터셋을 사용할 것입니다.
각 데이터 포인트는 하나의 와인을 나타냅니다. 각 와인은 11가지 물리화학적 특성에 대해 등급이 매겨져 있습니다: (1) 고정 산도(fixed acidity), (2) 휘발성 산도(volatile acidity), (3) 구연산(citric acid), (4) 잔류 당분(residual sugar), (5) 염화물(chlorides), (6) 유리 이산화황(free sulfur dioxide), (7) 총 이산화황(total sulfur dioxide), (8) 밀도(density), (9) pH, (10) 황산염(sulphates), (11) 알코올(alcohol).
또한 0(매우 나쁨)에서 10(매우 우수) 사이의 종합 품질 점수가 있는데, 이는 와인 전문가들에 의한 최소 세 번의 평가 결과에 대한 중앙값입니다. 이 데이터셋에 대한 더 자세한 정보는 <a href="http://archive.ics.uci.edu/ml/datasets/Wine+Quality">UCI 머신러닝 저장소</a>에서 확인할 수 있습니다.</p>
<p>데이터셋은 화이트 와인용과 레드 와인용 두 개의 파일로 나뉘어 있습니다.
가장 먼저 할 일은 <code>curl</code>을 사용하여 두 파일을 가져오는 것입니다 (물론 시간이 아까우니 <code>parallel</code>을 사용합니다).</p>
<pre>parallel "curl -sL http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-{}.csv &gt; wine-{}.csv" ::: red white#!enter=FALSE
C-C#!literal=FALSE</pre>
<p>세 개의 콜론(<code>:::</code>)은 <code>parallel</code>에 데이터를 전달하는 또 다른 방법입니다.</p>
<pre>cp /data/.cache/wine-*.csv .</pre>
<p>두 파일을 검사하고 줄 수를 세어봅시다.</p>
<pre>&lt; wine-red.csv nl |
fold |
trim
&lt; wine-white.csv nl | fold | trim
wc -l wine-{red,white}.csv</pre>
<p><span class="callout">&#10122;</span> 명확성을 위해 <code>nl</code>을 사용하여 줄 번호를 추가했습니다.
<br><span class="callout">&#10123;</span> 헤더 전체를 보기 위해 <code>fold</code>를 사용했습니다.</p>
<p>언뜻 보기에 이 데이터는 꽤 깨끗해 보입니다.
그래도 대부분의 커맨드 라인 도구가 기대하는 형식에 더 잘 부합하도록 정제(scrub)해 보겠습니다.
구체적으로 다음 작업을 할 것입니다.</p>
<ul>
<li>헤더를 소문자로 변환합니다.</li>
<li>세미콜론(<code>;</code>)을 쉼표(<code>,</code>)로 바꿉니다.</li>
<li>공백을 언더스코어(<code>_</code>)로 바꿉니다.</li>
<li>불필요한 따옴표를 제거합니다.</li>
</ul>
<p><code>tr</code> 도구를 사용하면 이 모든 작업을 처리할 수 있습니다.
이번에는 옛 추억을 되살려 <code>for</code> 루프를 사용하여 두 파일을 처리해 보겠습니다.</p>
<pre>for COLOR in red white; do
&lt; wine-$COLOR.csv tr '[A-Z]; ' '[a-z],_' | tr -d \" &gt; wine-${COLOR}-clean.csv
done</pre>
<p>또한 두 파일을 결합하여 단일 데이터셋을 만들어 봅시다.
<code>csvstack</code><span class="citation"><a href="#fn110" class="footnote-ref" id="fnref110"><sup>110</sup></a></span>을 사용하여 <em>type</em>이라는 열을 추가할 것입니다. 이 열은 첫 번째 파일의 행에는 “red”, 두 번째 파일의 행에는 “white”라는 값을 갖게 됩니다.</p>
<pre>csvstack -g red,white -n type wine-{red,white}-clean.csv |
xsv select 2-,1 &gt; wine.csv</pre>
<p><span class="callout">&#10122;</span> 새 열 <em>type</em>은 <code>csvstack</code>에 의해 맨 앞에 배치됩니다.
<br><span class="callout">&#10123;</span> 일부 알고리즘은 레이블이 마지막 열에 있다고 가정하므로, <code>xsv</code>를 사용하여 <em>type</em> 열을 맨 뒤로 옮깁니다.</p>
<p>대부분의 머신러닝 알고리즘은 결측값(missing values)을 처리하지 못하므로, 이 데이터셋에 결측값이 있는지 확인하는 것이 좋습니다.</p>
<pre>csvstat wine.csv --nulls</pre>
<p>훌륭합니다!
만약 결측값이 있었다면 해당 특성의 평균값이나 가장 빈번한 값 등으로 채워 넣을 수 있었을 것입니다.
대안적으로, 결측값이 하나라도 있는 데이터 포인트를 아예 제거하는 덜 정교한 접근 방식도 있습니다.
그냥 호기심에, 레드 와인과 화이트 와인의 품질 분포가 어떻게 다른지 살펴봅시다.</p>
<pre>rush run -t 'ggplot(df, aes(x = quality, fill = type)) + geom_density(adjust = 3, alpha = 0.5)' wine.csv &gt; wine-quality.png
display wine-quality.png</pre>
<p>밀도 그래프를 통해 화이트 와인의 품질이 더 높은 값 쪽으로 분포되어 있음을 알 수 있습니다.
이것이 화이트 와인이 전반적으로 레드 와인보다 더 좋다는 뜻일까요, 아니면 화이트 와인 전문가들이 레드 와인 전문가들보다 더 쉽게 높은 점수를 준다는 뜻일까요?
그것은 데이터가 우리에게 말해주지 않는 부분입니다.
혹시 알코올 농도와 품질 사이에 관계가 있을까요?
<code>rush</code>를 사용하여 알아봅시다.</p>
<pre>rush plot --x alcohol --y quality --color type --geom smooth wine.csv &gt; wine-alcohol-vs-quality.png
display wine-alcohol-vs-quality.png</pre>
<p>유레카! 흠흠, 이제 모델링을 계속해 볼까요?</p>
</div>
<div id="tapkee를-사용한-차원-축소" class="section level2" number="9.3">
<h2 number="9.3"><span class="header-section-number">9.3</span> Tapkee를 사용한 차원 축소</h2>
<p>차원 축소의 목표는 고차원의 데이터 포인트를 저차원의 매핑으로 옮기는 것입니다.
핵심 과제는 유사한 데이터 포인트들이 저차원 매핑에서도 서로 가깝게 유지되도록 하는 것입니다.
이전 섹션에서 보았듯이, 우리의 와인 데이터셋은 13개의 특성을 포함하고 있습니다.
시각화하기에 가장 직관적인 두 개의 차원으로 축소를 진행해 보겠습니다.</p>
<p>차원 축소는 종종 탐색적 데이터 분석(EDA)의 일부로 간주됩니다.
플로팅하기에 특성이 너무 많을 때 유용합니다.
산점도 행렬(scatter-plot matrix)을 만들 수도 있지만, 이는 한 번에 두 개의 특성만 보여줄 수 있습니다.
또한 다른 머신러닝 알고리즘을 위한 전처리 단계로도 유용합니다.</p>
<p>대부분의 차원 축소 알고리즘은 비지도 학습입니다.
이는 데이터 포인트의 레이블을 사용하지 않고 저차원 매핑을 구축한다는 의미입니다.</p>
<p>이 섹션에서는 PCA(주성분 분석, Principal Components Analysis<span class="citation"><a href="#fn111" class="footnote-ref" id="fnref111"><sup>111</sup></a></span>)와 t-SNE(t-분포 확률적 임베딩, t-distributed Stochastic Neighbor Embedding<span class="citation"><a href="#fn112" class="footnote-ref" id="fnref112"><sup>112</sup></a></span>)라는 두 가지 기술을 살펴보겠습니다.</p>
<div id="tapkee-소개" class="section level3" number="9.3.1">
<h3 number="9.3.1"><span class="header-section-number">9.3.1</span> Tapkee 소개</h3>
<p>Tapkee는 차원 축소를 위한 C++ 템플릿 라이브러리입니다<span class="citation"><a href="#fn113" class="footnote-ref" id="fnref113"><sup>113</sup></a></span>.
이 라이브러리에는 다음을 포함한 많은 차원 축소 알고리즘이 구현되어 있습니다.</p>
<ul>
<li>국소 선형 임베딩(Locally Linear Embedding)</li>
<li>Isomap</li>
<li>다차원 척도법(Multidimensional Scaling)</li>
<li>PCA</li>
<li>t-SNE</li>
</ul>
<p>이 알고리즘들에 대한 자세한 정보는 <a href="http://tapkee.lisitsyn.me/">Tapkee 웹사이트</a>에서 찾을 수 있습니다.
Tapkee는 주로 다른 애플리케이션에 포함될 수 있는 라이브러리지만, <code>tapkee</code>라는 커맨드 라인 도구도 제공합니다.
이를 사용하여 와인 데이터셋의 차원 축소를 수행해 보겠습니다.</p>
</div>
<div id="선형-및-비선형-매핑" class="section level3" number="9.3.2">
<h3 number="9.3.2"><span class="header-section-number">9.3.2</span> 선형 및 비선형 매핑</h3>
<p>먼저, 각 특성이 동일하게 중요하게 취급되도록 표준화(standardization)를 사용하여 특성의 스케일을 조정하겠습니다.
일반적으로 머신러닝 알고리즘을 적용할 때 스케일 조정을 하면 더 나은 결과를 얻을 수 있습니다.</p>
<p>스케일 조정을 위해 <code>rush</code>와 <code>tidyverse</code> 패키지를 사용합니다.</p>
<pre>rush run --tidyverse --output wine-scaled.csv \
'select(df, -type) %&gt;%
scale() %&gt;%
as_tibble() %&gt;%
mutate(type = df$type)' wine.csv
csvlook wine-scaled.csv</pre>
<p><span class="callout">&#10122;</span> <code>scale()</code> 함수는 수치형 열에만 작동하므로 <em><code>type</code></em> 열을 임시로 제거해야 합니다.
<br><span class="callout">&#10123;</span> <code>scale()</code> 함수는 데이터 프레임을 받지만 행렬을 반환합니다.
<br><span class="callout">&#10124;</span> <code>as_tibble()</code> 함수는 행렬을 다시 데이터 프레임으로 변환합니다.
<br><span class="callout">&#10125;</span> 마지막으로 <em><code>type</code></em> 열을 다시 추가합니다.</p>
<p>이제 두 가지 차원 축소 기술을 적용하고 <code>Rio-scatter</code>를 사용하여 매핑을 시각화해 보겠습니다.</p>
<pre>xsv select '!type' wine-scaled.csv |
header -d |
tapkee --method pca |
tee wine-pca.txt | trim</pre>
<p><span class="callout">&#10122;</span> <em><code>type</code></em> 열을 제외합니다.
<br><span class="callout">&#10123;</span> 헤더를 제거합니다.
<br><span class="callout">&#10124;</span> PCA를 적용합니다.</p>
<pre>&lt; wine-pca.txt header -a pc1,pc2 |
paste -d, - &lt;(xsv select type wine-scaled.csv) |
tee wine-pca.csv | csvlook</pre>
<p><span class="callout">&#10122;</span> <em><code>pc1</code></em>과 <em><code>pc2</code></em> 열이 있는 헤더를 다시 추가합니다.
<br><span class="callout">&#10123;</span> <em><code>type</code></em> 열을 다시 추가합니다.</p>
<p>이제 산점도를 생성할 수 있습니다.</p>
<pre>rush plot --x pc1 --y pc2 --color type --shape type wine-pca.csv &gt; wine-pca.png
display wine-pca.png</pre>
<p>동일한 방식으로 t-SNE를 수행해 보겠습니다.</p>
<pre>xsv select '!type' wine-scaled.csv |
header -d |
tapkee --method t-sne |
header -a x,y |
paste -d, - &lt;(xsv select type wine-scaled.csv) |
rush plot --x x --y y --color type --shape type &gt; wine-tsne.png</pre>
<p><span class="callout">&#10122;</span> <em><code>type</code></em> 열을 제외합니다.
<br><span class="callout">&#10123;</span> 헤더를 제거합니다.
<br><span class="callout">&#10124;</span> t-SNE를 적용합니다.
<br><span class="callout">&#10125;</span> <em><code>x</code></em>와 <em><code>y</code></em> 열이 있는 헤더를 다시 추가합니다.
<br><span class="callout">&#10126;</span> <em><code>type</code></em> 열을 다시 추가합니다.
<br><span class="callout">&#10127;</span> 산점도를 생성합니다.</p>
<pre>display wine-tsne.png</pre>
<p>t-SNE가 PCA보다 물리화학적 특성을 기반으로 레드 와인과 화이트 와인을 더 잘 분리하는 것을 볼 수 있습니다.
이 산점도들은 데이터셋이 특정한 구조를 가지고 있음을 확인시켜 줍니다. 즉, 특성과 레이블 사이에 관계가 있습니다.
이를 확인했으니 이제 안심하고 지도 학습(supervised machine learning)을 적용해 보겠습니다.
먼저 회귀 작업을 시작하고 이어서 분류 작업을 진행하겠습니다.</p>
</div>
</div>
<div id="vowpal-wabbit을-사용한-회귀" class="section level2" number="9.4">
<h2 number="9.4"><span class="header-section-number">9.4</span> Vowpal Wabbit을 사용한 회귀</h2>
<p>이 섹션에서는 와인의 물리화학적 특성을 기반으로 화이트 와인의 품질을 예측하는 모델을 만들 것입니다.
품질은 0에서 10 사이의 숫자이므로, 이를 회귀(regression) 작업으로 간주할 수 있습니다.</p>
<p>이를 위해 Vowpal Wabbit, 줄여서 <code>vw</code>를 사용할 것입니다.</p>
<div id="데이터-준비하기" class="section level3" number="9.4.1">
<h3 number="9.4.1"><span class="header-section-number">9.4.1</span> 데이터 준비하기</h3>
<p>CSV 파일로 작업하는 대신, <code>vw</code>는 자체적인 데이터 형식을 사용합니다.
<code>csv2vw</code><span class="citation"><a href="#fn114" class="footnote-ref" id="fnref114"><sup>114</sup></a></span> 도구는 이름에서 알 수 있듯이 CSV를 이 형식으로 변환할 수 있습니다.
<code>--label</code> 옵션은 어떤 열이 레이블을 포함하고 있는지 지정하는 데 사용됩니다.
결과를 살펴봅시다.</p>
<pre>csv2vw wine-white-clean.csv --label quality | trim</pre>
<p>이 형식에서 각 줄은 하나의 데이터 포인트입니다.
줄은 레이블로 시작하고, 그 뒤에 파이프 기호(<code>|</code>)가 오며, 그 다음에는 공백으로 구분된 특성 이름/값 쌍들이 옵니다.
CSV 형식과 비교했을 때 이 형식이 지나치게 장황해 보일 수도 있지만, 가중치(weights), 태그(tags), 네임스페이스(namespaces), 그리고 희소 특성 표현(sparse feature representation)과 같은 더 많은 유연함을 제공합니다.
와인 데이터셋에서는 이러한 유연성이 필요하지 않지만, 더 복잡한 문제에 <code>vw</code>를 적용할 때는 유용할 수 있습니다.
이 <a href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Input-format">기사</a>에서 <code>vw</code> 형식에 대해 더 자세히 설명하고 있습니다.</p>
<p>회귀 모델을 만들거나 <em>훈련(train)</em>하고 나면, 이를 사용하여 아직 보지 못한 새로운 데이터 포인트에 대해 예측을 수행할 수 있습니다.
즉, 모델이 이전에 본 적 없는 와인을 제공하면 그 품질을 예측하거나 <em>테스트(test)</em>할 수 있습니다.
이러한 예측의 정확도를 적절하게 평가하려면, 훈련에 사용하지 않을 데이터를 일부 따로 떼어놓아야 합니다.
보통 전체 데이터셋의 80%를 훈련용으로 사용하고 나머지 20%를 테스트용으로 사용합니다.</p>
<p>먼저 <code>split</code><span class="citation"><a href="#fn115" class="footnote-ref" id="fnref115"><sup>115</sup></a></span>을 사용하여 전체 데이터셋을 동일한 다섯 부분으로 나누어 이 작업을 수행할 수 있습니다.
<code>wc</code>를 사용하여 각 부분의 데이터 포인트 수를 확인합니다.</p>
<pre>csv2vw wine-white-clean.csv --label quality |
shuf |
split -d -n r/5 - wine-part-
wc -l wine-part-*</pre>
<p><span class="callout">&#10122;</span> <code>shuf</code><span class="citation"><a href="#fn116" class="footnote-ref" id="fnref116"><sup>116</sup></a></span> 도구는 데이터셋을 무작위로 섞어서 훈련 세트와 테스트 세트가 유사한 품질 분포를 갖도록 보장합니다.</p>
<p>이제 첫 번째 부분(즉, 20%)을 테스트 세트인 <em>wine-test.vw</em>로 사용하고, 나머지 네 부분(즉, 80%)을 합쳐서 훈련 세트인 <em>wine-train.vw</em>를 만듭니다.</p>
<pre>mv wine-part-00 wine-test.vw
cat wine-part-* &gt; wine-train.vw
rm wine-part-*
wc -l wine-*.vw</pre>
<p>이제 <code>vw</code>를 사용하여 모델을 훈련할 준비가 되었습니다.</p>
</div>
<div id="모델-훈련하기" class="section level3" number="9.4.2">
<h3 number="9.4.2"><span class="header-section-number">9.4.2</span> 모델 훈련하기</h3>
<p><code>vw</code> 도구는 매우 많은(거의 400개에 달하는!) 옵션을 제공합니다.
다행히 효과적으로 사용하기 위해 그 모든 옵션이 필요한 것은 아닙니다.
여기서 사용하는 옵션들을 설명하기 위해 각 옵션을 별도의 줄에 적어보겠습니다.</p>
<pre>vw \
--data wine-train.vw \
--final_regressor wine.model \
--passes 10 \
--cache_file wine.cache \
--nn 3 \
--quadratic :: \
--l2 0.000005 \
--bit_precision 25</pre>
<p><span class="callout">&#10122;</span> <em>wine-train.vw</em> 파일이 모델 훈련에 사용됩니다.
<br><span class="callout">&#10123;</span> 모델 또는 <em>회귀분석기(regressor)</em>는 <em>wine.model</em> 파일에 저장됩니다.
<br><span class="callout">&#10124;</span> 훈련 패스(passes)의 횟수입니다.
<br><span class="callout">&#10125;</span> 여러 번의 패스를 수행할 때 캐싱이 필요합니다.
<br><span class="callout">&#10126;</span> 3개의 은닉 유닛(hidden units)을 가진 신경망을 사용합니다.
<br><span class="callout">&#10127;</span> 모든 입력 특성을 기반으로 이차(quadratic) 특성을 생성하여 사용합니다. 중복되는 특성은 <code>vw</code>에 의해 제거됩니다.
<br><span class="callout">&#10128;</span> L2 규제(regularization)를 사용합니다.
<br><span class="callout">&#10129;</span> 특성을 저장하는 데 25비트를 사용합니다.</p>
<p>이제 회귀 모델을 훈련시켰으니, 이를 사용하여 예측을 해보겠습니다.</p>
</div>
<div id="모델-테스트하기" class="section level3" number="9.4.3">
<h3 number="9.4.3"><span class="header-section-number">9.4.3</span> 모델 테스트하기</h3>
<p>모델은 <em>wine.model</em> 파일에 저장되어 있습니다.
이 모델을 사용하여 예측을 수행하기 위해, 이번에는 다른 옵션들을 사용하여 <code>vw</code>를 다시 실행합니다.</p>
<pre>vw \
--data wine-test.vw \
--initial_regressor wine.model \
--testonly \
--predictions predictions \
--quiet
bat predictions | trim</pre>
<p><span class="callout">&#10122;</span> <em>wine-test.vw</em> 파일이 모델 테스트에 사용됩니다.
<br><span class="callout">&#10123;</span> <em>wine.model</em> 파일에 저장된 모델을 사용합니다.
<br><span class="callout">&#10124;</span> 레이블 정보를 무시하고 테스트만 수행합니다.
<br><span class="callout">&#10125;</span> 예측 결과는 <em>predictions</em>라는 파일에 저장됩니다.
<br><span class="callout">&#10126;</span> 진단 메시지와 진행 상황 업데이트를 출력하지 않습니다.</p>
<p><code>paste</code>를 사용하여 <em>predictions</em> 파일에 담긴 예측값과 <em>wine-test.vw</em> 파일에 담긴 실제값(관측값, observed values)을 결합해 봅시다.
<code>awk</code>를 사용하여 예측값과 관측값을 비교하고 평균 절대 오차(MAE, Mean Absolute Error)를 계산할 수 있습니다.
MAE는 화이트 와인의 품질을 예측할 때 <code>vw</code>가 평균적으로 얼마나 차이가 나는지 알려줍니다.</p>
<pre>paste -d, predictions &lt;(cut -d '|' -f 1 wine-test.vw) |
tee results.csv |
awk -F, '{E+=sqrt(($1-$2)^2)} END {print "MAE: " E/NR}' |
cowsay</pre>
<p>예측값은 평균적으로 약 0.6점 정도 차이가 납니다.
<code>rush plot</code>을 사용하여 관측값과 예측값 사이의 관계를 시각화해 봅시다.</p>
<pre>&lt; results.csv header -a "predicted,observed" |
rush plot --x observed --y predicted --geom jitter &gt; wine-regression.png
display wine-regression.png</pre>
<p>모델 훈련에 사용된 옵션들이 조금 복잡해 보일 수 있습니다.
모든 기본값(default values)을 사용했을 때 <code>vw</code>의 성능이 어떠한지 확인해 봅시다.</p>
<pre>vw -d wine-train.vw -f wine2.model --quiet
vw -data wine-test.vw -i wine2.model -t -p predictions --quiet
paste -d, predictions &lt;(cut -d '|' -f 1 wine-test.vw) |
awk -F, '{E+=sqrt(($1-$2)^2)} END {print "MAE: " E/NR}'</pre>
<p><span class="callout">&#10122;</span> 회귀 모델 훈련
<br><span class="callout">&#10123;</span> 회귀 모델 테스트
<br><span class="callout">&#10124;</span> 평균 절대 오차(MAE) 계산</p>
<p>기본값을 사용했을 때 MAE가 0.04 더 높게 나타났습니다. 이는 예측 결과가 약간 더 나빠졌음을 의미합니다.</p>
<p>이 섹션에서는 <code>vw</code>가 할 수 있는 일의 극히 일부만을 다루었습니다.
이 도구에 그렇게 많은 옵션이 있는 데는 이유가 있습니다.
회귀 외에도 이진 분류(binary classification), 다중 클래스 분류(multi-class classification), 강화 학습(reinforcement learning), 그리고 잠재 디리클레 할당(Latent Dirichlet Allocation, LDA) 등을 지원합니다.
<a href="https://vowpalwabbit.org/">웹사이트</a>에서 더 많은 튜토리얼과 기사를 찾아볼 수 있습니다.</p>
</div>
</div>
<div id="scikit-learn-laboratory를-사용한-분류" class="section level2" number="9.5">
<h2 number="9.5"><span class="header-section-number">9.5</span> SciKit-Learn Laboratory를 사용한 분류</h2>
<!-- TODO: Explain SKLL better -->
<p>이 섹션에서는 와인이 레드인지 화이트인지를 예측하는 분류 모델(분류기, classifier)을 훈련시킬 것입니다.
이 작업에도 <code>vw</code>를 사용할 수 있지만, 다른 도구인 SciKit-Learn Laboratory(SKLL)를 소개해 드리고 싶습니다.
이름에서 알 수 있듯이, 이 도구는 파이썬에서 널리 쓰이는 머신러닝 패키지인 SciKit-Learn을 기반으로 구축되었습니다.
SKLL 자체도 파이썬 패키지이며, 커맨드 라인에서 SciKit-Learn을 사용할 수 있게 해주는 <code>run_experiment</code> 도구를 제공합니다.
저는 패키지 이름과 일치하여 기억하기 쉬운 <code>skll</code>이라는 별칭(alias)을 사용하여 <code>run_experiment</code>를 호출하겠습니다.</p>
<pre>alias skll=run_experiment
skll</pre>
<div id="데이터-준비하기-1" class="section level3" number="9.5.1">
<h3 number="9.5.1"><span class="header-section-number">9.5.1</span> 데이터 준비하기</h3>
<p><code>skll</code>은 훈련용 데이터셋과 테스트용 데이터셋이 서로 다른 디렉터리에 있되 같은 파일 이름을 가질 것을 기대합니다.
예측치(predictions)가 반드시 원래 데이터셋과 같은 순서로 나오지 않으므로, 예측치를 올바른 데이터 포인트와 일치시킬 수 있도록 고유 식별자를 포함하는 <em><code>id</code></em> 열을 추가하겠습니다.
균형 잡힌(balanced) 데이터셋을 만들어 봅시다.</p>
<pre>NUM_RED="$(&lt; wine-red-clean.csv wc -l)"
csvstack -n type -g red,white \
wine-red-clean.csv \
&lt;(&lt; wine-white-clean.csv body shuf | head -n $NUM_RED) |
body shuf |
nl -s, -w1 -v0 |
sed '1s/0,/id,/' |
tee wine-balanced.csv | csvlook</pre>
<p><span class="callout">&#10122;</span> 레드 와인의 수를 <em><code>NUM_RED</code></em> 변수에 저장합니다.
<br><span class="callout">&#10123;</span> 모든 레드 와인과 무작위로 샘플링된 동일한 수의 화이트 와인을 결합합니다.
<br><span class="callout">&#10124;</span> <code>nl</code>을 사용하여 각 줄 앞에 “줄 번호”를 추가합니다.
<br><span class="callout">&#10125;</span> 적절한 열 이름이 되도록 첫 번째 줄의 “0”을 “id”로 바꿉니다.</p>
<p>이제 이 균형 잡힌 데이터셋을 훈련 세트와 테스트 세트로 나눕니다.</p>
<pre>mkdir -p {train,test}
HEADER="$(&lt; wine-balanced.csv header)"
&lt; wine-balanced.csv header -d | shuf | split -d -n r/5 - wine-part-
wc -l wine-part-*
cat wine-part-00 | header -a $HEADER &gt; test/features.csv &amp;&amp; rm wine-part-00
cat wine-part-* | header -a $HEADER &gt; train/features.csv &amp;&amp; rm wine-part-*
wc -l t*/features.csv</pre>
<p>이제 균형 잡힌 훈련 세트와 테스트 세트가 준비되었으니, 분류기를 만드는 단계를 진행할 수 있습니다.</p>
</div>
<div id="실험-실행하기" class="section level3" number="9.5.2">
<h3 number="9.5.2"><span class="header-section-number">9.5.2</span> 실험 실행하기</h3>
<p><code>skll</code>에서 분류기를 훈련시키려면 설정 파일(configuration file)에 실험을 정의해야 합니다.
이 정의에는 데이터셋을 어디서 찾을지, 어떤 분류기를 사용할지 등을 명시하는 여러 섹션이 포함됩니다.
여기서 사용할 설정 파일 <em>classify.cfg</em>는 다음과 같습니다.</p>
<pre>bat classify.cfg</pre>
<p><code>skll</code>을 사용하여 실험을 실행합니다.</p>
<pre>skll -l classify.cfg 2&gt;/dev/null</pre>
<p><code>-l</code> 옵션은 로컬 모드에서 실행할 것을 지정합니다.
<code>skll</code>은 클러스터에서 실험을 실행하는 기능도 제공합니다.
실험이 완료되는 데 걸리는 시간은 선택한 알고리즘의 복잡도와 데이터의 크기에 따라 달라집니다.</p>
</div>
<div id="결과-분석하기" class="section level3" number="9.5.3">
<h3 number="9.5.3"><span class="header-section-number">9.5.3</span> 결과 분석하기</h3>
<p>모든 분류기의 훈련과 테스트가 완료되면, 결과는 <em>output</em> 디렉터리에서 확인할 수 있습니다.</p>
<pre>ls -1 output</pre>
<p><code>skll</code>은 각 분류기에 대해 네 개의 파일을 생성합니다: 로그 파일 한 개, 결과 파일 두 개, 그리고 예측값 파일 한 개입니다.
다음 SQL 쿼리를 사용하여 알고리즘 이름과 등급별 정확도를 추출해 보겠습니다.</p>
<pre>&lt; output/wine_summary.tsv csvsql --query "SELECT learner_name, accuracy FROM stdin ORDER BY accuracy DESC" | csvlook -I</pre>
<p>여기서 가장 중요한 열은 정확도를 나타내는 <em><code>accuracy</code></em>로, 이는 올바르게 분류된 데이터 포인트의 비율을 의미합니다.
이를 통해 실제로 모든 알고리즘이 매우 좋은 성능을 보이고 있음을 알 수 있습니다.
RandomForestClassifier가 가장 좋은 성능을 보였고, 그 뒤를 KNeighborsClassifier가 근소한 차이로 따르고 있습니다.</p>
<p>각 JSON 파일에는 혼동 행렬(confusion matrix)이 포함되어 있어 각 분류기의 성능에 대한 추가적인 통찰을 제공합니다.
혼동 행렬은 열이 실제 레이블(레드와 화이트)을 나타내고 행이 예측된 레이블을 나타내는 표입니다.
대각선 상의 숫자가 높을수록 정확한 예측이 많음을 의미합니다.
<code>jq</code>를 사용하여 각 분류기의 이름과 해당 혼동 행렬을 인쇄할 수 있습니다.</p>
<pre>jq -r '.[] | "\(.learner_name):\n\(.result_table)\n"' output/*.json</pre>
<p>혼동 행렬은 특히 분류해야 할 클래스가 세 개 이상일 때 어떤 종류의 오분류가 발생하는지 확인하거나, 각 클래스별로 오분류 비용이 다를 때 특히 도움이 됩니다.</p>
<p>사용 관점에서 볼 때, <code>vw</code>와 <code>skll</code>이 서로 다른 두 가지 접근 방식을 취한다는 점이 흥미롭습니다.
<code>vw</code>는 커맨드 라인 옵션을 사용하는 반면, <code>skll</code>은 별도의 설정 파일이 필요합니다.
두 방식 모두 장단점이 있습니다.
커맨드 라인 옵션은 더 즉흥적인 사용을 가능하게 하지만, 설정 파일은 아마도 재현(reproduce)하기가 더 쉽습니다.
또한 이미 보았듯이, 수많은 옵션과 함께 <code>vw</code>를 호출하는 방식은 스크립트나 <em>Makefile</em>에 쉽게 넣을 수 있습니다.
반대로, <code>skll</code>이 설정 파일 없이 옵션을 받도록 만드는 것은 비교적 덜 명확합니다.</p>
</div>
</div>
<div id="요약-8" class="section level2" number="9.6">
<h2 number="9.6"><span class="header-section-number">9.6</span> 요약</h2>
<p>이 장에서는 데이터 모델링에 대해 살펴보았습니다.
예제를 통해 비지도 학습인 차원 축소, 그리고 지도 학습인 회귀와 분류라는 세 가지 서로 다른 머신러닝 작업에 대해 깊이 파고들어 보았습니다.
아쉽게도 본격적인 머신러닝 튜토리얼은 이 책의 범위를 벗어납니다.
머신러닝에 대해 더 배우고 싶은 분들을 위해 다음 섹션에서 몇 권의 책을 추천해 드립니다.
이것으로 이 책에서 다루는 데이터 과학 OSEMN 모델의 네 번째이자 마지막 단계를 마쳤습니다.
다음 장은 마지막 중간 막(intermezzo) 장으로, 커맨드 라인을 다른 곳에서 활용하는 방법을 다룰 것입니다.</p>
</div>
<div id="더-읽어보기-4" class="section level2" number="9.7">
<h2 number="9.7"><span class="header-section-number">9.7</span> 더 읽어보기</h2>
<ul>
<li>Sebastian Raschka와 Vahid Mirjalili의 저서 <em>Python Machine Learning</em>은 머신러닝에 대한 포괄적인 개요와 파이썬을 사용한 적용 방법을 제공합니다.</li>
<li>Jared Lander의 <em>R for Everyone</em>의 후반부 장들에서 R을 사용하여 다양한 머신러닝 작업을 수행하는 방법을 설명합니다.</li>
<li>머신러닝에 대해 더 깊이 이해하고 싶다면, Christopher Bishop의 <em>Pattern Recognition and Machine Learning</em>과 David MacKay의 <em>Information Theory, Inference, and Learning Algorithms</em>를 강력히 추천합니다.</li>
<li>t-SNE 알고리즘에 대해 더 자세히 알고 싶다면, Laurens van der Maaten과 Geoffrey Hinton의 원저 논문인 <em>Visualizing Data Using T-SNE</em>를 추천합니다.</li>
</ul>
<!--chapter:end:09.Rmd-->
</div>
</div>
<div id="chapter-10-polyglot-data-science" class="section level1" number="10">
<h1 number="10"><span class="header-section-number">10</span> 다국어 데이터 과학</h1>
<p>다국어 사용자(polyglot)란 여러 언어를 말하는 사람을 뜻합니다.
제가 생각하는 다국어 데이터 과학자는 데이터를 수집, 정제, 탐색, 모델링하기 위해 여러 프로그래밍 언어, 도구 및 기술을 사용하는 사람입니다.</p>
<p>커맨드 라인은 이러한 다국어 접근 방식을 장려합니다.
커맨드 라인은 도구가 유닉스 철학을 따르기만 한다면 해당 도구가 어떤 프로그래밍 언어로 작성되었는지 상관하지 않습니다.
우리는 <a href="#chapter-4-creating-command-line-tools">4장</a>에서 Bash, Python, R로 커맨드 라인 도구를 만들며 이를 명확히 확인했습니다.
게다가 우리는 CSV 파일에서 직접 SQL 쿼리를 실행했고 커맨드 라인에서 R 표현식을 실행하기도 했습니다.
요약하자면, 우리는 이미 충분히 인식하지 못한 채로 다국어 데이터 과학을 수행해 온 것입니다!</p>
<p>이 장에서는 이를 뒤집어서 한 걸음 더 나아가 보겠습니다.
다양한 프로그래밍 언어와 환경에서 커맨드 라인을 활용하는 방법을 보여드리겠습니다.
솔직히 말해서, 우리는 데이터 과학 커리어 전체를 커맨드 라인에서만 보내지는 않을 것이기 때문입니다.
저의 경우, 데이터를 분석할 때는 종종 RStudio IDE를 사용하고 무언가를 구현할 때는 파이썬을 자주 사용합니다.
저는 작업을 완수하는 데 도움이 되는 것이라면 무엇이든 사용합니다.</p>
<p>다른 애플리케이션으로 전환하지 않고도 커맨드 라인을 항상 손이 닿는 곳에 둘 수 있다는 사실은 큰 위안이 됩니다.
별도의 애플리케이션으로 옮겨가서 워크플로우를 끊지 않고도 빠르게 명령어를 실행할 수 있게 해줍니다.
<code>curl</code>로 파일을 다운로드하거나, <code>head</code>로 데이터를 검사하거나, <code>git</code>으로 백업을 만들거나, <code>make</code>로 웹사이트를 컴파일하는 등의 작업을 예로 들 수 있습니다.
일반적으로 평소라면 많은 코드가 필요하거나 커맨드 라 없이는 아예 불가능한 작업들입니다.</p>
<div id="개요-7" class="section level2" number="10.1">
<h2 number="10.1"><span class="header-section-number">10.1</span> 개요</h2>
<p>이 장에서 여러분은 다음 방법을 배우게 됩니다.</p>
<ul>
<li>JupyterLab 및 RStudio IDE 내에서 터미널 실행하기</li>
<li>Python 및 R에서 임의의 커맨드 라인 도구와 상호작용하기</li>
<li>Apache Spark에서 쉘 명령어를 사용하여 데이터 변환하기</li>
</ul>
<p>이 장은 다음 파일들로 시작합니다.</p>
<pre>cd /data/ch10
l</pre>
<p>이 파일들을 가져오는 방법은 <a href="#chapter-2-getting-started">2장</a>에 설명되어 있습니다.
그 외의 파일들은 커맨드 라인 도구를 사용하여 다운로드하거나 생성한 것들입니다.</p>
</div>
<div id="jupyter" class="section level2" number="10.2">
<h2 number="10.2"><span class="header-section-number">10.2</span> Jupyter</h2>
<p>프로젝트 Jupyter는 2014년 IPython 프로젝트에서 탄생한 오픈소스 프로젝트로, 모든 프로그래밍 언어에 걸쳐 대화형 데이터 과학 및 과학적 컴퓨팅을 지원하도록 발전해 왔습니다.
Jupyter는 Python, R, Julia, Scala를 포함하여 40개 이상의 프로그래밍 언어를 지원합니다.
이 섹션에서는 파이썬에 집중하겠습니다.</p>
<p>이 프로젝트에는 JupyterLab, Jupyter Notebook, Jupyter Console이 포함됩니다.
파이썬을 대화형으로 다루는 가장 기본적인 방식인 Jupyter Console부터 시작하겠습니다.
다음은 커맨드 라인을 활용하는 몇 가지 방법을 보여주는 Jupyter Console 세션입니다.</p>
<pre>cat /data/.cache/jupyter-console#!expect_prompt=FALSE
C-C#!literal=FALSE</pre>
<p><span class="callout">&#10122;</span> <code>date</code>나 파이썬 패키지 설치를 위한 <code>pip</code>와 같은 임의의 쉘 명령어 및 파이프라인을 실행할 수 있습니다.
<br><span class="callout">&#10123;</span> <em>alice.txt</em>의 줄 수를 세기 위한 이 파이썬 코드 줄과 그 아래의 <code>wc</code> 호출을 비교해 보십시오.
<br><span class="callout">&#10124;</span> 표준 출력은 문자열 리스트로 반환되므로, <em>total_lines</em> 값을 사용하려면 첫 번째 항목을 가져와서 정수형으로 캐스팅해야 합니다.
<br><span class="callout">&#10125;</span> 파일을 다운로드하기 위한 이 셀과 다음 셀을 그 아래의 <code>curl</code> 호출과 비교해 보십시오.
<br><span class="callout">&#10126;</span> 중괄호를 사용하여 파이썬 변수를 쉘 명령어의 일부로 사용할 수 있습니다.
<br><span class="callout">&#10127;</span> 중괄호 문자를 그대로 사용하고 싶다면 두 번 입력하십시오.
<br><span class="callout">&#10128;</span> 파이썬 변수를 표준 입력으로 사용하는 것도 가능하지만, 보시다시피 상당히 까다롭습니다.</p>
<p>Jupyter Notebook은 본질적으로 Jupyter Console의 브라우저 기반 버전입니다.
느낌표(<code>!</code>)와 bash 매직(magic)을 포함하여 커맨드 라인을 활용하는 동일한 방식들을 지원합니다.
가장 큰 차이점은 노트북에 코드뿐만 아니라 마크업 텍스트, 수식, 데이터 시각화도 포함할 수 있다는 것입니다.
이러한 이유로 데이터 과학자들 사이에서 매우 인기가 있습니다.
Jupyter Notebook은 별도의 프로젝트이자 환경이지만, 저는 더 완벽한 IDE 기능을 제공하는 JupyterLab을 사용하여 노트북을 작업하는 것을 선호합니다.</p>
<p>그림 Figure @ref(fig:jupyterlab)은 JupyterLab의 스크린샷으로, 파일 탐색기(왼쪽), 코드 에디터(가운데), 노트북(오른쪽), 그리고 터미널(아래)을 보여줍니다. 뒤의 세 가지는 모두 커맨드 라인을 활용하는 방법을 보여줍니다.
코드는 다음 섹션에서 다시 다루겠습니다.
이 특정 노트북은 방금 논의한 콘솔 세션과 매우 유사합니다.
터미널은 여러분이 커맨드 라인 도구를 실행할 수 있는 완전한 쉘을 제공합니다.
이 터미널과 코드, 노트북 사이에는 상호작용이 불가능하다는 점에 유의하십시오.
따라서 이 터미널은 별도의 터미널 애플리케이션을 열어두는 것과 크게 다르지 않지만, Docker 컨테이너 내부나 원격 서버에서 작업할 때는 여전히 유용합니다.</p>

<div class="rmdcaution">
스크린샷의 이 노트북에는 이른바 <code>%%bash</code> 매직을 사용하는 셀도 포함되어 있는데, 이를 통해 여러 줄의 Bash 스크립트를 작성할 수 있습니다.
이 방식은 파이썬 변수를 사용하기가 훨씬 더 어렵기 때문에 권장하지 않습니다.
차라리 별도의 파일에 Bash 스크립트를 만들고 느낌표(<code>!</code>)를 사용하여 실행하는 것이 낫습니다.
</div>
</div>
<div id="python" class="section level2" number="10.3">
<h2 number="10.3"><span class="header-section-number">10.3</span> Python</h2>
<p><code>subprocess</code> 모듈을 사용하면 파이썬에서 커맨드 라인 도구를 실행하고 그들의 표준 입력 및 출력에 연결할 수 있습니다.
이 모듈은 오래된 <code>os.system()</code> 함수보다 권장되는 방식입니다.
기본적으로 쉘에서 실행되지는 않지만, <code>run()</code> 함수의 <code>shell</code> 인자를 통해 이를 변경할 수 있습니다.</p>
<pre>bat count.py</pre>
<p><span class="callout">&#10122;</span> 커맨드 라인을 활용하는 권장되는 방법은 <code>subprocess</code> 모듈의 <code>run()</code> 함수를 사용하는 것입니다.
<br><span class="callout">&#10123;</span> <em>filename</em> 파일을 엽니다.
<br><span class="callout">&#10124;</span> 전체 텍스트를 단어별로 나눕니다.
<br><span class="callout">&#10125;</span> <code>grep</code> 커맨드 라인 도구를 실행하며, 이때 <em>words</em>가 표준 입력으로 전달됩니다.
<br><span class="callout">&#10126;</span> 표준 출력은 하나의 긴 문자열로 제공됩니다. 여기서는 <em>pattern</em>의 발생 횟수를 세기 위해 각 줄바꿈 문자를 기준으로 문자열을 나눕니다.</p>
<p>이 커맨드 라인 도구는 다음과 같이 사용됩니다.</p>
<pre>./count.py alice.txt alice</pre>
<p>15행의 <code>run</code> 호출의 첫 번째 인자가 문자열 리스트라는 점에 주목하십시오. 첫 번째 항목은 커맨드 라인 도구의 이름이고, 나머지 항목들은 인자들입니다.
이는 단일 문자열을 전달하는 것과는 다릅니다.
또한 이는 리다이렉션이나 파이핑과 같은 기능을 가능하게 하는 다른 쉘 구문을 사용할 수 없음을 의미합니다.</p>
</div>
<div id="r" class="section level2" number="10.4">
<h2 number="10.4"><span class="header-section-number">10.4</span> R</h2>
<p>R에는 커맨드 라인을 활용하는 여러 가지 방법이 있습니다.</p>
<p>아래 예제에서는 R 세션을 시작하고 <code>system2()</code> 함수를 사용하여 <em>이상한 나라의 앨리스(Alice’s Adventures in Wonderland)</em>라는 책에서 <em>alice</em>라는 문자열이 몇 번 나타나는지 세어보겠습니다.</p>
<pre>R --quiet
lines &lt;- readLines("alice.txt")
head(lines)
words &lt;- unlist(strsplit(lines, " "))
head(words)
alice &lt;- system2("grep", c("-i", "alice"), input = words, stdout = TRUE)
head(alice)
length(alice)</pre>
<p><span class="callout">&#10122;</span> <em>alice.txt</em> 파일을 읽어옵니다.
<br><span class="callout">&#10123;</span> 텍스트를 단어별로 나눕니다.
<br><span class="callout">&#10124;</span> <code>grep</code> 커맨드 라인 도구를 호출하여 문자열 <em>alice</em>와 일치하는 줄만 남깁니다. 문자 벡터 <em>words</em>가 표준 입력으로 전달됩니다.
<br><span class="callout">&#10125;</span> 문자 벡터 <em>alice</em>의 요소 수를 셉니다.</p>
<p><code>system2()</code>의 단점은 문자 벡터를 커맨드 라인 도구의 표준 입력으로 전달하기 전에 먼저 파일에 기록한다는 점입니다.
이는 대량의 데이터와 잦은 호출을 처리할 때 문제가 될 수 있습니다.</p>
<p>데이터를 디스크에 쓰지 않고 직접 전달하는 명명된 파이프(named pipe)를 사용하는 것이 훨씬 더 효율적입니다.
이는 <code>pipe()</code>와 <code>fifo()</code> 함수를 통해 가능합니다.
이 방법을 제안해 준 Jim Hester에게 감사를 표합니다.
아래 코드는 이를 보여줍니다.</p>
<pre>out_con &lt;- fifo("out", "w+")
in_con &lt;- pipe("grep b &gt; out")
writeLines(c("foo", "bar"), in_con)
readLines(out_con)
close(out_con); close(in_con); unlink("out")</pre>
<p><span class="callout">&#10122;</span> <code>fifo()</code> 함수는 <em>out</em>이라는 특별한 선입선출(FIFO) 파일을 생성합니다. 이는 (stdin이나 stdout처럼) 파이프 연결에 대한 참조일 뿐이며, 실제로 디스크에 데이터가 기록되지는 않습니다.
<br><span class="callout">&#10123;</span> <code>grep</code> 도구는 <em>b</em>를 포함하는 줄만 남기고 이를 명명된 파이프 <em>out</em>에 씁니다.
<br><span class="callout">&#10124;</span> 두 개의 값을 쉘 명령어의 표준 입력으로 씁니다.
<br><span class="callout">&#10125;</span> <code>grep</code>에 의해 생성된 표준 출력을 문자 벡터로 읽어옵니다.
<br><span class="callout">&#10126;</span> 연결을 관리하고 특별 파일을 삭제합니다.</p>
<!-- check out the processx package https://processx.r-lib.org/. experimental at the time of writing. but seems very promising to working with connections in a more robust manner. -->
<!-- # all four options are executed in a shell.  -->
<!-- # no stdin and no stdout: system -->
<!-- # stdin but no stdout: writeLines(pipe) -->
<!-- # stdout but no stdin: readLines(pipe) -->
<!-- readLines(pipe("")) -->
<!-- # both stdin and stdout: fifo, readLines, writeLines -->
<!-- first-in first-out special file, named pipe -->
<!-- When processes are -->
<!-- exchanging data via the FIFO, the kernel passes all data -->
<!-- internally without writing it to the filesystem. -->
<!-- ## Leveraging the Command Line Elsewhere -->
<!-- ### Clipboard -->
<!-- yank -->
<!-- pbcopy pbpaste -->
<!-- when formatting emailadresses -->
<p>이 방식은 꽤 많은 상용구 코드(연결 생성, 쓰기, 읽기, 정리 등)를 필요로 하므로, 저는 이를 돕기 위한 함수 <code>sh()</code>를 작성했습니다.
<code>magrittr</code> 패키지의 파이프 연산자(<code>%&gt;%</code>)를 사용하여 여러 쉘 명령어를 사슬처럼 연결할 수 있습니다.</p>
<pre>library(magrittr)

sh &lt;- function(.data, command) {#! expect_prompt=FALSE
  temp_file &lt;- tempfile()#! expect_prompt=FALSE
  out_con &lt;- fifo(temp_file, "w+")#! expect_prompt=FALSE
  in_con &lt;- pipe(paste0(command, " &gt; ", temp_file))#! expect_prompt=FALSE
  writeLines(as.character(.data), in_con)#! expect_prompt=FALSE
  result &lt;- readLines(out_con)#! expect_prompt=FALSE
  close(out_con)#! expect_prompt=FALSE
  close(in_con)#! expect_prompt=FALSE
  unlink(temp_file)#! expect_prompt=FALSE
  result#! expect_prompt=FALSE
}

lines &lt;- readLines("alice.txt")
words &lt;- unlist(strsplit(lines, " "))

sh(words, "grep -i alice") %&gt;%#! expect_prompt=FALSE
  sh("wc -l") %&gt;%#! expect_prompt=FALSE
  sh("cowsay") %&gt;%#! expect_prompt=FALSE
  cli::cat_boxx()

q("no")#! expect_prompt=FALSE</pre>
</div>
<div id="rstudio" class="section level2" number="10.5">
<h2 number="10.5"><span class="header-section-number">10.5</span> RStudio</h2>
<p>RStudio IDE는 아마도 R을 사용하는 가장 인기 있는 환경일 것입니다.
RStudio를 열면 가장 먼저 콘솔 탭이 보입니다.</p>
<p>터미널 탭은 콘솔 탭 바로 옆에 있습니다.
터미널 탭은 완전한 쉘을 제공합니다.</p>
<p>JupyterLab과 마찬가지로, 이 터미널은 콘솔이나 R 스크립트와 직접 연결되어 있지 않다는 점에 유의하십시오.</p>
</div>
<div id="apache-spark" class="section level2" number="10.6">
<h2 number="10.6"><span class="header-section-number">10.6</span> Apache Spark</h2>
<p>Apache Spark는 클러스터 컴퓨팅 프레임워크입니다.
데이터를 메모리에 다 올리는 것이 불가능할 때 찾게 되는 강력한 도구입니다.
Spark 자체는 Scala로 작성되었지만, <a href="https://spark.apache.org/docs/latest/api/python/index.html">PySpark</a>를 사용하는 Python이나 <a href="https://spark.apache.org/docs/latest/sparkr.html">SparkR</a> 또는 <a href="https://spark.rstudio.com/">sparklyr</a>을 사용하는 R을 통해서도 상호작용할 수 있습니다.</p>
<p>데이터 처리 및 머신러닝 파이프라인은 일련의 변환(transformations)과 하나의 최종 작업(action)을 통해 정의됩니다.
이러한 변환 중 하나가 <code>pipe()</code> 변환으로, 이를 통해 전체 데이터셋을 Bash나 Perl 스크립트와 같은 쉘 명령어로 실행할 수 있습니다.
데이터셋의 항목들이 표준 입력으로 기록되고, 표준 출력은 문자열 RDD로 반환됩니다.</p>
<p>아래 세션에서 Spark 쉘을 시작하고 다시 한번 <em>이상한 나라의 앨리스</em>에서 <em>alice</em>의 발생 횟수를 세어보겠습니다.</p>
<pre>alias spark-shell=echo
spark-shell --master local[6]#!enter=FALSE
C-C#!literal=FALSE
cat /data/.cache/spark</pre>
<p><span class="callout">&#10122;</span> 각 줄이 하나의 요소가 되도록 <em>alice.txt</em>를 읽어옵니다.
<br><span class="callout">&#10123;</span> 각 요소를 공백을 기준으로 나눕니다. 즉, 각 줄이 단어들로 나누어집니다.
<br><span class="callout">&#10124;</span> 각 파티션을 <code>grep</code>으로 파이핑하여 문자열 <em>alice</em>와 일치하는 요소만 남깁니다.
<br><span class="callout">&#10125;</span> 각 파티션을 <code>wc</code>로 파이핑하여 요소의 수를 셉니다.
<br><span class="callout">&#10126;</span> 각 파티션에 대해 하나의 카운트 값이 생성됩니다.
<br><span class="callout">&#10127;</span> 모든 카운트를 합산하여 최종 카운트를 구합니다. 요소들을 문자열에서 정수형으로 먼저 변환해야 함에 유의하십시오.
<br><span class="callout">&#10128;</span> 위의 단계들을 하나의 명령어로 결합한 것입니다.</p>

<div class="rmdtip">
<code>pipe()</code> 변환은 PySpark, SparkR, sparklyr에서도 사용할 수 있습니다.
</div>
<!-- https://stackoverflow.com/questions/54239583/question-about-rdd-pipe-operator-on-apache-spark -->
<p>If you want to use a custom command-line tool in your pipeline, then you need to make sure that it’s present on all nodes in the cluster (known as the executors).
One way to do this is to specify the filename(s) with the <code>--files</code> option when you’re submitting Spark applications using <code>spark-submit</code>.</p>
<p>Matei Zaharia와 Bill Chambers(Apache Spark의 원저자)는 그들의 저서 <em>Spark: The Definitive Guide</em>에서 “<code>pipe</code> 메소드는 아마도 Spark의 가장 흥미로운 메소드 중 하나일 것”이라고 언급했습니다.
정말 대단한 찬사입니다!
Apache Spark의 개발자들이 50년 된 기술을 활용할 수 있는 기능을 추가했다는 것은 정말 멋진 일이라고 생각합니다.</p>
<!-- ### Notable mentions -->
<!-- - Julia: Blog post with an introduction: https://blog.leahhanson.us/post/julia/julia-commands.html -->
<!-- - Visual Studio Code https://code.visualstudio.com/docs/editor/integrated-terminal -->
<!-- - Emacs -->
<!-- - VIM (using ! command) -->
<!-- - OS: Guake, -->
<!-- - OS: iTerm2:    https://www.sharmaprakash.com.np/guake-like-dropdown-terminal-in-mac/ -->
<!-- https://github.com/shelljs/shelljs -->
<!-- https://amoffat.github.io/sh/ -->
<!-- https://plumbum.readthedocs.io/en/latest/ -->
<!-- <\!-- ## Other Combinations -\-> -->
<!-- - reticulate -->
<!-- - Rpy2 -->
<!-- - sparkr -->
<!-- - sparklyr -->
<!-- TODO: MUST: Write Summary or Conclusion -->
<!-- # Summary -->
<!-- TODO: MUST: Talk about other combinations between languages. This is already possible with this approah, but there are tighter integrations. -->
</div>
<div id="요약-9" class="section level2" number="10.7">
<h2 number="10.7"><span class="header-section-number">10.7</span> 요약</h2>
<p>이 장에서 여러분은 프로그래밍 언어와 다른 환경을 포함하여 다양한 상황에서 커맨드 라인을 활용하는 몇 가지 방법을 배웠습니다.
커맨드 라인이 진공 상태에서 존재하는 것이 아니라는 점을 깨닫는 것이 중요합니다.
가장 중요한 것은 작업을 안정적으로 완수할 수 있는 도구들을 사용하는 것이며, 때로는 이들을 조합해서 사용하는 것입니다.</p>
<p>이제 네 개의 OSEMN 장과 네 개의 중간 막(intermezzo) 장을 모두 마쳤으니, 이제 마지막 장에서 전체 내용을 마무리하고 결론을 맺을 시간입니다.</p>
</div>
<div id="더-읽어보기-5" class="section level2" number="10.8">
<h2 number="10.8"><span class="header-section-number">10.8</span> 더 읽어보기</h2>
<ul>
<li>커맨드 라인을 사용하지 않고 두 프로그래밍 언어를 직접 통합하는 방법도 있습니다. 예를 들어, R의 <a href="https://rstudio.github.io/reticulate/"><code>reticulate</code> 패키지</a>를 사용하면 파이썬과 직접 인터페이스할 수 있습니다.</li>
</ul>
<!--chapter:end:10.Rmd-->
</div>
</div>
<div id="chapter-11-conclusion" class="section level1" number="11">
<h1 number="11"><span class="header-section-number">11</span> 결론</h1>
<p>이 마지막 장으로 책을 마무리하겠습니다.
먼저 이전 10개 장에서 논의한 내용을 요약하고, 여러분께 세 가지 조언과 함께 우리가 다루었던 관련 주제들을 더 깊이 탐구할 수 있는 자료들을 제안해 드리겠습니다.
마지막으로 질문이나 의견이 있거나 공유하고 싶은 새로운 커맨드 라인 도구가 있는 경우에 대비하여 저와 연락할 수 있는 몇 가지 방법을 알려드립니다.</p>
<div id="요약해-봅시다" class="section level2" number="11.1">
<h2 number="11.1"><span class="header-section-number">11.1</span> 요약해 봅시다</h2>
<p>이 책은 데이터 과학을 수행하는 데 있어 커맨드 라인을 사용하는 힘을 탐구했습니다.
상대적으로 젊은 분야인 데이터 과학이 직면한 과제들을 이처럼 오랜 시간 검증된 기술로 해결할 수 있다는 것은 매우 흥미로운 발견이라고 생각합니다.
이제 여러분이 커맨드 라인으로 무엇을 할 수 있는지 이해하셨기를 바랍니다.
수많은 커맨드 라인 도구들은 데이터 과학을 구성하는 다양한 작업들에 적합한 온갖 가능성을 제공합니다.</p>
<p>데이터 과학에 대한 많은 정의가 존재합니다.
<a href="#chapter-1-introduction">1장</a>에서 저는 Mason과 Wiggins이 정의한 OSEMN 모델을 소개했습니다. 왜냐하면 매우 구체적인 작업들로 연결되는 아주 실용적인 모델이기 때문입니다.
OSEMN은 데이터 수집(obtaining), 정제(scrubbing), 탐색(exploring), 모델링(modeling), 해석(interpreting)의 약자입니다. 또한 <a href="#chapter-1-introduction">1장</a>에서는 왜 커맨드 라인이 이러한 데이터 과학 작업들에 매우 적합한지도 설명했습니다.</p>
<p><a href="#chapter-2-getting-started">2장</a>에서는 이 책에서 사용된 모든 도구를 얻는 방법을 설명했습니다. 또한 <a href="#chapter-2-getting-started">2장</a>에서는 커맨드 라인의 필수적인 도구와 개념들에 대한 소개도 제공했습니다.</p>
<p>네 개의 OSEMN 모델 장에서는 커맨드 라인을 사용하여 실용적인 작업들을 수행하는 데 집중했습니다.
다섯 번째 단계인 데이터 해석(interpreting data)에 대해서는 별도의 장을 할애하지 않았습니다. 솔직히 말해서 커맨드 라인은커녕 컴퓨터조차도 이 단계에서는 거의 도움이 되지 않기 때문입니다.
하지만 이 주제에 대해 더 읽어볼 만한 몇 가지 포인터를 제공했습니다.</p>
<p>네 개의 중간 막(intermezzo) 장에서는 커맨드 라인에서 데이터 과학을 수행하는 데 있어 어느 한 단계에만 국한되지 않는 더 넓은 주제들을 살펴보았습니다.
<a href="#chapter-4-creating-command-line-tools">4장</a>에서는 한 줄짜리 명령어(one-liners)와 기존 코드를 재사용 가능한 커맨드 라인 도구로 바꾸는 방법을 설명했습니다.
<a href="#chapter-6-project-management-with-make">6장</a>에서는 <code>make</code>라는 도구를 사용하여 데이터 워크플로우를 관리하는 방법을 설명했습니다.
<a href="#chapter-8-parallel-pipelines">8장</a>에서는 일반적인 커맨드 라인 도구와 파이프라인을 GNU Parallel을 사용하여 병렬로 실행하는 방법을 보여주었습니다.
<a href="#chapter-10-polyglot-data-science">10장</a>에서는 커맨드 라인이 진공 상태에서 존재하는 것이 아니라 다른 프로그래밍 언어나 환경에서도 활용될 수 있음을 보여주었습니다.
이 중간 막 장들에서 다룬 주제들은 여러분의 데이터 워크플로우 어느 지점에서도 적용될 수 있습니다.</p>
<p>데이터 과학을 수행하는 데 사용할 수 있고 관련이 있는 모든 커맨드 라인 도구를 보여주는 것은 불가능합니다.
새로운 도구들이 매일 만들어지고 있기 때문입니다.
이제 이해하셨겠지만, 이 책은 도구의 전수 조사를 제공하기보다는 커맨드 라인을 사용한다는 아이디어 자체에 더 중점을 두었습니다.</p>
</div>
<div id="세-가지-조언" class="section level2" number="11.2">
<h2 number="11.2"><span class="header-section-number">11.2</span> 세 가지 조언</h2>
<p>여러분은 아마도 이 장들을 읽고 코드 예제들을 따라 하는 데 꽤 많은 시간을 보냈을 것입니다.
이러한 투자의 효과를 극대화하고 여러분이 데이터 과학 워크플로우에 커맨드 라인을 계속해서 통합할 가능성을 높이기 위해, 저는 여러분께 세 가지 조언을 드리고 싶습니다: (1) 인내심을 갖고(be patient), (2) 창의적이며(be creative), (3) 실용적이 되십시오(be practical). 다음 세 개의 하위 섹션에서 각 조언에 대해 자세히 설명하겠습니다.</p>
<div id="인내심을-가지십시오" class="section level3" number="11.2.1">
<h3 number="11.2.1"><span class="header-section-number">11.2.1</span> 인내심을 가지십시오</h3>
<p>제가 드릴 수 있는 첫 번째 조언은 인내심을 가지라는 것입니다.
커맨드 라인에서 데이터를 다루는 것은 프로그래밍 언어를 사용하는 것과 다르며, 따라서 다른 사고방식이 필요합니다.</p>
<p>또한, 커맨드 라인 도구들 자체에도 독특한 특징이나 불일치하는 부분이 있습니다.
이는 부분적으로 이 도구들이 수십 년에 걸쳐 수많은 사람에 의해 개발되었기 때문입니다.
혹시라도 그 수많은 옵션에 대해 당황하게 된다면, 잊지 말고 <code>--help</code>, <code>man</code>, <code>tldr</code> 또는 자주 사용하는 검색 엔진을 활용해 보세요.</p>
<p>여전히, 특히 처음에는 좌절감을 느낄 수 있습니다.
저를 믿으세요, 커맨드 라인과 그 도구들을 사용하는 연습을 하다 보면 점점 더 능숙해질 것입니다.
커맨드 라인은 수십 년 동안 존재해 왔으며, 앞으로도 수십 년 동안 계속 존재할 것입니다.
그것은 투자할 가치가 충분합니다.</p>
</div>
<div id="창의적이-되십시오" class="section level3" number="11.2.2">
<h3 number="11.2.2"><span class="header-section-number">11.2.2</span> 창의적이 되십시오</h3>
<p>그와 관련된 두 번째 조언은 창의적이 되라는 것입니다.
커맨드 라인은 매우 유연합니다.
커맨드 라인 도구들을 결합함으로써, 여러분이 생각하는 것보다 더 많은 일을 해낼 수 있습니다.</p>
<p>저는 여러분이 즉시 프로그래밍 언어로 되돌아가지 않기를 권장합니다.
그리고 프로그래밍 언어를 사용해야 할 때는, 그 코드가 어떤 방식으로든 일반화되거나 재사용될 수 있을지 생각해 보세요.
만약 그렇다면 <a href="#chapter-4-creating-command-line-tools">4장</a>에서 논의한 단계들을 따라 그 코드로 여러분만의 커맨드 라인 도구를 만드는 것을 고려해 보세요.
여러분의 도구가 다른 사람들에게도 유익할 것이라고 믿는다면 오픈 소스로 만드는 한 걸음을 더 나아갈 수도 있습니다.
커맨드 라인에서 수행하는 방법을 알고 있는 단계가 있지만, 현재 작업 중인 주요 프로그래밍 언어나 환경의 편안함을 떠나고 싶지 않을 수도 있습니다.
그럴 때는 <a href="#chapter-10-polyglot-data-science">10장</a>에 나열된 접근 방식 중 하나를 사용할 수도 있습니다.</p>
</div>
<div id="실용적이-되십시오" class="section level3" number="11.2.3">
<h3 number="11.2.3"><span class="header-section-number">11.2.3</span> 실용적이 되십시오</h3>
<p>세 번째 조언은 실용적이 되라는 것입니다.
실용적이 되는 것은 창의적이 되는 것과 관련이 있지만, 별도의 설명이 필요합니다.
이전 하위 섹션에서 저는 즉시 프로그래밍 언어로 되돌아가지 말라고 언급했습니다.
물론 커맨드 라인에도 한계는 있습니다.
책 전반에 걸쳐 저는 커맨드 라인이 데이터 과학을 수행하는 데 있어 보조적인(companion) 접근 방식으로 간주되어야 한다고 강조해 왔습니다.</p>
<p>저는 커맨드 라인에서 데이터 과학을 수행하기 위한 네 단계를 논의했습니다.
실제로 커맨드 라인의 적용 가능성은 1단계가 4단계보다 더 높습니다.
여러분은 당면한 작업에 가장 잘 맞는 접근 방식을 사용해야 합니다.
그리고 워크플로우의 어느 지점에서든 접근 방식들을 혼합하여 사용하는 것도 완벽하게 괜찮습니다.
<a href="#chapter-10-polyglot-data-science">10장</a>에서 보여드렸듯이, 커맨드 라인은 다른 접근 방식, 프로그래밍 언어, 통계 환경과 통합되는 데 매우 훌륭합니다.
각 접근 방식에는 일정한 트레이드오프(trade-off)가 있으며, 커맨드 라인에 능숙해지는 과정 중 일부는 언제 어떤 방식을 사용할지 배우는 것입니다.</p>
<p>결론적으로, 여러분이 인내심을 갖고 창의적이며 실용적이 될 때, 커맨드 라인은 여러분을 더 효율적이고 생산적인 데이터 과학자로 만들어 줄 것입니다.</p>
</div>
</div>
<div id="앞으로-어디로-나아가야-할까요" class="section level2" number="11.3">
<h2 number="11.3"><span class="header-section-number">11.3</span> 앞으로 어디로 나아가야 할까요?</h2>
<p>이 책은 커맨드 라인과 데이터 과학의 접점에 관한 것이므로, 많은 관련 주제가 맛보기로만 다루어졌습니다.
이제 이러한 주제들을 더 깊이 탐구하는 것은 여러분의 몫입니다.
다음 하위 섹션들은 참고할 만한 주제 리스트와 권장 자료들을 제공합니다.</p>
</div>
<div id="커맨드-라인" class="section level2" number="11.4">
<h2 number="11.4"><span class="header-section-number">11.4</span> 커맨드 라인</h2>
<ul>
<li><em>The Linux Command Line: A Complete Introduction, 2nd Edition</em> By William E. Shotts, Jr. (No Starch Press, 2019)</li>
<li><em>Unix Power Tools, 3rd Edition</em> by Jerry Peek, Shelley Powers, Tim O’Reilly, and Mike Loukides (O’Reilly Media, 2002)</li>
<li><em>Learning the Vi and Vim Editors, 7th Edition</em> by Arnold Robbins, Elbert Hannah, and Linda Lamb (O’Reilly Media, 2008)</li>
</ul>
<div id="쉘-프로그래밍" class="section level3" number="11.4.1">
<h3 number="11.4.1"><span class="header-section-number">11.4.1</span> 쉘 프로그래밍</h3>
<ul>
<li><em>Classic Shell Scripting</em> by Arnold Robbins and Nelson H.F. Beebe (O’Reilly Media, 2005)</li>
<li><em>Wicked Cool Shell Scripts, 2nd Edition</em> by Dave Taylor and Brandon Perry (No Starch Press, 2017)</li>
<li><em>Bash Cookbook</em> by Carl Albing JP Vossen (O’Reilly Media, 2018)</li>
</ul>
</div>
<div id="python-r-그리고-sql" class="section level3" number="11.4.2">
<h3 number="11.4.2"><span class="header-section-number">11.4.2</span> Python, R, 그리고 SQL</h3>
<ul>
<li><em>Learn Python 3 the Hard Way</em> by Zed A. Shaw (Addison-Wesley Professional, 2017)</li>
<li><em>Python for Data Analysis, 2nd Edition</em> by Wes McKinney (O’Reilly Media, 2017)</li>
<li><em>Data Science from Scratch, 2nd Edition</em> by Joel Grus (O’Reilly Media, 2019)</li>
<li><em>R for Data Science</em> by Garrett Grolemund and Hadley Wickham (O’Reilly Media, 2016)</li>
<li><em>R for Everyone, 2nd edition</em> by Jared Lander (Addison-Wesley Professional, 2017)</li>
<li><em>Sams Teach Yourself SQL in 10 Minutes a Day, 5th Edition</em> by Ben Forta (Sams, 2020)</li>
</ul>
</div>
<div id="api" class="section level3" number="11.4.3">
<h3 number="11.4.3"><span class="header-section-number">11.4.3</span> API</h3>
<ul>
<li><em>Mining the Social Web, 3rd Edition</em> by Matthew A. Russell and Mikhail Klassen (O’Reilly Media, 2019)</li>
<li><em>Data Source Handbook</em> by Pete Warden (O’Reilly Media, 2011)</li>
</ul>
</div>
<div id="머신러닝" class="section level3" number="11.4.4">
<h3 number="11.4.4"><span class="header-section-number">11.4.4</span> 머신러닝</h3>
<ul>
<li><em>Python Machine Learning, 3rd Edition</em> by Sebastian Raschka and Vahid Mirjalili (Packt Publishing, 2019)</li>
<li><em>Pattern Recognition and Machine Learning</em> by Christopher M. Bishop (Springer, 2006)</li>
<li><em>Information Theory, Inference, and Learning Algorithms</em> by David MacKay (Cambridge University Press, 2003)</li>
</ul>
</div>
</div>
<div id="연락하기" class="section level2" number="11.5">
<h2 number="11.5"><span class="header-section-number">11.5</span> 연락하기</h2>
<p>이 책은 커맨드 라인과 수많은 도구를 만든 많은 사람이 없었다면 세상에 나올 수 없었을 것입니다.
데이터 과학을 위한 현재의 커맨드 라인 도구 생태계는 커뮤니티의 노력의 결과라고 해도 과언이 아닙니다.
저는 여러분께 사용할 수 있는 수많은 커맨드 라인 도구 중 극히 일부만을 보여드릴 수 있었습니다.
새로운 도구들은 매일 만들어지고 있으며, 어쩌면 여러분도 언젠가 직접 도구를 만드실지도 모릅니다.
그런 경우, 여러분의 이야기를 듣고 싶습니다.
질문, 의견 또는 제안 사항이 있을 때 언제든지 연락해 주시면 감사하겠습니다.
저와 연락할 수 있는 몇 가지 방법은 다음과 같습니다.</p>
<ul>
<li>이메일: <a href="mailto:jeroen@jeroenjanssens.com" class="email">jeroen@jeroenjanssens.com</a></li>
<li>트위터: <a href="https://twitter.com/jeroenhjanssens/">@jeroenhjanssens</a></li>
<li>책 웹사이트: <a href="https://datascienceatthecommandline.com/" class="uri">https://datascienceatthecommandline.com/</a></li>
<li>책 GitHub 저장소: <a href="https://github.com/jeroenjanssens/data-science-at-the-command-line" class="uri">https://github.com/jeroenjanssens/data-science-at-the-command-line</a></li>
</ul>
<p>감사합니다.</p>
<!--chapter:end:11.Rmd-->
<!--A[appendix]
[[appendix-tools]]
A-->
</div>
</div>
<div id="커맨드-라인-도구-목록" class="section level1 unnumbered" number="">
<h1 class="unnumbered" number="">커맨드 라인 도구 목록</h1>
<p>이 장은 이 책에서 논의된 모든 커맨드 라인 도구들에 대한 개요입니다.
여기에는 바이너리 실행 파일, 인터프리터 스크립트, 그리고 Z Shell 빌트인(builtins) 및 키워드가 포함됩니다.
각 커맨드 라인 도구에 대해 가능한 경우 그리고 적절한 경우 다음과 같은 정보가 제공됩니다.</p>
<ul>
<li>커맨드 라인에 입력할 실제 명령어</li>
<li>설명</li>
<li>책에서 사용된 버전</li>
<li>해당 버전이 출시된 연도</li>
<li>주요 저자</li>
<li>더 많은 정보를 찾을 수 있는 웹사이트</li>
<li>도움말을 얻는 방법</li>
<li>사용 예시</li>
</ul>
<p>여기에 나열된 모든 커맨드 라인 도구는 Docker 이미지에 포함되어 있습니다.
설정 방법은 <a href="#chapter-2-getting-started">2장</a>을 참조하십시오.
오픈 소스 소프트웨어를 인용하는 것은 간단하지 않으며, 일부 정보가 누락되었거나 정확하지 않을 수 있음에 유의하십시오.</p>
<div id="alias" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">alias</h2>
<p>별칭을 정의하거나 표시합니다.
<code>alias</code>는 Z shell 빌트인입니다.</p>
<pre>type alias
man zshbuiltins | grep -A 10 alias#!enter=FALSE
C-C#!literal=FALSE
alias l
alias python=python3</pre>
</div>
<div id="awk" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">awk</h2>
<p>패턴 스캐닝 및 텍스트 처리 언어입니다.
<code>awk</code> (버전 1.3.4), Mike D. Brennan 및 Thomas E. Dickey 제작 (2019).
더 많은 정보: <a href="https://invisible-island.net/mawk" class="uri">https://invisible-island.net/mawk</a>.</p>
<pre>type awk
man awk#!enter=FALSE
C-C#!literal=FALSE
seq 5 | awk '{sum+=$1} END {print sum}'</pre>
</div>
<div id="aws" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">aws</h2>
<p>AWS 서비스를 관리하기 위한 통합 도구입니다.
<code>aws</code> (버전 2.1.32), Amazon Web Services 제작 (2021).
더 많은 정보: <a href="https://aws.amazon.com/cli" class="uri">https://aws.amazon.com/cli</a>.</p>
<pre>type aws
aws --help#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="bash" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">bash</h2>
<p>GNU Bourne-Again SHell입니다.
<code>bash</code> (버전 5.0.17), Brian Fox 및 Chet Ramey 제작 (2019).
더 많은 정보: <a href="https://www.gnu.org/software/bash" class="uri">https://www.gnu.org/software/bash</a>.</p>
<pre>type bash
man bash#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="bat" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">bat</h2>
<p>구문 강조 및 Git 연동 기능이 있는 cat 클론입니다.
<code>bat</code> (버전 0.18.0), David Peter 제작 (2021).
더 많은 정보: <a href="https://github.com/sharkdp/bat" class="uri">https://github.com/sharkdp/bat</a>.</p>
<pre>type bat
man bat#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="bc" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">bc</h2>
<p>임의 정밀도 계산기 언어입니다.
<code>bc</code> (버전 1.07.1), Philip A. Nelson 제작 (2017).
더 많은 정보: <a href="https://www.gnu.org/software/bc" class="uri">https://www.gnu.org/software/bc</a>.</p>
<pre>type bc
man bc#!enter=FALSE
C-C#!literal=FALSE
bc -l &lt;&lt;&lt; 'e(1)'</pre>
</div>
<div id="body" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">body</h2>
<p>첫 번째 줄을 제외한 모든 줄에 명령을 적용합니다.
<code>body</code> (버전 0.1), Jeroen Janssens 제작 (2021).
더 많은 정보: <a href="https://github.com/jeroenjanssens/dsutils" class="uri">https://github.com/jeroenjanssens/dsutils</a>.</p>
<pre>type body
seq 10 | header -a 'values' | body shuf</pre>
</div>
<div id="cat" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">cat</h2>
<p>파일들을 연결하여 표준 출력으로 인쇄합니다.
<code>cat</code> (버전 8.30), Torbjorn Granlund 및 Richard M. Stallman 제작 (2018).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type cat
man cat#!enter=FALSE
C-C#!literal=FALSE
cat *.log &gt; all.log#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="cd" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">cd</h2>
<p>쉘 작업 디렉토리를 변경합니다.
<code>cd</code>는 Z shell 빌트인입니다.</p>
<pre>type cd
man zshbuiltins | grep -A 10 cd#!enter=FALSE
C-C#!literal=FALSE
cd ~
pwd
cd ..
pwd
cd /data/ch01</pre>
</div>
<div id="chmod" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">chmod</h2>
<p>파일 모드 비트를 변경합니다.
<code>chmod</code> (버전 8.30), David MacKenzie 및 Jim Meyering 제작 (2018).
저는 <a href="#chapter-4-creating-command-line-tools">4장</a>에서 도구를 실행 가능하게 만들기 위해 <code>chmod</code>를 사용했습니다.
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type chmod
man chmod#!enter=FALSE
C-C#!literal=FALSE
chmod u+x script.sh#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="cols" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">cols</h2>
<p>일부 열에 명령을 적용합니다.
<code>cols</code> (버전 0.1), Jeroen Janssens 제작 (2021).
더 많은 정보: <a href="https://github.com/jeroenjanssens/dsutils" class="uri">https://github.com/jeroenjanssens/dsutils</a>.</p>
<pre>type cols</pre>
</div>
<div id="column" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">column</h2>
<p>목록을 여러 열로 나열합니다.
<code>column</code> (버전 2.36.1), Karel Zak 제작 (2021).
더 많은 정보: <a href="https://www.kernel.org/pub/linux/utils/util-linux" class="uri">https://www.kernel.org/pub/linux/utils/util-linux</a>.</p>
<pre>type column</pre>
</div>
<div id="cowsay" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">cowsay</h2>
<p>말하는 소를 출력합니다. (설정 가능)
<code>cowsay</code> (버전 3.0.3), Tony Monroe 제작 (1999).
더 많은 정보: <a href="https://github.com/tnalpgge/rank-amateur-cowsay" class="uri">https://github.com/tnalpgge/rank-amateur-cowsay</a>.</p>
<pre>type cowsay
man cowsay#!enter=FALSE
C-C#!literal=FALSE
echo 'The command line is awesome!' | cowsay</pre>
</div>
<div id="cp" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">cp</h2>
<p>파일 및 디렉토리를 복사합니다.
<code>cp</code> (버전 8.30), Torbjorn Granlund, David MacKenzie 및 Jim Meyering 제작 (2018).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type cp
man cp#!enter=FALSE
C-C#!literal=FALSE
cp -r ~/Downloads/*.xlsx /data#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="csv2vw" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">csv2vw</h2>
<p>CSV를 Vowpal Wabbit 형식으로 변환합니다.
<code>csv2vw</code> (버전 0.1), Jeroen Janssens 제작 (2021).
더 많은 정보: <a href="https://github.com/jeroenjanssens/dsutils" class="uri">https://github.com/jeroenjanssens/dsutils</a>.</p>
<pre>type csv2vw</pre>
</div>
<div id="csvcut" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">csvcut</h2>
<p>CSV 파일을 필터링하고 자릅니다.
<code>csvcut</code> (버전 1.0.5), Christopher Groskopf 제작 (2020).
더 많은 정보: <a href="https://csvkit.rtfd.org" class="uri">https://csvkit.rtfd.org</a>.</p>
<pre>type csvcut
csvcut --help#!enter=FALSE
C-C#!literal=FALSE
csvcut -c bill,tip /data/ch05/tips.csv | trim</pre>
</div>
<div id="csvgrep" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">csvgrep</h2>
<p>CSV 파일을 검색합니다.
<code>csvgrep</code> (버전 1.0.5), Christopher Groskopf 제작 (2020).
더 많은 정보: <a href="https://csvkit.rtfd.org" class="uri">https://csvkit.rtfd.org</a>.</p>
<pre>type csvgrep
csvgrep --help#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="csvjoin" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">csvjoin</h2>
<p>지정된 열을 기준으로 CSV 파일을 병합합니다. (SQL 스타일 조인)
<code>csvjoin</code> (버전 1.0.5), Christopher Groskopf 제작 (2020).
더 많은 정보: <a href="https://csvkit.rtfd.org" class="uri">https://csvkit.rtfd.org</a>.</p>
<pre>type csvjoin
csvjoin --help#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="csvlook" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">csvlook</h2>
<p>콘솔에서 CSV 파일을 Markdown 호환 고정폭 표로 렌더링합니다.
<code>csvlook</code> (버전 1.0.5), Christopher Groskopf 제작 (2020).
더 많은 정보: <a href="https://csvkit.rtfd.org" class="uri">https://csvkit.rtfd.org</a>.</p>
<pre>type csvlook
csvlook --help#!enter=FALSE
C-C#!literal=FALSE
csvlook /data/ch05/tips.csv</pre>
</div>
<div id="csvquote" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">csvquote</h2>
<p>일반 유닉스 유틸리티가 CSV 데이터와 올바르게 작동하도록 설정합니다.
<code>csvquote</code> (버전 0.1), Dan Brown 제작 (2018).
더 많은 정보: <a href="https://github.com/dbro/csvquote" class="uri">https://github.com/dbro/csvquote</a>.</p>
<pre>type csvquote</pre>
</div>
<div id="csvsort" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">csvsort</h2>
<p>CSV 파일을 정렬합니다.
<code>csvsort</code> (버전 1.0.5), Christopher Groskopf 제작 (2020).
더 많은 정보: <a href="https://csvkit.rtfd.org" class="uri">https://csvkit.rtfd.org</a>.</p>
<pre>type csvsort
csvsort --help#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="csvsql" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">csvsql</h2>
<p>CSV 파일에 대해 SQL 문을 실행합니다.
<code>csvsql</code> (버전 1.0.5), Christopher Groskopf 제작 (2020).
더 많은 정보: <a href="https://csvkit.rtfd.org" class="uri">https://csvkit.rtfd.org</a>.</p>
<pre>type csvsql
csvsql --help#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="csvstack" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">csvstack</h2>
<p>여러 CSV 파일의 행을 쌓아 올립니다.
<code>csvstack</code> (버전 1.0.5), Christopher Groskopf 제작 (2020).
더 많은 정보: <a href="https://csvkit.rtfd.org" class="uri">https://csvkit.rtfd.org</a>.</p>
<pre>type csvstack
csvstack --help#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="csvstat" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">csvstat</h2>
<p>CSV 파일의 각 열에 대한 기술 통계를 인쇄합니다.
<code>csvstat</code> (버전 1.0.5), Christopher Groskopf 제작 (2020).
더 많은 정보: <a href="https://csvkit.rtfd.org" class="uri">https://csvkit.rtfd.org</a>.</p>
<pre>type csvstat
csvstat --help#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="curl" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">curl</h2>
<p>URL을 전송합니다.
<code>curl</code> (버전 7.68.0), Daniel Stenberg 제작 (2016).
더 많은 정보: <a href="https://curl.haxx.se" class="uri">https://curl.haxx.se</a>.</p>
<pre>type curl
man curl#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="cut" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">cut</h2>
<p>파일의 각 줄에서 섹션을 제거합니다.
<code>cut</code> (버전 8.30), David M. Ihnat, David MacKenzie 및 Jim Meyering 제작 (2019).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type cut
man cut#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="display" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">display</h2>
<p>X 서버에 이미지 또는 이미지 시퀀스를 표시합니다.
<code>display</code> (버전 6.9.10-23), ImageMagick Studio LLC 제작 (2019).
더 많은 정보: <a href="https://imagemagick.org" class="uri">https://imagemagick.org</a>.</p>
<pre>type display</pre>
</div>
<div id="dseq" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">dseq</h2>
<p>날짜 시퀀스를 생성합니다.
<code>dseq</code> (버전 0.1), Jeroen Janssens 제작 (2021).
더 많은 정보: <a href="https://github.com/jeroenjanssens/dsutils" class="uri">https://github.com/jeroenjanssens/dsutils</a>.</p>
<pre>type dseq
dseq 3</pre>
</div>
<div id="echo" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">echo</h2>
<p>텍스트 한 줄을 표시합니다.
<code>echo</code> (버전 8.30), Brian Fox 및 Chet Ramey 제작 (2019).
리터럴 텍스트를 다음 도구의 표준 입력으로 사용하는 데 유용합니다.
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type echo
man echo#!enter=FALSE
C-C#!literal=FALSE
echo Hippopotomonstrosesquippedaliophobia | cowsay
echo -n Hippopotomonstrosesquippedaliophobia | wc -c</pre>
</div>
<div id="env" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">env</h2>
<p>수정된 환경에서 프로그램을 실행합니다.
<code>env</code> (버전 8.30), Richard Mlynarik, David MacKenzie 및 Assaf Gordon 제작 (2018).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type env
man env#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="export" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">export</h2>
<p>쉘 변수에 대해 내보내기(export) 속성을 설정합니다. 쉘 변수를 다른 커맨드 라인 도구에서 사용할 수 있게 만드는 데 유용합니다.
<code>export</code>는 Z shell 빌트인입니다.</p>
<pre>type export
man zshbuiltins | grep -A 10 export#!enter=FALSE
C-C#!literal=FALSE
export PATH="$PATH:$HOME/bin"</pre>
</div>
<div id="fc" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">fc</h2>
<p>대화형 기록 메커니즘을 제어합니다.
<code>fc</code>는 Z shell 빌트인입니다.
저는 <a href="#chapter-4-creating-command-line-tools">4장</a>에서 명령어를 <code>nano</code>에서 편집하기 위해 <code>fc</code>를 사용했습니다.</p>
<pre>type fc
man zshbuiltins | grep -A 10 '^ *fc '#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="find" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">find</h2>
<p>디렉토리 계층 구조에서 파일을 검색합니다.
<code>find</code> (버전 4.7.0), Eric B. Decker, James Youngman 및 Kevin Dalley 제작 (2019).
더 많은 정보: <a href="https://www.gnu.org/software/findutils" class="uri">https://www.gnu.org/software/findutils</a>.</p>
<pre>type find
man find#!enter=FALSE
C-C#!literal=FALSE
find /data -type f -name '*.csv' -size -3</pre>
</div>
<div id="fold" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">fold</h2>
<p>지정된 너비에 맞춰 각 입력 줄을 감쌉니다(wrap).
<code>fold</code> (버전 8.30), David MacKenzie 제작 (2020).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type fold
man fold#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="for" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">for</h2>
<p>목록의 각 멤버에 대해 명령을 실행합니다.
<code>for</code>는 Z shell 빌트인입니다.
<a href="#chapter-8-parallel-pipelines">8장</a>에서 저는 <code>for</code> 대신 <code>parallel</code>을 사용할 때의 이점에 대해 논의합니다.</p>
<pre>type for
man zshmisc | grep -EA 10 '^ *for '#!enter=FALSE
C-C#!literal=FALSE
for i in {A..C} "It's easy as" {1..3}; do echo $i; done</pre>
</div>
<div id="fx" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">fx</h2>
<p>대화형 JSON 뷰어입니다.
<code>fx</code> (버전 20.0.2), Anton Medvedev 제작 (2020).
더 많은 정보: <a href="https://github.com/antonmedv/fx" class="uri">https://github.com/antonmedv/fx</a>.</p>
<pre>type fx
fx --help#!enter=FALSE
C-C#!literal=FALSE
echo '[1,2,3]' | fx 'this.map(x =&gt; x * 2)'</pre>
</div>
<div id="git" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">git</h2>
<p>분산 버전 관리 시스템입니다.
<code>git</code> (버전 2.25.1), Linus Torvalds 및 Junio C. Hamano 제작 (2021).
더 많은 정보: <a href="https://git-scm.com" class="uri">https://git-scm.com</a>.</p>
<pre>type git
man git#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="grep" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">grep</h2>
<p>패턴과 일치하는 줄을 출력합니다.
<code>grep</code> (버전 3.4), Jim Meyering 제작 (2019).
더 많은 정보: <a href="https://www.gnu.org/software/grep" class="uri">https://www.gnu.org/software/grep</a>.</p>
<pre>type grep
man grep#!enter=FALSE
C-C#!literal=FALSE
seq 100 | grep 3 | wc -l</pre>
</div>
<div id="gron" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">gron</h2>
<p>JSON을 검색(grep) 가능하게 만듭니다.
<code>gron</code> (버전 0.6.1), Tom Hudson 제작 (2021).
더 많은 정보: <a href="https://github.com/TomNomNom/gron" class="uri">https://github.com/TomNomNom/gron</a>.</p>
<pre>type gron
man gron#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="head" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">head</h2>
<p>파일의 앞부분을 출력합니다.
<code>head</code> (버전 8.30), David MacKenzie 및 Jim Meyering 제작 (2019).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type head
man head#!enter=FALSE
C-C#!literal=FALSE
seq 100 | head -n 5</pre>
</div>
<div id="header" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">header</h2>
<p>헤더 라인을 추가, 교체 및 삭제합니다.
<code>header</code> (버전 0.1), Jeroen Janssens 제작 (2021).
더 많은 정보: <a href="https://github.com/jeroenjanssens/dsutils" class="uri">https://github.com/jeroenjanssens/dsutils</a>.</p>
<pre>type header</pre>
</div>
<div id="history" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">history</h2>
<p>GNU History 라이브러리입니다.
<code>history</code> (버전 8.1), Brian Fox 및 Chet Ramey 제작 (2020).
더 많은 정보: <a href="https://www.gnu.org/software/bash" class="uri">https://www.gnu.org/software/bash</a>.</p>
<pre>type history</pre>
</div>
<div id="hostname" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">hostname</h2>
<p>시스템의 호스트 이름을 표시하거나 설정합니다.
<code>hostname</code> (버전 3.23), Peter Tobias, Bernd Eckenfels 및 Michael Meskes 제작 (2021).
더 많은 정보: <a href="https://sourceforge.net/projects/net-tools/" class="uri">https://sourceforge.net/projects/net-tools/</a>.</p>
<pre>type hostname
man hostname#!enter=FALSE
C-C#!literal=FALSE
hostname
hostname -i</pre>
</div>
<div id="in2csv" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">in2csv</h2>
<p>일반적이지만 덜 멋진 테이블 데이터 형식을 CSV로 변환합니다.
<code>in2csv</code> (버전 1.0.5), Christopher Groskopf 제작 (2020).
더 많은 정보: <a href="https://csvkit.rtfd.org" class="uri">https://csvkit.rtfd.org</a>.</p>
<pre>type in2csv
in2csv --help#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="jq" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">jq</h2>
<p>커맨드 라인용 JSON 프로세서입니다.
<code>jq</code> (버전 1.6), Stephen Dolan 제작 (2021).
더 많은 정보: <a href="https://stedolan.github.com/jq" class="uri">https://stedolan.github.com/jq</a>.</p>
<pre>type jq
man jq#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="json2csv" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">json2csv</h2>
<p>JSON을 CSV로 변환합니다.
<code>json2csv</code> (버전 1.2.1), Jehiah Czebotar 제작 (2019).
더 많은 정보: <a href="https://github.com/jehiah/json2csv" class="uri">https://github.com/jehiah/json2csv</a>.</p>
<pre>type json2csv
json2csv --help#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="l" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">l</h2>
<p>디렉토리 내용을 긴 형식(long format)으로 나열합니다. 디렉토리는 파일보다 먼저 그룹화되고, 파일 크기는 읽기 쉬운 단위로 표시되며, 접근 권한도 포함됩니다.
<code>l</code> 제작자 미상 (1999).</p>
<pre>type l
cd /data/ch03
ls
l</pre>
</div>
<div id="less" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">less</h2>
<p>more의 반대입니다. (파일 내용을 페이지 단위로 보여주는 유틸리티)
<code>less</code> (버전 551), Mark Nudelman 제작 (2019).
더 많은 정보: <a href="https://www.greenwoodsoftware.com/less" class="uri">https://www.greenwoodsoftware.com/less</a>.</p>
<pre>type less
man less#!enter=FALSE
C-C#!literal=FALSE
less README#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="ls" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">ls</h2>
<p>디렉토리 내용을 나열합니다.
<code>ls</code> (버전 8.30), Richard M. Stallman 및 David MacKenzie 제작 (2019).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type ls
man ls#!enter=FALSE
C-C#!literal=FALSE
ls /data</pre>
</div>
<div id="make" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">make</h2>
<p>컴퓨터 프로그램을 유지 관리하기 위한 프로그램입니다.
<code>make</code> (버전 4.3), Stuart I. Feldman 제작 (2020).
더 많은 정보: <a href="https://www.gnu.org/software/make" class="uri">https://www.gnu.org/software/make</a>.</p>
<pre>type make
man make#!enter=FALSE
C-C#!literal=FALSE
make sandwich#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="man" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">man</h2>
<p>시스템 참조 매뉴얼에 대한 인터페이스입니다. (도움말 시스템)
<code>man</code> (버전 2.9.1), John W. Eaton 및 Colin Watson 제작 (2020).
더 많은 정보: <a href="https://nongnu.org/man-db" class="uri">https://nongnu.org/man-db</a>.</p>
<pre>type man
man man#!enter=FALSE
C-C#!literal=FALSE
man excel</pre>
</div>
<div id="mkdir" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">mkdir</h2>
<p>디렉토리를 생성합니다.
<code>mkdir</code> (버전 8.30), David MacKenzie 제작 (2019).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type mkdir
man mkdir#!enter=FALSE
C-C#!literal=FALSE
mkdir -p /data/ch{01..10}#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="mv" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">mv</h2>
<p>파일을 이동하거나 이름을 변경합니다.
<code>mv</code> (버전 8.30), Mike Parker, David MacKenzie 및 Jim Meyering 제작 (2020).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type mv
man mv#!enter=FALSE
C-C#!literal=FALSE
mv results{,.bak}#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="nano" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">nano</h2>
<p>Pico에서 영감을 받은 Nano’s ANOther 에디터입니다.
<code>nano</code> (버전 5.4), Benno Schulenberg 외 다수 제작 (2020).
더 많은 정보: <a href="https://nano-editor.org" class="uri">https://nano-editor.org</a>.</p>
<pre>type nano</pre>
</div>
<div id="nl" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">nl</h2>
<p>파일의 줄에 번호를 매깁니다.
<code>nl</code> (버전 8.30), Scott Bartram 및 David MacKenzie 제작 (2020).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type nl
man nl#!enter=FALSE
C-C#!literal=FALSE
nl /data/ch05/alice.txt | head</pre>
</div>
<div id="parallel" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">parallel</h2>
<p>동일 노드 또는 원격 노드에서 병렬로 작업을 빌드하고 실행합니다.
<code>parallel</code> (버전 20161222), Ole Tange 제작 (2016).
더 많은 정보: <a href="https://www.gnu.org/software/parallel" class="uri">https://www.gnu.org/software/parallel</a>.</p>
<pre>type parallel
man parallel#!enter=FALSE
C-C#!literal=FALSE
seq 3 | parallel "echo Processing file {}.csv"</pre>
</div>
<div id="paste" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">paste</h2>
<p>파일의 줄을 병합합니다.
<code>paste</code> (버전 8.30), David M. Ihnat 및 David MacKenzie 제작 (2019).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type paste
man paste#!enter=FALSE
C-C#!literal=FALSE
paste -d, &lt;(seq 5) &lt;(dseq 5)
seq 5 | paste -sd+</pre>
</div>
<div id="pbc" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">pbc</h2>
<p>병렬 bc(병렬 계산기)입니다.
<code>pbc</code> Jeroen Janssens 제작 (2021).
더 많은 정보: <a href="https://github.com/jeroenjanssens/dsutils" class="uri">https://github.com/jeroenjanssens/dsutils</a>.</p>
<pre>type pbc
seq 3 | pbc '{1}^2'</pre>
</div>
<div id="pip" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">pip</h2>
<p>Python 패키지를 설치하고 관리하기 위한 도구입니다.
<code>pip</code> (버전 20.0.2), PyPA 제작 (2020).
더 많은 정보: <a href="https://pip.pypa.io" class="uri">https://pip.pypa.io</a>.</p>
<pre>type pip
man pip#!enter=FALSE
C-C#!literal=FALSE
pip install pandas#!enter=FALSE
C-C#!literal=FALSE
pip freeze | grep sci</pre>
</div>
<div id="pup" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">pup</h2>
<p>커맨드 라인에서 HTML을 파싱합니다.
<code>pup</code> (버전 0.4.0), Eric Chiang 제작 (2016).
더 많은 정보: <a href="https://github.com/EricChiang/pup" class="uri">https://github.com/EricChiang/pup</a>.</p>
<pre>type pup
pup --help#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="pwd" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">pwd</h2>
<p>작업 디렉토리의 이름을 인쇄합니다.
<code>pwd</code> (버전 8.30), Jim Meyering 제작 (2019).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type pwd
man pwd#!enter=FALSE
C-C#!literal=FALSE
cd ~
pwd</pre>
</div>
<div id="python-1" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">python</h2>
<p>인터프리터 방식의 대화형 객체 지향 프로그래밍 언어입니다.
<code>python</code> (버전 3.8.5), The Python Software Foundation 제작 (2021).
더 많은 정보: <a href="https://www.python.org" class="uri">https://www.python.org</a>.</p>
<pre>type python
man python#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="r-1" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">R</h2>
<p>통계 컴퓨팅을 위한 언어 및 환경입니다.
<code>R</code> (버전 4.0.4), The R Foundation for Statistical Computing 제작 (2021).
더 많은 정보: <a href="https://www.r-project.org" class="uri">https://www.r-project.org</a>.</p>
<pre>type R
man R#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="rev" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">rev</h2>
<p>각 줄의 문자 순서를 반대로 바꿉니다.
<code>rev</code> (버전 2.36.1), Karel Zak 제작 (2021).
더 많은 정보: <a href="https://www.kernel.org/pub/linux/utils/util-linux" class="uri">https://www.kernel.org/pub/linux/utils/util-linux</a>.</p>
<pre>type rev
echo 'Satire: Veritas' | rev
echo 'Ça va?' | rev | cut -c 2- | rev</pre>
</div>
<div id="rm" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">rm</h2>
<p>파일이나 디렉토리를 제거합니다.
<code>rm</code> (버전 8.30), Paul Rubin 외 다수 제작 (2019).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type rm
man rm#!enter=FALSE
C-C#!literal=FALSE
rm *.old#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="rush" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">rush</h2>
<p>쉘에서 실행하는 R 한 줄짜리 명령어 도구입니다.
<code>rush</code> (버전 0.1), Jeroen Janssens 제작 (2021).
더 많은 정보: <a href="https://github.com/jeroenjanssens/rush" class="uri">https://github.com/jeroenjanssens/rush</a>.</p>
<pre>type rush
rush --help#!enter=FALSE
C-C#!literal=FALSE
rush run '6*7'
rush run --tidyverse 'filter(starwars, species == "Human") %&gt;% select(name)'</pre>
</div>
<div id="sample" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">sample</h2>
<p>특정 확률, 지정된 지연 시간 또는 특정 지속 시간 동안 표준 입력의 줄을 필터링합니다.
<code>sample</code> (버전 0.2.4), Jeroen Janssens 제작 (2021).
더 많은 정보: <a href="https://github.com/jeroenjanssens/sample" class="uri">https://github.com/jeroenjanssens/sample</a>.</p>
<pre>type sample
sample --help#!enter=FALSE
C-C#!literal=FALSE
seq 1000 | sample -r 0.01 | trim 5</pre>
</div>
<div id="scp" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">scp</h2>
<p>OpenSSH 보안 파일 복사 도구입니다.
<code>scp</code> (버전 1:8.2p1-4ubuntu0.2), Timo Rinne 및 Tatu Ylonen 제작 (2019).
더 많은 정보: <a href="https://www.openssh.com" class="uri">https://www.openssh.com</a>.</p>
<pre>type scp
man scp#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="sed" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">sed</h2>
<p>텍스트를 필터링하고 변환하기 위한 스트림 에디터입니다.
<code>sed</code> (버전 4.7), Jay Fenlason 외 다수 제작 (2018).
더 많은 정보: <a href="https://www.gnu.org/software/sed" class="uri">https://www.gnu.org/software/sed</a>.</p>
<pre>type sed
man sed#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="seq" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">seq</h2>
<p>숫자 시퀀스를 인쇄합니다.
<code>seq</code> (버전 8.30), Ulrich Drepper 제작 (2019).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type seq
man seq#!enter=FALSE
C-C#!literal=FALSE
seq 3
seq 10 5 20</pre>
</div>
<div id="servewd" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">servewd</h2>
<p>간단한 HTTP 서버를 사용하여 현재 작업 디렉토리를 서비스합니다.
<code>servewd</code> (버전 0.1), Jeroen Janssens 제작 (2021).
더 많은 정보: <a href="https://github.com/jeroenjanssens/dsutils" class="uri">https://github.com/jeroenjanssens/dsutils</a>.</p>
<pre>type servewd
servewd --help#!enter=FALSE
C-C#!literal=FALSE
cd /data &amp;&amp; servewd 8000#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="shuf" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">shuf</h2>
<p>무작위 순열을 생성합니다.
<code>shuf</code> (버전 8.30), Paul Eggert 제작 (2019).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type shuf
man shuf#!enter=FALSE
C-C#!literal=FALSE
echo {a..z} | tr ' ' '\n' | shuf | trim 5
shuf -i 1-100 | trim 5</pre>
</div>
<div id="skll" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">skll</h2>
<p>SciKit-Learn Laboratory입니다.
<code>skll</code> (버전 2.5.0), Educational Testing Service 제작 (2021).
실제 도구는 <code>run_experiment</code>입니다. 저는 기억하기 더 쉽기 때문에 별칭 <code>skll</code>을 사용합니다.
더 많은 정보: <a href="https://skll.readthedocs.org" class="uri">https://skll.readthedocs.org</a>.</p>
<pre>type skll
skll --help#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="sort" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">sort</h2>
<p>텍스트 파일의 줄을 정렬합니다.
<code>sort</code> (버전 8.30), Mike Haertel 및 Paul Eggert 제작 (2019).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type sort
man sort#!enter=FALSE
C-C#!literal=FALSE
echo '3\n7\n1\n3' | sort</pre>
</div>
<div id="split" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">split</h2>
<p>파일을 여러 조각으로 나눕니다.
<code>split</code> (버전 8.30), Torbjorn Granlund 및 Richard M. Stallman 제작 (2019).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type split
man split#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="sponge" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">sponge</h2>
<p>표준 입력을 흡수하여 파일에 씁니다.
<code>sponge</code> (버전 0.65), Colin Watson 및 Tollef Fog Heen 제작 (2021).
단일 파이프라인에서 동일한 파일을 읽고 쓰고 싶을 때 유용합니다.
더 많은 정보: <a href="https://joeyh.name/code/moreutils" class="uri">https://joeyh.name/code/moreutils</a>.</p>
<pre>type sponge</pre>
</div>
<div id="sql2csv" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">sql2csv</h2>
<p>데이터베이스에서 SQL 쿼리를 실행하고 결과를 CSV 파일로 출력합니다.
<code>sql2csv</code> (버전 1.0.5), Christopher Groskopf 제작 (2020).
더 많은 정보: <a href="https://csvkit.rtfd.org" class="uri">https://csvkit.rtfd.org</a>.</p>
<pre>type sql2csv
sql2csv --help#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="ssh" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">ssh</h2>
<p>OpenSSH 원격 로그인 클라이언트입니다.
<code>ssh</code> (버전 1:8.2p1-4ubuntu0.2), Tatu Ylonen 외 다수 제작 (2020).
더 많은 정보: <a href="https://www.openssh.com" class="uri">https://www.openssh.com</a>.</p>
<pre>type ssh
man ssh#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="sudo" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">sudo</h2>
<p>다른 사용자로 명령을 실행합니다.
<code>sudo</code> (버전 1.8.31), Todd C. Miller 제작 (2019).
더 많은 정보: <a href="https://www.sudo.ws" class="uri">https://www.sudo.ws</a>.</p>
<pre>type sudo
man sudo#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="tail" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">tail</h2>
<p>파일의 마지막 부분을 출력합니다.
<code>tail</code> (버전 8.30), Paul Rubin 외 다수 제작 (2019).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type tail
man tail#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="tapkee" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">tapkee</h2>
<p>효율적인 차원 축소 라이브러리입니다.
<code>tapkee</code> (버전 1.2), Sergey Lisitsyn 외 다수 제작 (2013).
더 많은 정보: <a href="http://tapkee.lisitsyn.me" class="uri">http://tapkee.lisitsyn.me</a>.</p>
<pre>type tapkee
tapkee --help#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="tar" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">tar</h2>
<p>아카이빙 유틸리티입니다.
<code>tar</code> (버전 1.30), John Gilmore 및 Jay Fenlason 제작 (2014).
더 많은 정보: <a href="https://www.gnu.org/software/tar" class="uri">https://www.gnu.org/software/tar</a>.</p>
<pre>type tar
man tar#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="tee" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">tee</h2>
<p>표준 입력에서 읽어 표준 출력과 파일에 씁니다.
<code>tee</code> (버전 8.30), Mike Parker 외 다수 제작 (2019).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type tee
man tee#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="telnet" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">telnet</h2>
<p>TELNET 프로토콜에 대한 사용자 인터페이스입니다.
<code>telnet</code> (버전 0.17), Mats Erik Andersson 외 다수 제작 (1999).
더 많은 정보: <a href="http://www.hcs.harvard.edu/~dholland/computers/netkit.html" class="uri">http://www.hcs.harvard.edu/~dholland/computers/netkit.html</a>.</p>
<pre>type telnet</pre>
</div>
<div id="tldr" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">tldr</h2>
<p>콘솔 명령에 대한 협업 치트 시트입니다.
<code>tldr</code> (버전 3.3.7), Owen Voke 제작 (2021).
더 많은 정보: <a href="https://tldr.sh" class="uri">https://tldr.sh</a>.</p>
<pre>type tldr
tldr --help#!enter=FALSE
C-C#!literal=FALSE
tldr tar | trim</pre>
</div>
<div id="tr" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">tr</h2>
<p>문자를 변환하거나 삭제합니다.
<code>tr</code> (버전 8.30), Jim Meyering 제작 (2018).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type tr
man tr#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="tree" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">tree</h2>
<p>디렉토리 내용을 트리 형식으로 나열합니다.
<code>tree</code> (버전 1.8.0), Steve Baker 제작 (2018).
더 많은 정보: <a href="https://launchpad.net/ubuntu/+source/tree" class="uri">https://launchpad.net/ubuntu/+source/tree</a>.</p>
<pre>type tree
man tree#!enter=FALSE
C-C#!literal=FALSE
tree / | trim</pre>
</div>
<div id="trim" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">trim</h2>
<p>출력을 지정된 높이와 너비로 자릅니다.
<code>trim</code> Jeroen Janssens 제작 (2021).
더 많은 정보: <a href="https://github.com/jeroenjanssens/dsutils" class="uri">https://github.com/jeroenjanssens/dsutils</a>.</p>
<pre>type trim
echo {a..z}-{0..9} | fold | trim 5 60</pre>
</div>
<div id="ts" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">ts</h2>
<p>입력에 타임스탬프를 추가합니다.
<code>ts</code> (버전 0.65), Joey Hess 제작 (2021).
더 많은 정보: <a href="https://joeyh.name/code/moreutils" class="uri">https://joeyh.name/code/moreutils</a>.</p>
<pre>type ts
echo seq 5 | sample -d 500 | ts</pre>
</div>
<div id="type" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">type</h2>
<p>커맨드 라인 도구의 유형과 위치를 표시합니다.
<code>type</code>은 Z shell 빌트인입니다.</p>
<pre>type type
man zshbuiltins | grep -A 10 '^ *type '#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="uniq" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">uniq</h2>
<p>중복된 줄을 보고하거나 누락시킵니다.
<code>uniq</code> (버전 8.30), Richard M. Stallman 및 David MacKenzie 제작 (2019).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type uniq
man uniq#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="unpack" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">unpack</h2>
<p>일반적인 파일 형식의 압축을 해제합니다.
<code>unpack</code> (버전 0.1), Patrick Brisbin 제작 (2013).
더 많은 정보: <a href="https://github.com/jeroenjanssens/dsutils" class="uri">https://github.com/jeroenjanssens/dsutils</a>.</p>
<pre>type unpack</pre>
</div>
<div id="unrar" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">unrar</h2>
<p>rar 아카이브에서 파일을 추출합니다.
<code>unrar</code> (버전 0.0.1), Ben Asselstine 외 다수 제작 (2014).
더 많은 정보: <a href="http://home.gna.org/unrar" class="uri">http://home.gna.org/unrar</a>.</p>
<pre>type unrar
man unrar#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="unzip" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">unzip</h2>
<p>ZIP 아카이브의 압축 파일을 나열, 테스트 및 추출합니다.
<code>unzip</code> (버전 6.0), Samuel H. Smith 외 다수 제작 (2009).
더 많은 정보: <a href="http://www.info-zip.org/pub/infozip" class="uri">http://www.info-zip.org/pub/infozip</a>.</p>
<pre>type unzip
man unzip#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="vw" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">vw</h2>
<p>온라인 학습을 위한 빠른 머신러닝 라이브러리입니다.
<code>vw</code> (버전 8.10.1), John Langford 제작 (2021).
더 많은 정보: <a href="https://vowpalwabbit.org" class="uri">https://vowpalwabbit.org</a>.</p>
<pre>type vw
vw --help --quiet#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="wc" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">wc</h2>
<p>각 파일의 줄 바꿈, 단어 및 바이트 수를 인쇄합니다.
<code>wc</code> (버전 8.30), Paul Rubin 및 David MacKenzie 제작 (2019).
더 많은 정보: <a href="https://www.gnu.org/software/coreutils" class="uri">https://www.gnu.org/software/coreutils</a>.</p>
<pre>type wc
man wc#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="which" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">which</h2>
<p>명령어의 위치를 찾습니다.
<code>which</code> (버전 0.1) 제작자 미상 (2016).
더 많은 정보: .</p>
<pre>type which
man which#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="xml2json" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">xml2json</h2>
<p>xml-mapping을 사용하여 XML 입력을 JSON 출력으로 변환합니다.
<code>xml2json</code> (버전 0.0.3), François Parmentier 제작 (2016).
더 많은 정보: <a href="https://github.com/parmentf/xml2json" class="uri">https://github.com/parmentf/xml2json</a>.</p>
<pre>type xml2json</pre>
</div>
<div id="xmlstarlet" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">xmlstarlet</h2>
<p>커맨드 라인용 XML/XSLT 툴킷입니다.
<code>xmlstarlet</code> (버전 1.6.1), Dagobert Michelsen 외 다수 제작 (2019).
더 많은 정보: <a href="https://sourceforge.net/projects/xmlstar" class="uri">https://sourceforge.net/projects/xmlstar</a>.</p>
<pre>type xmlstarlet
man xmlstarlet#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="xsv" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">xsv</h2>
<p>Rust로 작성된 빠른 CSV 커맨드 라인 툴킷입니다.
<code>xsv</code> (버전 0.13.0), Andrew Gallant 제작 (2018).
더 많은 정보: <a href="https://github.com/BurntSushi/xsv" class="uri">https://github.com/BurntSushi/xsv</a>.</p>
<pre>type xsv
xsv --help#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="zcat" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">zcat</h2>
<p>파일의 압축을 해제하여 표준 출력으로 연결합니다.
<code>zcat</code> (버전 1.10), Paul Eggert 제작 (2021).
더 많은 정보: <a href="https://www.nongnu.org/zutils/zutils.html" class="uri">https://www.nongnu.org/zutils/zutils.html</a>.</p>
<pre>type zcat
man zcat#!enter=FALSE
C-C#!literal=FALSE</pre>
</div>
<div id="zsh" class="section level2 unnumbered" number="">
<h2 class="unnumbered" number="">zsh</h2>
<p>Z 쉘입니다.
<code>zsh</code> (버전 5.8), Paul Falstad 및 Peter Stephenson 제작 (2020).
더 많은 정보: <a href="https://www.zsh.org" class="uri">https://www.zsh.org</a>.</p>
<pre>type zsh
man zsh#!enter=FALSE
C-C#!literal=FALSE</pre>
<!--chapter:end:tools.Rmd-->
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><span class="citeproc-not-found" data-reference-id="jeroenhjanssens"><strong>???</strong></span><a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>유닉스 운영체제의 개발은 1969년에 시작되었습니다. 시작부터 커맨드 라인을 갖추고 있었습니다. <a href="#essential-concepts">2.3절</a>에서 다룰 파이프(pipes)라는 중요한 개념은 1973년에 추가되었습니다.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p><span class="citeproc-not-found" data-reference-id="Mason2010이"><strong>???</strong></span><a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p><span class="citeproc-not-found" data-reference-id="Patil2012는"><strong>???</strong></span><a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>Christopher Groskopf, <em>csvstat – Print Descriptive Statistics for Each Column in a CSV File</em>, version 1.0.5, 2020, <a href="https://csvkit.rtfd.org" role="doc-biblioref">https://csvkit.rtfd.org</a>.<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>Jeroen Janssens, <em>rush – R One-Liners from the Shell</em>, version 0.1, 2021, <a href="https://github.com/jeroenjanssens/rush" role="doc-biblioref">https://github.com/jeroenjanssens/rush</a>.<a href="#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p><span class="citeproc-not-found" data-reference-id="Shron2014의"><strong>???</strong></span><a href="#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>Ole Tange, <em>parallel – Build and Execute Shell Command Lines from Standard Input in Parallel</em>, version 20161222, 2016, <a href="https://www.gnu.org/software/parallel" role="doc-biblioref">https://www.gnu.org/software/parallel</a>.<a href="#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>Linus Torvalds and Junio C. Hamano, <em>git – the Stupid Content Tracker</em>, version 2.25.1, 2021, <a href="https://git-scm.com" role="doc-biblioref">https://git-scm.com</a>.<a href="#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>얼마나 많은 슈퍼컴퓨터가 리눅스를 실행하는지 추적하는 <a href="https://top500.org/statistics/details/osfam/1/">TOP500</a>을 참고하세요.<a href="#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>Richard M. Stallman and David MacKenzie, <em>ls – List Directory Contents</em>, version 8.30, 2019, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>Torbjorn Granlund and Richard M. Stallman, <em>cat – Concatenate Files and Print on the Standard Output</em>, version 8.30, 2018, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>Stephen Dolan, <em>jq – Command-Line JSON Processor</em>, version 1.6, 2021, <a href="https://stedolan.github.com/jq" role="doc-biblioref">https://stedolan.github.com/jq</a>.<a href="#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>Ulrich Drepper, <em>seq – Print a Sequence of Numbers</em>, version 8.30, 2019, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref14" class="footnote-back">↩︎</a></p></li>
<li id="fn15"><p>Jim Meyering, <em>pwd – Print Name of Working Directory</em>, version 8.30, 2019, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref15" class="footnote-back">↩︎</a></p></li>
<li id="fn16"><p>David MacKenzie and Jim Meyering, <em>head – Output the First Part of Files</em>, version 8.30, 2019, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref16" class="footnote-back">↩︎</a></p></li>
<li id="fn17"><p>David M. Ihnat and David MacKenzie, <em>paste – Merge Lines of Files</em>, version 8.30, 2019, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref17" class="footnote-back">↩︎</a></p></li>
<li id="fn18"><p>Philip A. Nelson, <em>bc – an Arbitrary Precision Calculator Language</em>, version 1.07.1, 2017, <a href="https://www.gnu.org/software/bc" role="doc-biblioref">https://www.gnu.org/software/bc</a>.<a href="#fnref18" class="footnote-back">↩︎</a></p></li>
<li id="fn19"><p>Eric S Raymond, <em>The Art of Unix Programming</em> (Addison-Wesley Professional, 2003).<a href="#fnref19" class="footnote-back">↩︎</a></p></li>
<li id="fn20"><p>Jim Meyering, <em>grep – Print Lines That Match Patterns</em>, version 3.4, 2019, <a href="https://www.gnu.org/software/grep" role="doc-biblioref">https://www.gnu.org/software/grep</a>.<a href="#fnref20" class="footnote-back">↩︎</a></p></li>
<li id="fn21"><p>Paul Rubin and David MacKenzie, <em>wc – Print Newline, Word, and Byte Counts for Each File</em>, version 8.30, 2019, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref21" class="footnote-back">↩︎</a></p></li>
<li id="fn22"><p>Mike Haertel and Paul Eggert, <em>sort – Sort Lines of Text Files</em>, version 8.30, 2019, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref22" class="footnote-back">↩︎</a></p></li>
<li id="fn23"><p>Karel Zak, <em>rev – Reverse Lines Characterwise</em>, version 2.36.1, 2021, <a href="https://www.kernel.org/pub/linux/utils/util-linux" role="doc-biblioref">https://www.kernel.org/pub/linux/utils/util-linux</a>.<a href="#fnref23" class="footnote-back">↩︎</a></p></li>
<li id="fn24"><p><a href="http://porkmail.org/era/unix/award.html">일부 사용자들</a>은 이것을 <code>cat</code>의 잘못된 사용(useless use of cat)이라고 생각합니다. <code>cat</code>의 목적은 파일들을 연결(concatenate)하는 것이며, 이 목적이 아니라면 프로세스 낭비라고 주장합니다. 저는 이것이 사소한 논쟁이라고 생각합니다. 우리에겐 더 중요한 할 일들이 많으니까요!<a href="#fnref24" class="footnote-back">↩︎</a></p></li>
<li id="fn25"><p>Colin Watson and Tollef Fog Heen, <em>sponge – Soak up Standard Input and Write to a File</em>, version 0.65, 2021, <a href="https://joeyh.name/code/moreutils" role="doc-biblioref">https://joeyh.name/code/moreutils</a>.<a href="#fnref25" class="footnote-back">↩︎</a></p></li>
<li id="fn26"><p>Jeroen Janssens, <em>dseq – Generate Sequence of Dates</em>, version 0.1, 2021, <a href="https://github.com/jeroenjanssens/dsutils" role="doc-biblioref">https://github.com/jeroenjanssens/dsutils</a>.<a href="#fnref26" class="footnote-back">↩︎</a></p></li>
<li id="fn27"><p>Scott Bartram and David MacKenzie, <em>nl – Number Lines of Files</em>, version 8.30, 2020, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref27" class="footnote-back">↩︎</a></p></li>
<li id="fn28"><p>Mike Parker, David MacKenzie, and Jim Meyering, <em>mv – Move (Rename) Files</em>, version 8.30, 2020, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref28" class="footnote-back">↩︎</a></p></li>
<li id="fn29"><p>Paul Rubin et al., <em>rm – Remove Files or Directories</em>, version 8.30, 2019, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref29" class="footnote-back">↩︎</a></p></li>
<li id="fn30"><p>Torbjorn Granlund, David MacKenzie, and Jim Meyering, <em>cp – Copy Files and Directories</em>, version 8.30, 2018, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref30" class="footnote-back">↩︎</a></p></li>
<li id="fn31"><p>David MacKenzie, <em>mkdir – Make Directories</em>, version 8.30, 2019, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref31" class="footnote-back">↩︎</a></p></li>
<li id="fn32"><p>John W. Eaton and Colin Watson, <em>man – an Interface to the System Reference Manuals</em>, version 2.9.1, 2020, <a href="https://nongnu.org/man-db" role="doc-biblioref">https://nongnu.org/man-db</a>.<a href="#fnref32" class="footnote-back">↩︎</a></p></li>
<li id="fn33"><p>Owen Voke, <em>tldr – Collaborative Cheatsheets for Console Commands</em>, version 3.3.7, 2021, <a href="https://tldr.sh" role="doc-biblioref">https://tldr.sh</a>.<a href="#fnref33" class="footnote-back">↩︎</a></p></li>
<li id="fn34"><p>Daniel Stenberg, <em>curl – Transfer a URL</em>, version 7.68.0, 2016, <a href="https://curl.haxx.se" role="doc-biblioref">https://curl.haxx.se</a>.<a href="#fnref34" class="footnote-back">↩︎</a></p></li>
<li id="fn35"><p>Christopher Groskopf, <em>in2csv – Convert Common, but Less Awesome, Tabular Data Formats to CSV</em>, version 1.0.5, 2020, <a href="https://csvkit.rtfd.org" role="doc-biblioref">https://csvkit.rtfd.org</a>.<a href="#fnref35" class="footnote-back">↩︎</a></p></li>
<li id="fn36"><p>Christopher Groskopf, <em>sql2csv – Execute an SQL Query on a Database and Output the Result to a CSV File</em>, version 1.0.5, 2020, <a href="https://csvkit.rtfd.org" role="doc-biblioref">https://csvkit.rtfd.org</a>.<a href="#fnref36" class="footnote-back">↩︎</a></p></li>
<li id="fn37"><p>John Gilmore and Jay Fenlason, <em>tar – an Archiving Utility</em>, version 1.30, 2014, <a href="https://www.gnu.org/software/tar" role="doc-biblioref">https://www.gnu.org/software/tar</a>.<a href="#fnref37" class="footnote-back">↩︎</a></p></li>
<li id="fn38"><p>Eric Chiang, <em>pup – Parsing Html at the Command Line</em>, version 0.4.0, 2016, <a href="https://github.com/EricChiang/pup" role="doc-biblioref">https://github.com/EricChiang/pup</a>.<a href="#fnref38" class="footnote-back">↩︎</a></p></li>
<li id="fn39"><p>Samuel H. Smith et al., <em>unzip – List, Test and Extract Compressed Files in a ZIP Archive</em>, version 6.0, 2009, <a href="http://www.info-zip.org/pub/infozip" role="doc-biblioref">http://www.info-zip.org/pub/infozip</a>.<a href="#fnref39" class="footnote-back">↩︎</a></p></li>
<li id="fn40"><p>Ben Asselstine, Christian Scheurer, and Johannes Winkelmann, <em>unrar – Extract Files from Rar Archives</em>, version 0.0.1, 2014, <a href="http://home.gna.org/unrar" role="doc-biblioref">http://home.gna.org/unrar</a>.<a href="#fnref40" class="footnote-back">↩︎</a></p></li>
<li id="fn41"><p>Patrick Brisbin, <em>unpack – Extract Common File Formats</em>, version 0.1, 2013, <a href="https://github.com/jeroenjanssens/dsutils" role="doc-biblioref">https://github.com/jeroenjanssens/dsutils</a>.<a href="#fnref41" class="footnote-back">↩︎</a></p></li>
<li id="fn42"><p>Yakov Shafranovich, “Common Format and MIME Type for Comma-Separated Values (CSV) Files,” 2005.<a href="#fnref42" class="footnote-back">↩︎</a></p></li>
<li id="fn43"><p>Christopher Groskopf, <em>csvlook – Render a CSV File in the Console as a Markdown-Compatible, Fixed-Width Table</em>, version 1.0.5, 2020, <a href="https://csvkit.rtfd.org" role="doc-biblioref">https://csvkit.rtfd.org</a>.<a href="#fnref43" class="footnote-back">↩︎</a></p></li>
<li id="fn44"><p><a href="https://github.com/r-dbi/RSQLite/blob/master/inst/db/datasets.sqlite">GitHub</a>에서 이용 가능합니다.<a href="#fnref44" class="footnote-back">↩︎</a></p></li>
<li id="fn45"><p>Mats Erik Andersson, Andreas Henriksson, and Christoph Biedl, <em>telnet – User Interface to the TELNET Protocol</em>, version 0.17, 1999, <a href="http://www.hcs.harvard.edu/~dholland/computers/netkit.html" role="doc-biblioref">http://www.hcs.harvard.edu/~dholland/computers/netkit.html</a>.<a href="#fnref45" class="footnote-back">↩︎</a></p></li>
<li id="fn46"><p>누군가 아카이브 메모리에서 삭제하여 서버에 연결할 수 없다면, 언제든 <a href="https://www.youtube.com/results?search_query=towel.blinkenlights.nl">YouTube의 <code>telnet</code> 세션 녹화본</a>을 감상할 수 있습니다.<a href="#fnref46" class="footnote-back">↩︎</a></p></li>
<li id="fn47"><p><em>Classic Shell Scripting</em> (O’Reilly Media, 2005).<a href="#fnref47" class="footnote-back">↩︎</a></p></li>
<li id="fn48"><p>Jim Meyering, <em>tr – Translate or Delete Characters</em>, version 8.30, 2018, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref48" class="footnote-back">↩︎</a></p></li>
<li id="fn49"><p>Meyering, <em>grep – Print Lines That Match Patterns</em>.<a href="#fnref49" class="footnote-back">↩︎</a></p></li>
<li id="fn50"><p>Haertel and Eggert, <em>sort – Sort Lines of Text Files</em>.<a href="#fnref50" class="footnote-back">↩︎</a></p></li>
<li id="fn51"><p>Richard M. Stallman and David MacKenzie, <em>uniq – Report or Omit Repeated Lines</em>, version 8.30, 2019, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref51" class="footnote-back">↩︎</a></p></li>
<li id="fn52"><p>Brian Fox and Chet Ramey, <em>bash – GNU Bourne-Again SHell</em>, version 5.0.17, 2019, <a href="https://www.gnu.org/software/bash" role="doc-biblioref">https://www.gnu.org/software/bash</a>.<a href="#fnref52" class="footnote-back">↩︎</a></p></li>
<li id="fn53"><p>David MacKenzie and Jim Meyering, <em>chmod – Change File Mode Bits</em>, version 8.30, 2018, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref53" class="footnote-back">↩︎</a></p></li>
<li id="fn54"><p>Benno Schulenberg et al., <em>nano – Nano’s ANOther editor, inspired by Pico</em>, version 5.4, 2020, <a href="https://nano-editor.org" role="doc-biblioref">https://nano-editor.org</a>.<a href="#fnref54" class="footnote-back">↩︎</a></p></li>
<li id="fn55"><p>The Python Software Foundation, <em>python – an Interpreted, Interactive, Object-Oriented Programming Language</em>, version 3.8.5, 2021, <a href="https://www.python.org" role="doc-biblioref">https://www.python.org</a>.<a href="#fnref55" class="footnote-back">↩︎</a></p></li>
<li id="fn56"><p>Richard Mlynarik, David MacKenzie, and Assaf Gordon, <em>env – Run a Program in a Modified Environment</em>, version 8.32, 2020, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref56" class="footnote-back">↩︎</a></p></li>
<li id="fn57"><p>The R Foundation for Statistical Computing, <em>R – a Language and Environment for Statistical Computing</em>, version 4.0.4, 2021, <a href="https://www.r-project.org" role="doc-biblioref">https://www.r-project.org</a>.<a href="#fnref57" class="footnote-back">↩︎</a></p></li>
<li id="fn58"><p>Jacob Perkins, <em>Python Text Processing with Nltk 2.0 Cookbook</em> (Packt Publishing, 2010).<a href="#fnref58" class="footnote-back">↩︎</a></p></li>
<li id="fn59"><p>Wes McKinney, <em>Python for Data Analysis</em> (O’Reilly Media, 2012).<a href="#fnref59" class="footnote-back">↩︎</a></p></li>
<li id="fn60"><p>이 코드는 <a href="https://github.com/joelgrus/fizzbuzz/blob/master/fizzbuzz/cycle_of_15.py">Joel Grus의 Python 스크립트</a>를 수정한 것입니다.<a href="#fnref60" class="footnote-back">↩︎</a></p></li>
<li id="fn61"><p>Meyering, <em>grep – Print Lines That Match Patterns</em>.<a href="#fnref61" class="footnote-back">↩︎</a></p></li>
<li id="fn62"><p>Mike D. Brennan and Thomas E. Dickey, <em>awk – Pattern Scanning and Text Processing Language</em>, version 1.3.4, 2019, <a href="https://invisible-island.net/mawk" role="doc-biblioref">https://invisible-island.net/mawk</a>.<a href="#fnref62" class="footnote-back">↩︎</a></p></li>
<li id="fn63"><p>Dolan, <em>jq – Command-Line JSON Processor</em>.<a href="#fnref63" class="footnote-back">↩︎</a></p></li>
<li id="fn64"><p>Chiang, <em>pup – Parsing Html at the Command Line</em>.<a href="#fnref64" class="footnote-back">↩︎</a></p></li>
<li id="fn65"><p>Stallman and MacKenzie, <em>uniq – Report or Omit Repeated Lines</em>.<a href="#fnref65" class="footnote-back">↩︎</a></p></li>
<li id="fn66"><p>Janssens, <em>rush – R One-Liners from the Shell</em>.<a href="#fnref66" class="footnote-back">↩︎</a></p></li>
<li id="fn67"><p>The Linux Information Project, “Plain Text Definition,” 2007, <a href="http://www.linfo.org/plain_text.html" role="doc-biblioref">http://www.linfo.org/plain_text.html</a>.<a href="#fnref67" class="footnote-back">↩︎</a></p></li>
<li id="fn68"><p>Andrew Hunt and David Thomas, <em>The Pragmatic Programmer</em> (Addison-Wesley, 1999).<a href="#fnref68" class="footnote-back">↩︎</a></p></li>
<li id="fn69"><p>Raymond, <em>The Art of Unix Programming</em>.<a href="#fnref69" class="footnote-back">↩︎</a></p></li>
<li id="fn70"><p>MacKenzie and Meyering, <em>head – Output the First Part of Files</em>.<a href="#fnref70" class="footnote-back">↩︎</a></p></li>
<li id="fn71"><p>Jay Fenlason et al., <em>sed – Stream Editor for Filtering and Transforming Text</em>, version 4.7, 2018, <a href="https://www.gnu.org/software/sed" role="doc-biblioref">https://www.gnu.org/software/sed</a>.<a href="#fnref71" class="footnote-back">↩︎</a></p></li>
<li id="fn72"><p>Paul Rubin et al., <em>tail – Output the Last Part of Files</em>, version 8.30, 2019, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref72" class="footnote-back">↩︎</a></p></li>
<li id="fn73"><p>Jeroen Janssens, <em>sample – Filter Lines from Standard Input According to Some Probability, with a Given Delay, and for a Certain Duration</em>, version 0.2.4, 2021, <a href="https://github.com/jeroenjanssens/sample" role="doc-biblioref">https://github.com/jeroenjanssens/sample</a>.<a href="#fnref73" class="footnote-back">↩︎</a></p></li>
<li id="fn74"><p>Joey Hess, <em>ts – Timestamp Input</em>, version 0.65, 2021, <a href="https://joeyh.name/code/moreutils" role="doc-biblioref">https://joeyh.name/code/moreutils</a>.<a href="#fnref74" class="footnote-back">↩︎</a></p></li>
<li id="fn75"><p>Meyering, <em>tr – Translate or Delete Characters</em>.<a href="#fnref75" class="footnote-back">↩︎</a></p></li>
<li id="fn76"><p>Jeroen Janssens, <em>body – Apply Command to All but the First Line</em>, version 0.1, 2021, <a href="https://github.com/jeroenjanssens/dsutils" role="doc-biblioref">https://github.com/jeroenjanssens/dsutils</a>.<a href="#fnref76" class="footnote-back">↩︎</a></p></li>
<li id="fn77"><p>Jeroen Janssens, <em>header – Add, Replace, and Delete Header Lines</em>, version 0.1, 2021, <a href="https://github.com/jeroenjanssens/dsutils" role="doc-biblioref">https://github.com/jeroenjanssens/dsutils</a>.<a href="#fnref77" class="footnote-back">↩︎</a></p></li>
<li id="fn78"><p>Jeroen Janssens, <em>cols – Apply Command to Subset of Columns</em>, version 0.1, 2021, <a href="https://github.com/jeroenjanssens/dsutils" role="doc-biblioref">https://github.com/jeroenjanssens/dsutils</a>.<a href="#fnref78" class="footnote-back">↩︎</a></p></li>
<li id="fn79"><p>Christopher Groskopf, <em>csvsql – Execute SQL Statements on CSV Files</em>, version 1.0.5, 2020, <a href="https://csvkit.rtfd.org" role="doc-biblioref">https://csvkit.rtfd.org</a>.<a href="#fnref79" class="footnote-back">↩︎</a></p></li>
<li id="fn80"><p>Christopher Groskopf, <em>csvcut – Filter and Truncate CSV Files</em>, version 1.0.5, 2020, <a href="https://csvkit.rtfd.org" role="doc-biblioref">https://csvkit.rtfd.org</a>.<a href="#fnref80" class="footnote-back">↩︎</a></p></li>
<li id="fn81"><p>Christopher Groskopf, <em>csvgrep – Search CSV Files</em>, version 1.0.5, 2020, <a href="https://csvkit.rtfd.org" role="doc-biblioref">https://csvkit.rtfd.org</a>.<a href="#fnref81" class="footnote-back">↩︎</a></p></li>
<li id="fn82"><p>Mike Parker, Richard M. Stallman, and David MacKenzie, <em>tee – Read from Standard Input and Write to Standard Output and Files</em>, version 8.30, 2019, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref82" class="footnote-back">↩︎</a></p></li>
<li id="fn83"><p>Ihnat and MacKenzie, <em>paste – Merge Lines of Files</em>.<a href="#fnref83" class="footnote-back">↩︎</a></p></li>
<li id="fn84"><p>Christopher Groskopf, <em>csvjoin – Execute a SQL-Like Join to Merge CSV Files on a Specified Column or Columns</em>, version 1.0.5, 2020, <a href="https://csvkit.rtfd.org" role="doc-biblioref">https://csvkit.rtfd.org</a>.<a href="#fnref84" class="footnote-back">↩︎</a></p></li>
<li id="fn85"><p>Chiang, <em>pup – Parsing Html at the Command Line</em>.<a href="#fnref85" class="footnote-back">↩︎</a></p></li>
<li id="fn86"><p>François Parmentier, <em>xml2json – Convert an XML Input to a JSON Output, Using xml-mapping</em>, version 0.0.3, 2016, <a href="https://github.com/parmentf/xml2json" role="doc-biblioref">https://github.com/parmentf/xml2json</a>.<a href="#fnref86" class="footnote-back">↩︎</a></p></li>
<li id="fn87"><p>Jehiah Czebotar, <em>json2csv – Convert JSON to CSV</em>, version 1.2.1, 2019, <a href="https://github.com/jehiah/json2csv" role="doc-biblioref">https://github.com/jehiah/json2csv</a>.<a href="#fnref87" class="footnote-back">↩︎</a></p></li>
<li id="fn88"><p>Stuart I. Feldman, <em>make – A Program for Maintaining Computer Programs</em>, version 4.3, 2020, <a href="https://www.gnu.org/software/make" role="doc-biblioref">https://www.gnu.org/software/make</a>.<a href="#fnref88" class="footnote-back">↩︎</a></p></li>
<li id="fn89"><p>Factual, <em>drake – Data Workflow Tool, Like a "Make for Data"</em>, version 1.0.3, 2016, <a href="https://github.com/Factual/drake" role="doc-biblioref">https://github.com/Factual/drake</a>.<a href="#fnref89" class="footnote-back">↩︎</a></p></li>
<li id="fn90"><p>Torvalds and Hamano, <em>git – the Stupid Content Tracker</em>.<a href="#fnref90" class="footnote-back">↩︎</a></p></li>
<li id="fn91"><p>Mark Nudelman, <em>less – Opposite of more</em>, version 551, 2019, <a href="https://www.greenwoodsoftware.com/less" role="doc-biblioref">https://www.greenwoodsoftware.com/less</a>.<a href="#fnref91" class="footnote-back">↩︎</a></p></li>
<li id="fn92"><p>Groskopf, <em>csvstat – Print Descriptive Statistics for Each Column in a CSV File</em>.<a href="#fnref92" class="footnote-back">↩︎</a></p></li>
<li id="fn93"><p>The R Foundation for Statistical Computing, <em>R – a Language and Environment for Statistical Computing</em>.<a href="#fnref93" class="footnote-back">↩︎</a></p></li>
<li id="fn94"><p>Janssens, <em>rush – R One-Liners from the Shell</em>.<a href="#fnref94" class="footnote-back">↩︎</a></p></li>
<li id="fn95"><p>Jeroen Janssens, <em>servewd – Serve the Current Working Directory Using a Simple HTTP Server</em>, version 0.1, 2021, <a href="https://github.com/jeroenjanssens/dsutils" role="doc-biblioref">https://github.com/jeroenjanssens/dsutils</a>.<a href="#fnref95" class="footnote-back">↩︎</a></p></li>
<li id="fn96"><p>Tange, <em>parallel – Build and Execute Shell Command Lines from Standard Input in Parallel</em>.<a href="#fnref96" class="footnote-back">↩︎</a></p></li>
<li id="fn97"><p>Nelson, <em>bc – an Arbitrary Precision Calculator Language</em>.<a href="#fnref97" class="footnote-back">↩︎</a></p></li>
<li id="fn98"><p>Stallman and MacKenzie, <em>ls – List Directory Contents</em>.<a href="#fnref98" class="footnote-back">↩︎</a></p></li>
<li id="fn99"><p>Eric B. Decker, James Youngman, and Kevin Dalley, <em>find – Search for Files in a Directory Hierarchy</em>, version 4.7.0, 2019, <a href="https://www.gnu.org/software/findutils" role="doc-biblioref">https://www.gnu.org/software/findutils</a>.<a href="#fnref99" class="footnote-back">↩︎</a></p></li>
<li id="fn100"><p>Hess, <em>ts – Timestamp Input</em>.<a href="#fnref100" class="footnote-back">↩︎</a></p></li>
<li id="fn101"><p>Jeroen Janssens, <em>pbc – Parallel bc</em>, version 0.1, 2021, <a href="https://github.com/jeroenjanssens/dsutils" role="doc-biblioref">https://github.com/jeroenjanssens/dsutils</a>.<a href="#fnref101" class="footnote-back">↩︎</a></p></li>
<li id="fn102"><p>Amazon Web Services, <em>aws – Unified Tool to Manage AWS Services</em>, version 2.1.32, 2021, <a href="https://aws.amazon.com/cli" role="doc-biblioref">https://aws.amazon.com/cli</a>.<a href="#fnref102" class="footnote-back">↩︎</a></p></li>
<li id="fn103"><p>Tatu Ylonen et al., <em>ssh – OpenSSH Remote Login Client</em>, version 1:8.2p1-4ubuntu0.2, 2020, <a href="https://www.openssh.com" role="doc-biblioref">https://www.openssh.com</a>.<a href="#fnref103" class="footnote-back">↩︎</a></p></li>
<li id="fn104"><p>Peter Tobias, Bernd Eckenfels, and Michael Meskes, <em>hostname – Show or Set the System’s Host Name</em>, version 3.23, 2021, <a href="https://sourceforge.net/projects/net-tools/" role="doc-biblioref">https://sourceforge.net/projects/net-tools/</a>.<a href="#fnref104" class="footnote-back">↩︎</a></p></li>
<li id="fn105"><p>Paul Eggert, <em>zcat – Decompress and Concatenate Files to Standard Output</em>, version 1.10, 2021, <a href="https://www.nongnu.org/zutils/zutils.html" role="doc-biblioref">https://www.nongnu.org/zutils/zutils.html</a>.<a href="#fnref105" class="footnote-back">↩︎</a></p></li>
<li id="fn106"><p>Janssens, <em>rush – R One-Liners from the Shell</em>.<a href="#fnref106" class="footnote-back">↩︎</a></p></li>
<li id="fn107"><p>Sergey Lisitsyn, Christian Widmer, and Fernando J. Iglesias Garcia, <em>tapkee – an Efficient Dimension Reduction Library</em>, version 1.2, 2013, <a href="http://tapkee.lisitsyn.me" role="doc-biblioref">http://tapkee.lisitsyn.me</a>.<a href="#fnref107" class="footnote-back">↩︎</a></p></li>
<li id="fn108"><p>John Langford, <em>vw – Fast Machine Learning Library for Online Learning</em>, version 8.10.1, 2021, <a href="https://vowpalwabbit.org" role="doc-biblioref">https://vowpalwabbit.org</a>.<a href="#fnref108" class="footnote-back">↩︎</a></p></li>
<li id="fn109"><p>Educational Testing Service, <em>skll – SciKit-Learn Laboratory</em>, version 2.5.0, 2021, <a href="https://skll.readthedocs.org" role="doc-biblioref">https://skll.readthedocs.org</a>.<a href="#fnref109" class="footnote-back">↩︎</a></p></li>
<li id="fn110"><p>Christopher Groskopf, <em>csvstack – Stack up the Rows from Multiple CSV Files</em>, version 1.0.5, 2020, <a href="https://csvkit.rtfd.org" role="doc-biblioref">https://csvkit.rtfd.org</a>.<a href="#fnref110" class="footnote-back">↩︎</a></p></li>
<li id="fn111"><p>K. Pearson, “On Lines and Planes of Closest Fit to Systems of Points in Space,” <em>Philosophical Magazine</em> 2, no. 11 (1901): 559–72.<a href="#fnref111" class="footnote-back">↩︎</a></p></li>
<li id="fn112"><p>Laurens van der Maaten and Geoffrey Everest Hinton, “Visualizing Data Using T-SNE,” <em>Journal of Machine Learning Research</em> 9 (2008): 2579–2605.<a href="#fnref112" class="footnote-back">↩︎</a></p></li>
<li id="fn113"><p>Sergey Lisitsyn, Christian Widmer, and Fernando J. Iglesias Garcia, “Tapkee: An Efficient Dimension Reduction Library,” <em>Journal of Machine Learning Research</em> 14 (2013): 2355–9.<a href="#fnref113" class="footnote-back">↩︎</a></p></li>
<li id="fn114"><p>Jeroen Janssens, <em>csv2vw – Convert CSV to Vowpal Wabbit Format</em>, version 0.1, 2021, <a href="https://github.com/jeroenjanssens/dsutils" role="doc-biblioref">https://github.com/jeroenjanssens/dsutils</a>.<a href="#fnref114" class="footnote-back">↩︎</a></p></li>
<li id="fn115"><p>Torbjorn Granlund and Richard M. Stallman, <em>split – Split a File into Pieces</em>, version 8.30, 2019, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref115" class="footnote-back">↩︎</a></p></li>
<li id="fn116"><p>Paul Eggert, <em>shuf – Generate Random Permutations</em>, version 8.30, 2019, <a href="https://www.gnu.org/software/coreutils" role="doc-biblioref">https://www.gnu.org/software/coreutils</a>.<a href="#fnref116" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<!--bookdown:body:end-->
  </main>

  <div class="col-md-3 col-lg-3 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page">
      <h2>On this page</h2>
      <div id="book-on-this-page"></div>

      <div class="book-extra">
        <ul class="list-unstyled">
          <li><a id="book-source" href="#">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="#">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
      </div>
    </nav>
  </div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5">
  <div class="container-fluid">
    <div class="row">
      <div class="d-none d-lg-block col-lg-2 sidebar"></div>
      <div class="col-sm-12 col-md-9 col-lg-7 mt-3" style="max-width: 45rem;">
        <p><strong>커맨드 라인에서 시작하는 데이터 과학, 2판</strong> by <a href="https://twitter.com/jeroenhjanssens" class="text-light">Jeroen Janssens</a>. Updated on January 29, 2026. This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
      </div>
      <div class="col-md-3 col-lg-3 d-none d-md-block sidebar"></div>
    </div>
  </div>
</footer>


</body>

</html>
