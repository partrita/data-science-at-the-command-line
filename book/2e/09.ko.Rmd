---
suppress-bibliography: true
---

```{r console_start, include=FALSE}
console_start()
```

```{console setup_history, include=FALSE}
 export CHAPTER="09"
 export HISTFILE=/history/history_${CHAPTER}
 rm -f $HISTFILE
```


# 데이터 모델링 {#chapter-9-modeling-data}

이 장에서는 OSEMN 모델의 네 번째 단계인 데이터 모델링을 수행합니다.
일반적으로 말해서 모델은 데이터에 대한 추상적이거나 높은 수준의 설명입니다.
모델링은 개별 데이터 포인트에서 한 걸음 물러나 더 큰 그림을 본다는 점에서 시각화를 만드는 것과 약간 비슷합니다.

시각화는 모양, 위치 및 색상으로 특징지어집니다. 즉, 보고 해석할 수 있습니다.
반면에 모델은 내부적으로 숫자로 특징지어지므로 컴퓨터가 예를 들어 새 데이터 포인트에 대한 예측을 하는 데 사용할 수 있습니다.
(모델을 이해하고 성능을 확인하기 위해 여전히 모델을 시각화할 수 있습니다.)

이 장에서는 데이터를 모델링하는 데 일반적으로 사용되는 세 가지 유형의 알고리즘을 고려합니다.

- 차원 축소
- 회귀
- 분류

이러한 알고리즘은 통계 및 기계 학습 분야에서 비롯되므로 어휘를 약간 변경하겠습니다.
CSV 파일( *데이터 세트*라고도 함)이 있다고 가정해 보겠습니다.
헤더를 제외한 각 행은 *데이터 포인트*로 간주됩니다.
각 데이터 포인트에는 측정된 하나 이상의 *기능* 또는 속성이 있습니다.
때로는 데이터 포인트에 *레이블*도 있으며, 이는 일반적으로 판단 또는 결과입니다.
아래에서 와인 데이터 세트를 소개할 때 이것이 더 구체적으로 됩니다.

첫 번째 유형의 알고리즘(차원 축소)은 대부분 비지도 학습이며, 이는 데이터 세트의 기능만을 기반으로 모델을 만듭니다.
마지막 두 가지 유형의 알고리즘(회귀 및 분류)은 정의상 지도 학습 알고리즘이며, 이는 레이블도 모델에 통합합니다.

```{block2, type="rmdcaution"}
이 장은 결코 기계 학습에 대한 소개가 아닙니다.
즉, 많은 세부 사항을 간략하게 설명해야 합니다.
일반적인 조언은 데이터에 적용하기 전에 알고리즘에 익숙해지는 것입니다.
이 장의 끝에서는 기계 학습에 대한 몇 가지 책을 추천합니다.
```

## 개요

이 장에서는 다음을 수행하는 방법을 배웁니다.

- `tapkee` [@tapkee]를 사용하여 데이터 세트의 차원을 줄입니다.
- `vw` [@vw]를 사용하여 화이트 와인의 품질을 예측합니다.
- `skll` [@skll]을 사용하여 와인을 레드 또는 화이트로 분류합니다.

이 장은 다음 파일로 시작합니다.

```{console cd}
cd /data/ch09
l
```

이러한 파일을 가져오는 지침은 [2장](#chapter-2-getting-started)에 있습니다.
다른 모든 파일은 명령줄 도구를 사용하여 다운로드하거나 생성됩니다.


## 와인 좀 더 주세요!

이 장 전체에서 포르투갈 와인인 비뉴 베르데의 레드 및 화이트 품종에 대한 와인 시음가의 노트 데이터 세트를 사용합니다.
각 데이터 포인트는 와인을 나타냅니다. 각 와인은 11가지 물리화학적 특성에 따라 평가됩니다. (1) 고정 산도, (2) 휘발성 산도, (3) 구연산, (4) 잔류 설탕, (5) 염화물, (6) 유리 아황산, (7) 총 아황산, (8) 밀도, (9) pH, (10) 황산염, (11) 알코올.
또한 0(매우 나쁨)에서 10(우수) 사이의 전체 품질 점수가 있으며, 이는 와인 전문가의 최소 3회 평가 중앙값입니다. 이 데이터 세트에 대한 자세한 내용은 [UCI 기계 학습 저장소](http://archive.ics.uci.edu/ml/datasets/Wine+Quality)에서 확인할 수 있습니다.

데이터 세트는 화이트 와인용과 레드 와인용 두 개의 파일로 나뉩니다.
가장 첫 번째 단계는 `curl`을 사용하여 두 파일을 얻는 것입니다(물론 하루 종일 걸리지 않도록 `parallel`도 사용합니다).

```{console}
parallel "curl -sL http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-{}.csv > wine-{}.csv" ::: red white#!enter=FALSE
C-C#!literal=FALSE
```

세 개의 콜론은 `parallel`에 데이터를 전달하는 또 다른 방법입니다.

```{console cp_cache_wine}
cp /data/.cache/wine-*.csv .
```

두 파일을 모두 검사하고 줄 수를 계산해 보겠습니다.

```{console, callouts=c(1, 2)}
< wine-red.csv nl |
fold |
trim
< wine-white.csv nl | fold | trim
wc -l wine-{red,white}.csv
```
<1> 명확성을 위해 `nl`을 사용하여 줄 번호를 추가합니다.
<2> 전체 헤더를 보려면 `fold`를 사용합니다.

언뜻 보기에는 이 데이터가 상당히 깨끗해 보입니다.
그래도 대부분의 명령줄 도구가 예상하는 것과 더 일치하도록 정제해 보겠습니다.
구체적으로 다음을 수행합니다.

- 헤더를 소문자로 변환합니다.
- 세미콜론을 쉼표로 바꿉니다.
- 공백을 밑줄로 바꿉니다.
- 불필요한 따옴표를 제거합니다.

`tr` 도구는 이러한 모든 작업을 처리할 수 있습니다.
이번에는 예전처럼 for 루프를 사용하여 두 파일을 모두 처리해 보겠습니다.

```{console}
for COLOR in red white; do
< wine-$COLOR.csv tr '[A-Z]; ' '[a-z],_' | tr -d \" > wine-${COLOR}-clean.csv
done
```

두 파일을 결합하여 단일 데이터 세트를 만들어 보겠습니다.
`csvstack`[@csvstack]을 사용하여 첫 번째 파일의 행에는 "red" 값을, 두 번째 파일의 행에는 "white" 값을 갖는 *type*이라는 열을 추가합니다.

```{console, callouts=c(1, 2)}
csvstack -g red,white -n type wine-{red,white}-clean.csv |
xsv select 2-,1 > wine.csv
```
<1> 새 열 *type*은 `csvstack`에 의해 맨 앞에 배치됩니다.
<2> 일부 알고리즘은 레이블이 마지막 열이라고 가정하므로 `xsv`를 사용하여 열 *type*을 끝으로 이동합니다.

이 데이터 세트에 누락된 값이 있는지 확인하는 것이 좋습니다. 대부분의 기계 학습 알고리즘은 누락된 값을 처리할 수 없기 때문입니다.

```{console}
csvstat wine.csv --nulls
```

훌륭합니다!
누락된 값이 있으면 해당 기능의 평균 또는 가장 일반적인 값으로 채울 수 있습니다.
덜 미묘한 대안적인 접근 방식은 누락된 값이 하나 이상 있는 데이터 포인트를 제거하는 것입니다.
그냥 궁금해서 레드 와인과 화이트 와인 모두 품질 분포가 어떻게 보이는지 살펴보겠습니다.

```{console}
rush run -t 'ggplot(df, aes(x = quality, fill = type)) + geom_density(adjust = 3, alpha = 0.5)' wine.csv > wine-quality.png
display wine-quality.png
```
```{r plot_wine_quality, echo=FALSE, fig.cap="밀도 플롯을 사용하여 레드 와인과 화이트 와인의 품질 비교", fig.align="center", out.width="90%"}
knitr::include_graphics("images/wine-quality.png")
```

밀도 플롯에서 화이트 와인의 품질이 더 높은 값으로 분포되어 있음을 알 수 있습니다.
이것은 화이트 와인이 전반적으로 레드 와인보다 낫다는 것을 의미합니까, 아니면 화이트 와인 전문가가 레드 와인 전문가보다 더 쉽게 높은 점수를 준다는 것을 의미합니까?
그것은 데이터가 우리에게 알려주지 않는 것입니다.
아니면 알코올과 품질 사이에 관계가 있을까요?
`rush`를 사용하여 알아봅시다.

```{console}
rush plot --x alcohol --y quality --color type --geom smooth wine.csv > wine-alcohol-vs-quality.png
display wine-alcohol-vs-quality.png
```
```{r plot_wine_alchohol_vs_quality, echo=FALSE, fig.cap="와인의 알코올 함량과 품질 간의 관계", fig.align="center", out.width="90%"}
knitr::include_graphics("images/wine-alcohol-vs-quality.png")
```

유레카! 흠, 모델링을 좀 더 해볼까요?


## Tapkee를 사용한 차원 축소

차원 축소의 목표는 고차원 데이터 포인트를 저차원 매핑에 매핑하는 것입니다.
과제는 유사한 데이터 포인트를 저차원 매핑에서 가깝게 유지하는 것입니다.
이전 섹션에서 보았듯이 와인 데이터 세트에는 13개의 기능이 포함되어 있습니다.
시각화하기 쉽기 때문에 두 가지 차원을 고수할 것입니다.

차원 축소는 종종 탐색의 일부로 간주됩니다.
플로팅할 기능이 너무 많을 때 유용합니다.
산점도 행렬을 수행할 수 있지만 한 번에 두 가지 기능만 보여줍니다.
다른 기계 학습 알고리즘의 전처리 단계로도 유용합니다.

대부분의 차원 축소 알고리즘은 비지도 학습입니다.
즉, 저차원 매핑을 구성하기 위해 데이터 포인트의 레이블을 사용하지 않습니다.

이 섹션에서는 주성분 분석(PCA) [@Pearson1901]과 t-분포 확률적 이웃 임베딩(t-SNE) [@van2008visualizing]이라는 두 가지 기술을 살펴봅니다.


### Tapkee 소개

Tapkee는 차원 축소를 위한 C++ 템플릿 라이브러리입니다 [@Lisitsyn2013].
이 라이브러리에는 다음을 포함한 많은 차원 축소 알고리즘 구현이 포함되어 있습니다.

- 로컬 선형 임베딩
- 아이소맵
- 다차원 스케일링
- PCA
- t-SNE

이러한 알고리즘에 대한 자세한 내용은 [Tapkee 웹사이트](http://tapkee.lisitsyn.me/)에서 확인할 수 있습니다.
Tapkee는 주로 다른 응용 프로그램에 포함될 수 있는 라이브러리이지만 명령줄 도구 `tapkee`도 제공합니다.
이를 사용하여 와인 데이터 세트에 대한 차원 축소를 수행합니다.


### 선형 및 비선형 매핑

먼저 표준화를 사용하여 기능을 확장하여 각 기능이 동일하게 중요하도록 합니다.
이는 일반적으로 기계 학습 알고리즘을 적용할 때 더 나은 결과를 가져옵니다.

확장하려면 `rush`와 `tidyverse` 패키지를 사용합니다.

```{console, callouts=c(2:5)}
rush run --tidyverse --output wine-scaled.csv \
'select(df, -type) %>%
scale() %>%
as_tibble() %>%
mutate(type = df$type)' wine.csv
csvlook wine-scaled.csv
```
<1> `scale()`은 숫자 열에서만 작동하므로 *`type`* 열을 임시로 제거해야 합니다.
<2> `scale()` 함수는 데이터 프레임을 허용하지만 행렬을 반환합니다.
<3> 함수 `as_tibble()`은 행렬을 다시 데이터 프레임으로 변환합니다.
<4> 마지막으로 *`type`* 열을 다시 추가합니다.

이제 두 가지 차원 축소 기술을 모두 적용하고 `Rio-scatter`를 사용하여 매핑을 시각화합니다.

```{console create_wine_pca, callouts=1:3}
xsv select '!type' wine-scaled.csv |
header -d |
tapkee --method pca |
tee wine-pca.txt | trim
```
<1> *`type`* 열 선택 취소
<2> 헤더 제거
<3> PCA 적용

```{console apply_pca, callouts=1:2}
< wine-pca.txt header -a pc1,pc2 |
paste -d, - <(xsv select type wine-scaled.csv) |
tee wine-pca.csv | csvlook
```
<1> *`pc1`*과 *`pc2`* 열이 있는 헤더 다시 추가
<2> *`type`* 열 다시 추가

이제 산점도를 만들 수 있습니다.

```{console plot_pca}
rush plot --x pc1 --y pc2 --color type --shape type wine-pca.csv > wine-pca.png
display wine-pca.png
```
```{r, echo=FALSE, fig.cap="PCA를 사용한 선형 차원 축소", fig.align="center", out.width="90%"}
knitr::include_graphics("images/wine-pca.png")
```

동일한 접근 방식으로 t-SNE를 수행해 보겠습니다.

```{console apply_tsne, callouts=1:6}
xsv select '!type' wine-scaled.csv |
header -d |
tapkee --method t-sne |
header -a x,y |
paste -d, - <(xsv select type wine-scaled.csv) |
rush plot --x x --y y --color type --shape type > wine-tsne.png
```
<1> *`type`* 열 선택 취소
<2> 헤더 제거
<3> t-SNE 적용
<4> *`x`*와 *`y`* 열이 있는 헤더 다시 추가
<5> *`type`* 열 다시 추가
<6> 산점도 만들기

```{console}
display wine-tsne.png
```
```{r, echo=FALSE, fig.cap="t-SNE를 사용한 비선형 차원 축소", fig.align="center", out.width="90%"}
knitr::include_graphics("images/wine-tsne.png")
```

t-SNE가 물리화학적 특성을 기반으로 레드 와인과 화이트 와인을 분리하는 데 PCA보다 더 나은 작업을 수행하는 것을 볼 수 있습니다.
이러한 산점도는 데이터 세트에 특정 구조가 있음을 확인합니다. 즉, 기능과 레이블 사이에 관계가 있습니다.
이를 알고 있으므로 지도 기계 학습을 적용하여 앞으로 나아가는 데 편안합니다.
회귀 작업부터 시작한 다음 분류 작업으로 계속 진행하겠습니다.


## Vowpal Wabbit을 사용한 회귀

이 섹션에서는 물리화학적 특성을 기반으로 화이트 와인의 품질을 예측하는 모델을 만듭니다.
품질은 0에서 10 사이의 숫자이므로 이것을 회귀 작업으로 간주할 수 있습니다.

이를 위해 Vowpal Wabbit 또는 `vw`를 사용합니다.



### 데이터 준비

CSV로 작업하는 대신 `vw`에는 자체 데이터 형식이 있습니다.
도구 `csv2vw`[@csv2vw]는 이름에서 알 수 있듯이 CSV를 이 형식으로 변환할 수 있습니다.
`--label` 옵션은 레이블이 포함된 열을 나타내는 데 사용됩니다.
결과를 살펴보겠습니다.

```{console}
csv2vw wine-white-clean.csv --label quality | trim
```

이 형식에서 각 줄은 하나의 데이터 포인트입니다.
줄은 레이블로 시작하고 파이프 기호가 뒤따르며 공백으로 구분된 기능 이름/값 쌍이 이어집니다.
이 형식은 CSV 형식과 비교할 때 지나치게 장황해 보일 수 있지만 가중치, 태그, 네임스페이스 및 희소 기능 표현과 같은 더 많은 유연성을 제공합니다.
와인 데이터 세트에서는 이러한 유연성이 필요하지 않지만 더 복잡한 문제에 `vw`를 적용할 때 유용할 수 있습니다.
이 [기사](https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Input-format)는 `vw` 형식을 더 자세히 설명합니다.

회귀 모델을 만들거나 *훈련*한 후에는 새롭고 보이지 않는 데이터 포인트에 대한 예측을 하는 데 사용할 수 있습니다.
즉, 모델에 이전에 보지 못한 와인을 제공하면 품질을 예측하거나 *테스트*할 수 있습니다.
이러한 예측의 정확도를 올바르게 평가하려면 훈련에 사용되지 않을 일부 데이터를 따로 보관해야 합니다.
일반적으로 전체 데이터 세트의 80%를 훈련에 사용하고 나머지 20%를 테스트에 사용합니다.

먼저 `split`[@split]을 사용하여 전체 데이터 세트를 5개의 동일한 부분으로 분할하여 이를 수행할 수 있습니다.
`wc`를 사용하여 각 부분의 데이터 포인트 수를 확인합니다.

```{console, callouts=2}
csv2vw wine-white-clean.csv --label quality |
shuf |
split -d -n r/5 - wine-part-
wc -l wine-part-*
```
<1> 도구 `shuf`[@shuf]는 훈련 세트와 테스트 세트 모두 유사한 품질 분포를 갖도록 데이터 세트를 무작위화합니다.

이제 첫 번째 부분(즉, 20%)을 테스트 세트 *wine-test.vw*에 사용하고 나머지 네 부분(즉, 80%)을 훈련 세트 *wine-train.vw*에 결합할 수 있습니다.

```{console}
mv wine-part-00 wine-test.vw
cat wine-part-* > wine-train.vw
rm wine-part-*
wc -l wine-*.vw
```

이제 `vw`를 사용하여 모델을 훈련할 준비가 되었습니다.


### 모델 훈련

도구 `vw`는 다양한 옵션(거의 400개!)을 허용합니다.
다행히 효과적으로 사용하기 위해 모든 옵션이 필요한 것은 아닙니다.
여기서 사용하는 옵션에 주석을 달기 위해 각 옵션을 별도의 줄에 배치합니다.

```{console, callouts=2:9}
vw \
--data wine-train.vw \
--final_regressor wine.model \
--passes 10 \
--cache_file wine.cache \
--nn 3 \
--quadratic :: \
--l2 0.000005 \
--bit_precision 25
```
<1> 파일 *wine-train.vw*는 모델을 훈련하는 데 사용됩니다.
<2> 모델 또는 *회귀자*는 파일 *wine.model*에 저장됩니다.
<3> 훈련 패스 수입니다.
<4> 여러 패스를 만들 때 캐싱이 필요합니다.
<5> 3개의 은닉 단위를 가진 신경망을 사용합니다.
<6> 모든 입력 기능을 기반으로 이차 기능을 만들고 사용합니다. 중복 항목은 `vw`에서 제거됩니다.
<7> l2 정규화를 사용합니다.
<8> 기능을 저장하는 데 25비트를 사용합니다.

이제 회귀 모델을 훈련했으므로 예측을 해보겠습니다.


### 모델 테스트

모델은 파일 *wine.model*에 저장됩니다.
해당 모델을 사용하여 예측하려면 다른 옵션 세트로 `vw`를 다시 실행합니다.

```{console, callouts=2:6}
vw \
--data wine-test.vw \
--initial_regressor wine.model \
--testonly \
--predictions predictions \
--quiet
bat predictions | trim
```
<1> 파일 *wine-test.vw*는 모델을 테스트하는 데 사용됩니다.
<2> 파일 *wine.model*에 저장된 모델을 사용합니다.
<3> 레이블 정보를 무시하고 테스트만 합니다.
<4> 예측은 *predictions*라는 파일에 저장됩니다.
<5> 진단 및 진행률 업데이트를 출력하지 않습니다.

`paste`를 사용하여 파일 *predictions*의 예측과 파일 *wine-test.vw*에 있는 실제 또는 *관찰된* 값을 결합해 보겠습니다.
`awk`를 사용하여 예측된 값과 관찰된 값을 비교하고 평균 절대 오차(MAE)를 계산할 수 있습니다.
MAE는 화이트 와인의 품질을 예측할 때 `vw`가 평균적으로 얼마나 벗어나는지 알려줍니다.

```{console callouts="cowsay"}
paste -d, predictions <(cut -d '|' -f 1 wine-test.vw) |
tee results.csv |
awk -F, '{E+=sqrt(($1-$2)^2)} END {print "MAE: " E/NR}' |
cowsay
```

따라서 예측은 평균적으로 약 0.6포인트 벗어납니다.
`rush plot`을 사용하여 관찰된 값과 예측된 값 간의 관계를 시각화해 보겠습니다.

```{console}
< results.csv header -a "predicted,observed" |
rush plot --x observed --y predicted --geom jitter > wine-regression.png
display wine-regression.png
```
```{r, echo=FALSE, fig.cap="Vowpal Wabbit을 사용한 회귀", fig.align="center", out.width="90%"}
knitr::include_graphics("images/wine-regression.png")
```

모델을 훈련하는 데 사용된 옵션이 다소 부담스러울 수 있다는 것을 이해합니다.
모든 기본값을 사용할 때 `vw`가 어떻게 수행되는지 살펴보겠습니다.

```{console, callouts=c(1, 3, 5)}
vw -d wine-train.vw -f wine2.model --quiet
vw -data wine-test.vw -i wine2.model -t -p predictions --quiet
paste -d, predictions <(cut -d '|' -f 1 wine-test.vw) |
awk -F, '{E+=sqrt(($1-$2)^2)} END {print "MAE: " E/NR}'
```
<1> 회귀 모델 훈련
<2> 회귀 모델 테스트
<3> 평균 절대 오차 계산

분명히 기본값을 사용하면 MAE가 0.04 더 높으므로 예측이 약간 더 나쁩니다.

이 섹션에서는 `vw`가 할 수 있는 작업의 일부만 다루었습니다.
매우 많은 옵션을 허용하는 데에는 이유가 있습니다.
회귀 외에도 이진 분류, 다중 클래스 분류, 강화 학습, 잠재 디리클레 할당 등을 지원합니다.
[웹사이트](https://vowpalwabbit.org/)에는 더 자세히 알아볼 수 있는 많은 자습서와 기사가 있습니다.


## SciKit-Learn Laboratory를 사용한 분류

<!-- TODO: Explain SKLL better -->

이 섹션에서는 와인이 레드인지 화이트인지 예측하는 분류 모델 또는 *분류기*를 훈련합니다.
이를 위해 `vw`를 사용할 수도 있지만 다른 도구인 SciKit-Learn Laboratory(SKLL)를 보여 드리고자 합니다.
이름에서 알 수 있듯이 Python용 인기 있는 기계 학습 패키지인 SciKit-Learn 위에 구축되었습니다.
SKLL 자체는 Python 패키지이며 명령줄에서 SciKit-Learn을 사용할 수 있도록 하는 `run_experiment` 도구를 제공합니다.
`run_experiment` 대신 패키지 이름과 일치하여 기억하기 쉽기 때문에 별칭 `skll`을 사용합니다.

```{console skll_alias}
alias skll=run_experiment
skll
```


### 데이터 준비

`skll`은 훈련 및 테스트 데이터 세트가 별도의 디렉터리에 있는 동일한 파일 이름을 갖도록 예상합니다.
예측이 반드시 원래 데이터 세트와 동일한 순서는 아니므로 예측을 올바른 데이터 포인트와 일치시킬 수 있도록 고유 식별자가 포함된 *`id`* 열을 추가합니다.
균형 잡힌 데이터 세트를 만들어 보겠습니다.

```{console skll_create_features, callouts=c("NUM_RED", "csvstack", "nl", "sed")}
NUM_RED="$(< wine-red-clean.csv wc -l)"
csvstack -n type -g red,white \
wine-red-clean.csv \
<(< wine-white-clean.csv body shuf | head -n $NUM_RED) |
body shuf |
nl -s, -w1 -v0 |
sed '1s/0,/id,/' |
tee wine-balanced.csv | csvlook
```
<1> 레드 와인 수를 변수 *`NUM_RED`*에 저장합니다.
<2> 모든 레드 와인을 화이트 와인의 무작위 샘플과 결합합니다.
<3> 각 줄 앞에 `nl`을 사용하여 "줄 번호"를 추가합니다.
<4> 첫 번째 줄의 "0"을 "id"로 바꾸어 적절한 열 이름이 되도록 합니다.

이 균형 잡힌 데이터 세트를 훈련 세트와 테스트 세트로 분할해 보겠습니다.

```{console}
mkdir -p {train,test}
HEADER="$(< wine-balanced.csv header)"
< wine-balanced.csv header -d | shuf | split -d -n r/5 - wine-part-
wc -l wine-part-*
cat wine-part-00 | header -a $HEADER > test/features.csv && rm wine-part-00
cat wine-part-* | header -a $HEADER > train/features.csv && rm wine-part-*
wc -l t*/features.csv
```

이제 균형 잡힌 훈련 데이터 세트와 균형 잡힌 테스트 데이터 세트가 있으므로 분류기를 빌드할 수 있습니다.


### 실험 실행

`skll`에서 분류기를 훈련하는 것은 구성 파일에서 실험을 정의하여 수행됩니다.
데이터 세트를 찾을 위치, 분류기 등을 지정하는 여러 섹션으로 구성됩니다.
다음은 사용할 구성 파일 *classify.cfg*입니다.

```{console bat_cfg}
bat classify.cfg
```

`skll`을 사용하여 실험을 실행합니다.

```{console skll}
skll -l classify.cfg 2>/dev/null
```

옵션 `-l`은 로컬 모드에서 실행하도록 지정합니다.
`skll`은 클러스터에서 실험을 실행할 수 있는 가능성도 제공합니다.
실험을 실행하는 데 걸리는 시간은 선택한 알고리즘의 복잡성과 데이터 크기에 따라 다릅니다.


### 결과 구문 분석

모든 분류기가 훈련되고 테스트되면 *output* 디렉터리에서 결과를 찾을 수 있습니다.

```{console ls_output}
ls -1 output
```

`skll`은 각 분류기에 대해 네 개의 파일을 생성합니다. 로그 하나, 결과 두 개, 예측 하나입니다.
다음 SQL 쿼리를 사용하여 알고리즘 이름을 추출하고 정확도별로 정렬합니다.

```{console}
< output/wine_summary.tsv csvsql --query "SELECT learner_name, accuracy FROM stdin ORDER BY accuracy DESC" | csvlook -I
```

여기서 관련 열은 올바르게 분류된 데이터 포인트의 백분율을 나타내는 *`accuracy`*입니다.
이것으로부터 실제로 모든 알고리즘이 매우 잘 수행됨을 알 수 있습니다.
RandomForestClassifier가 가장 성능이 좋은 알고리즘으로 나타났으며 KNeighborsClassifier가 그 뒤를 바짝 쫓고 있습니다.

각 JSON 파일에는 각 분류기의 성능에 대한 추가 통찰력을 제공하는 혼동 행렬이 포함되어 있습니다.
혼동 행렬은 열이 실제 레이블(빨간색과 흰색)을 나타내고 행이 예측된 레이블을 나타내는 테이블입니다.
대각선에 숫자가 높을수록 예측이 더 정확하다는 의미입니다.
`jq`를 사용하면 각 분류기의 이름과 관련 혼동 행렬을 인쇄할 수 있습니다.

```{console}
jq -r '.[] | "\(.learner_name):\n\(.result_table)\n"' output/*.json
```

혼동 행렬은 클래스가 두 개 이상인 경우 특히 유용하므로 어떤 종류의 오분류가 발생하는지 확인할 수 있으며 잘못된 분류 비용이 각 클래스에 대해 동일하지 않은 경우에도 유용합니다.

사용 관점에서 `vw`와 `skll`이 두 가지 다른 접근 방식을 취한다는 점이 흥미롭습니다.
`vw`는 명령줄 옵션을 사용하는 반면 `skll`은 별도의 파일이 필요합니다.
두 접근 방식 모두 장단점이 있습니다.
명령줄 옵션은 더 많은 임시 사용을 가능하게 하지만 구성 파일은 아마도 재현하기가 더 쉬울 것입니다.
그러나 보았듯이 여러 옵션으로 `vw`를 호출하는 것은 스크립트나 *Makefile*에 쉽게 배치할 수 있습니다.
반대로 `skll`이 구성 파일이 필요하지 않도록 옵션을 허용하도록 만드는 것은 덜 간단합니다.


## 요약

이 장에서는 데이터 모델링을 살펴보았습니다.
예제를 통해 비지도 학습인 차원 축소와 지도 학습인 회귀 및 분류라는 세 가지 다른 기계 학습 작업을 살펴보았습니다.
적절한 기계 학습 자습서는 안타깝게도 이 책의 범위를 벗어납니다.
다음 섹션에서는 기계 학습에 대해 더 자세히 알고 싶은 경우를 대비하여 몇 가지 권장 사항을 제공합니다.
이것은 이 책에서 다루는 데이터 과학을 위한 OSEMN 모델의 네 번째이자 마지막 단계였습니다.
다음 장은 마지막 막간 장이며 다른 곳에서 명령줄을 활용하는 것에 관한 것입니다.


## 추가 탐색을 위해

- Sebastian Raschka와 Vahid Mirjalili의 책 *Python Machine Learning*은 기계 학습에 대한 포괄적인 개요와 Python을 사용하여 적용하는 방법을 제공합니다.
- Jared Lander의 책 *R for Everyone*의 뒷부분에서는 R을 사용하여 다양한 기계 학습 작업을 수행하는 방법을 설명합니다.
- 기계 학습에 대한 더 깊은 이해를 원한다면 Christopher Bishop의 *Pattern Recognition and Machine Learning*과 David MacKay의 *Information Theory, Inference, and Learning Algorithms*를 강력히 추천합니다.
- t-SNE 알고리즘에 대해 더 자세히 알고 싶다면 Laurens van der Maaten과 Geoffrey Hinton의 원본 논문인 *Visualizing Data Using T-SNE*를 추천합니다.
