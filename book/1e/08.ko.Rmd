# 병렬 파이프라인 {#chapter-8-parallel-pipelines}

이전 장에서는 전체 작업을 한 번에 처리하는 명령과 파이프라인을 다루었습니다. 그러나 실제로는 동일한 명령이나 파이프라인을 여러 번 실행해야 하는 작업에 직면할 수 있습니다. 예를 들어 다음과 같은 작업이 필요할 수 있습니다.

- 수백 개의 웹 페이지 스크랩.
- 수십 개의 API 호출을 수행하고 해당 출력을 변환합니다.
- 다양한 매개변수 값에 대해 분류기를 학습합니다.
- 데이터 세트의 모든 기능 쌍에 대한 산점도를 생성합니다.

위의 예에서 어떤 형태의 반복이 포함됩니다. 즐겨 사용하는 스크립팅 또는 프로그래밍 언어를 사용하면 for 루프 또는 while 루프로 이를 처리합니다. 명령줄에서 가장 먼저 하고 싶은 일은 `<Up>` 키를 누르고(이전 명령을 다시 가져옴) 필요한 경우 수정하고 `<Enter>` 키를 누르는 것입니다(명령을 다시 실행함). 두세 번은 괜찮지만 예를 들어 수십 개의 파일에 대해 이 작업을 수행한다고 상상해 보십시오. 이러한 접근 방식은 금방 번거롭고 시간 비효율적이 됩니다. 좋은 소식은 명령줄에서도 이러한 루프를 작성할 수 있다는 것입니다. 이 장은 반복에 관한 것입니다.

때로는 빠른 명령을 차례로 반복하는 것(직렬)으로 충분합니다. 여러 코어(그리고 어쩌면 여러 시스템)가 있는 경우 특히 데이터 집약적인 작업에 직면했을 때 이를 활용할 수 있다면 좋을 것입니다. 여러 코어 또는 시스템을 사용하면 총 실행 시간이 크게 줄어들 수 있습니다. 이 장에서는 정확히 이를 처리할 수 있는 매우 강력한 도구인 GNU Parallel을 소개합니다. GNU Parallel을 사용하면 숫자, 줄, 파일과 같은 다양한 인수를 사용하여 명령이나 파이프라인을 적용할 수 있습니다. 또한 명령을 병렬로 실행할 수 있습니다.

## 개요

이 막간 장에서는 명령과 파이프라인을 여러 번 실행해야 하는 작업의 속도를 높이는 몇 가지 접근 방식을 설명합니다. 이 장의 주요 목표는 GNU Parallel이라는 도구의 유연성과 강력함을 보여주는 것입니다. 이 도구는 이 책에서 설명하는 다른 모든 도구와 결합할 수 있으므로 데이터 과학을 위해 명령줄을 사용하는 방식을 긍정적으로 바꿀 것입니다. 이 장에서는 다음에 대해 배웁니다.

- 숫자, 줄, 파일 범위에 대해 직렬로 명령을 실행합니다.
- 큰 작업을 여러 개의 작은 작업으로 나눕니다.
- GNU Parallel을 사용하여 병렬로 파이프라인을 실행합니다.
- 여러 시스템에 파이프라인을 배포합니다.

## 직렬 처리

병렬화에 대해 알아보기 전에 직렬 방식으로 루핑하는 것을 살펴보겠습니다. 이 기능은 항상 사용할 수 있고 구문이 다른 프로그래밍 언어의 루핑과 매우 유사하며 GNU Parallel 도구를 정말로 감사하게 될 것이므로 이 방법을 아는 것이 좋습니다.

이 장의 소개에 제공된 예에서 루프할 세 가지 유형의 항목을 추출할 수 있습니다. (1) 숫자, (2) 줄, (3) 파일. 이 세 가지 유형의 항목은 다음 세 하위 섹션에서 각각 설명합니다.

### 숫자에 대한 루핑

0에서 100 사이의 모든 짝수의 제곱을 계산해야 한다고 상상해 보십시오. `bc`라는 도구가 있는데, 기본적으로 방정식을 파이프할 수 있는 명령줄 계산기입니다. 4의 제곱을 계산하는 명령은 다음과 같습니다.

```{bash, eval=FALSE}
$ echo "4^2" | bc
16
```

일회성 계산에는 완벽합니다. 그러나 소개에서 언급했듯이 `<Up>` 키를 누르고 숫자를 변경하고 `<Enter>` 키를 51번 누르는 것은 미친 짓일 것입니다! 이 경우 for 루프를 사용하여 Bash가 힘든 작업을 수행하도록 하는 것이 좋습니다.

```{bash, eval=FALSE}
$ for i in {0..100..2}
> do
> echo "$i^2" | bc
> done | tail
6724
7056
7396
7744
8100
8464
8836
9216
9604
10000
```

여기에는 여러 가지 일이 진행 중입니다.

- Bash에는 중괄호 확장이라는 기능이 있으며, 이는 *{0..100..2}*를 공백으로 구분된 목록(*0 2 4 … 98 100*)으로 변환합니다.
- 변수 *i*는 첫 번째 반복에서 값 *1*을, 두 번째 반복에서 *2*를 할당받는 식으로 진행됩니다. 이 변수의 값은 달러 기호 *\$*를 접두사로 붙여 명령에서 사용할 수 있습니다. 셸은 `echo`가 실행되기 전에 *\$i*를 해당 값으로 바꿉니다. `do`와 `done` 사이에 둘 이상의 명령이 있을 수 있습니다.
- for 루프의 출력을 `tail`로 파이프하여 마지막 10개 값만 표시합니다.

구문이 즐겨 사용하는 프로그래밍 언어와 비교하여 약간 이상하게 보일 수 있지만 bash 셸에서 항상 사용할 수 있으므로 기억할 가치가 있습니다. 곧 명령을 반복하는 더 좋고 유연한 방법을 소개합니다.

### 줄에 대한 루핑

루프할 수 있는 두 번째 유형의 항목은 줄입니다. 이러한 줄은 파일이나 표준 입력에서 올 수 있습니다. 줄에는 숫자, 날짜, 이메일 주소 등 무엇이든 포함될 수 있으므로 매우 일반적인 접근 방식입니다.

고객에게 이메일을 보내고 싶다고 상상해 보십시오. <https://randomuser.me/> API를 사용하여 가짜 사용자를 생성해 보겠습니다.

```{bash, eval=FALSE}
$ curl -s "https://randomuser.me/api/1.2/?results=5" > data/users.json
$ < data/users.json jq -r '.results[].email' > data/emails.txt
$ cat data/emails.txt
kaylee.anderson64@example.com
arthur.baker92@example.com
chloe.graham66@example.com
wyatt.nelson80@example.com
peter.coleman75@example.com
```

while 루프를 사용하여 *emails.txt*의 줄을 반복할 수 있습니다.

```{bash, eval=FALSE}
$ while read line
> do
> echo "Sending invitation to ${line}."
> done < data/emails.txt
kaylee.anderson64@example.com으로 초대장 발송 중.
arthur.baker92@example.com으로 초대장 발송 중.
chloe.graham66@example.com으로 초대장 발송 중.
wyatt.nelson80@example.com으로 초대장 발송 중.
peter.coleman75@example.com으로 초대장 발송 중.
```

- 이 경우 Bash가 입력에 몇 줄이 포함되어 있는지 미리 알 수 없으므로 while 루프를 사용해야 합니다.
- 이 경우 *line* 변수 주위의 중괄호는 필요하지 않지만(변수 이름에 마침표를 포함할 수 없으므로) 여전히 좋은 습관입니다.
- 이 리디렉션은 `while` 앞에 배치할 수도 있습니다.

특수 파일 표준 입력 */dev/stdin*을 지정하여 while 루프에 대화식으로 입력을 제공할 수도 있습니다. 완료되면 `<Ctrl-D>`를 누릅니다.

```{bash, eval=FALSE}
$ while read i; do echo "You typed: $i."; done < /dev/stdin
하나
입력한 내용: 하나.
둘
입력한 내용: 둘.
셋
입력한 내용: 셋.
```

그러나 이 방법은 `<Enter>` 키를 누르면 해당 입력 줄에 대해 `do`와 `done` 사이의 명령이 즉시 실행된다는 단점이 있습니다.

### 파일에 대한 루핑

이 섹션에서는 자주 반복해야 하는 세 번째 유형의 항목인 파일에 대해 설명합니다.

특수 문자를 처리하려면 `ls` 대신 글로빙(즉, 경로 이름 확장)을 사용하십시오.

```{bash, eval=FALSE}
$ for filename in *.csv
> do
> echo "Processing ${filename}."
> done
countries.csv 처리 중.
```

숫자와 마찬가지로 중괄호 확장과 마찬가지로 *\*.csv*는 for 루프에서 처리되기 전에 먼저 목록으로 확장됩니다.

파일을 찾는 더 정교한 대안은 다음과 같은 `find` [@find]입니다.

- 크기, 액세스 시간 및 권한과 같은 속성에 대한 정교한 검색을 허용합니다.
- 대시를 처리합니다.
- 공백 및 줄 바꿈과 같은 특수 문자를 처리합니다.

```{bash, eval=FALSE}
$ find data -name '*.csv' -exec echo "Processing {}" \;
data/countries.csv 처리 중
data/movies.csv 처리 중
data/top250.csv 처리 중
```

다음은 `parallel`을 사용한 동일한 내용입니다.

```{bash, eval=FALSE}
$ find data -name '*.csv' -print0 | parallel -0 echo "Processing {}"
data/countries.csv 처리 중
data/movies.csv 처리 중
data/top250.csv 처리 중
```

`-print0` 옵션을 사용하면 줄 바꿈이나 다른 유형의 공백이 포함된 파일 이름을 find 출력을 처리하는 프로그램에서 올바르게 해석할 수 있습니다. 파일 이름에 공백이나 줄 바꿈과 같은 특수 문자가 포함되어 있지 않다고 확신하는 경우 `-print0` 및 `-0` 옵션을 생략할 수 있습니다.

```{block2, type="rmdtip"}

처리할 목록이 너무 복잡해지면 항상 결과를 임시 파일에 저장한 다음 파일에서 줄을 반복하는 방법을 사용할 수 있습니다.
```

## 병렬 처리

예제 \@ref(exm:slow-sh)에 표시된 것과 같이 매우 오래 실행되는 명령이 있다고 가정합니다.

```{example slow-sh, name="~/book/ch08/slow.sh"}
```
```{bash, eval=FALSE}
#!/bin/bash
echo "작업 $1 시작"
duration=$((1+RANDOM%5))
sleep $duration
echo "작업 $1은(는) ${duration}초 걸렸습니다"
```

- *\$RANDOM*은 0에서 32767 사이의 의사 난수 정수를 반환하는 내부 Bash 함수입니다. 해당 숫자를 5로 나눈 나머지에 1을 더하면 숫자가 1에서 5 사이가 됩니다.

이 프로세스는 사용 가능한 모든 리소스를 차지하지 않습니다. 그리고 이 명령을 여러 번 실행해야 하는 경우가 있습니다. 예를 들어 전체 파일 시퀀스를 다운로드해야 합니다.

병렬화하는 순진한 방법은 백그라운드에서 명령을 실행하는 것입니다.

```{bash, eval=FALSE}
$ cd ~/book/ch08
$ for i in {1..4}; do
> (slow.sh $i; echo Processed $i) &
> done
[1] 3334
[2] 3335
[3] 3336
[4] 3338
$ 작업 2 시작
작업 1 시작
작업 3 시작
작업 4 시작
작업 4는 1초 걸렸습니다
4 처리됨
작업 3은 4초 걸렸습니다
작업 2는 4초 걸렸습니다
3 처리됨
2 처리됨
작업 1은 4초 걸렸습니다
1 처리됨
```

- 괄호는 하위 셸을 만듭니다. 앰퍼샌드는 백그라운드에서 실행되도록 합니다.

하위 셸의 문제점은 한 번에 모두 실행된다는 것입니다. 최대 프로세스 수를 제어하는 메커니즘이 없습니다. 이 방법은 사용하지 않는 것이 좋습니다.

```{bash, eval=FALSE}
$ while read i; do
> (slow.sh "$i"; ) &
> done < data/movies.txt
[1] 3404
[2] 3405
[3] 3406
스타워즈 작업 시작
매트릭스 작업 시작
나 홀로 집에 작업 시작
[4] 3407
[5] 3410
$ 백 투 더 퓨처 작업 시작
인디아나 존스 작업 시작
나 홀로 집에 작업은 2초 걸렸습니다
매트릭스 작업은 2초 걸렸습니다
스타워즈 작업은 2초 걸렸습니다
백 투 더 퓨처 작업은 3초 걸렸습니다
인디아나 존스 작업은 4초 걸렸습니다
```

```{block2, type="rmdnote"}

모든 것을 병렬화할 수 있는 것은 아닙니다. API 호출은 특정 수로 제한될 수 있거나 일부 명령은 하나의 인스턴스만 가질 수 있습니다.
```

```{block2, type="rmdimportant"}

인용이 중요합니다. *\$i*를 인용하지 않으면 각 영화의 첫 번째 단어만 스크립트 *slow.sh*로 전달됩니다.
```

이 순진한 접근 방식에는 두 가지 문제가 있습니다. 첫째, 동시에 실행 중인 프로세스 수를 제어할 방법이 없습니다. 둘째, 로깅: 어떤 출력이 어떤 입력에 속하는지 알 수 없습니다.

```{bash, eval=FALSE}
$ < data/movies parallel -j3 slow.sh "{}"
스타워즈 작업 시작
스타워즈 작업은 3초 걸렸습니다
나 홀로 집에 작업 시작
나 홀로 집에 작업은 3초 걸렸습니다
매트릭스 작업 시작
매트릭스 작업은 4초 걸렸습니다
인디아나 존스 작업 시작
인디아나 존스 작업은 1초 걸렸습니다
백 투 더 퓨처 작업 시작
백 투 더 퓨처 작업은 5초 걸렸습니다
```

### GNU Parallel 소개

GNU Parallel은 Ole Tange가 작성한 명령줄 도구입니다. 이 도구를 사용하면 명령과 파이프라인을 병렬화할 수 있습니다. 이 도구의 장점은 기존 도구를 그대로 사용할 수 있다는 것입니다. 수정할 필요가 없습니다.

```{block2, type="rmdcaution"}

GNU Parallel을 계속해서 작성하고 있다는 것을 눈치채셨을 것입니다. "parallel"이라는 이름의 도구가 두 개 있기 때문입니다. 데이터 과학 도구 상자를 사용하는 경우 이미 올바른 도구가 설치되어 있습니다. 그렇지 않으면 `parallel --version`을 실행하여 올바른 도구가 설치되었는지 다시 확인하십시오.
```

GNU Parallel의 세부 사항을 살펴보기 전에 위에서 언급한 for 루프를 병렬화하는 것이 얼마나 쉬운지 보여주는 간단한 예제를 살펴보겠습니다.

```{bash, eval=FALSE}
$ seq 5 | parallel "echo {}^2 | bc"
1
4
9
16
25
```

이것은 인수 없이 가장 간단한 형태의 `parallel`입니다. 보시다시피 기본적으로 for 루프 역할을 합니다. (정확히 무슨 일이 일어나고 있는지는 나중에 설명하겠습니다.) 110개 이상의 명령줄 인수(!)를 사용하여 GNU Parallel은 많은 추가 기능을 제공합니다. 걱정하지 마십시오. 이 장이 끝날 때쯤이면 가장 중요한 기능에 대해 확실하게 이해하게 될 것입니다.

다음 명령을 실행하여 GNU Parallel을 설치합니다.

```{bash, eval=FALSE}
$ wget http://ftp.gnu.org/gnu/parallel/parallel-latest.tar.bz2
$ tar -xvjf parallel-latest.tar.bz2 > extracted-files
$ cd $(head -n 1 extracted-files)
$ ./configure && make && sudo make install
```

GNU Parallel이 올바르게 설치되었는지 확인할 수 있습니다.

```{bash, eval=FALSE}
$ parallel --version | head -n 1
GNU parallel 20140622
```

생성된 파일과 디렉터리를 안전하게 삭제할 수 있습니다.

```{bash, eval=FALSE}
$ cd ..
$ rm -r $(head -n 1 extracted-files)
$ rm parallel-latest.tar.bz2 extracted-files
```

```{block2, type="rmdtip"}

`parallel`을 우리만큼 자주 사용하는 경우 *.bashrc*에 *alias p=parallel*을 추가하여 별칭(예: `p`)을 만들 수 있습니다. (이 장에서는 명확성을 위해 `parallel`을 사용합니다.)
```

### 입력 지정

GNU Parallel에 대한 가장 중요한 인수는 모든 입력에 대해 실행하려는 명령입니다. 문제는 입력 항목을 명령줄의 어디에 삽입해야 하는가입니다. 아무것도 지정하지 않으면 입력 항목이 명령에 추가됩니다. 일반적으로 원하는 것이지만 하나 이상의 자리 표시자를 사용하여 입력 항목을 명령에 삽입할 위치를 명시적으로 지정하는 것이 좋습니다.

```{block2, type="rmdnote"}

GNU Parallel에 입력을 제공하는 방법은 여러 가지가 있습니다. 이 장 전체에서처럼 입력을 파이프하는 것을 선호합니다. 일반적으로 적용 가능하고 파이프라인을 왼쪽에서 오른쪽으로 구성할 수 있기 때문입니다. 다른 입력 제공 방법에 대해서는 parallel의 man 페이지를 참조하십시오.
```

대부분의 경우 입력 항목 전체를 그대로 사용하고 싶을 것입니다. 이를 위해서는 하나의 자리 표시자만 필요합니다. 두 개의 중괄호를 사용하여 자리 표시자, 즉 입력 항목을 넣을 위치를 지정합니다.

```{bash, eval=FALSE}
$ seq 5 | parallel echo {}
```

입력 항목이 파일인 경우 파일 이름을 수정하는 데 사용할 수 있는 몇 가지 특수 자리 표시자가 있습니다. 예를 들어 *{./}*를 사용하면 파일 이름의 기본 이름만 사용됩니다.

입력 줄에 구분 기호로 구분된 여러 부분이 있는 경우 자리 표시자에 숫자를 추가할 수 있습니다. 예를 들면 다음과 같습니다.

```{bash, eval=FALSE}
$ < input.csv | parallel -C, "mv {1} {2}"
```

여기서는 동일한 자리 표시자 수정자를 적용할 수 있습니다. 동일한 입력 항목을 재사용할 수도 있습니다. parallel에 대한 입력이 헤더가 있는 CSV 파일인 경우 열 이름을 자리 표시자로 사용할 수 있습니다.

```{bash, eval=FALSE}
$ < input.csv | parallel -C, --header : "invite {name} {email}"
```

때로는 변경되는 입력 없이 동일한 명령을 실행하고 싶을 수도 있습니다. 이것도 병렬로 가능합니다. `-N0` 매개변수를 지정하고 실행하려는 만큼의 줄을 입력으로 제공하기만 하면 됩니다.

```{bash, eval=FALSE}
$ seq 5 | parallel -N0 "echo The command line rules"
The command line rules
The command line rules
The command line rules
The command line rules
```

```{block2, type="rmdtip"}

GNU Parallel 명령이 올바르게 설정되었는지 궁금한 경우 `--dryrun` 옵션을 추가할 수 있습니다. 실제로 명령을 실행하는 대신 GNU Parallel은 실행될 것처럼 모든 명령을 정확하게 인쇄합니다.
```

### 동시 작업 수 제어

기본적으로 parallel은 CPU 코어당 하나의 작업을 실행합니다. *jobs*의 약자인 `-j` 명령줄 인수를 사용하여 병렬로 실행될 작업 수를 제어할 수 있습니다. 숫자를 지정하면 해당 수의 작업이 병렬로 실행됩니다. 숫자 앞에 더하기 기호를 붙이면 parallel은 *N*개의 작업과 CPU 코어 수를 더한 만큼 실행합니다. 숫자 앞에 빼기 기호를 붙이면 parallel은 *N-M*개의 작업을 실행합니다. 여기서 *N*은 CPU 코어 수입니다. `-j` 매개변수에 백분율을 지정할 수도 있습니다. 따라서 기본값은 CPU 코어 수의 100%입니다. 병렬로 실행할 최적의 작업 수는 실행 중인 실제 명령에 따라 다릅니다.

```{bash, eval=FALSE}
$ seq 5 | parallel -j0 "echo Hi {}"
Hi 1
Hi 2
Hi 3
Hi 4
Hi 5
```

```{bash, eval=FALSE}
$ seq 5 | parallel -j200% "echo Hi {}"
Hi 1
Hi 2
Hi 3
Hi 4
Hi 5
```

`-j1`을 지정하면 명령이 직렬로 실행됩니다. 이것은 도구의 이름에 걸맞지 않지만 여전히 용도가 있습니다. 예를 들어 한 번에 하나의 연결만 허용하는 API에 액세스해야 하는 경우입니다. `-j0`을 지정하면 parallel은 가능한 한 많은 작업을 병렬로 실행합니다. 이것은 하위 셸이 있는 루프와 비교할 수 있습니다. 이것은 권장되지 않습니다.

### 로깅 및 출력

각 명령의 출력을 저장하려면 다음을 수행하고 싶을 수 있습니다.

```{bash, eval=FALSE}
$ seq 5 | parallel "echo \"Hi {}\" > data/ch08/hi-{}.txt"
```

이렇게 하면 출력이 개별 파일에 저장됩니다. 또는 모든 것을 하나의 큰 파일에 저장하려면 다음을 수행할 수 있습니다.

```{bash, eval=FALSE}
$ seq 5 | parallel "echo Hi {}" >> data/ch08/one-big-file.txt
```

그러나 GNU Parallel은 각 작업의 출력을 입력 값을 기반으로 하는 파일 이름으로 별도의 파일에 저장하는 `--results` 옵션을 제공합니다.

```{bash, eval=FALSE}
$ seq 5 | parallel --results data/ch08/outdir "echo Hi {}"
Hi 1
Hi 2
Hi 3
Hi 4
Hi 5
$ find data/ch08/outdir
data/ch08/outdir
data/ch08/outdir/1
data/ch08/outdir/1/1
data/ch08/outdir/1/1/stderr
data/ch08/outdir/1/1/stdout
data/ch08/outdir/1/3
data/ch08/outdir/1/3/stderr
data/ch08/outdir/1/3/stdout
data/ch08/outdir/1/5
data/ch08/outdir/1/5/stderr
data/ch08/outdir/1/5/stdout
data/ch08/outdir/1/2
data/ch08/outdir/1/2/stderr
data/ch08/outdir/1/2/stdout
data/ch08/outdir/1/4
data/ch08/outdir/1/4/stderr
data/ch08/outdir/1/4/stdout
```

여러 작업을 병렬로 실행하는 경우 작업이 실행되는 순서가 입력 순서와 일치하지 않을 수 있습니다. 따라서 작업 출력도 뒤섞입니다. 동일한 순서를 유지하려면 `--keep-order` 옵션 또는 `-k` 옵션을 지정하기만 하면 됩니다.

때로는 어떤 입력이 어떤 출력을 생성했는지 기록하는 것이 유용합니다. GNU Parallel을 사용하면 `--tag` 옵션을 사용하여 출력에 *태그*를 지정할 수 있습니다.

```{bash, eval=FALSE}
$ seq 5 | parallel --tag "echo Hi {}"
1       Hi 1
2       Hi 2
3       Hi 3
4       Hi 4
5       Hi 5
```

### 병렬 도구 만들기

이 장의 시작 부분에서 사용한 `bc` 도구는 자체적으로 병렬이 아닙니다. 그러나 `parallel`을 사용하여 병렬화할 수 있습니다. 데이터 과학 도구 상자에는 `pbc` [@pbc]라는 도구가 포함되어 있습니다. 해당 코드는 예제 \@ref(exm:script-pbc)에 나와 있습니다.

```{example script-pbc, name="병렬 bc"}
```
```{bash, eval=FALSE}
#!/usr/bin/env bash
parallel -C, -k -j100% "echo '$1' | bc -l"
```

이 도구를 사용하면 이 장의 시작 부분에서 사용한 코드를 다음과 같이 단순화할 수 있습니다.

```{bash, eval=FALSE}
$ seq 100 | pbc '{1}^2' | tail
8281
8464
8649
8836
9025
9216
9409
9604
9801
10000
```

## 분산 처리

때로는 로컬 시스템이 모든 코어를 사용하더라도 제공할 수 있는 것보다 더 많은 성능이 필요합니다. 다행히 GNU Parallel은 원격 시스템의 성능도 활용할 수 있으므로 파이프라인 속도를 크게 높일 수 있습니다.

좋은 점은 GNU Parallel을 원격 시스템에 설치할 필요가 없다는 것입니다. 필요한 것은 SSH를 통해 원격 시스템에 연결할 수 있다는 것뿐이며, GNU Parallel도 파이프라인을 배포하는 데 이를 사용합니다. (GNU Parallel이 설치되어 있으면 각 원격 시스템에서 사용할 코어 수를 결정하는 데 도움이 될 수 있습니다. 이에 대해서는 나중에 자세히 설명합니다.)

먼저 실행 중인 AWS EC2 인스턴스 목록을 가져옵니다. 원격 시스템이 없더라도 걱정하지 마십시오. GNU Parallel이 사용할 원격 시스템을 알려주는 `--slf hostnames`의 모든 항목을 `--sshlogin :`으로 바꿀 수 있습니다. 이렇게 하면 이 섹션의 예제를 계속 따라 할 수 있습니다.

어떤 원격 시스템을 사용할지 알게 되면 다음 세 가지 분산 처리 유형을 고려합니다.

- 원격 시스템에서 일반 명령을 간단히 실행합니다.
- 로컬 데이터를 원격 시스템 간에 직접 배포합니다.

    -   원격 시스템으로 파일을 보내고 처리한 다음 결과를 검색합니다.

### 실행 중인 AWS EC2 인스턴스 목록 가져오기

이 섹션에서는 줄당 원격 시스템의 호스트 이름 하나가 포함된 *hostnames*라는 파일을 만듭니다. Amazon Web Services를 예로 사용하고 있습니다. 다른 클라우드 컴퓨팅 서비스를 사용하거나 자체 서버가 있는 경우 직접 *hostnames* 파일을 만드십시오.

AWS API에 대한 명령줄 인터페이스인 `aws`를 사용하여 명령줄에서 실행 중인 AWS EC2 인스턴스 목록을 얻을 수 있습니다 [@aws]. 데이터 과학 도구 상자를 사용하지 않는 경우 다음과 같이 `pip` [@pip]를 사용하여 `awscli`를 설치합니다.

```{bash, eval=FALSE}
$ pip install awscli
```

`aws`를 사용하면 온라인 AWS 관리 콘솔에서 할 수 있는 거의 모든 작업을 수행할 수 있습니다. 이 명령을 사용하여 AWS에서 실행 중인 EC2 인스턴스 목록을 가져오지만 훨씬 더 많은 작업을 수행할 수 있습니다.

온라인 관리 콘솔이나 `aws` 명령줄 도구를 통해 인스턴스를 시작하는 방법을 알고 있다고 가정합니다.

`aws ec2 describe-instances` 명령은 모든 EC2 인스턴스에 대한 많은 정보를 JSON 형식으로 반환합니다( <http://docs.aws.amazon.com/cli/latest/reference/ec2/describe-instances.html> 참조). `jq`를 사용하여 관련 필드를 추출합니다.

```{bash, eval=FALSE}
$ aws ec2 describe-instances | jq '.Reservations[].Instances[] | '\
> '{public_dns: .PublicDnsName, state: .State.Name}'
{
  "state": "실행 중",
  "public_dns": "ec2-54-88-122-140.compute-1.amazonaws.com"
}
{
  "state": "중지됨",
  "public_dns": null
}
```

EC2 인스턴스의 가능한 상태는 *pending*, *running*, *shutting-down*, *terminated*, *stopping*, *stopped*입니다. 실행 중인 인스턴스에만 파이프라인을 배포할 수 있으므로 실행 중이 아닌 인스턴스를 필터링합니다.

```{bash, eval=FALSE}
$ aws ec2 describe-instances | jq -r '.Reservations[].Instances[] | '\
> 'select(.State.Name=="running") | .PublicDnsName' > hostnames
$ cat hostnames
ec2-54-88-122-140.compute-1.amazonaws.com
ec2-54-88-89-208.compute-1.amazonaws.com
```

(*raw*를 의미하는 `-r`을 생략하면 호스트 이름이 큰따옴표로 묶입니다.) 나중에 `parallel`에 전달할 수 있도록 출력을 *hostnames*에 저장합니다.

언급했듯이 `parallel`은 `ssh`를 사용하여 EC2 인스턴스에 연결합니다. `ssh`가 EC2 인스턴스에 연결하는 방법을 알 수 있도록 *\~/.ssh/config*에 다음을 추가합니다.

```
Host *.amazonaws.com
    IdentityFile ~/.ssh/MyKeyFile.pem
    User ubuntu
```

실행 중인 배포판에 따라 사용자 이름이 *ubuntu*와 다를 수 있습니다.

### 원격 시스템에서 명령 실행

분산 처리의 첫 번째 유형은 원격 시스템에서 일반 명령을 간단히 실행하는 것입니다. 먼저 호스트 목록 명령줄 도구 `hostname`을 실행하여 parallel이 작동하는지 다시 확인해 보겠습니다.

```{bash, eval=FALSE}
$ parallel --nonall --slf hostnames hostname
ip-172-31-23-204
ip-172-31-23-205
```

여기서 `--slf`는 `--sshloginfile`의 약자이고 `--nonall`은 `parallel`에게 매개변수 없이 *hostnames* 파일의 모든 원격 시스템에서 동일한 명령을 실행하도록 지시합니다. 원격 시스템을 활용할 수 없는 경우 `--slf hostnames`를 `--sshlogin :`으로 바꾸면 명령이 로컬 시스템에서 실행됩니다.

```{bash, eval=FALSE}
$ parallel --nonall --sshlogin : hostname
data-science-toolbox
```

모든 원격 시스템에서 동일한 명령을 한 번 실행하는 데는 시스템당 하나의 코어만 필요합니다. `parallel`에 전달된 인수 목록을 배포하려는 경우 잠재적으로 둘 이상의 코어를 사용할 수 있습니다. 코어 수가 명시적으로 지정되지 않은 경우 `parallel`은 이를 결정하려고 시도합니다.

    $ seq 2 | parallel --slf hostnames echo 2>&1 | fold
    bash: parallel: 명령을 찾을 수 없습니다
    parallel: 경고: ec2-54-88-122-140.comp에서 CPU 수를 파악할 수 없습니다
    ute-1.amazonaws.com (). 1을 사용합니다.
    1
    2

이 경우 두 원격 시스템 중 하나에 `parallel`이 설치되어 있습니다. 그중 하나에서 `parallel`을 찾을 수 없다는 경고 메시지가 표시됩니다. 결과적으로 `parallel`은 코어 수를 결정할 수 없으며 기본적으로 하나의 코어를 사용합니다. 이 경고 메시지가 표시되면 다음 네 가지 중 하나를 수행할 수 있습니다.

- 걱정하지 말고 시스템당 하나의 코어를 사용하는 것에 만족하십시오.
- `-j`를 통해 시스템당 작업 수를 지정합니다.
- *hostnames* 파일의 각 호스트 이름 앞에 예를 들어 두 개의 코어를 원하면 *2/*를 넣어 시스템당 사용할 코어 수를 지정합니다.
- 패키지 관리자를 사용하여 GNU Parallel을 설치합니다. 예를 들어 Ubuntu에서는 다음과 같습니다.

```{bash, eval=FALSE}
$ parallel --nonall --slf hostnames "sudo apt-get install -y parallel"
```

### 원격 시스템 간 로컬 데이터 배포

분산 처리의 두 번째 유형은 원격 시스템 간에 로컬 데이터를 직접 배포하는 것입니다. 여러 원격 시스템을 사용하여 처리하려는 매우 큰 데이터 세트가 있다고 상상해 보십시오. 간단하게 하기 위해 1에서 1000까지의 모든 정수를 합산합니다. 먼저 원격 시스템의 호스트 이름과 `wc`를 사용하여 수신한 입력 길이를 인쇄하여 입력이 실제로 배포되는지 다시 확인해 보겠습니다.

```{bash, eval=FALSE}
$ seq 1000 | parallel -N100 --pipe --slf hosts  "(hostname; wc -l) | paste -sd:"
ip-172-31-23-204:100
ip-172-31-23-205:100
ip-172-31-23-205:100
ip-172-31-23-204:100
ip-172-31-23-205:100
ip-172-31-23-204:100
ip-172-31-23-205:100
ip-172-31-23-204:100
ip-172-31-23-205:100
ip-172-31-23-204:100
```

1000개의 숫자가 100개 하위 집합(`-N100`으로 지정됨)으로 균등하게 배포되는지 확인할 수 있습니다. 이제 모든 숫자를 합산할 준비가 되었습니다.

```{bash, eval=FALSE}
seq 1000 | parallel -N100 --pipe --slf hosts "paste -sd+ | bc" | paste -sd+ | bc
500500
```

여기서는 원격 시스템에서 받은 10개의 합계도 즉시 합산합니다. 답이 올바른지 다시 확인해 보겠습니다.

```{bash, eval=FALSE}
$ seq 1000 | paste -sd+ | bc
500500
```

좋습니다. 작동합니다. 원격 시스템에서 실행하려는 더 큰 명령이 있는 경우 별도의 스크립트에 넣고 `parallel`을 사용하여 스크립트를 업로드할 수도 있습니다.

*sum*이라는 매우 간단한 명령줄 도구를 만들어 보겠습니다.

```{bash, eval=FALSE}
#!/usr/bin/env bash
paste -sd+ | bc
```

[4장](#chapter-4-creating-reusable-command-line-tools)에서 설명한 대로 실행 가능하게 만드는 것을 잊지 마십시오. 다음 명령은 먼저 *sum* 파일을 업로드합니다.

    $ seq 1000 | parallel -N100 --basefile sum --pipe --slf hosts './sum' | ./sum
    500500

물론 1000개의 숫자를 합산하는 것은 장난감 예일뿐입니다. 로컬에서 수행하는 것이 훨씬 빨랐을 것입니다. 그러나 GNU Parallel이 얼마나 강력할 수 있는지 이 예에서 분명히 알 수 있기를 바랍니다.

### 원격 시스템에서 파일 처리

분산 처리의 세 번째 유형은 원격 시스템으로 파일을 보내고 처리한 다음 결과를 검색하는 것입니다. 뉴욕시의 각 자치구에 대해 311에 서비스 요청이 얼마나 자주 접수되는지 계산하고 싶다고 상상해 보십시오. 아직 로컬 시스템에 해당 데이터가 없으므로 먼저 훌륭한 API를 사용하여 <https://data.cityofnewyork.us/>에서 가져오겠습니다.

```{bash, eval=FALSE}
$ seq 0 100 900 | parallel  "curl -sL 'http://data.cityofnewyork.us/resource'"\
> "'/erm2-nwe9.json?\$limit=100&\$offset={}' | jq -c '.[]' | gzip > {#}.json.gz"
```

`jq -c '.[]'`는 JSON 객체 배열을 평면화하여 한 줄로 만드는 데 사용됩니다. 이제 압축된 JSON 데이터가 포함된 10개의 파일이 있습니다. JSON 한 줄이 어떻게 생겼는지 살펴보겠습니다.

```{bash, eval=FALSE}
$ zcat 1.json.gz | head -n 1 | fold
{"school_region":"Unspecified","park_facility_name":"Unspecified","x_coordinate_
state_plane":"945974","agency_name":"Department of Health and Mental Hygiene","u
nique_key":"147","facility_type":"N/A","status":"Assigned","school_address":"Uns
pecified","created_date":"2006-08-29T21:25:23","community_board":"01 STATEN ISLA
ND","incident_zip":"10302","school_name":"Unspecified","location":{"latitude":"4
0.62745427115626","longitude":"-74.13789056665027","needs_recoding":false},"comp
laint_type":"Food Establishment","city":"STATEN ISLAND","park_borough":"STATEN I
SLAND","school_state":"Unspecified","longitude":"-74.13789056665027","intersecti
on_street_1":"DECKER AVENUE","y_coordinate_state_plane":"167905","due_date":"200
6-10-05T21:25:23","latitude":"40.62745427115626","school_code":"Unspecified","sc
hool_city":"Unspecified","address_type":"INTERSECTION","intersection_street_2":"
BARRETT AVENUE","school_number":"Unspecified","resolution_action_updated_date":"
2006-10-06T00:00:17","descriptor":"Handwashing","school_zip":"Unspecified","loca
tion_type":"Restaurant/Bar/Deli/Bakery","agency":"DOHMH","borough":"STATEN ISLAN
D","school_phone_number":"Unspecified"}
```

로컬 시스템에서 자치구당 총 서비스 요청 수를 가져오려면 다음 명령을 실행합니다.

```{bash, eval=FALSE}
$ zcat *.json.gz |
> ./jq -r '.borough' |
> tr '[A-Z] ' '[a-z]_' |
> sort | uniq -c |
> awk '{print $2","$1}' |
> header -a borough,count |
> csvsort -rc count | csvlook
|----------------+--------|
|  자치구        | 횟수   |
|----------------+--------|
|  미지정        | 467    |
|  맨해튼        | 274    |
|  브루클린      | 103    |
|  퀸스          | 77     |
|  브롱크스      | 44     |
|  스태튼아일랜드 | 35     |
|----------------+--------|
```

이것은 상당히 긴 파이프라인이고 잠시 후 `parallel`과 함께 다시 사용할 것이므로 살펴볼 가치가 있습니다.

- `zcat`을 사용하여 모든 압축 파일을 확장합니다.
- 각 호출에 대해 `jq`를 사용하여 자치구 이름을 추출합니다.
- 자치구 이름을 소문자로 변환하고 공백을 밑줄로 바꿉니다(`awk`는 기본적으로 공백을 기준으로 분할하므로).
- `sort` 및 `uniq`를 사용하여 각 자치구의 발생 횟수를 계산합니다.

- `awk`를 사용하여 개수와 자치구를 반대로 하고 쉼표로 구분합니다.
- `header`를 사용하여 헤더를 추가합니다.
- `csvsort` [@csvsort]를 사용하여 개수별로 정렬하고 표를 인쇄합니다.

잠시 동안 우리 자신의 시스템이 너무 느려서 이 파이프라인을 로컬에서 수행할 수 없다고 상상해 보십시오. GNU Parallel을 사용하여 로컬 파일을 원격 시스템 간에 배포하고 처리하도록 한 다음 결과를 검색할 수 있습니다.

```{bash, eval=FALSE}
$ ls *.json.gz |
> parallel -v --basefile jq \
> --trc {.}.csv \
> --slf hostnames \
> "zcat {} | ./jq -r '.borough' | tr '[A-Z] ' '[a-z]_' | sort | uniq -c |"\
> " awk '{print \$2\",\"\$1}' > {.}.csv"
zcat 10.json.gz | ./jq -r '.borough' | sort | uniq -c | awk '{print $2","$1}'
zcat 2.json.gz | ./jq -r '.borough' | sort | uniq -c | awk '{print $2","$1}'
zcat 1.json.gz | ./jq -r '.borough' | sort | uniq -c | awk '{print $2","$1}'
zcat 3.json.gz | ./jq -r '.borough' | sort | uniq -c | awk '{print $2","$1}'
zcat 4.json.gz | ./jq -r '.borough' | sort | uniq -c | awk '{print $2","$1}'
zcat 5.json.gz | ./jq -r '.borough' | sort | uniq -c | awk '{print $2","$1}'
zcat 6.json.gz | ./jq -r '.borough' | sort | uniq -c | awk '{print $2","$1}'
zcat 7.json.gz | ./jq -r '.borough' | sort | uniq -c | awk '{print $2","$1}'
zcat 8.json.gz | ./jq -r '.borough' | sort | uniq -c | awk '{print $2","$1}'
zcat 9.json.gz | ./jq -r '.borough' | sort | uniq -c | awk '{print $2","$1}'
```

이 긴 명령은 다음과 같이 나뉩니다.

- 파일 목록을 인쇄하고 `parallel`로 파이프합니다.
- `jq` 바이너리를 각 원격 시스템으로 전송합니다. 다행히 jq에는 종속성이 없습니다. `--trc`(이는 `--cleanup` 명령줄 인수를 의미함)를 지정했으므로 이 파일은 마지막에 원격 시스템에서 제거됩니다.
- 명령줄 인수 `--trc {.}.csv`는 `--transfer --return {.}.csv --cleanup`의 약자입니다. (대체 문자열 *{.}*은 마지막 확장자가 없는 입력 파일 이름으로 바뀝니다.) 여기서 이는 JSON 파일이 원격 시스템으로 전송되고 CSV 파일이 로컬 시스템으로 반환되며 각 작업 후 두 파일 모두 원격 시스템에서 제거됨을 의미합니다.
- 호스트 이름 목록을 지정합니다. 로컬에서 시도하려면 `--self hostnames` 대신 `--sshlogin :`을 지정할 수 있다는 것을 기억하십시오.

- `awk` 표현식의 이스케이프 처리에 유의하십시오. 따옴표 처리는 때때로 까다로울 수 있습니다. 여기서 달러 기호와 큰따옴표는 이스케이프 처리됩니다. 따옴표 처리가 너무 혼란스러워지면 `sum`과 같이 파이프라인을 별도의 명령줄 도구에 넣을 수 있다는 것을 기억하십시오.

이 명령을 실행하는 동안 어느 시점에서 원격 시스템 중 하나에서 `ls`를 실행하면 `parallel`이 실제로 바이너리 `jq`, JSON 파일 및 CSV 파일을 전송(및 정리)하는 것을 볼 수 있습니다.

```{bash, eval=FALSE}
$ ssh $(head -n 1 hostnames) ls
1.json.csv
1.json.gz
jq
```

각 CSV 파일은 다음과 같습니다.

```{bash, eval=FALSE}
$ cat 1.json.csv
bronx,3
brooklyn,5
manhattan,24
queens,3
staten_island,2
unspecified,63
```

Rio와 R의 `aggregate` 함수를 사용하여 각 CSV 파일의 개수를 합산할 수 있습니다.

```{bash, eval=FALSE}
$ cat *.csv | header -a borough,count |
> Rio -e 'aggregate(count ~ borough, df, sum)' |
> csvsort -rc count | csvlook
|----------------+--------|
|  자치구        | 횟수   |
|----------------+--------|
|  미지정        | 467    |
|  맨해튼        | 274    |
|  브루클린      | 103    |
|  퀸스          | 77     |
|  브롱크스      | 44     |
|  스태튼아일랜드 | 35     |
|----------------+--------|
```

또는 결과를 집계하기 위해 SQL을 선호하는 경우 [5장](#chapter-5-scrubbing-data)에서 설명한 대로 `csvsql`을 사용할 수 있습니다.

```{bash, eval=FALSE}
$ cat *.csv | header -a borough,count |
> csvsql --query 'SELECT borough, SUM(count) AS count FROM stdin '\
> 'GROUP BY borough ORDER BY count DESC' | csvlook
|----------------+--------|
|  자치구        | 횟수   |
|----------------+--------|
|  미지정        | 467    |
|  맨해튼        | 274    |
|  브루클린      | 103    |
|  퀸스          | 77     |
|  브롱크스      | 44     |
|  스태튼아일랜드 | 35     |
|----------------+--------|
```

## 논의

데이터 과학자로서 우리는 데이터를 다루며 때로는 많은 양의 데이터를 다룹니다. 즉, 때로는 명령을 여러 번 실행하거나 데이터 집약적인 명령을 여러 코어에 분산해야 합니다. 이 장에서는 명령을 병렬화하는 것이 얼마나 쉬운지 보여주었습니다. GNU Parallel은 일반적인 명령줄 도구의 속도를 높이고 여러 코어와 원격 시스템에 배포하는 매우 강력하고 유연한 도구입니다. 많은 기능을 제공하며 이 장에서는 겨우 표면만 긁었을 뿐입니다. 다루지 않은 GNU Parallel의 일부 기능은 다음과 같습니다.

- 입력을 지정하는 다양한 방법.
- 모든 작업의 로그를 유지합니다.
- 시스템 부하가 특정 수준 미만일 때만 새 작업을 시작합니다.
- 작업 시간 초과, 재개 및 재시도.

GNU Parallel과 가장 중요한 옵션에 대한 기본적인 이해가 되면 추가 자료 섹션에 나열된 자습서를 살펴보는 것이 좋습니다.

## 추가 자료

* Tange, O. 2011. “GNU Parallel - the Command-Line Power Tool.”<em>;Login: The USENIX Magazine</em> 36 (1). Frederiksberg, Denmark:42–47. <a href="http://www.gnu.org/s/parallel" class="uri">http://www.gnu.org/s/parallel</a>.
* Tange, Ole. 2014. “GNU Parallel.” <a href="http://www.gnu.org/software/parallel" class="uri">http://www.gnu.org/software/parallel</a>.
* Services, Amazon Web. 2014. “AWS Command Line Interface.” <a href="http://aws.amazon.com/cli" class="uri">http://aws.amazon.com/cli</a>.
