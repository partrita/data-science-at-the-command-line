# 소개 {#chapter-1-introduction}

이 책은 명령줄에서 데이터 과학을 수행하는 것에 관한 것입니다. 저희의 목표는 명령줄의 강력한 기능을 활용하는 방법을 알려줌으로써 여러분을 더 효율적이고 생산적인 데이터 과학자로 만드는 것입니다.

제목에 "데이터 과학"과 "명령줄"이라는 두 용어가 모두 포함되어 있어 설명이 필요합니다. 40년 이상[^1] 된 기술이 불과 몇 년밖에 안 된 분야에 어떻게 유용할 수 있을까요?

오늘날 데이터 과학자들은 엄청나게 많은 흥미로운 기술과 프로그래밍 언어 중에서 선택할 수 있습니다. Python, R, Hadoop, Julia, Pig, Hive, Spark는 몇 가지 예에 불과합니다. 이미 이러한 기술 중 하나 이상에 대한 경험이 있을 수 있습니다. 그렇다면 데이터 과학을 수행하기 위해 여전히 명령줄에 관심을 가져야 하는 이유는 무엇일까요? 명령줄은 이러한 다른 기술과 프로그래밍 언어가 제공하지 않는 무엇을 제공할까요?

이것들은 모두 타당한 질문입니다. 이 첫 번째 장에서는 다음과 같이 이러한 질문에 답할 것입니다. 첫째, 이 책의 중추 역할을 할 데이터 과학의 실용적인 정의를 제공합니다. 둘째, 명령줄의 다섯 가지 중요한 이점을 나열합니다. 셋째, 실제 사용 사례를 통해 명령줄의 강력함과 유연성을 보여줍니다. 이 장이 끝날 때까지 데이터 과학을 수행하기 위해 명령줄을 배울 가치가 있다는 것을 확신시켜 드리고자 합니다.

## 개요

이 장에서는 다음을 배웁니다.

- 데이터 과학의 실용적인 정의
- 명령줄이 정확히 무엇이며 어떻게 사용할 수 있는지
- 명령줄이 데이터 과학을 수행하기에 훌륭한 환경인 이유

## 데이터 과학은 OSEMN입니다

데이터 과학 분야는 아직 초기 단계이며, 따라서 데이터 과학이 포괄하는 내용에 대한 다양한 정의가 존재합니다. 이 책 전체에서 저희는 @Mason2010의 매우 실용적인 정의를 사용합니다. 그들은 다음 다섯 가지 단계에 따라 데이터 과학을 정의합니다. (1) 데이터 획득, (2) 데이터 정제, (3) 데이터 탐색, (4) 데이터 모델링, (5) 데이터 해석. 함께 이러한 단계는 OSEMN 모델( *awesome*으로 발음)을 형성합니다. 이 정의는 각 단계(아래에서 설명하는 5단계, 데이터 해석 제외)가 자체 장을 가지고 있기 때문에 이 책의 중추 역할을 합니다. 아래에서는 각 단계에 수반되는 내용을 설명합니다.

```{block2, type="rmdcomment"}
다섯 가지 단계는 선형적이고 점진적인 방식으로 논의되지만, 실제로는 단계 사이를 앞뒤로 이동하거나 여러 단계를 동시에 수행하는 것이 매우 일반적입니다. 데이터 과학을 수행하는 것은 반복적이고 비선형적인 프로세스입니다. 예를 들어, 데이터를 모델링하고 결과를 보면 데이터 세트의 기능을 조정하기 위해 정제 단계로 돌아가기로 결정할 수 있습니다.
```

### 데이터 획득

데이터가 없으면 할 수 있는 데이터 과학이 거의 없습니다. 따라서 첫 번째 단계는 데이터를 획득하는 것입니다. 이미 데이터를 보유하고 있을 만큼 운이 좋지 않다면 다음 중 하나 이상을 수행해야 할 수 있습니다.

- 다른 위치(예: 웹페이지 또는 서버)에서 데이터 다운로드
- 데이터베이스 또는 API(예: MySQL 또는 Twitter)에서 데이터 쿼리
- 다른 파일(예: HTML 파일 또는 스프레드시트)에서 데이터 추출
- 직접 데이터 생성(예: 센서 읽기 또는 설문 조사 수행)

[3장](#chapter-3-obtaining-data)에서는 명령줄을 사용하여 데이터를 획득하는 몇 가지 방법을 설명합니다. 획득한 데이터는 텍스트, CSV, JSON 또는 HTML/XML 형식일 가능성이 큽니다. 다음 단계는 이 데이터를 정제하는 것입니다.

### 데이터 정제

획득한 데이터에 누락된 값, 불일치, 오류, 이상한 문자 또는 흥미롭지 않은 열이 있는 것은 드문 일이 아닙니다. 이 경우 흥미로운 작업을 수행하기 전에 데이터를 *정제*하거나 정리해야 합니다. 일반적인 정제 작업은 다음과 같습니다.

- 줄 필터링
- 특정 열 추출
- 값 바꾸기
- 단어 추출
- 누락된 값 처리
- 한 형식에서 다른 형식으로 데이터 변환

데이터 과학자들은 흥미로운 데이터 시각화와 통찰력 있는 모델(3단계 및 4단계)을 만드는 것을 좋아하지만, 일반적으로 필요한 데이터를 먼저 획득하고 정제하는 데 많은 노력이 들어갑니다(1단계 및 2단계). *데이터 주짓수*에서 @Patil2012는 "모든 데이터 프로젝트 작업의 80%는 데이터 정리에 있다"고 말합니다. [5장](#chapter-5-scrubbing-data)에서는 명령줄이 이러한 데이터 정제 작업을 수행하는 데 어떻게 도움이 되는지 보여줍니다.

### 데이터 탐색

데이터를 정제했으면 탐색할 준비가 된 것입니다. 여기서부터 데이터에 실제로 몰입하게 되므로 흥미로워집니다. [7장](#chapter-7-exploring-data)에서는 명령줄을 사용하여 다음을 수행하는 방법을 보여줍니다.

- 데이터 보기
- 데이터에서 통계 도출
- 흥미로운 시각화 만들기

[7장](#chapter-7-exploring-data)에서 소개된 명령줄 도구에는 `csvstat` [@csvstat], `feedgnuplot` [@feedgnuplot], `Rio` [@Rio]가 포함됩니다.

### 데이터 모델링

데이터를 설명하거나 무슨 일이 일어날지 예측하려면 데이터의 통계 모델을 만들고 싶을 것입니다. 모델을 만드는 기술에는 클러스터링, 분류, 회귀 및 차원 축소가 포함됩니다. 명령줄은 처음부터 새 모델을 구현하는 데 적합하지 않습니다. 그러나 명령줄에서 모델을 빌드할 수 있다는 것은 매우 유용합니다. [9장](#chapter-9-modeling-data)에서는 로컬에서 모델을 빌드하거나 API를 사용하여 클라우드에서 계산을 수행하는 몇 가지 명령줄 도구를 소개합니다.

### 데이터 해석

OSEMN 모델의 마지막이자 아마도 가장 중요한 단계는 데이터 해석입니다. 이 단계에는 다음이 포함됩니다.

- 데이터에서 결론 도출
- 결과가 무엇을 의미하는지 평가
- 결과 전달

솔직히 말해서 컴퓨터는 여기서 거의 쓸모가 없으며 이 단계에서는 명령줄이 실제로 작동하지 않습니다. 이 단계에 도달하면 사용자에게 달려 있습니다. 이것은 OSEMN 모델에서 자체 장이 없는 유일한 단계입니다. 대신 @Shron2014의 *데이터로 생각하기*를 참조하시기 바랍니다.

## 막간 장

OSEMN 단계를 다루는 장 사이에는 세 개의 막간 장이 있습니다. 각 막간 장에서는 데이터 과학에 관한 보다 일반적인 주제와 이를 위해 명령줄을 사용하는 방법을 설명합니다. 이러한 주제는 데이터 과학 프로세스의 모든 단계에 적용할 수 있습니다.

[4장](#chapter-4-creating-reusable-command-line-tools)에서는 명령줄에서 재사용 가능한 도구를 만드는 방법을 설명합니다. 이러한 개인 도구는 명령줄에 입력한 긴 명령이나 Python 또는 R과 같이 이미 작성한 기존 코드에서 가져올 수 있습니다. 자신만의 도구를 만들 수 있으면 더 효율적이고 생산적이 될 수 있습니다.

명령줄은 데이터 과학을 수행하기 위한 대화형 환경이므로 작업 흐름을 추적하기가 어려울 수 있습니다. [6장](#chapter-6-managing-your-data-workflow)에서는 작업과 작업 간의 종속성 측면에서 데이터 과학 작업 흐름을 정의할 수 있는 Drake [@drake]라는 명령줄 도구를 보여줍니다. 이 도구는 사용자뿐만 아니라 동료와 동료를 위해서도 작업 흐름의 재현성을 높입니다.

[8장](#chapter-8-parallel-pipelines)에서는 명령과 도구를 병렬로 실행하여 속도를 높이는 방법을 설명합니다. GNU Parallel [@parallel]이라는 명령줄 도구를 사용하면 매우 큰 데이터 세트에 명령줄 도구를 적용하고 여러 코어와 원격 시스템에서 실행할 수 있습니다.

## 명령줄이란 무엇입니까?

데이터 과학에 명령줄을 사용해야 하는 *이유*를 논의하기 전에 명령줄이 실제로 어떻게 생겼는지 살펴보겠습니다(이미 익숙할 수 있습니다). 그림 \@ref(fig:mac-terminal)과 그림 \@ref(fig:ubuntu-terminal)은 각각 macOS와 Ubuntu에서 기본적으로 나타나는 명령줄 스크린샷을 보여줍니다. Ubuntu는 GNU/Linux의 특정 배포판이며, 이 책 전체에서 이를 가정합니다.

```{r mac-terminal, echo=FALSE, fig.cap="macOS의 명령줄", fig.align="center"}
knitr::include_graphics("images/screenshot_terminal_mac_dst.png")
```

```{r ubuntu-terminal, echo=FALSE, fig.cap="Ubuntu의 명령줄", fig.align="center"}
knitr::include_graphics("images/screenshot_terminal_ubuntu_dst.png")
```

두 스크린샷에 표시된 창을 터미널이라고 합니다. 이것은 셸과 상호 작용할 수 있도록 하는 프로그램입니다. 입력하는 명령을 실행하는 것은 셸입니다. (Ubuntu와 macOS 모두 기본 셸은 Bash입니다.)

```{block2, type="rmdnote"}
Microsoft Windows 명령줄(명령 프롬프트 또는 PowerShell이라고도 함)은 이 책에 제시된 명령과 근본적으로 다르고 호환되지 않으므로 표시하지 않습니다. 좋은 소식은 Microsoft Windows에 데이터 과학 도구 상자를 설치하여 따라 할 수 있다는 것입니다. 데이터 과학 도구 상자를 설치하는 방법은 [2장](#chapter-2-getting-started)에서 설명합니다.
```

명령을 입력하는 것은 그래픽 사용자 인터페이스를 통해 컴퓨터와 상호 작용하는 것과는 매우 다른 방식입니다. 예를 들어 Microsoft Excel에서 데이터를 주로 처리하는 데 익숙하다면 이 접근 방식이 처음에는 위협적으로 보일 수 있습니다. 두려워하지 마십시오. 명령줄 작업에 매우 빠르게 익숙해질 것이라고 저희를 믿으십시오.

이 책에서 저희가 입력하는 명령과 생성되는 출력은 텍스트로 표시됩니다. 예를 들어, 두 스크린샷의 터미널 내용(환영 메시지 후)은 다음과 같습니다.

```{bash, eval=FALSE}
$ whoami
vagrant
$ hostname
data-science-toolbox
$ date
Tue Jul 22 02:52:09 UTC 2014
$ echo '명령줄은 굉장합니다!' | cowsay
 ______________________________
< 명령줄은 굉장합니다! >
 ------------------------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
                ||----w |
                ||     ||
```

각 명령 앞에 달러 기호(**$**)가 있는 것을 알 수 있습니다. 이것을 프롬프트라고 합니다. 두 스크린샷의 프롬프트에는 사용자 이름(`vagrant`), 호스트 이름(`data-science-toolbox`) 및 현재 작업 디렉터리(`\~`)와 같은 더 많은 정보가 표시되었습니다. 예제에서는 달러 기호만 표시하는 것이 관례입니다. 왜냐하면 프롬프트는 (1) 세션 중에 변경될 수 있고(다른 디렉터리로 이동할 때), (2) 사용자가 사용자 지정할 수 있으며(예: 시간 또는 현재 `git` [@git] 브랜치를 표시할 수도 있음), (3) 명령 자체와는 관련이 없기 때문입니다.

다음 장에서는 필수적인 명령줄 개념에 대해 훨씬 더 자세히 설명합니다. 이제 데이터 과학을 수행하기 위해 명령줄을 사용해야 하는 *이유*를 먼저 설명할 차례입니다.

## 왜 명령줄에서 데이터 과학을 해야 할까요?

명령줄에는 데이터 과학자로서 효율성과 생산성을 크게 향상시킬 수 있는 많은 장점이 있습니다. 장점을 대략적으로 그룹화하면 명령줄은 민첩하고, 증강적이며, 확장 가능하고, 확장 가능하며, 어디에나 있습니다. 아래에서 각 장점에 대해 자세히 설명합니다.

### 명령줄은 민첩합니다

명령줄의 첫 번째 장점은 민첩하게 작업할 수 있다는 것입니다. 데이터 과학은 매우 대화형이고 탐색적인 특성을 가지며, 작업 환경은 이를 허용해야 합니다. 명령줄은 두 가지 방법으로 이를 달성합니다.

첫째, 명령줄은 소위 읽기-평가-인쇄-루프(REPL)를 제공합니다. 즉, 명령을 입력하고 **<Enter>** 키를 누르면 명령이 즉시 평가됩니다. REPL은 스크립트, 대규모 프로그램 및 예를 들어 Hadoop 작업과 관련된 편집-컴파일-실행-디버그 주기보다 데이터 과학을 수행하는 데 훨씬 더 편리한 경우가 많습니다. 명령은 즉시 실행되고, 원하는 대로 중지할 수 있으며, 빠르게 변경할 수 있습니다. 이 짧은 반복 주기를 통해 데이터를 실제로 다룰 수 있습니다.

둘째, 명령줄은 파일 시스템에 매우 가깝습니다. 데이터는 데이터 과학을 수행하는 주요 요소이므로 데이터 세트가 포함된 파일을 쉽게 사용할 수 있어야 합니다. 명령줄은 이를 위한 많은 편리한 도구를 제공합니다.

### 명령줄은 증강적입니다

현재 데이터 과학 워크플로에 어떤 기술(R, IPython 또는 Hadoop이든)이 포함되어 있든 해당 워크플로를 포기하라고 제안하는 것이 아니라는 점을 알아야 합니다. 대신 명령줄은 현재 사용하고 있는 기술을 증폭시키는 증강 기술로 여기에 제시됩니다.

명령줄은 다른 기술과 잘 통합됩니다. 한편으로는 자체 환경에서 명령줄을 자주 사용할 수 있습니다. 예를 들어 Python과 R을 사용하면 명령줄 도구를 실행하고 출력을 캡처할 수 있습니다. 다른 한편으로는 코드(예: 이미 작성한 Python 또는 R 함수)를 명령줄 도구로 바꿀 수 있습니다. 이에 대해서는 [4장](#chapter-4-creating-reusable-command-line-tools)에서 자세히 다룰 것입니다. 또한 명령줄은 다양한 데이터베이스 및 Microsoft Excel과 같은 파일 형식과 쉽게 협력할 수 있습니다.

결국 모든 기술에는 장단점(명령줄 포함)이 있으므로 여러 가지를 알고 당면한 작업에 가장 적합한 것을 사용하는 것이 좋습니다. 때로는 R을 사용하고, 때로는 명령줄을 사용하고, 때로는 펜과 종이를 사용하기도 합니다. 이 책이 끝날 때쯤이면 언제 명령줄을 사용할 수 있고 언제 즐겨 사용하는 프로그래밍 언어나 통계 컴퓨팅 환경을 계속 사용하는 것이 더 나은지 확실하게 이해하게 될 것입니다.

### 명령줄은 확장 가능합니다

명령줄에서 작업하는 것은 그래픽 사용자 인터페이스(GUI)를 사용하는 것과 매우 다릅니다. 명령줄에서는 입력을 통해 작업을 수행하는 반면 GUI에서는 마우스로 가리키고 클릭하여 작업을 수행합니다.

명령줄에서 수동으로 입력하는 모든 것은 스크립트와 도구를 통해 자동화할 수도 있습니다. 이렇게 하면 실수를 했거나, 데이터 세트가 변경되었거나, 동료가 동일한 분석을 수행하려는 경우 명령을 매우 쉽게 다시 실행할 수 있습니다. 또한 명령은 특정 간격으로, 원격 서버에서, 그리고 많은 데이터 청크에서 병렬로 실행할 수 있습니다(이에 대한 자세한 내용은 8장에서 설명).

명령줄은 자동화할 수 있으므로 확장 가능하고 반복 가능합니다. 가리키고 클릭하는 것을 자동화하는 것은 간단하지 않으므로 GUI는 확장 가능하고 반복 가능한 데이터 과학을 수행하기에 덜 적합한 환경입니다.

### 명령줄은 확장 가능합니다

명령줄 자체는 40년 전에 발명되었습니다. 핵심 기능은 대체로 변경되지 않았지만 명령줄의 주력인 *도구*는 매일 개발되고 있습니다.

명령줄 자체는 언어에 구애받지 않습니다. 이를 통해 명령줄 도구를 다양한 프로그래밍 언어로 작성할 수 있습니다. 오픈 소스 커뮤니티는 데이터 과학에 사용할 수 있는 많은 무료 고품질 명령줄 도구를 생산하고 있습니다.

이러한 명령줄 도구는 함께 작동할 수 있으므로 명령줄은 매우 유연합니다. 자신만의 도구를 만들 수도 있으므로 명령줄의 효과적인 기능을 확장할 수 있습니다.

### 명령줄은 어디에나 있습니다

명령줄은 Ubuntu Linux 및 macOS를 포함한 모든 Unix 계열 운영 체제와 함께 제공되므로 많은 곳에서 찾을 수 있습니다. [Top 500 슈퍼컴퓨터 사이트에 대한 기사](http://top500.org/blog/lists/2013/11/press-release)에 따르면 상위 500대 슈퍼컴퓨터의 95%가 GNU/Linux를 실행하고 있습니다. 따라서 이러한 슈퍼컴퓨터 중 하나를 사용하게 되거나 쥬라기 공원에서 문 잠금 장치가 작동하지 않는 상황에 처하게 된다면 명령줄을 사용하는 방법을 아는 것이 좋습니다!

그러나 GNU/Linux는 슈퍼컴퓨터에서만 실행되는 것이 아닙니다. 서버, 노트북 및 임베디드 시스템에서도 실행됩니다. 요즘 많은 회사에서 클라우드 컴퓨팅을 제공하여 즉시 새 시스템을 쉽게 시작할 수 있습니다. 이러한 시스템(또는 일반적으로 서버)에 로그인하면 명령줄에 도달할 가능성이 높습니다.

명령줄이 많은 곳에서 사용 가능하다는 점 외에도 명령줄이 유행이 아니라는 점에 유의하는 것도 중요합니다. 이 기술은 40년 이상 사용되어 왔으며 개인적으로 앞으로 40년 더 사용될 것이라고 확신합니다. 따라서 (데이터 과학을 위해) 명령줄 사용법을 배우는 것은 가치 있는 투자입니다.

## 실제 사용 사례

이전 섹션에서는 데이터 과학의 정의를 제공하고 명령줄이 데이터 과학을 수행하기에 훌륭한 환경이 될 수 있는 이유를 설명했습니다. 이제 실제 사용 사례를 통해 명령줄의 강력함과 유연성을 보여줄 차례입니다. 꽤 빠르게 진행할 것이므로 아직 이해가 되지 않는 부분이 있더라도 걱정하지 마십시오.

개인적으로 뉴욕 패션 위크가 언제 열리는지 기억하지 못하는 것 같습니다. 일 년에 두 번 열린다는 것은 알지만 매번 놀랍습니다! 이 섹션에서는 *뉴욕 타임스*의 멋진 API를 참조하여 언제 열리는지 알아볼 것입니다. [개발자 웹사이트](http://developer.nytimes.com)에서 자신만의 API 키를 얻으면 예를 들어 기사를 검색하고, 베스트셀러 목록을 얻고, 이벤트 목록을 볼 수 있습니다.

쿼리할 특정 API 엔드포인트는 기사 검색 엔드포인트입니다. 뉴욕 패션 위크에 대한 *뉴욕 타임스*의 보도량이 급증하면 개최 여부를 알 수 있을 것으로 예상합니다. API 결과는 페이지로 나뉘므로 동일한 쿼리를 여러 번 실행해야 하지만 페이지 번호는 다릅니다. (검색 엔진에서 다음을 클릭하는 것과 같습니다.) 여기서 GNU Parallel [@parallel]이 `for` 루프 역할을 할 수 있으므로 매우 유용합니다. 전체 명령은 다음과 같습니다( `parallel`에 지정된 모든 명령줄 인수에 대해 걱정하지 마십시오. [8장](#parallel-pipelines)에서 자세히 설명할 것입니다).

```{bash, eval=FALSE}
$ cd ~/book/ch01/data
$ parallel -j1 --progress --delay 0.1 --results results "curl -sL "\
> "'http://api.nytimes.com/svc/search/v2/articlesearch.json?q=New+York+'"\
> "'Fashion+Week&begin_date={1}0101&end_date={1}1231&page={2}&api-key='"\
> "'<your-api-key>'" ::: {2009..2013} ::: {0..99} > /dev/null

컴퓨터 / CPU 코어 / 실행할 최대 작업 수
1:local / 4 / 1

컴퓨터:실행 중인 작업/완료된 작업/% 시작된 작업/완료하는 데 걸린 평균 시간(초)
local:1/9/100%/0.4s
```

기본적으로 2009-2014년에 대해 동일한 쿼리를 수행하고 있습니다. API는 쿼리당 최대 100페이지(0부터 시작)만 허용하므로 중괄호 확장을 사용하여 100개의 숫자를 생성하고 있습니다. 이러한 숫자는 쿼리의 *page* 매개변수에서 사용됩니다. `New+York+Fashion+Week` 검색어가 포함된 기사를 검색하고 있습니다. API에는 특정 제한이 있으므로 한 번에 하나의 요청만 있고 요청 사이에 1초의 지연이 있는지 확인합니다. `<your-api-key>`를 기사 검색 엔드포인트에 대한 자신만의 API 키로 바꾸십시오.

각 요청은 10개의 기사를 반환하므로 총 1,000개의 기사입니다. 이것들은 페이지 조회수로 정렬되므로 보도 범위를 잘 추정할 수 있습니다. 결과는 JSON 형식이며 *results* 디렉터리에 저장합니다. 명령줄 도구 `tree` [@tree]는 하위 디렉터리가 어떻게 구성되어 있는지에 대한 개요를 제공합니다.

```{bash, eval=FALSE}
$ tree results | head
results
└── 1
    ├── 2009
    │   └── 2
    │       ├── 0
    │       │   ├── stderr
    │       │   └── stdout
    │       ├── 1
    │       │   ├── stderr
    │       │   └── stdout
```

`cat` [@cat], `jq` [@jq], `json2csv` [@json2csv]를 사용하여 결과를 결합하고 처리할 수 있습니다.

```{bash, eval=FALSE}
$ cat results/1/*/2/*/stdout |
> jq -c '.response.docs[] | {date: .pub_date, type: .document_type, '\
> 'title: .headline.main }' | json2csv -p -k date,type,title > fashion.csv
```

이 명령을 분석해 보겠습니다.

- 500개의 `parallel` 작업(또는 API 요청) 각각의 출력을 결합합니다.
- `jq`를 사용하여 각 기사의 게시 날짜, 문서 유형 및 헤드라인을 추출합니다.
- `json2csv`를 사용하여 JSON 데이터를 CSV로 변환하고 *fashion.csv*로 저장합니다.

`wc -l` [@wc]을 사용하면 이 데이터 세트에 4,855개의 기사가 포함되어 있음을 알 수 있습니다(2009년부터 모든 것을 검색했을 가능성이 높으므로 5,000개가 아님).

```{bash, eval=FALSE}
$ wc -l fashion.csv
4856 fashion.csv
```

데이터를 성공적으로 획득했는지 확인하기 위해 처음 10개 기사를 검사해 보겠습니다. 표에서 시간 및 시간대 정보를 생략하기 위해 *date* 열에 `cols` [@cols] 및 `cut` [@cut]을 적용하고 있습니다.

```{bash, eval=FALSE}
$ < fashion.csv cols -c date cut -dT -f1 | head | csvlook
|-------------+------------+-----------------------------------------|
|  날짜       | 유형       | 제목                                    |
|-------------+------------+-----------------------------------------|
|  2009-02-15 | 멀티미디어 | Michael Kors                            |
|  2009-02-20 | 멀티미디어 | 요약: 가을 패션 위크, 뉴욕              |
|  2009-09-17 | 멀티미디어 | UrbanEye: 마크 제이콥스 백스테이지      |
|  2009-02-16 | 멀티미디어 | 빌 커닝햄의 뉴욕 패션 위크              |
|  2009-02-12 | 멀티미디어 | 알렉산더 왕                             |
|  2009-09-17 | 멀티미디어 | 패션 위크 봄 2010                       |
|  2009-09-11 | 멀티미디어 | 유색인종 | 런웨이를 넘어서는 다양성     |
|  2009-09-14 | 멀티미디어 | 자신을 재창조하는 디자이너              |
|  2009-09-12 | 멀티미디어 | 길거리에서 | 캣워크                    |
|-------------+------------+-----------------------------------------|
```

성공한 것 같습니다! 통찰력을 얻으려면 데이터를 시각화하는 것이 좋습니다. 그림 \@ref(fig:fashion-week)에는 R [@R], `Rio` [@Rio], `ggplot2` [@Wickham2009]로 만든 선 그래프가 포함되어 있습니다.

```{bash, eval=FALSE}
$ < fashion.csv Rio -ge 'g + geom_freqpoly(aes(as.Date(date), color=type), '\
> 'binwidth=7) + scale_x_date() + labs(x="date", title="뉴욕 타임스의 뉴욕 패션 위크 보도")' | display
```

```{r fashion-week, echo=FALSE, fig.cap="뉴욕 타임스의 뉴욕 패션 위크 보도", fig.align="center"}
knitr::include_graphics("images/nyt-fashion-week-multi.png")
```

선 그래프를 보면 뉴욕 패션 위크가 일 년에 두 번 열린다는 것을 알 수 있습니다. 그리고 이제 언제인지 알 수 있습니다. 2월에 한 번, 9월에 한 번입니다. 올해도 같아서 준비할 수 있기를 바랍니다! 어쨌든 이 예제를 통해 *뉴욕 타임스* API가 흥미로운 데이터 소스라는 것을 보여드렸기를 바랍니다. 더 중요한 것은 명령줄이 데이터 과학을 수행하는 데 매우 강력한 접근 방식이 될 수 있다는 것을 확신시켜 드렸기를 바랍니다.

이 섹션에서는 몇 가지 중요한 개념과 흥미로운 명령줄 도구를 살펴보았습니다. 아직 이해가 되지 않는 부분이 있더라도 걱정하지 마십시오. 대부분의 개념은 [2장](#chapter-2-getting-started)에서 설명하고, 다음 장에서는 이 섹션에서 사용된 모든 명령줄 도구에 대해 자세히 설명합니다.

## 추가 읽을거리

* Mason, Hilary, and Chris H. Wiggins. 2010. “A Taxonomy of Data Science.” <a href="http://www.dataists.com/2010/09/a-taxonomy-of-data-science" class="uri">http://www.dataists.com/2010/09/a-taxonomy-of-data-science</a>.
* Patil, DJ. 2012. <em>Data Jujitsu</em>. O’Reilly Media.
* O'Neil, C. \& Schutt, R. 2013. <em>Doing Data Science</em>. O'Reilly Media.
* Shron, Max. 2014. <em>Thinking with Data</em>. O’Reilly Media.


[^1]: UNIX 운영 체제 개발은 [1969년에 시작되었습니다](http://www.unix.org/what_is_unix/history_timeline.html). 처음부터 명령줄을 특징으로 했으며 중요한 파이프 개념은 1973년에 추가되었습니다.
