# 데이터 정제 {#chapter-5-scrubbing-data}

두 장 전, 데이터 과학을 위한 OSEMN 모델의 1단계에서 다양한 출처에서 데이터를 얻는 방법을 살펴보았습니다. 이 데이터에 누락된 값, 불일치, 오류, 이상한 문자 또는 흥미롭지 않은 열이 있는 것은 드문 일이 아닙니다. 때로는 데이터의 특정 부분만 필요합니다. 그리고 때로는 데이터를 다른 형식으로 만들어야 합니다. 이러한 경우 3단계인 데이터 탐색으로 넘어가기 전에 데이터를 정제하거나 정리해야 합니다.

3장에서 얻은 데이터는 다양한 형식으로 제공될 수 있습니다. 가장 일반적인 형식은 일반 텍스트, CSV, JSON 및 HTML/XML입니다. 대부분의 명령줄 도구는 한 가지 형식으로만 작동하므로 데이터를 한 형식에서 다른 형식으로 변환할 수 있다는 것은 가치가 있습니다.

이 장에서 주로 다루는 형식인 CSV는 실제로 작업하기 가장 쉬운 형식이 아닙니다. XML 및 JSON과 달리 표준 구문이 없기 때문에 많은 CSV 데이터 세트가 손상되거나 서로 호환되지 않습니다.

데이터가 원하는 형식이 되면 일반적인 정제 작업을 적용할 수 있습니다. 여기에는 데이터 필터링, 바꾸기 및 병합이 포함됩니다. 명령줄은 대량의 데이터를 처리하도록 최적화된 강력한 명령줄 도구가 많이 존재하므로 이러한 종류의 작업에 특히 적합합니다. 이 장에서 논의할 도구에는 `cut` [@cut] 및 `sed` [@sed]와 같은 고전적인 도구와 `jq` [@jq] 및 `csvgrep` [@csvgrep]과 같은 새로운 도구가 포함됩니다.

이 장에서 논의하는 정제 작업은 입력 데이터에만 적용되는 것이 아닙니다. 때로는 일부 명령줄 도구의 출력을 다시 포맷해야 할 수도 있습니다. 예를 들어 `uniq -c`의 출력을 CSV 데이터 세트로 변환하려면 `awk` [@awk] 및 `header`를 사용할 수 있습니다.

```{bash, eval=FALSE}
$ printf 'foo\nbar\nfoo' | sort | uniq -c | sort -nr
      2 foo
      1 bar
$ printf 'foo\nbar\nfoo' | sort | uniq -c | sort -nr |
> awk '{print $2","$1}' | header -a 'value, count'
value,count
foo,2
bar,1
```

데이터에 이러한 명령줄 도구(또는 조합)가 제공하는 것보다 추가 기능이 필요한 경우 `csvsql`을 사용할 수 있습니다. 이것은 CSV 파일에서 직접 SQL 쿼리를 수행할 수 있는 새로운 명령줄 도구입니다. 그리고 이 장을 읽은 후에도 여전히 더 많은 유연성이 필요하다면 R, Python 또는 원하는 프로그래밍 언어를 자유롭게 사용할 수 있습니다.

명령줄 도구는 필요에 따라 소개됩니다. 때로는 여러 작업을 수행하기 위해 동일한 명령줄 도구를 사용하거나 그 반대로 동일한 작업을 수행하기 위해 여러 명령줄 도구를 사용할 수 있음을 알 수 있습니다. 이 장은 명령줄 도구보다는 문제나 레시피에 초점을 맞춘 요리책과 같이 더 구조화되어 있습니다.

## 개요

이 장에서는 다음을 수행하는 방법을 배웁니다.

- 데이터를 한 형식에서 다른 형식으로 변환합니다.
- CSV에 SQL 쿼리를 적용합니다.
- 줄을 필터링합니다.
- 값을 추출하고 바꿉니다.

- 열을 분할, 병합 및 추출합니다.

## 일반 텍스트에 대한 일반적인 정제 작업

이 섹션에서는 일반 텍스트에 대한 일반적인 정제 작업을 설명합니다. 공식적으로 일반 텍스트는 사람이 읽을 수 있는 문자 시퀀스와 선택적으로 특정 유형의 제어 문자(예: 탭 또는 줄 바꿈)를 나타냅니다(참조: <http://www.linfo.org/plain_text.html>). 예로는 전자책, 이메일, 로그 파일 및 소스 코드가 있습니다.

이 책의 목적을 위해 일반 텍스트에 일부 데이터가 포함되어 있고 CSV 형식과 같은 명확한 표 구조나 JSON 및 HTML 형식과 같은 중첩 구조가 없다고 가정합니다. 이러한 형식은 이 장의 뒷부분에서 설명합니다. 이러한 작업은 CSV, JSON 및 XML/HTML 형식에도 적용할 수 있지만 도구가 데이터를 일반 텍스트로 처리한다는 점에 유의하십시오.

### 줄 필터링

첫 번째 정제 작업은 줄 필터링입니다. 즉, 입력 데이터에서 각 줄이 출력으로 전달될 수 있는지 여부가 평가됩니다.

#### 위치 기준

줄을 필터링하는 가장 간단한 방법은 위치를 기준으로 하는 것입니다. 이는 예를 들어 파일의 상위 10개 줄을 검사하거나 다른 명령줄 도구의 출력에서 특정 행을 추출하려는 경우에 유용할 수 있습니다. 위치를 기준으로 필터링하는 방법을 설명하기 위해 10개의 줄이 포함된 더미 파일을 만들어 보겠습니다.

```{bash, eval=FALSE}
$ seq -f "Line %g" 10 | tee data/lines
Line 1
Line 2
Line 3
Line 4
Line 5
Line 6
Line 7
Line 8
Line 9
Line 10
```

`head`, `sed` 또는 `awk`를 사용하여 처음 3줄을 인쇄할 수 있습니다.

```{bash, eval=FALSE}
$ < lines head -n 3
$ < lines sed -n '1,3p'
$ < lines awk 'NR<=3'
Line 1
Line 2
Line 3
```

마찬가지로 `tail` [@tail]을 사용하여 마지막 3줄을 인쇄할 수 있습니다.

```{bash, eval=FALSE}
$ < lines tail -n 3
Line 8
Line 9
Line 10
```

이를 위해 `sed`와 `awk`를 사용할 수도 있지만 `tail`이 훨씬 빠릅니다.

처음 3줄을 제거하는 방법은 다음과 같습니다.

```{bash, eval=FALSE}
$ < lines tail -n +4
$ < lines sed '1,3d'
$ < lines sed -n '1,3!p'
Line 4
Line 5
Line 6
Line 7
Line 8
Line 9
Line 10
```

tail을 사용하면 하나를 추가해야 합니다.

마지막 3줄을 제거하는 것은 `head`로 수행할 수 있습니다.

```{bash, eval=FALSE}
$ < lines head -n -3
Line 1
Line 2
Line 3
Line 4
Line 5
Line 6
Line 7
```

`sed`, `awk` 또는 `head`와 `tail`의 조합을 사용하여 특정 줄(이 경우 4, 5, 6)을 인쇄(또는 추출)할 수 있습니다.

```{bash, eval=FALSE}
$ < lines sed -n '4,6p'
$ < lines awk '(NR>=4)&&(NR<=6)'
$ < lines head -n 6 | tail -n 3
Line 4
Line 5
Line 6
```

시작과 단계를 지정하여 `sed`로 홀수 줄을 인쇄하거나 모듈로 연산자를 사용하여 `awk`로 홀수 줄을 인쇄합니다.

```{bash, eval=FALSE}
$ < lines sed -n '1~2p'
$ < lines awk 'NR%2'
Line 1
Line 3
Line 5
Line 7
Line 9
```

짝수 줄 인쇄도 비슷한 방식으로 작동합니다.

```{bash, eval=FALSE}
$ < lines sed -n '0~2p'
$ < lines awk '(NR+1)%2'
Line 2
Line 4
Line 6
Line 8
Line 10
```

#### 패턴 기준

때로는 내용에 따라 줄을 추출하거나 제거하고 싶을 수 있습니다. 줄 필터링을 위한 표준 명령줄 도구인 `grep`을 사용하면 특정 패턴이나 정규식과 일치하는 모든 줄을 인쇄할 수 있습니다. 예를 들어 *이상한 나라의 앨리스*에서 모든 장 제목을 추출하려면 다음과 같이 합니다.

```{bash, eval=FALSE}
$ grep -i chapter alice.txt
CHAPTER I. Down the Rabbit-Hole
CHAPTER II. The Pool of Tears
CHAPTER III. A Caucus-Race and a Long Tale
CHAPTER IV. The Rabbit Sends in a Little Bill
CHAPTER V. Advice from a Caterpillar
CHAPTER VI. Pig and Pepper
CHAPTER VII. A Mad Tea-Party
CHAPTER VIII. The Queen's Croquet-Ground
CHAPTER IX. The Mock Turtle's Story
CHAPTER X. The Lobster Quadrille
CHAPTER XI. Who Stole the Tarts?
CHAPTER XII. Alice's Evidence
```

여기서 `-i`는 대소문자를 구분하지 않음을 의미합니다. 정규식을 지정할 수도 있습니다. 예를 들어 *The*로 시작하는 제목만 인쇄하려면 다음과 같이 합니다.

```{bash, eval=FALSE}
$ grep -E '^CHAPTER (.*)\. The' alice.txt
CHAPTER II. The Pool of Tears
CHAPTER IV. The Rabbit Sends in a Little Bill
CHAPTER VIII. The Queen's Croquet-Ground
CHAPTER IX. The Mock Turtle's Story
CHAPTER X. The Lobster Quadrille
```

정규식을 사용하려면 `-E` 명령줄 인수를 지정해야 합니다. 그렇지 않으면 `grep`이 패턴을 리터럴 문자열로 해석합니다.

#### 무작위성 기준

데이터 파이프라인을 구성하는 과정에 있고 데이터가 많은 경우 파이프라인 디버깅이 번거로울 수 있습니다. 이 경우 데이터에서 샘플링하는 것이 유용할 수 있습니다. 명령줄 도구 `sample` [@sample]의 주요 목적은 줄 단위로 입력의 특정 백분율만 출력하여 데이터의 하위 집합을 얻는 것입니다.

```{bash, eval=FALSE}
$ seq 1000 | sample -r 1% | jq -c '{line: .}'
{"line":53}
{"line":119}
{"line":141}
{"line":228}
{"line":464}
{"line":476}
{"line":523}
{"line":657}
{"line":675}
{"line":865}
{"line":948}
```

여기서 모든 입력 줄은 `jq`로 전달될 확률이 1%입니다. 이 백분율은 분수(*1/100*) 또는 확률(*0.01*)로 지정할 수도 있습니다.

`sample`에는 디버깅 중일 때 유용할 수 있는 다른 두 가지 목적이 있습니다. 첫째, 출력에 약간의 지연을 추가할 수 있습니다. 이는 입력이 상수 스트림(예: 트위터 파이어호스)이고 데이터가 너무 빨리 들어와서 무슨 일이 일어나고 있는지 볼 수 없을 때 유용합니다. 둘째, `sample`에 타이머를 설정할 수 있습니다. 이렇게 하면 진행 중인 프로세스를 수동으로 종료할 필요가 없습니다. 이전 명령에 각 출력 줄 사이에 1초 지연을 추가하고 5초 동안만 실행하려면 다음과 같이 합니다.

```{bash, eval=FALSE}
$ seq 10000 | sample -r 1% -d 1000 -s 5 | jq -c '{line: .}'
```

불필요한 계산을 방지하려면 파이프라인에서 가능한 한 빨리 `sample`을 배치하십시오(이 주장은 `head` 및 `tail`과 같이 데이터를 줄이는 모든 명령줄 도구에 적용됨). 디버깅이 끝나면 파이프라인에서 간단히 제거할 수 있습니다.

### 값 추출

이전 예제에서 실제 장 제목을 추출하려면 `grep`의 출력을 `cut`으로 파이프하는 간단한 방법을 사용할 수 있습니다.

```{bash, eval=FALSE}
$ grep -i chapter alice.txt | cut -d' ' -f3-
Down the Rabbit-Hole
The Pool of Tears
A Caucus-Race and a Long Tale
The Rabbit Sends in a Little Bill
Advice from a Caterpillar
Pig and Pepper
A Mad Tea-Party
The Queen's Croquet-Ground
The Mock Turtle's Story
The Lobster Quadrille
Who Stole the Tarts?
Alice's Evidence
```

여기서 `cut`으로 전달되는 각 줄은 공백을 기준으로 필드로 분할된 다음 세 번째 필드에서 마지막 필드까지 인쇄됩니다. 총 필드 수는 입력 줄마다 다를 수 있습니다. `sed`를 사용하면 훨씬 더 복잡한 방식으로 동일한 작업을 수행할 수 있습니다.

```{bash, eval=FALSE}
$ sed -rn 's/^CHAPTER ([IVXLCDM]{1,})\. (.*)$/\2/p' alice.txt > /dev/null
```

(출력이 동일하므로 */dev/null*로 리디렉션하여 생략합니다.) 이 방법은 정규식과 역참조를 사용합니다. 여기서 `sed`는 `grep`이 수행한 작업도 대신합니다. 이 복잡한 방법은 더 간단한 방법이 작동하지 않을 때만 권장됩니다. 예를 들어 *chapter*가 새 장의 시작을 나타내는 데만 사용되는 것이 아니라 텍스트 자체의 일부인 경우입니다. 물론 이를 해결할 수 있는 여러 수준의 복잡성이 있지만 이것은 매우 엄격한 접근 방식을 설명하기 위한 것이었습니다. 실제로는 복잡성과 유연성 사이의 적절한 균형을 찾는 것이 중요합니다.

`cut`은 문자 위치를 기준으로 분할할 수도 있다는 점에 유의할 가치가 있습니다. 이는 입력 줄당 동일한 문자 집합을 추출(또는 제거)하려는 경우에 유용합니다.

```{bash, eval=FALSE}
$ grep -i chapter alice.txt | cut -c 9-
I. Down the Rabbit-Hole
II. The Pool of Tears
III. A Caucus-Race and a Long Tale
IV. The Rabbit Sends in a Little Bill
V. Advice from a Caterpillar
VI. Pig and Pepper
VII. A Mad Tea-Party
VIII. The Queen's Croquet-Ground
IX. The Mock Turtle's Story
X. The Lobster Quadrille
XI. Who Stole the Tarts?
XII. Alice's Evidence
```

`grep`에는 모든 일치 항목을 별도의 줄에 출력하는 훌륭한 기능이 있습니다.

```{bash, eval=FALSE}
$ < alice.txt grep -oE '\w{2,}' | head
Project
Gutenberg
Alice
Adventures
in
Wonderland
by
Lewis
Carroll
This
```

하지만 *a*로 시작하고 *e*로 끝나는 모든 단어의 데이터 세트를 만들고 싶다면 어떻게 해야 할까요? 물론 그것을 위한 파이프라인도 있습니다.

```{bash, eval=FALSE}
$ < alice.txt tr '[:upper:]' '[:lower:]' | grep -oE '\w{2,}' |
> grep -E '^a.*e$' | sort | uniq -c | sort -nr |
> awk '{print $2","$1}' | header -a word,count | head | csvlook
|-------------+--------|
|  단어       | 횟수   |
|-------------+--------|
|  alice      | 403    |
|  are        | 73     |
|  archive    | 13     |
|  agree      | 11     |
|  anyone     | 5      |
|  alone      | 5      |
|  age        | 4      |
|  applicable | 3      |
|  anywhere   | 3      |
|  alive      | 3      |
|-------------+--------|
```

### 값 바꾸기 및 삭제

번역을 의미하는 명령줄 도구 `tr`을 사용하여 개별 문자를 바꿀 수 있습니다. 예를 들어 공백은 다음과 같이 밑줄로 바꿀 수 있습니다.

```{bash, eval=FALSE}
$ echo 'hello world!' | tr ' ' '_'
hello_world!
```

두 개 이상의 문자를 바꿔야 하는 경우 결합할 수 있습니다.

```{bash, eval=FALSE}
$ echo 'hello world!' | tr ' !' '_?'
hello_world?
```

`tr`은 `-d` 인수를 지정하여 개별 문자를 삭제하는 데에도 사용할 수 있습니다.

```{bash, eval=FALSE}
$ echo 'hello world!' | tr -d -c '[a-z]'
helloworld
```

여기서는 실제로 두 가지 기능을 더 사용했습니다. 첫째, 문자 집합(모든 소문자)을 지정했습니다. 둘째, 보수 `-c`를 사용해야 함을 나타냈습니다. 즉, 이 명령은 소문자만 유지합니다. `tr`을 사용하여 텍스트를 대문자로 변환할 수도 있습니다.

```{bash, eval=FALSE}
$ echo 'hello world!' | tr '[a-z]' '[A-Z]'
HELLO WORLD!
$ echo 'hello world!' | tr '[:lower:]' '[:upper:]'
HELLO WORLD!
```

후자의 명령은 ASCII가 아닌 문자도 처리하므로 더 바람직합니다. 개별 문자 이상으로 작업해야 하는 경우 `sed`가 유용할 수 있습니다. 이상한 나라의 앨리스에서 장 제목을 추출하는 `sed`의 예를 이미 보았습니다. 추출, 삭제 및 바꾸기는 실제로 `sed`에서 모두 동일한 작업입니다. 다른 정규식만 지정하면 됩니다. 예를 들어 단어를 변경하고, 반복되는 공백을 제거하고, 선행 공백을 제거하려면 다음과 같이 합니다.

```{bash, eval=FALSE}
$ echo ' hello     world!' | sed -re 's/hello/bye/;s/\s+/ /g;s/\s+//'
bye world!
```

인수 `-g`는 전역을 의미하며, 동일한 명령을 동일한 줄에 두 번 이상 적용할 수 있음을 의미합니다. 선행 공백을 제거하는 두 번째 명령에는 필요하지 않습니다. 첫 번째 명령과 마지막 명령의 정규식은 하나의 정규식으로 결합할 수 있습니다.

## CSV 작업

### 본문과 헤더와 열, 오 마이!

`tr` 및 `grep`과 같이 일반 텍스트를 정제하는 데 사용한 명령줄 도구는 CSV에 항상 적용할 수 없습니다. 그 이유는 이러한 명령줄 도구에는 헤더, 본문 및 열에 대한 개념이 없기 때문입니다. `grep`을 사용하여 줄을 필터링하지만 항상 헤더를 출력에 포함하려면 어떻게 해야 할까요? 또는 `tr`을 사용하여 특정 열의 값만 대문자로 만들고 다른 열은 그대로 두려면 어떻게 해야 할까요? 이를 위한 다단계 해결 방법이 있지만 매우 번거롭습니다. 더 나은 방법이 있습니다. CSV에 일반 명령줄 도구를 활용하기 위해 `body` [@body], `header` [@header], `cols` [@cols]라는 세 가지 명령줄 도구를 소개합니다.

첫 번째 명령줄 도구인 `body`부터 시작하겠습니다. `body`를 사용하면 CSV 파일의 본문, 즉 헤더를 제외한 모든 것에 모든 명령줄 도구를 적용할 수 있습니다. 예를 들면 다음과 같습니다.

```{bash, eval=FALSE}
$ echo -e "value\n7\n2\n5\n3" | body sort -n
value
2
3
5
7
```

CSV 파일의 헤더가 한 줄만 차지한다고 가정합니다. 완전성을 위해 소스 코드는 다음과 같습니다.

```{bash, eval=FALSE}
#!/usr/bin/env bash
IFS= read -r header
printf '%s\n' "$header"
$@
```

작동 방식은 다음과 같습니다.

- 표준 입력에서 한 줄을 가져와 *\$header*라는 변수로 저장합니다.
- 헤더를 인쇄합니다.
- 표준 입력의 나머지 데이터에 `body`로 전달된 모든 명령줄 인수를 실행합니다.

또 다른 예입니다. 다음 CSV 파일의 줄 수를 센다고 상상해 보십시오.

```{bash, eval=FALSE}
$ seq 5 | header -a count
count
1
2
3
4
5
```

`wc -l`을 사용하면 모든 줄 수를 셀 수 있습니다.

```{bash, eval=FALSE}
$ seq 5 | header -a count | wc -l
6
```

본문의 줄(헤더를 제외한 모든 것)만 고려하려면 `body`를 추가하기만 하면 됩니다.

```{bash, eval=FALSE}
$ seq 5 | header -a count | body wc -l
count
5
```

헤더는 사용되지 않으며 출력에도 다시 인쇄됩니다.

두 번째 명령줄 도구인 `header`는 이름에서 알 수 있듯이 CSV 파일의 헤더를 조작할 수 있도록 합니다. 전체 소스 코드는 다음과 같습니다.

```{bash, eval=FALSE}
#!/usr/bin/env bash
get_header () {
        for i in $(seq $NUMROWS); do
                IFS= read -r LINE
                OLDHEADER="${OLDHEADER}${LINE}\n"
        done
}

print_header () {
        echo -ne "$1"
}

print_body () {
        cat
}

OLDHEADER=
NUMROWS=1

while getopts "dn:ha:r:e:" OPTION
do
        case $OPTION in
                n)
                        NUMROWS=$OPTARG
                        ;;
                a)
                        print_header "$OPTARG\n"
                        print_body
                        exit 1
                        ;;
                d)
                        get_header
                        print_body
                        exit 1
                        ;;
                r)
                        get_header
                        print_header "$OPTARG\n"
                        print_body
                        exit 1
                        ;;
                e)
                        get_header
                        print_header "$(echo -ne $OLDHEADER | eval $OPTARG)\n"
                        print_body
                        exit 1
                        ;;
                h)
                        usage
                        exit 1
                        ;;
        esac
done

get_header
print_header $OLDHEADER
```

인수가 제공되지 않으면 CSV 파일의 헤더가 인쇄됩니다.

```{bash, eval=FALSE}
$ < tips.csv | header
bill,tip,sex,smoker,day,time,size
```

이것은 `head -n 1`과 동일합니다. 헤더가 권장되지 않는 한 줄 이상인 경우 `-n 2`를 지정할 수 있습니다. CSV 파일에 헤더를 추가할 수도 있습니다.

```{bash, eval=FALSE}
$ seq 5 | header -a count
count
1
2
3
4
5
```

이것은 `echo "count" | cat - <(seq 5)`와 동일합니다. 헤더 삭제는 `-d` 명령줄 인수를 사용하여 수행됩니다.

```{bash, eval=FALSE}
$ < iris.csv | header -d | head
5.1,3.5,1.4,0.2,Iris-setosa
4.9,3.0,1.4,0.2,Iris-setosa
4.7,3.2,1.3,0.2,Iris-setosa
4.6,3.1,1.5,0.2,Iris-setosa
5.0,3.6,1.4,0.2,Iris-setosa
5.4,3.9,1.7,0.4,Iris-setosa
4.6,3.4,1.4,0.3,Iris-setosa
5.0,3.4,1.5,0.2,Iris-setosa
4.4,2.9,1.4,0.2,Iris-setosa
4.9,3.1,1.5,0.1,Iris-setosa
```

이것은 `tail -n +2`와 유사하지만 기억하기가 좀 더 쉽습니다. 헤더 바꾸기는 기본적으로 위 소스 코드를 보면 헤더를 먼저 삭제한 다음 추가하는 것이며 `-r`을 지정하여 수행됩니다. 여기서는 `body`와 결합합니다.

```{bash, eval=FALSE}
$ seq 5 | header -a line | body wc -l | header -r count
count
5
```

그리고 마지막으로, `body` 명령줄 도구가 본문에 수행하는 것과 유사하게 헤더에만 명령을 적용할 수 있습니다.

```{bash, eval=FALSE}
$ seq 5 | header -a line | header -e "tr '[a-z]' '[A-Z]'"
LINE
1
2
3
4
5
```

세 번째 명령줄 도구는 `cols`라고 하며, 특정 명령을 열의 하위 집합에만 적용할 수 있다는 점에서 `header` 및 `body`와 유사합니다. 코드는 다음과 같습니다.

```{bash, eval=FALSE}
#!/usr/bin/env bash
ARG="$1"
shift
COLUMNS="$1"
shift
EXPR="$@"
DIRTMP=$(mktemp -d)
mkfifo $DIRTMP/other_columns
tee $DIRTMP/other_columns | csvcut $ARG $COLUMNS | ${EXPR} |
paste -d, - <(csvcut ${ARG~~} $COLUMNS $DIRTMP/other_columns)
rm -rf $DIRTMP
```

예를 들어 팁 데이터 세트의 요일 열 값을 대문자로 만들고(다른 열과 헤더에 영향을 주지 않고) 싶다면 다음과 같이 `cols`를 `body`와 함께 사용합니다.

```{bash, eval=FALSE}
$ < tips.csv cols -c day body "tr '[a-z]' '[A-Z]'" | head -n 5 | csvlook -I
|------+-------+------+--------+--------+--------+-------|
|  요일 | 청구액 | 팁   | 성별   | 흡연여부 | 시간   | 인원수 |
|------+-------+------+--------+--------+--------+-------|
|  SUN | 16.99 | 1.01 | Female | No     | Dinner | 2     |
|  SUN | 10.34 | 1.66 | Male   | No     | Dinner | 3     |
|  SUN | 21.01 | 3.5  | Male   | No     | Dinner | 3     |
|  SUN | 23.68 | 3.31 | Male   | No     | Dinner | 2     |
|------+-------+------+--------+--------+--------+-------|
```

여러 명령줄 도구와 인수를 `header -e`, `body`, `cols`에 명령으로 전달하면 까다로운 따옴표 인용이 발생할 수 있습니다. 이러한 문제가 발생하면 이를 위해 별도의 명령줄 도구를 만들고 해당 명령을 전달하는 것이 가장 좋습니다.

결론적으로 일반적으로 CSV 데이터용으로 특별히 만들어진 명령줄 도구를 사용하는 것이 좋지만, 필요한 경우 `body`, `header`, `cols`를 사용하여 CSV 파일에 고전적인 명령줄 도구를 적용할 수도 있습니다.

### CSV에서 SQL 쿼리 수행

이 장에서 언급된 명령줄 도구가 충분한 유연성을 제공하지 않는 경우 명령줄에서 데이터를 정제하는 또 다른 방법이 있습니다. 명령줄 도구 `csvsql` [@csvsql]을 사용하면 CSV 파일에서 직접 SQL 쿼리를 실행할 수 있습니다. 아시다시피 SQL은 데이터 정제 작업을 정의하는 데 매우 강력한 언어입니다. 개별 명령줄 도구를 사용하는 것과는 매우 다른 방식입니다.

```{block2, type="rmdnote"}

데이터가 원래 관계형 데이터베이스에서 온 경우 가능하다면 해당 데이터베이스에서 SQL 쿼리를 실행한 다음 데이터를 CSV로 추출하십시오. 3장에서 설명했듯이 이를 위해 명령줄 도구 `sql2csv`를 사용할 수 있습니다. 데이터베이스에서 데이터를 CSV 파일로 먼저 내보낸 다음 SQL을 적용하면 속도가 느릴 뿐만 아니라 CSV 데이터에서 열 유형이 올바르게 유추되지 않을 가능성도 있습니다.
```

아래 정제 작업에서는 `csvsql`을 포함하는 몇 가지 솔루션을 포함합니다. 기본 명령은 다음과 같습니다.

```{bash, eval=FALSE}
$ seq 5 | header -a value | csvsql --query "SELECT SUM(value) AS sum FROM stdin"
sum
15
```

표준 입력을 `csvsql`에 전달하면 테이블 이름이 *stdin*으로 지정됩니다. 열 유형은 데이터에서 자동으로 유추됩니다. 나중에 CSV 파일 결합 섹션에서 볼 수 있듯이 여러 CSV 파일을 지정할 수도 있습니다. `csvsql`은 SQLite 방언을 사용한다는 점에 유의하십시오. SQL은 일반적으로 다른 솔루션보다 장황하지만 훨씬 더 유연합니다. SQL로 정제 문제를 해결하는 방법을 이미 알고 있다면 명령줄에서 사용하는 데 부끄러워할 필요가 없습니다!

## XML/HTML 및 JSON 작업

3장에서 보았듯이 얻은 데이터는 다양한 형식으로 제공될 수 있습니다. 가장 일반적인 형식은 일반 텍스트, CSV, JSON 및 HTML/XML입니다. 이 섹션에서는 데이터를 한 형식에서 다른 형식으로 변환할 수 있는 몇 가지 명령줄 도구를 보여줄 것입니다. 데이터를 변환하는 데에는 두 가지 이유가 있습니다.

첫째, 많은 시각화 및 기계 학습 알고리즘이 데이터베이스 테이블이나 스프레드시트와 같이 표 형식의 데이터를 필요로 하는 경우가 많습니다. CSV는 본질적으로 표 형식이지만 JSON 및 HTML/XML 데이터는 깊이 중첩된 구조를 가질 수 있습니다.

둘째, `cut` 및 `grep`과 같은 고전적인 도구를 포함한 많은 명령줄 도구는 일반 텍스트에서 작동합니다. 이는 텍스트가 명령줄 도구 간의 보편적인 인터페이스로 간주되기 때문입니다. 또한 다른 형식은 단순히 더 젊습니다. 이러한 각 형식은 일반 텍스트로 처리될 수 있으므로 이러한 명령줄 도구를 다른 형식에도 적용할 수 있습니다.

때로는 구조화된 데이터에 고전적인 도구를 적용하여 문제를 해결할 수 있습니다. 예를 들어 아래 JSON 데이터를 일반 텍스트로 처리하여 `sed`를 사용하여 *gender* 속성을 *sex*로 변경할 수 있습니다.

    $ sed -e 's/"gender":/"sex":/g' data/users.json | fold | head -n 3

다른 많은 명령줄 도구와 마찬가지로 `sed`는 데이터 구조를 사용하지 않습니다. 데이터 구조를 사용하는 명령줄 도구(예: 아래에서 설명하는 `jq`)를 사용하거나 데이터를 CSV와 같은 표 형식으로 먼저 변환한 다음 적절한 명령줄 도구를 적용하는 것이 좋습니다.

XML/HTML 및 JSON을 CSV로 변환하는 실제 사용 사례를 통해 시연할 것입니다. 여기서 사용할 명령줄 도구는 `curl`, `scrape` [@scrape], `xml2json` [@xml2json], `jq` [@jq], `json2csv` [@json2csv]입니다.

위키피디아에는 풍부한 정보가 있습니다. 이 정보의 대부분은 데이터 세트로 간주될 수 있는 표로 정렬되어 있습니다. 예를 들어 <http://en.wikipedia.org/wiki/List_of_countries_and_territories_by_border/area_ratio> 페이지에는 국경 길이, 면적 및 둘 사이의 비율과 함께 국가 및 영토 목록이 포함되어 있습니다.

이 데이터를 분석하는 데 관심이 있다고 상상해 보겠습니다. 이 섹션에서는 필요한 모든 단계와 해당 명령을 안내합니다. 모든 세부 사항을 다루지는 않으므로 즉시 모든 것을 이해하지 못할 수도 있습니다. 걱정하지 마십시오. 요점을 파악할 수 있을 것이라고 확신합니다. 이 섹션의 목적은 명령줄을 시연하는 것임을 기억하십시오. 이 섹션에서 사용된 모든 도구와 개념(그리고 그 이상)은 다음 장에서 설명합니다.

관심 있는 데이터 세트는 HTML에 포함되어 있습니다. 우리의 목표는 이 데이터 세트를 작업할 수 있는 표현으로 만드는 것입니다. 가장 첫 번째 단계는 `curl`을 사용하여 HTML을 다운로드하는 것입니다.

```{bash, eval=FALSE}
$ curl -sL 'http://en.wikipedia.org/wiki/List_of_countries_and_territories_'\
> 'by_border/area_ratio' > data/wiki.html
```

옵션 `-s`는 `curl`이 자동 모드로 작동하여 실제 HTML 이외의 다른 정보를 출력하지 않도록 합니다. HTML은 `data/wiki.html`이라는 파일에 저장됩니다. 처음 10줄이 어떻게 보이는지 살펴보겠습니다.

```{bash, eval=FALSE}
$ head -n 10 data/wiki.html | cut -c1-79
<!DOCTYPE html>
<html lang="en" dir="ltr" class="client-nojs">
<head>
<meta charset="UTF-8" /><title>국경/면적 비율별 국가 및 영토 목록
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" /><meta name="generator" c
<link rel="alternate" type="application/x-wiki" title="이 페이지 편집" href="/w
<link rel="edit" title="이 페이지 편집" href="/w/index.php?title=List_of_countr
<link rel="apple-touch-icon" href="//bits.wikimedia.org/apple-touch/wikipedia.p
<link rel="shortcut icon" href="//bits.wikimedia.org/favicon/wikipedia.ico" />
<link rel="search" type="application/opensearchdescription+xml" href="/w/opense
```

정상적으로 보입니다. (출력이 페이지에 맞도록 각 줄의 처음 79자만 표시합니다.)

브라우저의 개발자 도구를 사용하여 관심 있는 루트 HTML 요소가 클래스 *wikitable*을 가진 *&lt;table&gt;*임을 확인할 수 있었습니다. 이를 통해 `grep`을 사용하여 관심 있는 부분을 볼 수 있습니다(`-A` 명령줄 인수는 일치하는 줄 뒤에 보고 싶은 줄 수를 지정합니다).

```{bash, eval=FALSE}
$ < data/wiki.html grep wikitable -A 21
<table class="wikitable sortable">
<tr>
<th>순위</th>
<th>국가 또는 영토</th>
<th>총 육지 국경 길이 (km)</th>
<th>총 표면적 (km²)</th>
<th>국경/면적 비율 (km/km²)</th>
</tr>
<tr>
<td>1</td>
<td>바티칸 시국</td>
<td>3.2</td>
<td>0.44</td>
<td>7.2727273</td>
</tr>
<tr>
<td>2</td>
<td>모나코</td>
<td>4.4</td>
<td>2</td>
<td>2.2000000</td>
</tr>
```

이제 스크린샷에서 처음 보았던 국가와 해당 값을 실제로 볼 수 있습니다. 다음 단계는 HTML 파일에서 필요한 요소를 추출하는 것입니다. 이를 위해 `scrape` 도구를 사용합니다.

```{bash, eval=FALSE}
$ < data/wiki.html scrape -b -e 'table.wikitable > tr:not(:first-child)' \
> > data/table.html
$ head -n 21 data/table.html
<!DOCTYPE html>
<html>
<body>
<tr><td>1</td>
<td>바티칸 시국</td>
<td>3.2</td>
<td>0.44</td>
<td>7.2727273</td>
</tr>
<tr><td>2</td>
<td>모나코</td>
<td>4.4</td>
<td>2</td>
<td>2.2000000</td>
</tr>
<tr><td>3</td>
<td>산마리노</td>
<td>39</td>
<td>61</td>
<td>0.6393443</td>
</tr>
```

인수 `-e`( *표현식*을 의미하며 다른 많은 명령줄 도구에서도 마찬가지임)에 전달된 값은 소위 CSS 선택기입니다. 구문은 일반적으로 웹 페이지 스타일을 지정하는 데 사용되지만 HTML에서 특정 요소를 선택하는 데에도 사용할 수 있습니다. 이 경우 *wikitable* 클래스에 속하는 테이블의 일부인 모든 *&lt;tr&gt;* 요소 또는 *행*(첫 번째 제외)을 선택하려고 합니다. 이것이 바로 우리가 관심 있는 테이블입니다. 첫 번째 행을 원하지 않는 이유(*:not(first-child)*로 지정됨)는 테이블의 헤더를 원하지 않기 때문입니다. 이렇게 하면 각 행이 국가 또는 영토를 나타내는 데이터 세트가 생성됩니다. 보시다시피 이제 *&lt;html&gt;* 및 *&lt;body&gt;* 요소(`-b` 인수를 지정했기 때문)로 캡슐화된 원하는 *&lt;tr&gt;* 요소가 있습니다. 이렇게 하면 다음 도구인 `xml2json`이 작동할 수 있습니다.

이름에서 알 수 있듯이 `xml2json`은 XML(및 HTML)을 JSON으로 변환합니다.

```{bash, eval=FALSE}
$ < data/table.html xml2json > data/table.json
$ < data/table.json jq '.' | head -n 25
{
  "html": {
    "body": {
      "tr": [
        {
          "td": [
            {
              "$t": "1"
            },
            {
              "$t": "바티칸 시국"
            },
            {
              "$t": "3.2"
            },
            {
              "$t": "0.44"
            },
            {
              "$t": "7.2727273"
            }
          ]
        },
        {
          "td": [
```

HTML을 JSON으로 변환하는 이유는 JSON 데이터에서 작동하는 매우 강력한 도구인 `jq`가 있기 때문입니다. 다음 명령은 JSON 데이터의 특정 부분을 추출하여 작업할 수 있는 형태로 재구성합니다.

```{bash, eval=FALSE}
$ < data/table.json jq -c '.html.body.tr[] | {country: .td[1][],border:'\
> '.td[2][], surface: .td[3][]}' > data/countries.json
$ head -n 10 data/countries.json
{"surface":"0.44","border":"3.2","country":"바티칸 시국"}
{"surface":"2","border":"4.4","country":"모나코"}
{"surface":"61","border":"39","country":"산마리노"}
{"surface":"160","border":"76","country":"리히텐슈타인"}
{"surface":"34","border":"10.2","country":"신트마르턴 (네덜란드)"}
{"surface":"468","border":"120.3","country":"안도라"}
{"surface":"6","border":"1.2","country":"지브롤터 (영국)"}
{"surface":"54","border":"10.2","country":"생마르탱 (프랑스)"}
{"surface":"2586","border":"359","country":"룩셈부르크"}
{"surface":"6220","border":"466","country":"팔레스타인 영토"}
```

이제 뭔가 되어가고 있습니다. JSON은 많은 장점이 있는 매우 인기 있는 데이터 형식이지만, 우리의 목적을 위해서는 데이터를 CSV 형식으로 갖는 것이 더 좋습니다. `json2csv` 도구는 데이터를 JSON에서 CSV로 변환할 수 있습니다.

```{bash, eval=FALSE}
$ < data/countries.json json2csv -p -k border,surface > data/countries.csv
$ head -n 11 data/countries.csv | csvlook
|---------+----------|
|  국경   | 표면적   |
|---------+----------|
|  3.2    | 0.44     |
|  4.4    | 2        |
|  39     | 61       |
|  76     | 160      |
|  10.2   | 34       |
|  120.3  | 468      |
|  1.2    | 6        |
|  10.2   | 54       |
|  359    | 2586     |
|  466    | 6220     |
|---------+----------|
```

이제 데이터가 작업할 수 있는 형태가 되었습니다. 위키백과 페이지에서 CSV 데이터 세트를 얻기까지 꽤 많은 단계가 있었습니다. 그러나 위의 모든 명령을 하나로 결합하면 실제로는 매우 간결하고 표현력이 풍부하다는 것을 알 수 있습니다.

```{bash, eval=FALSE}
$ curl -sL 'http://en.wikipedia.org/wiki/List_of_countries'\
> '_and_territories_by_border/area_ratio' |
> scrape -be 'table.wikitable > tr:not(:first-child)' |
> xml2json | jq -c '.html.body.tr[] | {country: .td[1][],'\
> 'border: .td[2][], surface: .td[3][], ratio: .td[4][]}' |
> json2csv -p -k=border,surface | head -n 11 | csvlook
|---------+----------|
|  국경   | 표면적   |
|---------+----------|
|  3.2    | 0.44     |
|  4.4    | 2        |
|  39     | 61       |
|  76     | 160      |
|  10.2   | 34       |
|  120.3  | 468      |
|  1.2    | 6        |
|  10.2   | 54       |
|  359    | 2586     |
|  466    | 6220     |
|---------+----------|
```

이것으로 XML/HTML을 JSON으로, JSON을 CSV로 변환하는 시연을 마칩니다. `jq`는 훨씬 더 많은 작업을 수행할 수 있고 XML 데이터로 작업하기 위한 특수 도구가 존재하지만, 우리의 경험상 데이터를 가능한 한 빨리 CSV 형식으로 변환하는 것이 잘 작동하는 경향이 있습니다. 이렇게 하면 매우 특정한 도구보다는 일반적인 명령줄 도구에 능숙해지는 데 더 많은 시간을 할애할 수 있습니다.

## CSV에 대한 일반적인 정제 작업

### 열 추출 및 재정렬

명령줄 도구 `csvcut` [@csvcut]을 사용하여 열을 추출하고 재정렬할 수 있습니다. 예를 들어 아이리스 데이터 세트에서 숫자 값을 포함하는 열만 유지하고 가운데 두 열의 순서를 바꾸려면 다음과 같이 합니다.

```{bash, eval=FALSE}
$ < iris.csv csvcut -c sepal_length,petal_length,sepal_width,petal_width |
> head -n 5 | csvlook
|---------------+--------------+-------------+--------------|
|  꽃받침_길이 | 꽃잎_길이    | 꽃받침_너비 | 꽃잎_너비    |
|---------------+--------------+-------------+--------------|
|  5.1          | 1.4          | 3.5         | 0.2          |
|  4.9          | 1.4          | 3.0         | 0.2          |
|  4.7          | 1.3          | 3.2         | 0.2          |
|  4.6          | 1.5          | 3.1         | 0.2          |
|---------------+--------------+-------------+--------------|
```

또는 *보수*를 의미하는 `-C`를 사용하여 제외할 열을 지정할 수도 있습니다.

```{bash, eval=FALSE}
$ < iris.csv csvcut -C species | head -n 5 | csvlook
|---------------+-------------+--------------+--------------|
|  꽃받침_길이 | 꽃받침_너비 | 꽃잎_길이    | 꽃잎_너비    |
|---------------+-------------+--------------+--------------|
|  5.1          | 3.5         | 1.4          | 0.2          |
|  4.9          | 3.0         | 1.4          | 0.2          |
|  4.7          | 3.2         | 1.3          | 0.2          |
|  4.6          | 3.1         | 1.5          | 0.2          |
|---------------+-------------+--------------+--------------|
```

여기서 포함된 열은 동일한 순서로 유지됩니다. 열 이름 대신 열의 인덱스(1부터 시작)를 지정할 수도 있습니다. 예를 들어 홀수 열만 선택할 수 있습니다(필요한 경우!).

```{bash, eval=FALSE}
$ echo 'a,b,c,d,e,f,g,h,i\n1,2,3,4,5,6,7,8,9' |
> csvcut -c $(seq 1 2 9 | paste -sd,)
a,c,e,g,i
1,3,5,7,9
```

값에 쉼표가 없는 것이 확실하다면 `cut`을 사용하여 열을 추출할 수도 있습니다. `cut`은 다음 명령에서 보여주듯이 열 순서를 바꾸지 않는다는 점에 유의하십시오.

```{bash, eval=FALSE}
$ echo 'a,b,c,d,e,f,g,h,i\n1,2,3,4,5,6,7,8,9' | cut -d, -f 5,1,3
a,c,e
1,3,5
```

보시다시피 `-f`로 열을 지정하는 순서는 중요하지 않으며, `cut`을 사용하면 항상 원래 순서대로 표시됩니다. 완전성을 위해 아이리스 데이터 세트의 숫자 열을 추출하고 재정렬하는 SQL 접근 방식도 살펴보겠습니다.

```{bash, eval=FALSE}
$ < iris.csv csvsql --query "SELECT sepal_length, petal_length, "\
> "sepal_width, petal_width FROM stdin" | head -n 5 | csvlook
|---------------+--------------+-------------+--------------|
|  꽃받침_길이 | 꽃잎_길이    | 꽃받침_너비 | 꽃잎_너비    |
|---------------+--------------+-------------+--------------|
|  5.1          | 1.4          | 3.5         | 0.2          |
|  4.9          | 1.4          | 3.0         | 0.2          |
|  4.7          | 1.3          | 3.2         | 0.2          |
|  4.6          | 1.5          | 3.1         | 0.2          |
|---------------+--------------+-------------+--------------|
```

### 줄 필터링

CSV 파일에서 줄을 필터링하는 것과 일반 텍스트 파일에서 줄을 필터링하는 것의 차이점은 특정 열의 값을 기준으로 이 필터링을 수행하고 싶을 수 있다는 것입니다. 위치를 기준으로 필터링하는 것은 기본적으로 동일하지만 CSV 파일의 첫 번째 줄이 일반적으로 헤더라는 점을 고려해야 합니다. 헤더를 유지하려면 항상 `body` 명령줄 도구를 사용할 수 있다는 것을 기억하십시오.

```{bash, eval=FALSE}
$ seq 5 | sed -n '3,5p'
3
4
5
$ seq 5 | header -a count | body sed -n '3,5p'
count
3
4
5
```

특정 열 내의 특정 패턴을 기준으로 필터링하는 경우 `csvgrep`, `awk` 또는 물론 `csvsql`을 사용할 수 있습니다. 예를 들어 파티 크기가 4 이하인 모든 청구서를 제외하려면 다음과 같이 합니다.

```{bash, eval=FALSE}
$ csvgrep -c size -i -r "[1-4]" tips.csv | csvlook
|--------+------+--------+--------+------+--------+-------|
|  청구액 | 팁   | 성별   | 흡연여부 | 요일 | 시간   | 인원수 |
|--------+------+--------+--------+------+--------+-------|
|  29.8  | 4.2  | Female | No     | Thur | Lunch  | 6     |
|  34.3  | 6.7  | Male   | No     | Thur | Lunch  | 6     |
|  41.19 | 5.0  | Male   | No     | Thur | Lunch  | 5     |
|  27.05 | 5.0  | Female | No     | Thur | Lunch  | 6     |
|  29.85 | 5.14 | Female | No     | Sun  | Dinner | 5     |
|  48.17 | 5.0  | Male   | No     | Sun  | Dinner | 6     |
|  20.69 | 5.0  | Male   | No     | Sun  | Dinner | 5     |
|  30.46 | 2.0  | Male   | Yes    | Sun  | Dinner | 5     |
|  28.15 | 3.0  | Male   | Yes    | Sat  | Dinner | 5     |
|--------+------+--------+--------+------+--------+-------|
```

`awk`와 `csvsql` 모두 숫자 비교도 수행할 수 있습니다. 예를 들어 토요일이나 일요일에 40달러 이상의 모든 청구서를 가져오려면 다음과 같이 합니다.

```{bash, eval=FALSE}
$ < tips.csv awk -F, '($1 > 40.0) && ($5 ~ /S/)' | csvlook -I
|--------+------+--------+-----+-----+--------+----|
|  48.27 | 6.73 | Male   | No  | Sat | Dinner | 4  |
|--------+------+--------+-----+-----+--------+----|
|  44.3  | 2.5  | Female | Yes | Sat | Dinner | 3  |
|  48.17 | 5.0  | Male   | No  | Sun | Dinner | 6  |
|  50.81 | 10.0 | Male   | Yes | Sat | Dinner | 3  |
|  45.35 | 3.5  | Male   | Yes | Sun | Dinner | 3  |
|  40.55 | 3.0  | Male   | Yes | Sun | Dinner | 2  |
|  48.33 | 9.0  | Male   | No  | Sat | Dinner | 4  |
|--------+------+--------+-----+-----+--------+----|
```

`csvsql` 솔루션은 열 이름 대신 인덱스를 사용하므로 더 장황하지만 더 강력합니다.

```{bash, eval=FALSE}
$ < tips.csv csvsql --query "SELECT * FROM stdin "\
> "WHERE bill > 40 AND day LIKE '%S%'" | csvlook -I
|--------+------+--------+--------+-----+--------+-------|
|  청구액 | 팁   | 성별   | 흡연여부 | 요일 | 시간   | 인원수 |
|--------+------+--------+--------+-----+--------+-------|
|  48.27 | 6.73 | Male   | 0      | Sat | Dinner | 4     |
|  44.3  | 2.5  | Female | 1      | Sat | Dinner | 3     |
|  48.17 | 5.0  | Male   | 0      | Sun | Dinner | 6     |
|  50.81 | 10.0 | Male   | 1      | Sat | Dinner | 3     |
|  45.35 | 3.5  | Male   | 1      | Sun | Dinner | 3     |
|  40.55 | 3.0  | Male   | 1      | Sun | Dinner | 2     |
|  48.33 | 9.0  | Male   | 0      | Sat | Dinner | 4     |
|--------+------+--------+--------+-----+--------+-------|
```

SQL 쿼리의 *WHERE* 절의 유연성은 SQL이 날짜와 집합에서 작동하고 복잡한 절 조합을 형성할 수 있으므로 다른 명령줄 도구와 쉽게 일치시킬 수 없다는 점에 유의해야 합니다.

### 열 병합

열 병합은 관심 있는 값이 여러 열에 분산되어 있을 때 유용합니다. 이는 날짜(연도, 월, 일이 별도의 열일 수 있음) 또는 이름(성과 이름이 별도의 열일 수 있음)의 경우에 발생할 수 있습니다. 두 번째 상황을 고려해 보겠습니다.

입력 CSV는 현대 작곡가 목록입니다. 우리의 작업은 성과 이름을 전체 이름으로 결합하는 것이라고 상상해 보십시오. 이 작업을 위해 `sed`, `awk`, `cols` + `tr`, `csvsql`이라는 네 가지 다른 접근 방식을 제시합니다. 입력 CSV를 살펴보겠습니다.

```{bash, eval=FALSE}
$ < names.csv csvlook -I
|-----+-----------+------------+-------|
|  id | 성        | 이름       | 출생  |
|-----+-----------+------------+-------|
|  1  | Williams  | John       | 1932  |
|  2  | Elfman    | Danny      | 1953  |
|  3  | Horner    | James      | 1953  |
|  4  | Shore     | Howard     | 1946  |
|  5  | Zimmer    | Hans       | 1957  |
|-----+-----------+------------+-------|
```

첫 번째 접근 방식인 `sed`는 두 개의 문을 사용합니다. 첫 번째는 헤더를 바꾸는 것이고 두 번째는 두 번째 행부터 적용되는 역참조가 있는 정규식입니다.

```{bash, eval=FALSE}
$ < names.csv sed -re '1s/.*/id,full_name,born/g;'\
> '2,$s/(.*),(.*),(.*),(.*)/\1,\3 \2,\4/g' | csvlook -I
|-----+---------------+-------|
|  id | 전체_이름     | 출생  |
|-----+---------------+-------|
|  1  | John Williams | 1932  |
|  2  | Danny Elfman  | 1953  |
|  3  | James Horner  | 1953  |
|  4  | Howard Shore  | 1946  |
|  5  | Hans Zimmer   | 1957  |
|-----+---------------+-------|
```

`awk` 접근 방식은 다음과 같습니다.

```{bash, eval=FALSE}
$ < names.csv awk -F, 'BEGIN{OFS=","; print "id,full_name,born"}'\
> '{if(NR > 1) {print $1,$3" "$2,$4}}' | csvlook -I
|-----+---------------+-------|
|  id | 전체_이름     | 출생  |
|-----+---------------+-------|
|  1  | John Williams | 1932  |
|  2  | Danny Elfman  | 1953  |
|  3  | James Horner  | 1953  |
|  4  | Howard Shore  | 1946  |
|  5  | Hans Zimmer   | 1957  |
|-----+---------------+-------|
```

`tr`과 결합된 `cols` 접근 방식:

```{bash, eval=FALSE}
$ < names.csv | cols -c first_name,last_name tr \",\" \" \" |
> header -r full_name,id,born | csvcut -c id,full_name,born | csvlook -I
|-----+---------------+-------|
|  id | 전체_이름     | 출생  |
|-----+---------------+-------|
|  1  | John Williams | 1932  |
|  2  | Danny Elfman  | 1953  |
|  3  | James Horner  | 1953  |
|  4  | Howard Shore  | 1946  |
|  5  | Hans Zimmer   | 1957  |
|-----+---------------+-------|
```

`csvsql`은 쿼리를 실행하기 위해 SQLite를 데이터베이스로 사용하며 `||`는 연결을 의미한다는 점에 유의하십시오.

```{bash, eval=FALSE}
$ < names.csv csvsql --query "SELECT id, first_name || ' ' || last_name "\
> "AS full_name, born FROM stdin" | csvlook -I
|-----+-----------------------+-------|
|  id | 전체_이름             | 출생  |
|-----+-----------------------+-------|
|  1  | John Williams         | 1932  |
|  2  | Danny Elfman          | 1953  |
|  3  | James Horner          | 1953  |
|  4  | Howard Shore          | 1946  |
|  5  | Hans Zimmer           | 1957  |
|-----+-----------------------+-------|
```

*last\_name*에 쉼표가 포함되어 있으면 어떻게 될까요? 명확성을 위해 원시 입력 CSV를 살펴보겠습니다.

```{bash, eval=FALSE}
$ cat names-comma.csv
id,last_name,first_name,born
1,Williams,John,1932
2,Elfman,Danny,1953
3,Horner,James,1953
4,Shore,Howard,1946
5,Zimmer,Hans,1957
6,"Beethoven, van",Ludwig,1770
```

음, 처음 세 가지 접근 방식은 모두 다른 방식으로 실패하는 것 같습니다. `csvsql`만 성과 이름을 결합할 수 있습니다.

```{bash, eval=FALSE}
$ < names-comma.csv sed -re '1s/.*/id,full_name,born/g;'\
> '2,$s/(.*),(.*),(.*),(.*)/\1,\3 \2,\4/g' | tail -n 1
6,"Beethoven,Ludwig  van",1770
```

```{bash, eval=FALSE}
$ < names-comma.csv awk -F, 'BEGIN{OFS=","; print "id,full_name,born"}'\
> '{if(NR > 1) {print $1,$3" "$2,$4}}' | tail -n 1
6, van" "Beethoven,Ludwig
```

```{bash, eval=FALSE}
$ < names-comma.csv | cols -c first_name,last_name tr \",\" \" \" |
> header -r full_name,id,born | csvcut -c id,full_name,born | tail -n 1
6,"Ludwig ""Beethoven  van""",1770
```

```{bash, eval=FALSE}
$ < names-comma.csv csvsql --query "SELECT id, first_name || ' ' || last_name"\
> " AS full_name, born FROM stdin" | tail -n 1
6,"Ludwig Beethoven, van",1770
```

```{bash, eval=FALSE}
$ < names-comma.csv Rio -e 'df$full_name <- paste(df$first_name, df$last_name);'\
> 'df[c("id","full_name","born")]' | tail -n 1
6,"Ludwig Beethoven, van",1770
```

잠깐만요! 마지막 명령은 무엇입니까? R입니까? 사실 그렇습니다. `Rio` [@Rio]라는 명령줄 도구를 통해 평가된 R 코드입니다. 지금 당장 말할 수 있는 것은 이 접근 방식도 두 열을 병합하는 데 성공한다는 것입니다. 이 편리한 명령줄 도구에 대해서는 나중에 설명하겠습니다.

### 여러 CSV 파일 결합

#### 세로로 연결

예를 들어 매일 생성되는 데이터 세트가 있거나 각 데이터 세트가 다른 시장이나 제품을 나타내는 경우 세로 연결이 필요할 수 있습니다. 사랑하는 아이리스 데이터 세트를 세 개의 CSV 파일로 분할하여 다시 결합할 수 있도록 시뮬레이션해 보겠습니다. 명령줄 도구 모음인 `CRUSH`의 일부인 `fieldsplit` [@fieldsplit]을 사용합니다.

```{bash, eval=FALSE}
$ < iris.csv fieldsplit -d, -k -F species -p . -s .csv
```

여기서 명령줄 인수는 구분 기호(`-d`), 각 파일에 헤더를 유지할지 여부(`-k`), 가능한 출력 파일을 결정하는 값이 있는 열(`-F`), 상대 출력 경로(`-p`), 파일 이름 접미사(`-s`)를 각각 지정합니다. 아이리스 데이터 세트의 *species* 열에는 세 가지 다른 값이 포함되어 있으므로 각각 50개의 데이터 포인트와 헤더가 있는 세 개의 CSV 파일이 생성됩니다.

```{bash, eval=FALSE}
$ wc -l Iris-*.csv
  51 Iris-setosa.csv
  51 Iris-versicolor.csv
  51 Iris-virginica.csv
 153 total
```

`cat`을 사용하여 파일을 다시 연결하고 다음과 같이 `header -d`를 사용하여 첫 번째 파일을 제외한 모든 파일의 헤더를 제거할 수 있습니다.

```{bash, eval=FALSE}
$ cat Iris-setosa.csv <(< Iris-versicolor.csv header -d) \
> <(< Iris-virginica.csv header -d) | sed -n '1p;49,54p' | csvlook
|---------------+-------------+--------------+-------------+------------------|
|  꽃받침_길이 | 꽃받침_너비 | 꽃잎_길이    | 꽃잎_너비    | 종               |
|---------------+-------------+--------------+-------------+------------------|
|  4.6          | 3.2         | 1.4          | 0.2         | Iris-setosa      |
|  5.3          | 3.7         | 1.5          | 0.2         | Iris-setosa      |
|  5.0          | 3.3         | 1.4          | 0.2         | Iris-setosa      |
|  7.0          | 3.2         | 4.7          | 1.4         | Iris-versicolor  |
|  6.4          | 3.2         | 4.5          | 1.5         | Iris-versicolor  |
|  6.9          | 3.1         | 4.9          | 1.5         | Iris-versicolor  |
|---------------+-------------+--------------+-------------+------------------|
```

성공을 설명하기 위해 두 번째 파일에 속한 헤더와 처음 세 개의 본문 행만 인쇄하기 위해 `sed`를 사용하고 있습니다. 이 방법은 작동하지만 `csvstack` [@csvstack]을 사용하는 것이 더 쉽고 오류 발생 가능성이 적습니다.

```{bash, eval=FALSE}
$ csvstack Iris-*.csv | sed -n '1p;49,54p' | csvlook
|---------------+-------------+--------------+-------------+------------------|
|  꽃받침_길이 | 꽃받침_너비 | 꽃잎_길이    | 꽃잎_너비    | 종               |
|---------------+-------------+--------------+-------------+------------------|
|  4.6          | 3.2         | 1.4          | 0.2         | Iris-setosa      |
|  5.3          | 3.7         | 1.5          | 0.2         | Iris-setosa      |
|  5.0          | 3.3         | 1.4          | 0.2         | Iris-setosa      |
|  7.0          | 3.2         | 4.7          | 1.4         | Iris-versicolor  |
|  6.4          | 3.2         | 4.5          | 1.5         | Iris-versicolor  |
|  6.9          | 3.1         | 4.9          | 1.5         | Iris-versicolor  |
|---------------+-------------+--------------+-------------+------------------|
```

종 열이 존재하지 않는 경우 `csvstack`을 사용하여 파일 이름을 기반으로 새 열을 만들 수 있습니다.

```{bash, eval=FALSE}
$ csvstack Iris-*.csv -n species --filenames
```

또는 `-g`를 사용하여 그룹 이름을 지정할 수 있습니다.

```{bash, eval=FALSE}
$ csvstack Iris-*.csv -n class -g a,b,c | csvcut -C species |
> sed -n '1p;49,54p' | csvlook
|--------+--------------+-------------+--------------+--------------|
|  클래스 | 꽃받침_길이 | 꽃받침_너비 | 꽃잎_길이    | 꽃잎_너비    |
|--------+--------------+-------------+--------------+--------------|
|  a     | 4.6          | 3.2         | 1.4          | 0.2          |
|  a     | 5.3          | 3.7         | 1.5          | 0.2          |
|  a     | 5.0          | 3.3         | 1.4          | 0.2          |
|  b     | 7.0          | 3.2         | 4.7          | 1.4          |
|  b     | 6.4          | 3.2         | 4.5          | 1.5          |
|  b     | 6.9          | 3.1         | 4.9          | 1.5          |
|--------+--------------+-------------+--------------+--------------|
```

새 열 *class*가 맨 앞에 추가됩니다. 순서를 변경하려면 이 섹션 앞부분에서 설명한 대로 `csvcut`을 사용할 수 있습니다.

#### 가로로 연결

나란히 놓고 싶은 세 개의 CSV 파일이 있다고 가정해 보겠습니다. 파이프라인 중간에 `csvcut`의 결과를 저장하기 위해 `tee` [@tee]를 사용합니다.

```{bash, eval=FALSE}
$ < data/tips.csv csvcut -c bill,tip | tee data/bills.csv | head -n 3 | csvlook
|--------+-------|
|  청구액 | 팁    |
|--------+-------|
|  16.99 | 1.01  |
|  10.34 | 1.66  |
|--------+-------|
$ < data/tips.csv csvcut -c day,time | tee data/datetime.csv |
> head -n 3 | csvlook -I
|------+---------|
|  요일 | 시간    |
|------+---------|
|  Sun | Dinner  |
|  Sun | Dinner  |
|------+---------|
$ < data/tips.csv csvcut -c sex,smoker,size | tee data/customers.csv |
> head -n 3 | csvlook
|---------+--------+-------|
|  성별   | 흡연여부 | 인원수 |
|---------+--------+-------|
|  Female | No     | 2     |
|  Male   | No     | 3     |
|---------+--------+-------|
```

행이 정렬되어 있다고 가정하면 파일을 함께 `paste` [@paste]하기만 하면 됩니다.

```{bash, eval=FALSE}
$ paste -d, data/{bills,customers,datetime}.csv | head -n 3 | csvlook -I
|--------+------+--------+--------+------+-----+---------|
|  청구액 | 팁   | 성별   | 흡연여부 | 인원수 | 요일 | 시간    |
|--------+------+--------+--------+------+-----+---------|
|  16.99 | 1.01 | Female | No     | 2    | Sun | Dinner  |
|  10.34 | 1.66 | Male   | No     | 3    | Sun | Dinner  |
|--------+------+--------+--------+------+-----+---------|
```

여기서 명령줄 인수 `-d`는 `paste`에게 구분 기호로 쉼표를 사용하도록 지시합니다.

#### 결합

때로는 데이터를 세로 또는 가로 연결로 간단히 결합할 수 없습니다. 특히 관계형 데이터베이스의 경우 중복을 최소화하기 위해 데이터가 여러 테이블(또는 파일)에 분산되어 있는 경우가 있습니다. 아이리스 데이터 세트를 세 가지 유형의 아이리스 꽃에 대한 추가 정보, 즉 USDA 식별자로 확장하고 싶다고 상상해 보십시오. 마침 이러한 식별자가 있는 별도의 CSV 파일이 있습니다.

```{bash, eval=FALSE}
$ csvlook irismeta.csv
|------------------+----------------------------------------------+----------|
|  종              | 위키백과_url                                 | usda_id  |
|------------------+----------------------------------------------+----------|
|  Iris-versicolor | http://en.wikipedia.org/wiki/Iris_versicolor | IRVE2    |
|  Iris-virginica  | http://en.wikipedia.org/wiki/Iris_virginica  | IRVI     |
|  Iris-setosa     |                                              | IRSE     |
|------------------+----------------------------------------------+----------|
```

이 데이터 세트와 아이리스 데이터 세트의 공통점은 종 열입니다. `csvjoin` [@csvjoin]을 사용하여 두 데이터 세트를 결합할 수 있습니다.

```{bash, eval=FALSE}
$ csvjoin -c species iris.csv irismeta.csv | csvcut -c sepal_length,\
> sepal_width,species,usda_id | sed -n '1p;49,54p' | csvlook
|---------------+-------------+-----------------+----------|
|  꽃받침_길이 | 꽃받침_너비 | 종              | usda_id  |
|---------------+-------------+-----------------+----------|
|  4.6          | 3.2         | Iris-setosa     | IRSE     |
|  5.3          | 3.7         | Iris-setosa     | IRSE     |
|  5.0          | 3.3         | Iris-setosa     | IRSE     |
|  7.0          | 3.2         | Iris-versicolor | IRVE2    |
|  6.4          | 3.2         | Iris-versicolor | IRVE2    |
|  6.9          | 3.1         | Iris-versicolor | IRVE2    |
|---------------+-------------+-----------------+----------|
```

물론 `csvsql`을 사용하는 SQL 접근 방식도 사용할 수 있으며, 이는 평소와 같이 약간 더 길지만 잠재적으로 훨씬 더 유연합니다.

```{bash, eval=FALSE}
$ csvsql --query 'SELECT i.sepal_length, i.sepal_width, i.species, m.usda_id '\
> 'FROM iris i JOIN irismeta m ON (i.species = m.species)' \
> iris.csv irismeta.csv | sed -n '1p;49,54p' | csvlook
|---------------+-------------+-----------------+----------|
|  꽃받침_길이 | 꽃받침_너비 | 종              | usda_id  |
|---------------+-------------+-----------------+----------|
|  4.6          | 3.2         | Iris-setosa     | IRSE     |
|  5.3          | 3.7         | Iris-setosa     | IRSE     |
|  5.0          | 3.3         | Iris-setosa     | IRSE     |
|  7.0          | 3.2         | Iris-versicolor | IRVE2    |
|  6.4          | 3.2         | Iris-versicolor | IRVE2    |
|  6.9          | 3.1         | Iris-versicolor | IRVE2    |
|---------------+-------------+-----------------+----------|
```

## 추가 자료

* Molinaro, Anthony. 2005. <em>SQL Cookbook</em>. O’Reilly Media.
* Goyvaerts, Jan, and Steven Levithan. 2012. <em>Regular Expressions Cookbook</em>. 2nd Ed. O’Reilly Media.
* Dougherty, Dale, and Arnold Robbins. 1997. <em>Sed &amp; Awk</em>. 2nd Ed. O’Reilly Media.
