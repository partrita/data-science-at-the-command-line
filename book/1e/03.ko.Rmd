# 데이터 획득 {#chapter-3-obtaining-data}

이 장에서는 OSEMN 모델의 첫 번째 단계인 데이터 획득을 다룹니다. 결국 데이터가 없으면 수행할 수 있는 데이터 과학이 많지 않습니다. 당면한 데이터 과학 문제를 해결하는 데 필요한 데이터가 이미 어떤 형태로든 어떤 위치에 존재한다고 가정합니다. 우리의 목표는 이 데이터를 컴퓨터(또는 데이터 과학 도구 상자)로 가져와 작업할 수 있는 형태로 만드는 것입니다.

유닉스 철학에 따르면 텍스트는 보편적인 인터페이스입니다. 거의 모든 명령줄 도구는 텍스트를 입력으로 사용하거나 텍스트를 출력으로 생성하거나 둘 다 수행합니다. 이것이 명령줄 도구가 함께 잘 작동할 수 있는 주된 이유입니다. 그러나 보게 되겠지만 텍스트조차도 여러 형태로 나타날 수 있습니다.

데이터는 서버에서 다운로드하거나 데이터베이스를 쿼리하거나 웹 API에 연결하는 등 여러 가지 방법으로 얻을 수 있습니다. 때로는 데이터가 압축된 형태나 Microsoft Excel과 같은 이진 형식으로 제공됩니다. 이 장에서는 `curl` [@curl], `in2csv` [@in2csv], `sql2csv` [@sql2csv], `tar` [@tar]를 포함하여 명령줄에서 이 문제를 해결하는 데 도움이 되는 몇 가지 도구에 대해 설명합니다.

## 개요

이 장에서는 다음을 수행하는 방법을 배웁니다.

- 인터넷에서 데이터 획득
- 데이터베이스 쿼리
- 웹 API에 연결
- 파일 압축 해제
- Microsoft Excel 스프레드시트를 사용 가능한 데이터로 변환

## 로컬 파일을 데이터 과학 도구 상자에 복사

필요한 파일이 이미 컴퓨터에 있는 경우가 일반적입니다. 이 섹션에서는 해당 파일을 데이터 과학 도구 상자의 로컬 또는 원격 버전에 가져오는 방법을 설명합니다.

### 데이터 과학 도구 상자의 로컬 버전

[2장](#chapter-2-getting-started)에서 Vagrant 버전의 데이터 과학 도구 상자가 격리된 가상 환경이라고 언급했습니다. 다행히 한 가지 예외가 있습니다. 파일을 데이터 과학 도구 상자 안팎으로 전송할 수 있습니다. `vagrant up`을 실행한 로컬 디렉터리(*Vagrantfile* 파일이 포함된 디렉터리)는 데이터 과학 도구 상자의 디렉터리에 매핑됩니다. 이 디렉터리는 */vagrant*라고 합니다. 이것은 홈 디렉터리가 아닙니다. 이 디렉터리의 내용을 확인해 보겠습니다.

```{bash, eval=FALSE}
$ ls -1 /vagrant
build
Vagrantfile
```

로컬 컴퓨터에 파일이 있고 일부 명령줄 도구를 적용하려면 해당 디렉터리로 파일을 복사하거나 이동하기만 하면 됩니다. 바탕 화면에 *logs.csv*라는 파일이 있다고 가정해 보겠습니다. Linux 또는 macOS를 실행하는 경우 운영 체제에서 다음 명령을 실행합니다(데이터 과학 도구 상자 내부가 아님).

```{bash, eval=FALSE}
$ cp ~/Desktop/logs.csv .
```

그리고 Windows를 실행하는 경우 명령 프롬프트에서 다음 명령을 실행할 수 있습니다.

```powershell
> cd %UserProfile%\Desktop
> copy logs.csv MyDataScienceToolbox\
```

Windows 탐색기를 사용하여 파일을 디렉터리로 끌어다 놓을 수도 있습니다.

이제 파일은 */vagrant* 디렉터리에 있습니다. *\~/book/ch03/data*와 같이 데이터를 별도의 디렉터리에 보관하는 것이 좋습니다. 따라서 파일을 복사한 후 다음을 실행하여 이동할 수 있습니다.

```{bash, eval=FALSE}
$ mv /vagrant/logs.csv ~/book/ch03/data
$ cd ~/book/ch03
$ cat data/logs.csv
```

### 데이터 과학 도구 상자의 원격 버전

Linux 또는 macOS를 실행하는 경우 *secure copy*를 의미하는 `scp` [@scp]를 사용하여 EC2 인스턴스에 파일을 복사할 수 있습니다. EC2 인스턴스에 로그인하는 데 사용한 것과 동일한 키 페어 파일이 필요합니다.

```{bash, eval=FALSE}
$ scp -i  mykey.pem ~/Desktop/logs.csv \
> ubuntu@ec2-184-73-72-150.compute-1.amazonaws.com:data
```

예제의 호스트 이름 *ec2-184-73-72-150.compute-1.amazonaws.com*을 AWS 콘솔의 EC2 개요 페이지에 표시되는 값으로 바꿉니다.

## 파일 압축 해제

원본 데이터 세트가 매우 크거나 많은 파일 모음인 경우 파일은 (압축된) 아카이브일 수 있습니다. 반복되는 값이 많은 데이터 세트(예: 텍스트 파일의 단어 또는 JSON 파일의 키)는 특히 압축에 적합합니다.

압축 아카이브의 일반적인 파일 확장자는 *.tar.gz*, *.zip*, *.rar*입니다. 이러한 파일의 압축을 풀려면 각각 명령줄 도구 `tar` [@tar], `unzip` [@unzip], `unrar` [@unrar]를 사용합니다. 흔하지는 않지만 다른 도구가 필요한 파일 확장자가 몇 개 더 있습니다. 예를 들어 *logs.tar.gz*라는 파일의 압축을 풀려면 다음을 사용합니다.

```{bash, eval=FALSE}
$ cd ~/book/ch03
$ tar -xzvf data/logs.tar.gz
```

실제로 `tar`는 많은 명령줄 인수로 악명이 높습니다. 이 경우 네 가지 명령줄 인수 `x`, `z`, `v`, `f`는 `tar`가 아카이브에서 파일을 *추출*하고, 압축 해제 알고리즘으로 *gzip*을 사용하고, *자세한 정보*를 표시하고, 파일 *logs.tar.gz*를 사용하도록 지정합니다. 시간이 지나면 이 네 글자를 입력하는 데 익숙해지겠지만 더 편리한 방법이 있습니다.

다양한 명령줄 도구와 해당 옵션을 기억하는 대신 다양한 형식을 압축 해제하는 `unpack` [@unpack]이라는 편리한 스크립트가 있습니다. `unpack`은 압축을 풀려는 파일의 확장자를 보고 적절한 명령줄 도구를 호출합니다.

`unpack` 도구는 데이터 과학 도구 상자의 일부입니다. 부록에서 설치 방법을 확인할 수 있다는 것을 기억하십시오. 예제 \@ref(exm:script-unpack)는 `unpack`의 소스를 보여줍니다. Bash 스크립팅이 이 책의 초점은 아니지만 잠시 시간을 내어 작동 방식을 파악하는 것이 여전히 유용합니다.

```{example script-unpack, name="다양한 파일 형식 압축 해제"}
```
```{bash, eval=FALSE}
#!/usr/bin/env bash
# unpack: 일반적인 파일 형식 추출

# 매개변수가 없으면 사용법 표시
if [[ -z "$@" ]]; then
    echo " ${0##*/} <아카이브> - 일반적인 파일 형식 추출)"
    exit
fi

# 필요한 프로그램
req_progs=(7z unrar unzip)
for p in ${req_progs[@]}; do
    hash "$p" 2>&- || \
    { echo >&2 " 필요한 프로그램 \"$p\"이(가) 설치되지 않았습니다."; exit 1; }
done

# 파일 존재 여부 테스트
if [ ! -f "$@" ]; then
    echo "파일 \"$@\"이(가) 존재하지 않습니다"
    exit
fi

# 확장자를 참조로 사용하여 파일 추출
case "$@" in
    *.7z ) 7z x "$@" ;;
    *.tar.bz2 ) tar xvjf "$@" ;;
    *.bz2 ) bunzip2 "$@" ;;
    *.deb ) ar vx "$@" ;;
    *.tar.gz ) tar xvf "$@" ;;
    *.gz ) gunzip "$@" ;;
    *.tar ) tar xvf "$@" ;;
    *.tbz2 ) tar xvjf "$@" ;;
    *.tar.xz ) tar xvf "$@" ;;
    *.tgz ) tar xvzf "$@" ;;
    *.rar ) unrar x "$@" ;;
    *.zip ) unzip "$@" ;;
    *.Z ) uncompress "$@" ;;
    * ) echo " 지원되지 않는 파일 형식입니다" ;;
esac
```

이제 이 동일한 파일의 압축을 풀려면 다음을 간단히 사용합니다.

```{bash, eval=FALSE}
$ unpack logs.tar.gz
```

## Microsoft Excel 스프레드시트 변환

많은 사람들에게 Microsoft Excel은 작은 데이터 세트로 작업하고 계산을 수행하는 직관적인 방법을 제공합니다. 결과적으로 많은 데이터가 Microsoft Excel 스프레드시트에 포함되어 있습니다. 이러한 스프레드시트는 파일 이름의 확장자에 따라 독점적인 이진 형식(*.xls*) 또는 압축된 XML 파일 모음(*.xlsx*)으로 저장됩니다. 두 경우 모두 대부분의 명령줄 도구에서 데이터를 즉시 사용할 수 없습니다. 이러한 귀중한 데이터 세트가 이러한 방식으로 저장되어 있기 때문에 사용할 수 없다면 안타까울 것입니다.

다행히 Microsoft Excel 스프레드시트를 CSV 파일로 변환할 수 있는 `in2csv` [@in2csv]라는 명령줄 도구가 있습니다. CSV는 쉼표로 구분된 값을 의미합니다. CSV는 공식적인 사양이 없기 때문에 작업하기 까다로울 수 있습니다. [RFC 4180](http://www.ietf.org/rfc/rfc4180.txt)은 다음 세 가지 사항에 따라 CSV 형식을 정의합니다.

1.  각 레코드는 줄 바꿈(CRLF)으로 구분된 별도의 줄에 있습니다. 예를 들면 다음과 같습니다.

        aaa,bbb,ccc CRLF
        zzz,yyy,xxx CRLF

2.  파일의 마지막 레코드에는 끝 줄 바꿈이 있을 수도 있고 없을 수도 있습니다. 예를 들면 다음과 같습니다.

        aaa,bbb,ccc CRLF
        zzz,yyy,xxx

3.  파일의 첫 번째 줄에 일반 레코드 줄과 동일한 형식의 선택적 헤더 줄이 있을 수 있습니다. 이 헤더에는 파일의 필드에 해당하는 이름이 포함되며 파일의 나머지 레코드와 동일한 수의 필드를 포함해야 합니다(헤더 줄의 유무는 이 MIME 유형의 선택적 헤더 매개변수를 통해 표시되어야 함). 예를 들면 다음과 같습니다.

        field_name,field_name,field_name CRLF
        aaa,bbb,ccc CRLF
        zzz,yyy,xxx CRLF

인터넷 영화 데이터베이스(IMDb)의 상위 250개 영화가 포함된 스프레드시트를 사용하여 `in2csv`를 시연해 보겠습니다. 파일 이름은 *imdb-250.xlsx*이며 <http://www.overthinkingit.com/2011/10/11/imdb-top-250-movies-4th-edition/2>에서 얻을 수 있습니다. 데이터를 추출하려면 다음과 같이 `in2csv`를 호출합니다.

```{bash, eval=FALSE}
$ cd book/ch03
$ in2csv data/imdb-250.xlsx > data/imdb-250.csv
```

파일 형식은 이 경우 확장자 *.xlsx*에 의해 자동으로 결정됩니다. 데이터를 `in2csv`로 파이프하는 경우 형식을 명시적으로 지정해야 합니다. 데이터를 살펴보겠습니다.

```{bash, eval=FALSE}
$ in2csv imdb-250.xlsx | head | cut -c1-80
제목,제목 자르기,연도,순위,순위 (내림차순),평점,2010년에서 2011년 신규?,2010년 순위,R
셜록 주니어 (1924),셜록주니어(1924),1924,221,30,8,y,n/a,n/a,
잔 다르크의 수난 (1928),잔다르크의수난(1928),1928,212,39,8,y,n/
그의 연인 프라이데이 (1940),그의연인프라이데이(1940),1940,250,1,8,y,n/a,n/a,
도쿄 이야기 (1953),도쿄이야기(1953),1953,248,3,8,y,n/a,n/a,
리버티 밸런스를 쏜 사나이 (1962),리버티밸런스를쏜사나이(1962),1962,2
페르소나 (1966),페르소나(1966),1966,200,51,8,y,n/a,n/a,
스토커 (1979),스토커(1979),1979,243,8,8,y,n/a,n/a,
화니와 알렉산더 (1982),화니와알렉산더(1982),1982,210,41,8,y,n/a,n/a,
미녀와 야수 (1991),미녀와야수(1991),1991,249,2,8,y,n/a,n/a,
```

보시다시피 CSV는 기본적으로 가독성이 좋지 않습니다. 데이터를 `csvlook` [@csvlook]이라는 도구로 파이프하면 데이터를 표 형식으로 멋지게 지정합니다. 여기서는 `csvcut`을 사용하여 열의 하위 집합을 표시하여 표가 페이지에 맞도록 합니다.

```{bash, eval=FALSE}
$ in2csv data/imdb-250.xlsx | head | csvcut -c 제목,연도,평점 | csvlook
|------------------------------------------+------+---------|
|  제목                                    | 연도 | 평점  |
|------------------------------------------+------+---------|
|  셜록 주니어 (1924)                     | 1924 | 8       |
|  잔 다르크의 수난 (1928)       | 1928 | 8       |
|  그의 연인 프라이데이 (1940)                  | 1940 | 8       |
|  도쿄 이야기 (1953)                      | 1953 | 8       |
|  리버티 밸런스를 쏜 사나이 (1962) | 1962 | 8       |
|  페르소나 (1966)                          | 1966 | 8       |
|  스토커 (1979)                          | 1979 | 8       |
|  화니와 알렉산더 (1982)              | 1982 | 8       |
|  미녀와 야수 (1991)             | 1991 | 8       |
|------------------------------------------+------+---------|
```

스프레드시트에는 여러 워크시트가 포함될 수 있습니다. 기본적으로 `in2csv`는 첫 번째 워크시트를 추출합니다. 다른 워크시트를 추출하려면 워크시트 이름을 `--sheet` 옵션에 전달해야 합니다.

`in2csv`, `csvcut`, `csvlook` 도구는 실제로 CSV 데이터로 작업하기 위한 명령줄 도구 모음인 Csvkit의 일부입니다. Csvkit은 매우 유용한 도구가 많기 때문에 이 책에서 자주 사용됩니다. 데이터 과학 도구 상자를 실행 중인 경우 이미 Csvkit이 설치되어 있습니다. 그렇지 않으면 설치 방법에 대한 부록을 참조하십시오.

```{block2, type="rmdnote"}
`in2csv`의 대안적인 접근 방식은 Microsoft Excel 또는 LibreOffice Calc와 같은 오픈 소스 변형에서 스프레드시트를 열고 수동으로 CSV로 내보내는 것입니다. 이것은 일회성 솔루션으로 작동하지만 여러 파일로 확장하기 어렵고 자동화할 수 없다는 단점이 있습니다. 또한 원격 서버의 명령줄에서 작업하는 경우 이러한 응용 프로그램을 사용할 수 없을 가능성이 있습니다.
```

## 관계형 데이터베이스 쿼리

대부분의 회사는 관계형 데이터베이스에 데이터를 저장합니다. 관계형 데이터베이스의 예로는 MySQL, PostgreSQL, SQLite가 있습니다. 이러한 데이터베이스는 모두 약간 다른 방식으로 인터페이스합니다. 일부는 명령줄 도구나 명령줄 인터페이스를 제공하지만 다른 일부는 그렇지 않습니다. 또한 사용법과 출력에 있어서 일관성이 없습니다.

다행히 Csvkit 제품군의 일부인 `sql2csv`라는 명령줄 도구가 있습니다. Python SQLAlchemy 패키지를 활용하기 때문에 MySQL, Oracle, PostgreSQL, SQLite, Microsoft SQL Server, Sybase를 포함한 다양한 데이터베이스에서 공통 인터페이스를 통해 쿼리를 실행하는 데 하나의 도구만 사용하면 됩니다. `sql2csv`의 출력은 이름에서 알 수 있듯이 CSV 형식입니다.

관계형 데이터베이스에서 `SELECT` 쿼리를 실행하여 데이터를 얻을 수 있습니다. (`sql2csv`는 `INSERT`, `UPDATE`, `DELETE` 쿼리도 지원하지만 이 장의 목적은 아닙니다.) *iris.db*라는 SQLite 데이터베이스에서 특정 데이터 집합을 선택하려면 다음과 같이 `sql2csv`를 호출할 수 있습니다.

```{bash, eval=FALSE}
$ sql2csv --db 'sqlite:///data/iris.db' --query 'SELECT * FROM iris '\
> 'WHERE sepal_length > 7.5'
sepal_length,sepal_width,petal_length,petal_width,species
7.6,3.0,6.6,2.1,Iris-virginica
7.7,3.8,6.7,2.2,Iris-virginica
7.7,2.6,6.9,2.3,Iris-virginica
7.7,2.8,6.7,2.0,Iris-virginica
7.9,3.8,6.4,2.0,Iris-virginica
7.7,3.0,6.1,2.3,Iris-virginica
```

여기서는 `sepal_length`가 7.5보다 큰 모든 행을 선택하고 있습니다. `--db` 옵션은 데이터베이스 URL을 지정하며 일반적인 형식은 `dialect+driver://username:password@host:port/database`입니다.

## 인터넷에서 다운로드

인터넷은 의심할 여지 없이 가장 큰 데이터 리소스입니다. 이 데이터는 다양한 프로토콜을 사용하여 다양한 형태로 제공됩니다. 명령줄 도구 cURL [@curl]은 인터넷에서 데이터를 다운로드하는 데 있어 명령줄의 스위스 군용 칼로 간주될 수 있습니다.

브라우저를 통해 URL(*uniform resource locator*의 약자)에 액세스하면 다운로드되는 데이터를 해석할 수 있습니다. 예를 들어 HTML 파일은 웹사이트로 렌더링되고 MP3 파일은 자동으로 재생될 수 있으며 PDF 파일은 자동으로 다운로드되거나 뷰어에서 열릴 수 있습니다. 그러나 cURL을 사용하여 URL에 액세스하면 데이터는 있는 그대로 다운로드되어 표준 출력으로 인쇄됩니다. 그런 다음 다른 명령줄 도구를 사용하여 이 데이터를 추가로 처리할 수 있습니다.

cURL의 가장 쉬운 호출은 URL을 명령줄 인수로 간단히 지정하는 것입니다. 예를 들어 프로젝트 구텐베르크에서 마크 트웨인의 *허클베리 핀의 모험* 책을 다운로드하려면 다음 명령을 실행할 수 있습니다.

```{bash, eval=FALSE}
$ curl -s http://www.gutenberg.org/files/76/76-0.txt | head -n 10

프로젝트 구텐베르크 전자책 허클베리 핀의 모험, 완역판
마크 트웨인(새뮤얼 클레멘스) 저

이 전자책은 비용 없이 거의 모든 곳에서 누구나 사용할 수 있습니다.
제한 없이 복사, 배포 또는 재사용할 수 있습니다.
이 전자책에 포함된 프로젝트 구텐베르크 라이선스 조건 또는
www.gutenberg.net에서 온라인으로 제공되는 조건에 따라 사용하십시오.
```

기본적으로 cURL은 다운로드 속도와 예상 완료 시간을 보여주는 진행률 표시기를 출력합니다. 출력을 `head`와 같은 다른 명령줄 도구로 직접 파이프하는 경우 *자동*을 의미하는 `-s` 명령줄 인수를 지정하여 진행률 표시기를 비활성화하십시오. 예를 들어 다음 명령의 출력과 비교해 보십시오.

```{bash, eval=FALSE}
$ curl http://www.gutenberg.org/files/76/76-0.txt | head -n 10
  % 전체    % 수신 % Xferd  평균 속도   시간    시간     시간  현재
                                 Dload  Upload   전체   소요   남은 시간  속도

  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--

프로젝트 구텐베르크 전자책 허클베리 핀의 모험, 완역판
마크 트웨인(새뮤얼 클레멘스) 저

이 전자책은 비용 없이 거의 모든 곳에서 누구나 사용할 수 있습니다.
제한 없이 복사, 배포 또는 재사용할 수 있습니다.
이 전자책에 포함된 프로젝트 구텐베르크 라이선스 조건 또는
www.gutenberg.net에서 온라인으로 제공되는 조건에 따라 사용하십시오.
```

진행률 표시기를 비활성화하지 않은 두 번째 명령의 출력에는 원치 않는 텍스트와 오류 메시지까지 포함되어 있습니다. 데이터를 파일에 저장하는 경우 `-s` 옵션을 반드시 지정할 필요는 없습니다.

```{bash, eval=FALSE}
$ curl http://www.gutenberg.org/files/76/76-0.txt > data/finn.txt
```

`-o` 옵션으로 출력 파일을 명시적으로 지정하여 데이터를 저장할 수도 있습니다.

```{bash, eval=FALSE}
$ curl -s http://www.gutenberg.org/files/76/76-0.txt -o data/finn.txt
```

인터넷에서 데이터를 다운로드할 때 URL은 HTTP 또는 HTTPS 프로토콜을 가장 많이 사용합니다. 파일 전송 프로토콜을 의미하는 FTP 서버에서 다운로드하려면 cURL을 정확히 동일한 방식으로 사용합니다. URL이 암호로 보호된 경우 다음과 같이 사용자 이름과 암호를 지정할 수 있습니다.

```{bash, eval=FALSE}
$ curl -u 사용자이름:암호 ftp://호스트/파일
```

지정된 URL이 디렉터리인 경우 `curl`은 해당 디렉터리의 내용을 나열합니다.

*http://bit.ly/* 또는 *http://t.co/*로 시작하는 것과 같은 단축 URL에 액세스하면 브라우저가 자동으로 올바른 위치로 리디렉션합니다. 그러나 `curl`을 사용하면 리디렉션되려면 `-L` 또는 `--location` 옵션을 지정해야 합니다.

```{bash, eval=FALSE}
$ curl -L j.mp/locatbbar
```

`-L` 또는 `--location` 옵션을 지정하지 않으면 다음과 같은 내용이 표시될 수 있습니다.

```{bash, eval=FALSE}
$ curl j.mp/locatbbar
<html>
<head>
<title>bit.ly</title>
</head>
<body>
<a href="http://en.wikipedia.org/wiki/List_of_countries_and_territories_by_bo
rder/area_ratio">여기로 이동</a>
</body>
```

`-I` 또는 `--head` 옵션을 지정하면 `curl`은 응답의 HTTP 헤더만 가져옵니다.

```{bash, eval=FALSE}
$ curl -I j.mp/locatbbar
HTTP/1.1 301 영구 이동됨
서버: nginx
날짜: 2014년 5월 21일 수요일 18:50:28 GMT
콘텐츠 유형: text/html; charset=utf-8
연결: keep-alive
캐시 제어: private; max-age=90
콘텐츠 길이: 175
위치: http://en.wikipedia.org/wiki/List_of_countries_and_territories_by_bo
Mime-Version: 1.0
Set-Cookie: _bit=537cf574-002ba-07d79-2e1cf10a;domain=.j.mp;expires=Mon Nov 17
```

첫 번째 줄은 HTTP 상태 코드를 나타내며 이 경우 301(영구 이동됨)입니다. 이 URL이 리디렉션되는 위치도 볼 수 있습니다. <http://en.wikipedia.org/wiki/List_of_countries_and_territories_by_border/area_ratio>. 헤더를 검사하고 상태 코드를 가져오는 것은 `curl`이 예상한 결과를 제공하지 않는 경우 유용한 디버깅 도구입니다. 다른 일반적인 HTTP 상태 코드에는 404(찾을 수 없음) 및 403(금지됨)이 포함됩니다. 이 페이지에는 모든 HTTP 상태 코드가 나열되어 있습니다. <http://en.wikipedia.org/wiki/List_of_HTTP_status_codes>.

이 섹션을 마치자면 cURL은 인터넷에서 데이터를 다운로드하기 위한 간단한 명령줄 도구입니다. 가장 일반적인 세 가지 명령줄 인수는 진행률 표시기를 표시하지 않는 `-s`, 사용자 이름과 암호를 지정하는 `-u`, 자동으로 리디렉션을 따르는 `-L`입니다. 자세한 내용은 해당 man 페이지를 참조하십시오.

## 웹 API 호출

이전 섹션에서는 인터넷에서 개별 파일을 다운로드하는 방법을 설명했습니다. 인터넷에서 데이터를 가져오는 또 다른 방법은 *애플리케이션 프로그래밍 인터페이스*를 의미하는 웹 API를 사용하는 것입니다. 조직에서 제공하는 API의 수가 점점 더 빠르게 증가하고 있으며 이는 데이터 과학자에게 많은 흥미로운 데이터를 의미합니다.

웹 API는 웹사이트와 같이 멋진 레이아웃으로 표시되도록 만들어지지 않았습니다. 대신 대부분의 웹 API는 JSON 또는 XML과 같은 구조화된 형식으로 데이터를 반환합니다. 구조화된 형식의 데이터를 사용하면 `jq`와 같은 다른 도구에서 데이터를 쉽게 처리할 수 있다는 장점이 있습니다. 예를 들어 <https://randomuser.me>의 API는 다음 JSON 구조로 데이터를 반환합니다.

```{bash, eval=FALSE}
$ curl -s https://randomuser.me/api/1.2/ | jq .
{
  "results": [
    {
      "gender": "male",
      "name": {
        "title": "mr",
        "first": "jeffrey",
        "last": "lawson"
      },
      "location": {
        "street": "838 miller ave",
        "city": "washington",
        "state": "maryland",
        "postcode": 81831,
        "coordinates": {
          "latitude": "81.9488",
          "longitude": "-67.8247"
        },
        "timezone": {
          "offset": "+4:00",
          "description": "아부다비, 무스카트, 바쿠, 트빌리시"
        }
      },
      "email": "jeffrey.lawson@example.com",
      "login": {
        "uuid": "78918f6c-2658-4915-bebf-bfaa61a1624c",
        "username": "silverzebra774",
        "password": "treble",
        "salt": "iAtIKhvB",
        "md5": "4c02abeca4d6ca4dbfc0ddb33dcef29f",
        "sha1": "36e109513abf73df460cead89b78c749abe908fa",
        "sha256": "0155d9e6cabedfc3ad0f21d18b3ca3e738a8f17811dd57dc3b4dd386cd021963"
      },
      "dob": {
        "date": "1996-07-04T02:49:46Z",
        "age": 22
      },
      "registered": {
        "date": "2013-01-13T13:37:21Z",
        "age": 5
      },
      "phone": "(406)-041-2792",
      "cell": "(831)-085-8264",
      "id": {
        "name": "SSN",
        "value": "629-40-9671"
      },
      "picture": {
        "large": "https://randomuser.me/api/portraits/men/62.jpg",
        "medium": "https://randomuser.me/api/portraits/med/men/62.jpg",
        "thumbnail": "https://randomuser.me/api/portraits/thumb/men/62.jpg"
      },
      "nat": "US"
    }
  ],
  "info": {
    "seed": "4bd9f66fd83a6ec7",
    "results": 1,
    "page": 1,
    "version": "1.2"
  }
}
```

데이터는 멋진 방식으로 표시하기 위해 명령줄 도구 `jq`로 파이프됩니다. `jq`에는 [5장](#chapter-5-scrubbing-data)에서 살펴볼 더 많은 가능성이 있습니다.

일부 웹 API는 스트리밍 방식으로 데이터를 반환합니다. 즉, 연결하면 데이터가 영원히 계속 들어옵니다. 잘 알려진 예로는 전 세계에서 전송되는 모든 트윗을 지속적으로 스트리밍하는 트위터 "파이어호스"가 있습니다. 다행히 우리가 사용하는 대부분의 명령줄 도구도 스트리밍 방식으로 작동하므로 이러한 종류의 데이터도 사용할 수 있습니다.

일부 API는 OAuth 프로토콜을 사용하여 로그인해야 합니다. 소위 "OAuth 댄스"를 수행하는 데 도움이 되는 `curlicue` [@curlicue]라는 편리한 명령줄 도구가 있습니다. 이것이 설정되면 `curlicue`는 올바른 헤더로 `curl`을 호출합니다. 먼저 `curlicue-setup`으로 특정 API에 대해 한 번 설정한 다음 `curlicue`를 사용하여 해당 API를 호출할 수 있습니다. 예를 들어 트위터 API와 함께 `curlicue`를 사용하려면 다음을 실행합니다.

```{bash, eval=FALSE}
$ curlicue-setup \
> 'https://api.twitter.com/oauth/request_token' \
> 'https://api.twitter.com/oauth/authorize?oauth_token=$oauth_token' \
> 'https://api.twitter.com/oauth/access_token' \
> credentials
$ curlicue -f credentials \
> 'https://api.twitter.com/1/statuses/home_timeline.xml'
```

더 인기 있는 API의 경우 특수화된 명령줄 도구를 사용할 수 있습니다. 이는 API에 연결하는 편리한 방법을 제공하는 래퍼입니다. 예를 들어 [9장](#chapter-9-modeling-data)에서는 BigML의 예측 API에만 연결하는 명령줄 도구 `bigmler`를 사용합니다.

## 추가 읽을거리

* Molinaro, Anthony. 2005. <em>SQL Cookbook</em>. O’Reilly Media.
* Wikipedia. 2014. “List of Http Status Codes.” <a href="http://en.wikipedia.org/wiki/List_of_HTTP_status_codes" class="uri">http://en.wikipedia.org/wiki/List_of_HTTP_status_codes</a>.
